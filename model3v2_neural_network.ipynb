{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n",
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/dp_tomastik/code')\n",
    "    !bash \"/content/drive/My Drive/dp_tomastik/code/scripts/install_libs.sh\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "import SimpleITK as sitk\n",
    "from torchio import RandomAffine, Compose, ZNormalization\n",
    "\n",
    "import src.dataset.oars_labels_consts as OARS_LABELS\n",
    "from src.consts import DATASET_MAX_BOUNDING_BOX, DESIRE_BOUNDING_BOX_SIZE\n",
    "from src.helpers.threshold_calc_helpers import get_threshold_info_df\n",
    "from src.helpers.show_model_dataset_pred_preview import show_model_dataset_pred_preview\n",
    "from src.dataset.get_cut_lists import get_cut_lists\n",
    "from src.dataset.get_full_res_cut import get_full_res_cut\n",
    "from src.dataset.get_dataset import get_dataset\n",
    "from src.dataset.get_dataset_info import get_dataset_info\n",
    "from src.dataset.preview_dataset import preview_dataset\n",
    "from src.dataset.get_dataset_transform import get_dataset_transform\n",
    "from src.model_and_training.prepare_model import prepare_model\n",
    "from src.model_and_training.train_loop import train_loop\n",
    "from src.model_and_training.show_model_info import show_model_info\n",
    "from src.model_and_training.load_checkpoint_model_info import load_checkpoint_model_info\n",
    "from src.helpers.show_cuda_usage import show_cuda_usage\n",
    "from src.helpers.get_rescaled_pred import get_rescaled_preds\n",
    "from src.dataset.split_dataset import split_dataset, copy_split_dataset\n",
    "from src.helpers.compare_prediction_with_ground_true import compare_prediction_with_ground_true, compare_one_prediction_with_ground_true\n",
    "from src.helpers.get_img_outliers_pixels import get_img_outliers_pixels\n",
    "from src.helpers.get_raw_with_prediction import get_raw_with_prediction\n",
    "from src.model_and_training.getters.get_device import get_device\n",
    "from src.helpers.preview_3d_image import preview_3d_image\n",
    "\n",
    "from src.helpers.registration_helpers import get_registration_transform_np, transform_sitk\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "torch.manual_seed(20)\n",
    "logging.basicConfig(filename='logs/unetv3v2_model.log', level=logging.DEBUG)\n",
    "\n",
    "print('Dataset biggest bounding box wihtout spinal cord', DATASET_MAX_BOUNDING_BOX)\n",
    "print('Cut target size', DESIRE_BOUNDING_BOX_SIZE)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 8x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n",
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "# filter_labels = [OARS_LABELS.EYE_L, OARS_LABELS.EYE_R, OARS_LABELS.LENS_L, OARS_LABELS.LENS_R]\n",
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "dataset = get_dataset(shrink_factor=8, filter_labels=filter_labels)\n",
    "\n",
    "dataset.to_numpy()\n",
    "split_dataset_obj = split_dataset(dataset)\n",
    "\n",
    "get_dataset_info(dataset, split_dataset_obj)\n",
    "train_dataset, valid_dataset, test_dataset = itemgetter('train_dataset', 'valid_dataset', 'test_dataset')(split_dataset_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNetV3v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 120, 219), (136, 120, 219), (136, 120, 219), (136, 120, 219))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_ri = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/RI.mhd'))\n",
    "atlas_brainstem_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/brain_stem_map.mhd'))\n",
    "atlas_left_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/left_parotid_map.mhd'))\n",
    "atlas_right_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/right_parotid_map.mhd'))\n",
    "\n",
    "atlas_ri.shape, atlas_brainstem_map.shape, atlas_left_parotid_map.shape, atlas_right_parotid_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 160, 64, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0 done\n",
      "Index 1 done\n",
      "Index 2 done\n",
      "Index 3 done\n",
      "Index 4 done\n",
      "Index 5 done\n",
      "Index 6 done\n",
      "Index 7 done\n",
      "Index 8 done\n",
      "Index 9 done\n",
      "Index 10 done\n",
      "Index 11 done\n",
      "Index 12 done\n",
      "Index 13 done\n",
      "Index 14 done\n",
      "Index 15 done\n",
      "Index 16 done\n",
      "Index 17 done\n",
      "Index 18 done\n",
      "Index 19 done\n",
      "Index 20 done\n",
      "Index 21 done\n",
      "Index 22 done\n",
      "Index 23 done\n",
      "Index 24 done\n",
      "Index 25 done\n",
      "Index 26 done\n",
      "Index 27 done\n",
      "Index 28 done\n",
      "Index 29 done\n",
      "Index 30 done\n",
      "Index 31 done\n",
      "Index 32 done\n",
      "Index 33 done\n",
      "Index 34 done\n",
      "Index 35 done\n",
      "Index 36 done\n",
      "Index 37 done\n",
      "Index 38 done\n",
      "Index 39 done\n",
      "Index 40 done\n",
      "Index 41 done\n",
      "Index 42 done\n",
      "Index 43 done\n",
      "Index 44 done\n",
      "Index 45 done\n",
      "Index 46 done\n",
      "Index 47 done\n",
      "Index 48 done\n",
      "Index 49 done\n"
     ]
    }
   ],
   "source": [
    "atlas_input = (atlas_ri[60:], atlas_left_parotid_map[60:])\n",
    "merged_list = list()\n",
    "for dataset_index in range(len(dataset)):\n",
    "    dataset_input = dataset.get_raw_item_with_label_filter(dataset_index)\n",
    "\n",
    "    reg_output = get_registration_transform_np(atlas_input, dataset_input, numberOfIterations=50, show=False)\n",
    "    reg_output = reg_output.astype(np.float32)\n",
    "    print(f'Index {dataset_index} done')\n",
    "    merged_output = np.array([dataset.data_list[dataset_index][0], reg_output])\n",
    "    \n",
    "    merged_list.append(merged_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data_list = merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071.0, min -1024.0\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ecb7cead248d49855b4c350294b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=79, max=159), IntSlider(value=0, max=0))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6b1253925f40bfab7facd6b4ac2c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(dataset, preview_index=2, show_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 160, 64, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with dataset MODEL3\n",
      "folder '20210315-200928_3d_unet_model3'\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolas/fiit-dp-thesis-code/src/model_and_training/unet_architecture_v3v2.py:301: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  img_np = layer_output.data[0].detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Model number of params: 1221609, trainable 1221609\n",
      "\n",
      "\n",
      "\n",
      "Running training loop\n",
      "DEBUG: Writing to tensorboard before epoch True, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  0, step 0\n",
      "Batch train [1] loss 0.99567, dsc 0.00433\n",
      "Batch train [2] loss 0.99474, dsc 0.00526\n",
      "Batch train [3] loss 0.99429, dsc 0.00571\n",
      "Batch train [4] loss 0.99586, dsc 0.00414\n",
      "Batch train [5] loss 0.99468, dsc 0.00532\n",
      "Batch train [6] loss 0.99458, dsc 0.00542\n",
      "Batch train [7] loss 0.99465, dsc 0.00535\n",
      "Batch train [8] loss 0.99417, dsc 0.00583\n",
      "Batch train [9] loss 0.99474, dsc 0.00526\n",
      "Batch train [10] loss 0.99331, dsc 0.00669\n",
      "Batch train [11] loss 0.99309, dsc 0.00691\n",
      "Batch train [12] loss 0.99470, dsc 0.00530\n",
      "Batch train [13] loss 0.99462, dsc 0.00538\n",
      "Batch train [14] loss 0.99503, dsc 0.00497\n",
      "Batch train [15] loss 0.99455, dsc 0.00545\n",
      "Batch train [16] loss 0.99576, dsc 0.00424\n",
      "Batch train [17] loss 0.99440, dsc 0.00560\n",
      "Batch train [18] loss 0.99347, dsc 0.00653\n",
      "Batch train [19] loss 0.99481, dsc 0.00519\n",
      "Batch train [20] loss 0.99246, dsc 0.00754\n",
      "Epoch [1] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Batch eval [1] loss 0.99317, dsc 0.00683\n",
      "Batch eval [2] loss 0.99439, dsc 0.00561\n",
      "Batch eval [3] loss 0.99371, dsc 0.00629\n",
      "Batch eval [4] loss 0.99546, dsc 0.00454\n",
      "Batch eval [5] loss 0.99348, dsc 0.00652\n",
      "Epoch [1] valid done\n",
      "Epoch [1] T 30.02s, deltaT 30.02s, loss: train 0.99448, valid 0.99404, dsc: train 0.00552, valid 0.00596\n",
      "DEBUG: Writing to tensorboard before epoch True, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  1, step 0\n",
      "Batch train [1] loss 0.99401, dsc 0.00599\n",
      "Batch train [2] loss 0.99344, dsc 0.00656\n",
      "Batch train [3] loss 0.99564, dsc 0.00436\n",
      "Batch train [4] loss 0.99316, dsc 0.00684\n",
      "Batch train [5] loss 0.99319, dsc 0.00681\n",
      "Batch train [6] loss 0.99492, dsc 0.00508\n",
      "Batch train [7] loss 0.99405, dsc 0.00595\n",
      "Batch train [8] loss 0.99479, dsc 0.00521\n",
      "Batch train [9] loss 0.99341, dsc 0.00659\n",
      "Batch train [10] loss 0.99397, dsc 0.00603\n",
      "Batch train [11] loss 0.99383, dsc 0.00617\n",
      "Batch train [12] loss 0.99487, dsc 0.00513\n",
      "Batch train [13] loss 0.99431, dsc 0.00569\n",
      "Batch train [14] loss 0.99465, dsc 0.00535\n",
      "Batch train [15] loss 0.99290, dsc 0.00710\n",
      "Batch train [16] loss 0.99283, dsc 0.00717\n",
      "Batch train [17] loss 0.99296, dsc 0.00704\n",
      "Batch train [18] loss 0.99456, dsc 0.00544\n",
      "Batch train [19] loss 0.99442, dsc 0.00558\n",
      "Batch train [20] loss 0.99443, dsc 0.00557\n",
      "Epoch [2] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  1, step 0\n",
      "Batch eval [1] loss 0.99246, dsc 0.00754\n",
      "Batch eval [2] loss 0.99373, dsc 0.00627\n",
      "Batch eval [3] loss 0.99308, dsc 0.00692\n",
      "Batch eval [4] loss 0.99489, dsc 0.00511\n",
      "Batch eval [5] loss 0.99276, dsc 0.00724\n",
      "Epoch [2] valid done\n",
      "Epoch [2] T 60.65s, deltaT 30.63s, loss: train 0.99402, valid 0.99339, dsc: train 0.00598, valid 0.00661\n",
      "DEBUG: Writing to tensorboard before epoch True, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  2, step 0\n",
      "Batch train [1] loss 0.99415, dsc 0.00585\n",
      "Batch train [2] loss 0.99283, dsc 0.00717\n",
      "Batch train [3] loss 0.99473, dsc 0.00527\n",
      "Batch train [4] loss 0.99243, dsc 0.00757\n",
      "Batch train [5] loss 0.99286, dsc 0.00714\n",
      "Batch train [6] loss 0.99335, dsc 0.00665\n",
      "Batch train [7] loss 0.99170, dsc 0.00830\n",
      "Batch train [8] loss 0.99323, dsc 0.00677\n",
      "Batch train [9] loss 0.99181, dsc 0.00819\n",
      "Batch train [10] loss 0.99269, dsc 0.00731\n",
      "Batch train [11] loss 0.99467, dsc 0.00533\n",
      "Batch train [12] loss 0.99430, dsc 0.00570\n",
      "Batch train [13] loss 0.99340, dsc 0.00660\n",
      "Batch train [14] loss 0.99396, dsc 0.00604\n",
      "Batch train [15] loss 0.99405, dsc 0.00595\n",
      "Batch train [16] loss 0.99463, dsc 0.00537\n",
      "Batch train [17] loss 0.99378, dsc 0.00622\n",
      "Batch train [18] loss 0.99279, dsc 0.00721\n",
      "Batch train [19] loss 0.99433, dsc 0.00567\n",
      "Batch train [20] loss 0.99412, dsc 0.00588\n",
      "Epoch [3] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  2, step 0\n",
      "Batch eval [1] loss 0.99133, dsc 0.00867\n",
      "Batch eval [2] loss 0.99282, dsc 0.00718\n",
      "Batch eval [3] loss 0.99203, dsc 0.00797\n",
      "Batch eval [4] loss 0.99410, dsc 0.00590\n",
      "Batch eval [5] loss 0.99167, dsc 0.00833\n",
      "Epoch [3] valid done\n",
      "Epoch [3] T 91.03s, deltaT 30.37s, loss: train 0.99349, valid 0.99239, dsc: train 0.00651, valid 0.00761\n",
      "DEBUG: Writing to tensorboard before epoch True, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  3, step 0\n",
      "Batch train [1] loss 0.99399, dsc 0.00601\n",
      "Batch train [2] loss 0.99349, dsc 0.00651\n",
      "Batch train [3] loss 0.99280, dsc 0.00720\n",
      "Batch train [4] loss 0.99164, dsc 0.00836\n",
      "Batch train [5] loss 0.99486, dsc 0.00514\n",
      "Batch train [6] loss 0.99282, dsc 0.00718\n",
      "Batch train [7] loss 0.99380, dsc 0.00620\n",
      "Batch train [8] loss 0.99206, dsc 0.00794\n",
      "Batch train [9] loss 0.99445, dsc 0.00555\n",
      "Batch train [10] loss 0.99274, dsc 0.00726\n",
      "Batch train [11] loss 0.99167, dsc 0.00833\n",
      "Batch train [12] loss 0.99288, dsc 0.00712\n",
      "Batch train [13] loss 0.99416, dsc 0.00584\n",
      "Batch train [14] loss 0.99387, dsc 0.00613\n",
      "Batch train [15] loss 0.99252, dsc 0.00748\n",
      "Batch train [16] loss 0.99188, dsc 0.00812\n",
      "Batch train [17] loss 0.99322, dsc 0.00678\n",
      "Batch train [18] loss 0.99318, dsc 0.00682\n",
      "Batch train [19] loss 0.99221, dsc 0.00779\n",
      "Batch train [20] loss 0.99222, dsc 0.00778\n",
      "Epoch [4] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  3, step 0\n",
      "Batch eval [1] loss 0.99075, dsc 0.00925\n",
      "Batch eval [2] loss 0.99233, dsc 0.00767\n",
      "Batch eval [3] loss 0.99147, dsc 0.00853\n",
      "Batch eval [4] loss 0.99370, dsc 0.00630\n",
      "Batch eval [5] loss 0.99108, dsc 0.00892\n",
      "Epoch [4] valid done\n",
      "Epoch [4] T 120.97s, deltaT 29.94s, loss: train 0.99302, valid 0.99187, dsc: train 0.00698, valid 0.00813\n",
      "DEBUG: Writing to tensorboard before epoch True, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  4, step 0\n",
      "Batch train [1] loss 0.99252, dsc 0.00748\n",
      "Batch train [2] loss 0.99402, dsc 0.00598\n",
      "Batch train [3] loss 0.99172, dsc 0.00828\n",
      "Batch train [4] loss 0.99352, dsc 0.00648\n",
      "Batch train [5] loss 0.99325, dsc 0.00675\n",
      "Batch train [6] loss 0.99266, dsc 0.00734\n",
      "Batch train [7] loss 0.99388, dsc 0.00612\n",
      "Batch train [8] loss 0.99265, dsc 0.00735\n",
      "Batch train [9] loss 0.99299, dsc 0.00701\n",
      "Batch train [10] loss 0.99083, dsc 0.00917\n",
      "Batch train [11] loss 0.99291, dsc 0.00709\n",
      "Batch train [12] loss 0.99389, dsc 0.00611\n",
      "Batch train [13] loss 0.99277, dsc 0.00723\n",
      "Batch train [14] loss 0.99193, dsc 0.00807\n",
      "Batch train [15] loss 0.99147, dsc 0.00853\n",
      "Batch train [16] loss 0.99101, dsc 0.00899\n",
      "Batch train [17] loss 0.99244, dsc 0.00756\n",
      "Batch train [18] loss 0.99306, dsc 0.00694\n",
      "Batch train [19] loss 0.99171, dsc 0.00829\n",
      "Batch train [20] loss 0.99394, dsc 0.00606\n",
      "Epoch [5] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  4, step 0\n",
      "Batch eval [1] loss 0.99033, dsc 0.00967\n",
      "Batch eval [2] loss 0.99200, dsc 0.00800\n",
      "Batch eval [3] loss 0.99112, dsc 0.00888\n",
      "Batch eval [4] loss 0.99342, dsc 0.00658\n",
      "Batch eval [5] loss 0.99073, dsc 0.00927\n",
      "Epoch [5] valid done\n",
      "Epoch [5] T 150.75s, deltaT 29.78s, loss: train 0.99266, valid 0.99152, dsc: train 0.00734, valid 0.00848\n",
      "DEBUG: Writing to tensorboard before epoch True, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  5, step 0\n",
      "Batch train [1] loss 0.99250, dsc 0.00750\n",
      "Batch train [2] loss 0.99199, dsc 0.00801\n",
      "Batch train [3] loss 0.99224, dsc 0.00776\n",
      "Batch train [4] loss 0.99345, dsc 0.00655\n",
      "Batch train [5] loss 0.98960, dsc 0.01040\n",
      "Batch train [6] loss 0.99256, dsc 0.00744\n",
      "Batch train [7] loss 0.99300, dsc 0.00700\n",
      "Batch train [8] loss 0.99291, dsc 0.00709\n",
      "Batch train [9] loss 0.99433, dsc 0.00567\n",
      "Batch train [10] loss 0.99174, dsc 0.00826\n",
      "Batch train [11] loss 0.99072, dsc 0.00928\n",
      "Batch train [12] loss 0.99134, dsc 0.00866\n",
      "Batch train [13] loss 0.99273, dsc 0.00727\n",
      "Batch train [14] loss 0.99367, dsc 0.00633\n",
      "Batch train [15] loss 0.99332, dsc 0.00668\n",
      "Batch train [16] loss 0.99283, dsc 0.00717\n",
      "Batch train [17] loss 0.99141, dsc 0.00859\n",
      "Batch train [18] loss 0.99332, dsc 0.00668\n",
      "Batch train [19] loss 0.99164, dsc 0.00836\n",
      "Batch train [20] loss 0.99299, dsc 0.00701\n",
      "Epoch [6] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  5, step 0\n",
      "Batch eval [1] loss 0.99012, dsc 0.00988\n",
      "Batch eval [2] loss 0.99180, dsc 0.00820\n",
      "Batch eval [3] loss 0.99088, dsc 0.00912\n",
      "Batch eval [4] loss 0.99327, dsc 0.00673\n",
      "Batch eval [5] loss 0.99046, dsc 0.00954\n",
      "Epoch [6] valid done\n",
      "Epoch [6] T 180.60s, deltaT 29.85s, loss: train 0.99241, valid 0.99130, dsc: train 0.00759, valid 0.00870\n",
      "DEBUG: Writing to tensorboard before epoch True, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  6, step 0\n",
      "Batch train [1] loss 0.99307, dsc 0.00693\n",
      "Batch train [2] loss 0.98996, dsc 0.01004\n",
      "Batch train [3] loss 0.99141, dsc 0.00859\n",
      "Batch train [4] loss 0.99217, dsc 0.00783\n",
      "Batch train [5] loss 0.99346, dsc 0.00654\n",
      "Batch train [6] loss 0.99094, dsc 0.00906\n",
      "Batch train [7] loss 0.99188, dsc 0.00812\n",
      "Batch train [8] loss 0.99252, dsc 0.00748\n",
      "Batch train [9] loss 0.99197, dsc 0.00803\n",
      "Batch train [10] loss 0.99107, dsc 0.00893\n",
      "Batch train [11] loss 0.99269, dsc 0.00731\n",
      "Batch train [12] loss 0.99241, dsc 0.00759\n",
      "Batch train [13] loss 0.99392, dsc 0.00608\n",
      "Batch train [14] loss 0.99124, dsc 0.00876\n",
      "Batch train [15] loss 0.99382, dsc 0.00618\n",
      "Batch train [16] loss 0.99240, dsc 0.00760\n",
      "Batch train [17] loss 0.99265, dsc 0.00735\n",
      "Batch train [18] loss 0.99261, dsc 0.00739\n",
      "Batch train [19] loss 0.99216, dsc 0.00784\n",
      "Batch train [20] loss 0.99190, dsc 0.00810\n",
      "Epoch [7] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  6, step 0\n",
      "Batch eval [1] loss 0.98993, dsc 0.01007\n",
      "Batch eval [2] loss 0.99166, dsc 0.00834\n",
      "Batch eval [3] loss 0.99075, dsc 0.00925\n",
      "Batch eval [4] loss 0.99314, dsc 0.00686\n",
      "Batch eval [5] loss 0.99034, dsc 0.00966\n",
      "Epoch [7] valid done\n",
      "Epoch [7] T 211.06s, deltaT 30.45s, loss: train 0.99221, valid 0.99117, dsc: train 0.00779, valid 0.00883\n",
      "DEBUG: Writing to tensorboard before epoch True, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  7, step 0\n",
      "Batch train [1] loss 0.99270, dsc 0.00730\n",
      "Batch train [2] loss 0.99236, dsc 0.00764\n",
      "Batch train [3] loss 0.99394, dsc 0.00606\n",
      "Batch train [4] loss 0.99258, dsc 0.00742\n",
      "Batch train [5] loss 0.99211, dsc 0.00789\n",
      "Batch train [6] loss 0.99204, dsc 0.00796\n",
      "Batch train [7] loss 0.99389, dsc 0.00611\n",
      "Batch train [8] loss 0.99117, dsc 0.00883\n",
      "Batch train [9] loss 0.99176, dsc 0.00824\n",
      "Batch train [10] loss 0.99189, dsc 0.00811\n",
      "Batch train [11] loss 0.99082, dsc 0.00918\n",
      "Batch train [12] loss 0.98986, dsc 0.01014\n",
      "Batch train [13] loss 0.99193, dsc 0.00807\n",
      "Batch train [14] loss 0.99085, dsc 0.00915\n",
      "Batch train [15] loss 0.99339, dsc 0.00661\n",
      "Batch train [16] loss 0.99179, dsc 0.00821\n",
      "Batch train [17] loss 0.99123, dsc 0.00877\n",
      "Batch train [18] loss 0.99174, dsc 0.00826\n",
      "Batch train [19] loss 0.99268, dsc 0.00732\n",
      "Batch train [20] loss 0.99196, dsc 0.00804\n",
      "Epoch [8] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  7, step 0\n",
      "Batch eval [1] loss 0.98979, dsc 0.01021\n",
      "Batch eval [2] loss 0.99152, dsc 0.00848\n",
      "Batch eval [3] loss 0.99061, dsc 0.00939\n",
      "Batch eval [4] loss 0.99304, dsc 0.00696\n",
      "Batch eval [5] loss 0.99020, dsc 0.00980\n",
      "Epoch [8] valid done\n",
      "Epoch [8] T 241.51s, deltaT 30.45s, loss: train 0.99203, valid 0.99103, dsc: train 0.00797, valid 0.00897\n",
      "DEBUG: Writing to tensorboard before epoch True, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  8, step 0\n",
      "Batch train [1] loss 0.99284, dsc 0.00716\n",
      "Batch train [2] loss 0.99087, dsc 0.00913\n",
      "Batch train [3] loss 0.98945, dsc 0.01055\n",
      "Batch train [4] loss 0.99343, dsc 0.00657\n",
      "Batch train [5] loss 0.99222, dsc 0.00778\n",
      "Batch train [6] loss 0.99226, dsc 0.00774\n",
      "Batch train [7] loss 0.99242, dsc 0.00758\n",
      "Batch train [8] loss 0.99101, dsc 0.00899\n",
      "Batch train [9] loss 0.99034, dsc 0.00966\n",
      "Batch train [10] loss 0.99256, dsc 0.00744\n",
      "Batch train [11] loss 0.99213, dsc 0.00787\n",
      "Batch train [12] loss 0.99188, dsc 0.00812\n",
      "Batch train [13] loss 0.99099, dsc 0.00901\n",
      "Batch train [14] loss 0.99171, dsc 0.00829\n",
      "Batch train [15] loss 0.99290, dsc 0.00710\n",
      "Batch train [16] loss 0.99195, dsc 0.00805\n",
      "Batch train [17] loss 0.99281, dsc 0.00719\n",
      "Batch train [18] loss 0.99249, dsc 0.00751\n",
      "Batch train [19] loss 0.99156, dsc 0.00844\n",
      "Batch train [20] loss 0.99181, dsc 0.00819\n",
      "Epoch [9] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  8, step 0\n",
      "Batch eval [1] loss 0.98959, dsc 0.01041\n",
      "Batch eval [2] loss 0.99138, dsc 0.00862\n",
      "Batch eval [3] loss 0.99045, dsc 0.00955\n",
      "Batch eval [4] loss 0.99294, dsc 0.00706\n",
      "Batch eval [5] loss 0.99005, dsc 0.00995\n",
      "Epoch [9] valid done\n",
      "Epoch [9] T 271.90s, deltaT 30.39s, loss: train 0.99188, valid 0.99088, dsc: train 0.00812, valid 0.00912\n",
      "DEBUG: Writing to tensorboard before epoch True, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  9, step 0\n",
      "Batch train [1] loss 0.99272, dsc 0.00728\n",
      "Batch train [2] loss 0.99034, dsc 0.00966\n",
      "Batch train [3] loss 0.99193, dsc 0.00807\n",
      "Batch train [4] loss 0.99177, dsc 0.00823\n",
      "Batch train [5] loss 0.99128, dsc 0.00872\n",
      "Batch train [6] loss 0.99077, dsc 0.00923\n",
      "Batch train [7] loss 0.99294, dsc 0.00706\n",
      "Batch train [8] loss 0.99168, dsc 0.00832\n",
      "Batch train [9] loss 0.99000, dsc 0.01000\n",
      "Batch train [10] loss 0.99187, dsc 0.00813\n",
      "Batch train [11] loss 0.99318, dsc 0.00682\n",
      "Batch train [12] loss 0.99172, dsc 0.00828\n",
      "Batch train [13] loss 0.99274, dsc 0.00726\n",
      "Batch train [14] loss 0.99210, dsc 0.00790\n",
      "Batch train [15] loss 0.99285, dsc 0.00715\n",
      "Batch train [16] loss 0.99007, dsc 0.00993\n",
      "Batch train [17] loss 0.99275, dsc 0.00725\n",
      "Batch train [18] loss 0.99064, dsc 0.00936\n",
      "Batch train [19] loss 0.99177, dsc 0.00823\n",
      "Batch train [20] loss 0.99141, dsc 0.00859\n",
      "Epoch [10] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  9, step 0\n",
      "Batch eval [1] loss 0.98944, dsc 0.01056\n",
      "Batch eval [2] loss 0.99128, dsc 0.00872\n",
      "Batch eval [3] loss 0.99030, dsc 0.00970\n",
      "Batch eval [4] loss 0.99286, dsc 0.00714\n",
      "Batch eval [5] loss 0.98987, dsc 0.01013\n",
      "Epoch [10] valid done\n",
      "Epoch [10] T 302.22s, deltaT 30.32s, loss: train 0.99173, valid 0.99075, dsc: train 0.00827, valid 0.00925\n",
      "DEBUG: Writing to tensorboard before epoch True, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  10, step 0\n",
      "Batch train [1] loss 0.99179, dsc 0.00821\n",
      "Batch train [2] loss 0.99038, dsc 0.00962\n",
      "Batch train [3] loss 0.99168, dsc 0.00832\n",
      "Batch train [4] loss 0.99315, dsc 0.00685\n",
      "Batch train [5] loss 0.99190, dsc 0.00810\n",
      "Batch train [6] loss 0.99281, dsc 0.00719\n",
      "Batch train [7] loss 0.99118, dsc 0.00882\n",
      "Batch train [8] loss 0.98994, dsc 0.01006\n",
      "Batch train [9] loss 0.99292, dsc 0.00708\n",
      "Batch train [10] loss 0.99317, dsc 0.00683\n",
      "Batch train [11] loss 0.98885, dsc 0.01115\n",
      "Batch train [12] loss 0.99066, dsc 0.00934\n",
      "Batch train [13] loss 0.99108, dsc 0.00892\n",
      "Batch train [14] loss 0.99244, dsc 0.00756\n",
      "Batch train [15] loss 0.99116, dsc 0.00884\n",
      "Batch train [16] loss 0.99395, dsc 0.00605\n",
      "Batch train [17] loss 0.99028, dsc 0.00972\n",
      "Batch train [18] loss 0.99060, dsc 0.00940\n",
      "Batch train [19] loss 0.99174, dsc 0.00826\n",
      "Batch train [20] loss 0.99177, dsc 0.00823\n",
      "Epoch [11] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  10, step 0\n",
      "Batch eval [1] loss 0.98933, dsc 0.01067\n",
      "Batch eval [2] loss 0.99118, dsc 0.00882\n",
      "Batch eval [3] loss 0.99021, dsc 0.00979\n",
      "Batch eval [4] loss 0.99276, dsc 0.00724\n",
      "Batch eval [5] loss 0.98977, dsc 0.01023\n",
      "Epoch [11] valid done\n",
      "Epoch [11] T 332.77s, deltaT 30.54s, loss: train 0.99157, valid 0.99065, dsc: train 0.00843, valid 0.00935\n",
      "DEBUG: Writing to tensorboard before epoch True, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  11, step 0\n",
      "Batch train [1] loss 0.98886, dsc 0.01114\n",
      "Batch train [2] loss 0.99159, dsc 0.00841\n",
      "Batch train [3] loss 0.99275, dsc 0.00725\n",
      "Batch train [4] loss 0.99155, dsc 0.00845\n",
      "Batch train [5] loss 0.99209, dsc 0.00791\n",
      "Batch train [6] loss 0.99165, dsc 0.00835\n",
      "Batch train [7] loss 0.99222, dsc 0.00778\n",
      "Batch train [8] loss 0.99048, dsc 0.00952\n",
      "Batch train [9] loss 0.99103, dsc 0.00897\n",
      "Batch train [10] loss 0.99299, dsc 0.00701\n",
      "Batch train [11] loss 0.99197, dsc 0.00803\n",
      "Batch train [12] loss 0.99305, dsc 0.00695\n",
      "Batch train [13] loss 0.99002, dsc 0.00998\n",
      "Batch train [14] loss 0.99311, dsc 0.00689\n",
      "Batch train [15] loss 0.99037, dsc 0.00963\n",
      "Batch train [16] loss 0.99129, dsc 0.00871\n",
      "Batch train [17] loss 0.98939, dsc 0.01061\n",
      "Batch train [18] loss 0.98944, dsc 0.01056\n",
      "Batch train [19] loss 0.99167, dsc 0.00833\n",
      "Batch train [20] loss 0.99222, dsc 0.00778\n",
      "Epoch [12] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  11, step 0\n",
      "Batch eval [1] loss 0.98916, dsc 0.01084\n",
      "Batch eval [2] loss 0.99103, dsc 0.00897\n",
      "Batch eval [3] loss 0.99008, dsc 0.00992\n",
      "Batch eval [4] loss 0.99264, dsc 0.00736\n",
      "Batch eval [5] loss 0.98965, dsc 0.01035\n",
      "Epoch [12] valid done\n",
      "Epoch [12] T 363.00s, deltaT 30.23s, loss: train 0.99139, valid 0.99051, dsc: train 0.00861, valid 0.00949\n",
      "DEBUG: Writing to tensorboard before epoch True, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  12, step 0\n",
      "Batch train [1] loss 0.98961, dsc 0.01039\n",
      "Batch train [2] loss 0.99202, dsc 0.00798\n",
      "Batch train [3] loss 0.99199, dsc 0.00801\n",
      "Batch train [4] loss 0.99094, dsc 0.00906\n",
      "Batch train [5] loss 0.99315, dsc 0.00685\n",
      "Batch train [6] loss 0.99176, dsc 0.00824\n",
      "Batch train [7] loss 0.99273, dsc 0.00727\n",
      "Batch train [8] loss 0.98971, dsc 0.01029\n",
      "Batch train [9] loss 0.99069, dsc 0.00931\n",
      "Batch train [10] loss 0.99154, dsc 0.00846\n",
      "Batch train [11] loss 0.99203, dsc 0.00797\n",
      "Batch train [12] loss 0.99074, dsc 0.00926\n",
      "Batch train [13] loss 0.99055, dsc 0.00945\n",
      "Batch train [14] loss 0.99014, dsc 0.00986\n",
      "Batch train [15] loss 0.99056, dsc 0.00944\n",
      "Batch train [16] loss 0.98966, dsc 0.01034\n",
      "Batch train [17] loss 0.99141, dsc 0.00859\n",
      "Batch train [18] loss 0.99091, dsc 0.00909\n",
      "Batch train [19] loss 0.99309, dsc 0.00691\n",
      "Batch train [20] loss 0.99076, dsc 0.00924\n",
      "Epoch [13] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  12, step 0\n",
      "Batch eval [1] loss 0.98891, dsc 0.01109\n",
      "Batch eval [2] loss 0.99083, dsc 0.00917\n",
      "Batch eval [3] loss 0.98984, dsc 0.01016\n",
      "Batch eval [4] loss 0.99250, dsc 0.00750\n",
      "Batch eval [5] loss 0.98943, dsc 0.01057\n",
      "Epoch [13] valid done\n",
      "Epoch [13] T 393.34s, deltaT 30.34s, loss: train 0.99120, valid 0.99030, dsc: train 0.00880, valid 0.00970\n",
      "DEBUG: Writing to tensorboard before epoch True, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  13, step 0\n",
      "Batch train [1] loss 0.98985, dsc 0.01015\n",
      "Batch train [2] loss 0.98936, dsc 0.01064\n",
      "Batch train [3] loss 0.99115, dsc 0.00885\n",
      "Batch train [4] loss 0.98950, dsc 0.01050\n",
      "Batch train [5] loss 0.99151, dsc 0.00849\n",
      "Batch train [6] loss 0.99410, dsc 0.00590\n",
      "Batch train [7] loss 0.99174, dsc 0.00826\n",
      "Batch train [8] loss 0.99129, dsc 0.00871\n",
      "Batch train [9] loss 0.99112, dsc 0.00888\n",
      "Batch train [10] loss 0.99104, dsc 0.00896\n",
      "Batch train [11] loss 0.99183, dsc 0.00817\n",
      "Batch train [12] loss 0.99073, dsc 0.00927\n",
      "Batch train [13] loss 0.99244, dsc 0.00756\n",
      "Batch train [14] loss 0.98892, dsc 0.01108\n",
      "Batch train [15] loss 0.98989, dsc 0.01011\n",
      "Batch train [16] loss 0.99089, dsc 0.00911\n",
      "Batch train [17] loss 0.99208, dsc 0.00792\n",
      "Batch train [18] loss 0.98892, dsc 0.01108\n",
      "Batch train [19] loss 0.99125, dsc 0.00875\n",
      "Batch train [20] loss 0.99237, dsc 0.00763\n",
      "Epoch [14] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  13, step 0\n",
      "Batch eval [1] loss 0.98871, dsc 0.01129\n",
      "Batch eval [2] loss 0.99069, dsc 0.00931\n",
      "Batch eval [3] loss 0.98960, dsc 0.01040\n",
      "Batch eval [4] loss 0.99240, dsc 0.00760\n",
      "Batch eval [5] loss 0.98919, dsc 0.01081\n",
      "Epoch [14] valid done\n",
      "Epoch [14] T 423.64s, deltaT 30.29s, loss: train 0.99100, valid 0.99012, dsc: train 0.00900, valid 0.00988\n",
      "DEBUG: Writing to tensorboard before epoch True, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  14, step 0\n",
      "Batch train [1] loss 0.98957, dsc 0.01043\n",
      "Batch train [2] loss 0.99250, dsc 0.00750\n",
      "Batch train [3] loss 0.99216, dsc 0.00784\n",
      "Batch train [4] loss 0.99173, dsc 0.00827\n",
      "Batch train [5] loss 0.99105, dsc 0.00895\n",
      "Batch train [6] loss 0.99030, dsc 0.00970\n",
      "Batch train [7] loss 0.99109, dsc 0.00891\n",
      "Batch train [8] loss 0.99168, dsc 0.00832\n",
      "Batch train [9] loss 0.98796, dsc 0.01204\n",
      "Batch train [10] loss 0.98858, dsc 0.01142\n",
      "Batch train [11] loss 0.99243, dsc 0.00757\n",
      "Batch train [12] loss 0.99187, dsc 0.00813\n",
      "Batch train [13] loss 0.99194, dsc 0.00806\n",
      "Batch train [14] loss 0.99023, dsc 0.00977\n",
      "Batch train [15] loss 0.99065, dsc 0.00935\n",
      "Batch train [16] loss 0.98869, dsc 0.01131\n",
      "Batch train [17] loss 0.99262, dsc 0.00738\n",
      "Batch train [18] loss 0.98954, dsc 0.01046\n",
      "Batch train [19] loss 0.99105, dsc 0.00895\n",
      "Batch train [20] loss 0.99017, dsc 0.00983\n",
      "Epoch [15] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  14, step 0\n",
      "Batch eval [1] loss 0.98852, dsc 0.01148\n",
      "Batch eval [2] loss 0.99048, dsc 0.00952\n",
      "Batch eval [3] loss 0.98951, dsc 0.01049\n",
      "Batch eval [4] loss 0.99227, dsc 0.00773\n",
      "Batch eval [5] loss 0.98899, dsc 0.01101\n",
      "Epoch [15] valid done\n",
      "Epoch [15] T 454.01s, deltaT 30.37s, loss: train 0.99079, valid 0.98995, dsc: train 0.00921, valid 0.01005\n",
      "DEBUG: Writing to tensorboard before epoch True, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  15, step 0\n",
      "Batch train [1] loss 0.98935, dsc 0.01065\n",
      "Batch train [2] loss 0.99289, dsc 0.00711\n",
      "Batch train [3] loss 0.99157, dsc 0.00843\n",
      "Batch train [4] loss 0.99116, dsc 0.00884\n",
      "Batch train [5] loss 0.98937, dsc 0.01063\n",
      "Batch train [6] loss 0.98976, dsc 0.01024\n",
      "Batch train [7] loss 0.99229, dsc 0.00771\n",
      "Batch train [8] loss 0.99213, dsc 0.00787\n",
      "Batch train [9] loss 0.99231, dsc 0.00769\n",
      "Batch train [10] loss 0.99112, dsc 0.00888\n",
      "Batch train [11] loss 0.98785, dsc 0.01215\n",
      "Batch train [12] loss 0.99267, dsc 0.00733\n",
      "Batch train [13] loss 0.99055, dsc 0.00945\n",
      "Batch train [14] loss 0.99043, dsc 0.00957\n",
      "Batch train [15] loss 0.98891, dsc 0.01109\n",
      "Batch train [16] loss 0.98838, dsc 0.01162\n",
      "Batch train [17] loss 0.99055, dsc 0.00945\n",
      "Batch train [18] loss 0.99096, dsc 0.00904\n",
      "Batch train [19] loss 0.99141, dsc 0.00859\n",
      "Batch train [20] loss 0.98868, dsc 0.01132\n",
      "Epoch [16] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  15, step 0\n",
      "Batch eval [1] loss 0.98841, dsc 0.01159\n",
      "Batch eval [2] loss 0.99040, dsc 0.00960\n",
      "Batch eval [3] loss 0.98943, dsc 0.01057\n",
      "Batch eval [4] loss 0.99215, dsc 0.00785\n",
      "Batch eval [5] loss 0.98893, dsc 0.01107\n",
      "Epoch [16] valid done\n",
      "Epoch [16] T 484.02s, deltaT 30.01s, loss: train 0.99062, valid 0.98986, dsc: train 0.00938, valid 0.01014\n",
      "DEBUG: Writing to tensorboard before epoch True, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  16, step 0\n",
      "Batch train [1] loss 0.99006, dsc 0.00994\n",
      "Batch train [2] loss 0.98925, dsc 0.01075\n",
      "Batch train [3] loss 0.99090, dsc 0.00910\n",
      "Batch train [4] loss 0.99052, dsc 0.00948\n",
      "Batch train [5] loss 0.99080, dsc 0.00920\n",
      "Batch train [6] loss 0.99137, dsc 0.00863\n",
      "Batch train [7] loss 0.98891, dsc 0.01109\n",
      "Batch train [8] loss 0.99129, dsc 0.00871\n",
      "Batch train [9] loss 0.98930, dsc 0.01070\n",
      "Batch train [10] loss 0.99043, dsc 0.00957\n",
      "Batch train [11] loss 0.98956, dsc 0.01044\n",
      "Batch train [12] loss 0.99120, dsc 0.00880\n",
      "Batch train [13] loss 0.99161, dsc 0.00839\n",
      "Batch train [14] loss 0.99185, dsc 0.00815\n",
      "Batch train [15] loss 0.98942, dsc 0.01058\n",
      "Batch train [16] loss 0.98997, dsc 0.01003\n",
      "Batch train [17] loss 0.99089, dsc 0.00911\n",
      "Batch train [18] loss 0.99204, dsc 0.00796\n",
      "Batch train [19] loss 0.98805, dsc 0.01195\n",
      "Batch train [20] loss 0.99209, dsc 0.00791\n",
      "Epoch [17] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  16, step 0\n",
      "Batch eval [1] loss 0.98840, dsc 0.01160\n",
      "Batch eval [2] loss 0.99041, dsc 0.00959\n",
      "Batch eval [3] loss 0.98978, dsc 0.01022\n",
      "Batch eval [4] loss 0.99210, dsc 0.00790\n",
      "Batch eval [5] loss 0.98883, dsc 0.01117\n",
      "Epoch [17] valid done\n",
      "Epoch [17] T 514.39s, deltaT 30.37s, loss: train 0.99047, valid 0.98990, dsc: train 0.00953, valid 0.01010\n",
      "DEBUG: Writing to tensorboard before epoch True, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  17, step 0\n",
      "Batch train [1] loss 0.99075, dsc 0.00925\n",
      "Batch train [2] loss 0.99011, dsc 0.00989\n",
      "Batch train [3] loss 0.98980, dsc 0.01020\n",
      "Batch train [4] loss 0.99107, dsc 0.00893\n",
      "Batch train [5] loss 0.98829, dsc 0.01171\n",
      "Batch train [6] loss 0.98902, dsc 0.01098\n",
      "Batch train [7] loss 0.99040, dsc 0.00960\n",
      "Batch train [8] loss 0.98962, dsc 0.01038\n",
      "Batch train [9] loss 0.98884, dsc 0.01116\n",
      "Batch train [10] loss 0.98956, dsc 0.01044\n",
      "Batch train [11] loss 0.98936, dsc 0.01064\n",
      "Batch train [12] loss 0.99076, dsc 0.00924\n",
      "Batch train [13] loss 0.99014, dsc 0.00986\n",
      "Batch train [14] loss 0.99258, dsc 0.00742\n",
      "Batch train [15] loss 0.99078, dsc 0.00922\n",
      "Batch train [16] loss 0.99215, dsc 0.00785\n",
      "Batch train [17] loss 0.98775, dsc 0.01225\n",
      "Batch train [18] loss 0.99306, dsc 0.00694\n",
      "Batch train [19] loss 0.99099, dsc 0.00901\n",
      "Batch train [20] loss 0.99218, dsc 0.00782\n",
      "Epoch [18] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  17, step 0\n",
      "Batch eval [1] loss 0.98823, dsc 0.01177\n",
      "Batch eval [2] loss 0.99020, dsc 0.00980\n",
      "Batch eval [3] loss 0.98950, dsc 0.01050\n",
      "Batch eval [4] loss 0.99201, dsc 0.00799\n",
      "Batch eval [5] loss 0.98876, dsc 0.01124\n",
      "Epoch [18] valid done\n",
      "Epoch [18] T 544.67s, deltaT 30.28s, loss: train 0.99036, valid 0.98974, dsc: train 0.00964, valid 0.01026\n",
      "DEBUG: Writing to tensorboard before epoch True, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  18, step 0\n",
      "Batch train [1] loss 0.98899, dsc 0.01101\n",
      "Batch train [2] loss 0.99056, dsc 0.00944\n",
      "Batch train [3] loss 0.98847, dsc 0.01153\n",
      "Batch train [4] loss 0.99004, dsc 0.00996\n",
      "Batch train [5] loss 0.98936, dsc 0.01064\n",
      "Batch train [6] loss 0.98990, dsc 0.01010\n",
      "Batch train [7] loss 0.99029, dsc 0.00971\n",
      "Batch train [8] loss 0.98822, dsc 0.01178\n",
      "Batch train [9] loss 0.98901, dsc 0.01099\n",
      "Batch train [10] loss 0.99057, dsc 0.00943\n",
      "Batch train [11] loss 0.99075, dsc 0.00925\n",
      "Batch train [12] loss 0.99163, dsc 0.00837\n",
      "Batch train [13] loss 0.99270, dsc 0.00730\n",
      "Batch train [14] loss 0.98974, dsc 0.01026\n",
      "Batch train [15] loss 0.99081, dsc 0.00919\n",
      "Batch train [16] loss 0.99249, dsc 0.00751\n",
      "Batch train [17] loss 0.98812, dsc 0.01188\n",
      "Batch train [18] loss 0.99135, dsc 0.00865\n",
      "Batch train [19] loss 0.99221, dsc 0.00779\n",
      "Batch train [20] loss 0.99020, dsc 0.00980\n",
      "Epoch [19] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  18, step 0\n",
      "Batch eval [1] loss 0.98786, dsc 0.01214\n",
      "Batch eval [2] loss 0.99000, dsc 0.01000\n",
      "Batch eval [3] loss 0.98892, dsc 0.01108\n",
      "Batch eval [4] loss 0.99186, dsc 0.00814\n",
      "Batch eval [5] loss 0.98845, dsc 0.01155\n",
      "Epoch [19] valid done\n",
      "Epoch [19] T 574.73s, deltaT 30.06s, loss: train 0.99027, valid 0.98942, dsc: train 0.00973, valid 0.01058\n",
      "DEBUG: Writing to tensorboard before epoch True, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  19, step 0\n",
      "Batch train [1] loss 0.99189, dsc 0.00811\n",
      "Batch train [2] loss 0.99012, dsc 0.00988\n",
      "Batch train [3] loss 0.99199, dsc 0.00801\n",
      "Batch train [4] loss 0.98634, dsc 0.01366\n",
      "Batch train [5] loss 0.98750, dsc 0.01250\n",
      "Batch train [6] loss 0.99276, dsc 0.00724\n",
      "Batch train [7] loss 0.99194, dsc 0.00806\n",
      "Batch train [8] loss 0.98960, dsc 0.01040\n",
      "Batch train [9] loss 0.99050, dsc 0.00950\n",
      "Batch train [10] loss 0.99068, dsc 0.00932\n",
      "Batch train [11] loss 0.99050, dsc 0.00950\n",
      "Batch train [12] loss 0.99093, dsc 0.00907\n",
      "Batch train [13] loss 0.99113, dsc 0.00887\n",
      "Batch train [14] loss 0.99030, dsc 0.00970\n",
      "Batch train [15] loss 0.99112, dsc 0.00888\n",
      "Batch train [16] loss 0.98804, dsc 0.01196\n",
      "Batch train [17] loss 0.99163, dsc 0.00837\n",
      "Batch train [18] loss 0.99006, dsc 0.00994\n",
      "Batch train [19] loss 0.98986, dsc 0.01014\n",
      "Batch train [20] loss 0.98713, dsc 0.01287\n",
      "Epoch [20] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  19, step 0\n",
      "Batch eval [1] loss 0.98785, dsc 0.01215\n",
      "Batch eval [2] loss 0.98998, dsc 0.01002\n",
      "Batch eval [3] loss 0.98909, dsc 0.01091\n",
      "Batch eval [4] loss 0.99181, dsc 0.00819\n",
      "Batch eval [5] loss 0.98843, dsc 0.01157\n",
      "Epoch [20] valid done\n",
      "Epoch [20] T 604.73s, deltaT 30.00s, loss: train 0.99020, valid 0.98943, dsc: train 0.00980, valid 0.01057\n",
      "DEBUG: Writing to tensorboard before epoch True, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  20, step 0\n",
      "Batch train [1] loss 0.98807, dsc 0.01193\n",
      "Batch train [2] loss 0.98822, dsc 0.01178\n",
      "Batch train [3] loss 0.98875, dsc 0.01125\n",
      "Batch train [4] loss 0.99087, dsc 0.00913\n",
      "Batch train [5] loss 0.99195, dsc 0.00805\n",
      "Batch train [6] loss 0.99041, dsc 0.00959\n",
      "Batch train [7] loss 0.98879, dsc 0.01121\n",
      "Batch train [8] loss 0.99234, dsc 0.00766\n",
      "Batch train [9] loss 0.99044, dsc 0.00956\n",
      "Batch train [10] loss 0.99067, dsc 0.00933\n",
      "Batch train [11] loss 0.99041, dsc 0.00959\n",
      "Batch train [12] loss 0.98969, dsc 0.01031\n",
      "Batch train [13] loss 0.99020, dsc 0.00980\n",
      "Batch train [14] loss 0.98950, dsc 0.01050\n",
      "Batch train [15] loss 0.99169, dsc 0.00831\n",
      "Batch train [16] loss 0.98977, dsc 0.01023\n",
      "Batch train [17] loss 0.99241, dsc 0.00759\n",
      "Batch train [18] loss 0.98978, dsc 0.01022\n",
      "Batch train [19] loss 0.98919, dsc 0.01081\n",
      "Batch train [20] loss 0.98953, dsc 0.01047\n",
      "Epoch [21] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  20, step 0\n",
      "Batch eval [1] loss 0.98785, dsc 0.01215\n",
      "Batch eval [2] loss 0.98990, dsc 0.01010\n",
      "Batch eval [3] loss 0.98905, dsc 0.01095\n",
      "Batch eval [4] loss 0.99178, dsc 0.00822\n",
      "Batch eval [5] loss 0.98828, dsc 0.01172\n",
      "Epoch [21] valid done\n",
      "Epoch [21] T 634.80s, deltaT 30.07s, loss: train 0.99013, valid 0.98937, dsc: train 0.00987, valid 0.01063\n",
      "DEBUG: Writing to tensorboard before epoch True, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  21, step 0\n",
      "Batch train [1] loss 0.99152, dsc 0.00848\n",
      "Batch train [2] loss 0.98994, dsc 0.01006\n",
      "Batch train [3] loss 0.98948, dsc 0.01052\n",
      "Batch train [4] loss 0.98940, dsc 0.01060\n",
      "Batch train [5] loss 0.98848, dsc 0.01152\n",
      "Batch train [6] loss 0.98990, dsc 0.01010\n",
      "Batch train [7] loss 0.99218, dsc 0.00782\n",
      "Batch train [8] loss 0.99185, dsc 0.00815\n",
      "Batch train [9] loss 0.99148, dsc 0.00852\n",
      "Batch train [10] loss 0.98944, dsc 0.01056\n",
      "Batch train [11] loss 0.98686, dsc 0.01314\n",
      "Batch train [12] loss 0.98930, dsc 0.01070\n",
      "Batch train [13] loss 0.98898, dsc 0.01102\n",
      "Batch train [14] loss 0.99242, dsc 0.00758\n",
      "Batch train [15] loss 0.98886, dsc 0.01114\n",
      "Batch train [16] loss 0.99101, dsc 0.00899\n",
      "Batch train [17] loss 0.99008, dsc 0.00992\n",
      "Batch train [18] loss 0.98992, dsc 0.01008\n",
      "Batch train [19] loss 0.99213, dsc 0.00787\n",
      "Batch train [20] loss 0.98860, dsc 0.01140\n",
      "Epoch [22] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  21, step 0\n",
      "Batch eval [1] loss 0.98779, dsc 0.01221\n",
      "Batch eval [2] loss 0.98994, dsc 0.01006\n",
      "Batch eval [3] loss 0.98916, dsc 0.01084\n",
      "Batch eval [4] loss 0.99178, dsc 0.00822\n",
      "Batch eval [5] loss 0.98831, dsc 0.01169\n",
      "Epoch [22] valid done\n",
      "Epoch [22] T 664.74s, deltaT 29.93s, loss: train 0.99009, valid 0.98940, dsc: train 0.00991, valid 0.01060\n",
      "DEBUG: Writing to tensorboard before epoch True, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  22, step 0\n",
      "Batch train [1] loss 0.99094, dsc 0.00906\n",
      "Batch train [2] loss 0.98960, dsc 0.01040\n",
      "Batch train [3] loss 0.99132, dsc 0.00868\n",
      "Batch train [4] loss 0.98879, dsc 0.01121\n",
      "Batch train [5] loss 0.99055, dsc 0.00945\n",
      "Batch train [6] loss 0.99117, dsc 0.00883\n",
      "Batch train [7] loss 0.98963, dsc 0.01037\n",
      "Batch train [8] loss 0.99262, dsc 0.00738\n",
      "Batch train [9] loss 0.98988, dsc 0.01012\n",
      "Batch train [10] loss 0.99005, dsc 0.00995\n",
      "Batch train [11] loss 0.99216, dsc 0.00784\n",
      "Batch train [12] loss 0.98846, dsc 0.01154\n",
      "Batch train [13] loss 0.98882, dsc 0.01118\n",
      "Batch train [14] loss 0.99053, dsc 0.00947\n",
      "Batch train [15] loss 0.98912, dsc 0.01088\n",
      "Batch train [16] loss 0.98791, dsc 0.01209\n",
      "Batch train [17] loss 0.98879, dsc 0.01121\n",
      "Batch train [18] loss 0.99033, dsc 0.00967\n",
      "Batch train [19] loss 0.99169, dsc 0.00831\n",
      "Batch train [20] loss 0.98853, dsc 0.01147\n",
      "Epoch [23] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  22, step 0\n",
      "Batch eval [1] loss 0.98774, dsc 0.01226\n",
      "Batch eval [2] loss 0.98985, dsc 0.01015\n",
      "Batch eval [3] loss 0.98901, dsc 0.01099\n",
      "Batch eval [4] loss 0.99172, dsc 0.00828\n",
      "Batch eval [5] loss 0.98821, dsc 0.01179\n",
      "Epoch [23] valid done\n",
      "Epoch [23] T 694.74s, deltaT 30.00s, loss: train 0.99004, valid 0.98930, dsc: train 0.00996, valid 0.01070\n",
      "DEBUG: Writing to tensorboard before epoch True, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  23, step 0\n",
      "Batch train [1] loss 0.99234, dsc 0.00766\n",
      "Batch train [2] loss 0.98797, dsc 0.01203\n",
      "Batch train [3] loss 0.99217, dsc 0.00783\n",
      "Batch train [4] loss 0.99187, dsc 0.00813\n",
      "Batch train [5] loss 0.99046, dsc 0.00954\n",
      "Batch train [6] loss 0.98848, dsc 0.01152\n",
      "Batch train [7] loss 0.99167, dsc 0.00833\n",
      "Batch train [8] loss 0.99049, dsc 0.00951\n",
      "Batch train [9] loss 0.98933, dsc 0.01067\n",
      "Batch train [10] loss 0.99012, dsc 0.00988\n",
      "Batch train [11] loss 0.98997, dsc 0.01003\n",
      "Batch train [12] loss 0.98877, dsc 0.01123\n",
      "Batch train [13] loss 0.98994, dsc 0.01006\n",
      "Batch train [14] loss 0.99049, dsc 0.00951\n",
      "Batch train [15] loss 0.99052, dsc 0.00948\n",
      "Batch train [16] loss 0.99050, dsc 0.00950\n",
      "Batch train [17] loss 0.98670, dsc 0.01330\n",
      "Batch train [18] loss 0.98832, dsc 0.01168\n",
      "Batch train [19] loss 0.98996, dsc 0.01004\n",
      "Batch train [20] loss 0.98993, dsc 0.01007\n",
      "Epoch [24] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  23, step 0\n",
      "Batch eval [1] loss 0.98760, dsc 0.01240\n",
      "Batch eval [2] loss 0.98975, dsc 0.01025\n",
      "Batch eval [3] loss 0.98867, dsc 0.01133\n",
      "Batch eval [4] loss 0.99166, dsc 0.00834\n",
      "Batch eval [5] loss 0.98811, dsc 0.01189\n",
      "Epoch [24] valid done\n",
      "Epoch [24] T 724.82s, deltaT 30.08s, loss: train 0.99000, valid 0.98916, dsc: train 0.01000, valid 0.01084\n",
      "DEBUG: Writing to tensorboard before epoch True, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  24, step 0\n",
      "Batch train [1] loss 0.98966, dsc 0.01034\n",
      "Batch train [2] loss 0.98850, dsc 0.01150\n",
      "Batch train [3] loss 0.99019, dsc 0.00981\n",
      "Batch train [4] loss 0.98939, dsc 0.01061\n",
      "Batch train [5] loss 0.99027, dsc 0.00973\n",
      "Batch train [6] loss 0.98835, dsc 0.01165\n",
      "Batch train [7] loss 0.99177, dsc 0.00823\n",
      "Batch train [8] loss 0.98809, dsc 0.01191\n",
      "Batch train [9] loss 0.99024, dsc 0.00976\n",
      "Batch train [10] loss 0.99008, dsc 0.00992\n",
      "Batch train [11] loss 0.98924, dsc 0.01076\n",
      "Batch train [12] loss 0.99101, dsc 0.00899\n",
      "Batch train [13] loss 0.98976, dsc 0.01024\n",
      "Batch train [14] loss 0.99163, dsc 0.00837\n",
      "Batch train [15] loss 0.98890, dsc 0.01110\n",
      "Batch train [16] loss 0.99159, dsc 0.00841\n",
      "Batch train [17] loss 0.99118, dsc 0.00882\n",
      "Batch train [18] loss 0.99110, dsc 0.00890\n",
      "Batch train [19] loss 0.98825, dsc 0.01175\n",
      "Batch train [20] loss 0.99007, dsc 0.00993\n",
      "Epoch [25] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  24, step 0\n",
      "Batch eval [1] loss 0.98759, dsc 0.01241\n",
      "Batch eval [2] loss 0.98975, dsc 0.01025\n",
      "Batch eval [3] loss 0.98896, dsc 0.01104\n",
      "Batch eval [4] loss 0.99162, dsc 0.00838\n",
      "Batch eval [5] loss 0.98812, dsc 0.01188\n",
      "Epoch [25] valid done\n",
      "Epoch [25] T 754.73s, deltaT 29.90s, loss: train 0.98996, valid 0.98921, dsc: train 0.01004, valid 0.01079\n",
      "DEBUG: Writing to tensorboard before epoch True, 25, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  25, step 0\n",
      "Batch train [1] loss 0.98695, dsc 0.01305\n",
      "Batch train [2] loss 0.99148, dsc 0.00852\n",
      "Batch train [3] loss 0.99139, dsc 0.00861\n",
      "Batch train [4] loss 0.98870, dsc 0.01130\n",
      "Batch train [5] loss 0.99052, dsc 0.00948\n",
      "Batch train [6] loss 0.99017, dsc 0.00983\n",
      "Batch train [7] loss 0.99063, dsc 0.00937\n",
      "Batch train [8] loss 0.98844, dsc 0.01156\n",
      "Batch train [9] loss 0.99057, dsc 0.00943\n",
      "Batch train [10] loss 0.99091, dsc 0.00909\n",
      "Batch train [11] loss 0.98876, dsc 0.01124\n",
      "Batch train [12] loss 0.99120, dsc 0.00880\n",
      "Batch train [13] loss 0.98748, dsc 0.01252\n",
      "Batch train [14] loss 0.98936, dsc 0.01064\n",
      "Batch train [15] loss 0.99151, dsc 0.00849\n",
      "Batch train [16] loss 0.98864, dsc 0.01136\n",
      "Batch train [17] loss 0.98934, dsc 0.01066\n",
      "Batch train [18] loss 0.99009, dsc 0.00991\n",
      "Batch train [19] loss 0.99044, dsc 0.00956\n",
      "Batch train [20] loss 0.99205, dsc 0.00795\n",
      "Epoch [26] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 25, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  25, step 0\n",
      "Batch eval [1] loss 0.98763, dsc 0.01237\n",
      "Batch eval [2] loss 0.98970, dsc 0.01030\n",
      "Batch eval [3] loss 0.98875, dsc 0.01125\n",
      "Batch eval [4] loss 0.99162, dsc 0.00838\n",
      "Batch eval [5] loss 0.98812, dsc 0.01188\n",
      "Epoch [26] valid done\n",
      "Epoch [26] T 784.79s, deltaT 30.06s, loss: train 0.98993, valid 0.98916, dsc: train 0.01007, valid 0.01084\n",
      "DEBUG: Writing to tensorboard before epoch True, 26, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  26, step 0\n",
      "Batch train [1] loss 0.98946, dsc 0.01054\n",
      "Batch train [2] loss 0.99019, dsc 0.00981\n",
      "Batch train [3] loss 0.99014, dsc 0.00986\n",
      "Batch train [4] loss 0.98918, dsc 0.01082\n",
      "Batch train [5] loss 0.98978, dsc 0.01022\n",
      "Batch train [6] loss 0.98850, dsc 0.01150\n",
      "Batch train [7] loss 0.99128, dsc 0.00872\n",
      "Batch train [8] loss 0.98883, dsc 0.01117\n",
      "Batch train [9] loss 0.99292, dsc 0.00708\n",
      "Batch train [10] loss 0.98979, dsc 0.01021\n",
      "Batch train [11] loss 0.98798, dsc 0.01202\n",
      "Batch train [12] loss 0.98939, dsc 0.01061\n",
      "Batch train [13] loss 0.99164, dsc 0.00836\n",
      "Batch train [14] loss 0.99026, dsc 0.00974\n",
      "Batch train [15] loss 0.99086, dsc 0.00914\n",
      "Batch train [16] loss 0.98850, dsc 0.01150\n",
      "Batch train [17] loss 0.98872, dsc 0.01128\n",
      "Batch train [18] loss 0.98898, dsc 0.01102\n",
      "Batch train [19] loss 0.98835, dsc 0.01165\n",
      "Batch train [20] loss 0.99327, dsc 0.00673\n",
      "Epoch [27] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 26, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  26, step 0\n",
      "Batch eval [1] loss 0.98760, dsc 0.01240\n",
      "Batch eval [2] loss 0.98969, dsc 0.01031\n",
      "Batch eval [3] loss 0.98878, dsc 0.01122\n",
      "Batch eval [4] loss 0.99165, dsc 0.00835\n",
      "Batch eval [5] loss 0.98806, dsc 0.01194\n",
      "Epoch [27] valid done\n",
      "Epoch [27] T 814.90s, deltaT 30.11s, loss: train 0.98990, valid 0.98916, dsc: train 0.01010, valid 0.01085\n",
      "DEBUG: Writing to tensorboard before epoch True, 27, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  27, step 0\n",
      "Batch train [1] loss 0.98941, dsc 0.01059\n",
      "Batch train [2] loss 0.98873, dsc 0.01127\n",
      "Batch train [3] loss 0.98980, dsc 0.01020\n",
      "Batch train [4] loss 0.99116, dsc 0.00884\n",
      "Batch train [5] loss 0.98933, dsc 0.01067\n",
      "Batch train [6] loss 0.98793, dsc 0.01207\n",
      "Batch train [7] loss 0.99081, dsc 0.00919\n",
      "Batch train [8] loss 0.99196, dsc 0.00804\n",
      "Batch train [9] loss 0.98926, dsc 0.01074\n",
      "Batch train [10] loss 0.98980, dsc 0.01020\n",
      "Batch train [11] loss 0.99175, dsc 0.00825\n",
      "Batch train [12] loss 0.98765, dsc 0.01235\n",
      "Batch train [13] loss 0.99006, dsc 0.00994\n",
      "Batch train [14] loss 0.98766, dsc 0.01234\n",
      "Batch train [15] loss 0.99014, dsc 0.00986\n",
      "Batch train [16] loss 0.98903, dsc 0.01097\n",
      "Batch train [17] loss 0.99069, dsc 0.00931\n",
      "Batch train [18] loss 0.99226, dsc 0.00774\n",
      "Batch train [19] loss 0.98922, dsc 0.01078\n",
      "Batch train [20] loss 0.99082, dsc 0.00918\n",
      "Epoch [28] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 27, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  27, step 0\n",
      "Batch eval [1] loss 0.98746, dsc 0.01254\n",
      "Batch eval [2] loss 0.98964, dsc 0.01036\n",
      "Batch eval [3] loss 0.98867, dsc 0.01133\n",
      "Batch eval [4] loss 0.99155, dsc 0.00845\n",
      "Batch eval [5] loss 0.98805, dsc 0.01195\n",
      "Epoch [28] valid done\n",
      "Epoch [28] T 844.95s, deltaT 30.05s, loss: train 0.98987, valid 0.98908, dsc: train 0.01013, valid 0.01092\n",
      "DEBUG: Writing to tensorboard before epoch True, 28, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  28, step 0\n",
      "Batch train [1] loss 0.99098, dsc 0.00902\n",
      "Batch train [2] loss 0.99069, dsc 0.00931\n",
      "Batch train [3] loss 0.99154, dsc 0.00846\n",
      "Batch train [4] loss 0.98875, dsc 0.01125\n",
      "Batch train [5] loss 0.98870, dsc 0.01130\n",
      "Batch train [6] loss 0.98866, dsc 0.01134\n",
      "Batch train [7] loss 0.99047, dsc 0.00953\n",
      "Batch train [8] loss 0.99011, dsc 0.00989\n",
      "Batch train [9] loss 0.98791, dsc 0.01209\n",
      "Batch train [10] loss 0.99015, dsc 0.00985\n",
      "Batch train [11] loss 0.99182, dsc 0.00818\n",
      "Batch train [12] loss 0.98855, dsc 0.01145\n",
      "Batch train [13] loss 0.98920, dsc 0.01080\n",
      "Batch train [14] loss 0.99146, dsc 0.00854\n",
      "Batch train [15] loss 0.98686, dsc 0.01314\n",
      "Batch train [16] loss 0.98814, dsc 0.01186\n",
      "Batch train [17] loss 0.98948, dsc 0.01052\n",
      "Batch train [18] loss 0.99129, dsc 0.00871\n",
      "Batch train [19] loss 0.99178, dsc 0.00822\n",
      "Batch train [20] loss 0.99059, dsc 0.00941\n",
      "Epoch [29] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 28, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  28, step 0\n",
      "Batch eval [1] loss 0.98741, dsc 0.01259\n",
      "Batch eval [2] loss 0.98960, dsc 0.01040\n",
      "Batch eval [3] loss 0.98851, dsc 0.01149\n",
      "Batch eval [4] loss 0.99155, dsc 0.00845\n",
      "Batch eval [5] loss 0.98794, dsc 0.01206\n",
      "Epoch [29] valid done\n",
      "Epoch [29] T 874.98s, deltaT 30.02s, loss: train 0.98985, valid 0.98900, dsc: train 0.01015, valid 0.01100\n",
      "DEBUG: Writing to tensorboard before epoch True, 29, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  29, step 0\n",
      "Batch train [1] loss 0.98965, dsc 0.01035\n",
      "Batch train [2] loss 0.98695, dsc 0.01305\n",
      "Batch train [3] loss 0.98791, dsc 0.01209\n",
      "Batch train [4] loss 0.99010, dsc 0.00990\n",
      "Batch train [5] loss 0.98923, dsc 0.01077\n",
      "Batch train [6] loss 0.99058, dsc 0.00942\n",
      "Batch train [7] loss 0.99321, dsc 0.00679\n",
      "Batch train [8] loss 0.98851, dsc 0.01149\n",
      "Batch train [9] loss 0.99083, dsc 0.00917\n",
      "Batch train [10] loss 0.98919, dsc 0.01081\n",
      "Batch train [11] loss 0.98967, dsc 0.01033\n",
      "Batch train [12] loss 0.99205, dsc 0.00795\n",
      "Batch train [13] loss 0.98763, dsc 0.01237\n",
      "Batch train [14] loss 0.99057, dsc 0.00943\n",
      "Batch train [15] loss 0.98976, dsc 0.01024\n",
      "Batch train [16] loss 0.99109, dsc 0.00891\n",
      "Batch train [17] loss 0.99131, dsc 0.00869\n",
      "Batch train [18] loss 0.99143, dsc 0.00857\n",
      "Batch train [19] loss 0.98947, dsc 0.01053\n",
      "Batch train [20] loss 0.98766, dsc 0.01234\n",
      "Epoch [30] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 29, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  29, step 0\n",
      "Batch eval [1] loss 0.98739, dsc 0.01261\n",
      "Batch eval [2] loss 0.98959, dsc 0.01041\n",
      "Batch eval [3] loss 0.98862, dsc 0.01138\n",
      "Batch eval [4] loss 0.99152, dsc 0.00848\n",
      "Batch eval [5] loss 0.98794, dsc 0.01206\n",
      "Epoch [30] valid done\n",
      "Epoch [30] T 905.16s, deltaT 30.18s, loss: train 0.98984, valid 0.98901, dsc: train 0.01016, valid 0.01099\n",
      "DEBUG: Writing to tensorboard before epoch True, 30, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  30, step 0\n",
      "Batch train [1] loss 0.99028, dsc 0.00972\n",
      "Batch train [2] loss 0.98755, dsc 0.01245\n",
      "Batch train [3] loss 0.99014, dsc 0.00986\n",
      "Batch train [4] loss 0.98973, dsc 0.01027\n",
      "Batch train [5] loss 0.98797, dsc 0.01203\n",
      "Batch train [6] loss 0.99004, dsc 0.00996\n",
      "Batch train [7] loss 0.98903, dsc 0.01097\n",
      "Batch train [8] loss 0.98834, dsc 0.01166\n",
      "Batch train [9] loss 0.98910, dsc 0.01090\n",
      "Batch train [10] loss 0.98989, dsc 0.01011\n",
      "Batch train [11] loss 0.99173, dsc 0.00827\n",
      "Batch train [12] loss 0.99198, dsc 0.00802\n",
      "Batch train [13] loss 0.99114, dsc 0.00886\n",
      "Batch train [14] loss 0.98984, dsc 0.01016\n",
      "Batch train [15] loss 0.99055, dsc 0.00945\n",
      "Batch train [16] loss 0.98602, dsc 0.01398\n",
      "Batch train [17] loss 0.99268, dsc 0.00732\n",
      "Batch train [18] loss 0.99011, dsc 0.00989\n",
      "Batch train [19] loss 0.98963, dsc 0.01037\n",
      "Batch train [20] loss 0.99035, dsc 0.00965\n",
      "Epoch [31] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 30, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  30, step 0\n",
      "Batch eval [1] loss 0.98738, dsc 0.01262\n",
      "Batch eval [2] loss 0.98955, dsc 0.01045\n",
      "Batch eval [3] loss 0.98860, dsc 0.01140\n",
      "Batch eval [4] loss 0.99152, dsc 0.00848\n",
      "Batch eval [5] loss 0.98793, dsc 0.01207\n",
      "Epoch [31] valid done\n",
      "Epoch [31] T 935.14s, deltaT 29.98s, loss: train 0.98981, valid 0.98900, dsc: train 0.01019, valid 0.01100\n",
      "DEBUG: Writing to tensorboard before epoch True, 31, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  31, step 0\n",
      "Batch train [1] loss 0.98746, dsc 0.01254\n",
      "Batch train [2] loss 0.99008, dsc 0.00992\n",
      "Batch train [3] loss 0.98813, dsc 0.01187\n",
      "Batch train [4] loss 0.98907, dsc 0.01093\n",
      "Batch train [5] loss 0.98677, dsc 0.01323\n",
      "Batch train [6] loss 0.98932, dsc 0.01068\n",
      "Batch train [7] loss 0.99271, dsc 0.00729\n",
      "Batch train [8] loss 0.99070, dsc 0.00930\n",
      "Batch train [9] loss 0.99027, dsc 0.00973\n",
      "Batch train [10] loss 0.99068, dsc 0.00932\n",
      "Batch train [11] loss 0.98577, dsc 0.01423\n",
      "Batch train [12] loss 0.99073, dsc 0.00927\n",
      "Batch train [13] loss 0.98947, dsc 0.01053\n",
      "Batch train [14] loss 0.99071, dsc 0.00929\n",
      "Batch train [15] loss 0.98782, dsc 0.01218\n",
      "Batch train [16] loss 0.99125, dsc 0.00875\n",
      "Batch train [17] loss 0.99165, dsc 0.00835\n",
      "Batch train [18] loss 0.99072, dsc 0.00928\n",
      "Batch train [19] loss 0.99295, dsc 0.00705\n",
      "Batch train [20] loss 0.98940, dsc 0.01060\n",
      "Epoch [32] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 31, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  31, step 0\n",
      "Batch eval [1] loss 0.98749, dsc 0.01251\n",
      "Batch eval [2] loss 0.98958, dsc 0.01042\n",
      "Batch eval [3] loss 0.98881, dsc 0.01119\n",
      "Batch eval [4] loss 0.99149, dsc 0.00851\n",
      "Batch eval [5] loss 0.98785, dsc 0.01215\n",
      "Epoch [32] valid done\n",
      "Epoch [32] T 965.05s, deltaT 29.90s, loss: train 0.98978, valid 0.98904, dsc: train 0.01022, valid 0.01096\n",
      "DEBUG: Writing to tensorboard before epoch True, 32, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  32, step 0\n",
      "Batch train [1] loss 0.99115, dsc 0.00885\n",
      "Batch train [2] loss 0.99136, dsc 0.00864\n",
      "Batch train [3] loss 0.99052, dsc 0.00948\n",
      "Batch train [4] loss 0.98924, dsc 0.01076\n",
      "Batch train [5] loss 0.98783, dsc 0.01217\n",
      "Batch train [6] loss 0.99009, dsc 0.00991\n",
      "Batch train [7] loss 0.99148, dsc 0.00852\n",
      "Batch train [8] loss 0.98826, dsc 0.01174\n",
      "Batch train [9] loss 0.98997, dsc 0.01003\n",
      "Batch train [10] loss 0.99008, dsc 0.00992\n",
      "Batch train [11] loss 0.98934, dsc 0.01066\n",
      "Batch train [12] loss 0.98760, dsc 0.01240\n",
      "Batch train [13] loss 0.99159, dsc 0.00841\n",
      "Batch train [14] loss 0.98938, dsc 0.01062\n",
      "Batch train [15] loss 0.98937, dsc 0.01063\n",
      "Batch train [16] loss 0.99038, dsc 0.00962\n",
      "Batch train [17] loss 0.98747, dsc 0.01253\n",
      "Batch train [18] loss 0.99168, dsc 0.00832\n",
      "Batch train [19] loss 0.98868, dsc 0.01132\n",
      "Batch train [20] loss 0.98967, dsc 0.01033\n",
      "Epoch [33] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 32, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  32, step 0\n",
      "Batch eval [1] loss 0.98729, dsc 0.01271\n",
      "Batch eval [2] loss 0.98950, dsc 0.01050\n",
      "Batch eval [3] loss 0.98852, dsc 0.01148\n",
      "Batch eval [4] loss 0.99148, dsc 0.00852\n",
      "Batch eval [5] loss 0.98784, dsc 0.01216\n",
      "Epoch [33] valid done\n",
      "Epoch [33] T 994.90s, deltaT 29.85s, loss: train 0.98976, valid 0.98892, dsc: train 0.01024, valid 0.01108\n",
      "DEBUG: Writing to tensorboard before epoch True, 33, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  33, step 0\n",
      "Batch train [1] loss 0.98965, dsc 0.01035\n",
      "Batch train [2] loss 0.99130, dsc 0.00870\n",
      "Batch train [3] loss 0.98973, dsc 0.01027\n",
      "Batch train [4] loss 0.98834, dsc 0.01166\n",
      "Batch train [5] loss 0.99218, dsc 0.00782\n",
      "Batch train [6] loss 0.98978, dsc 0.01022\n",
      "Batch train [7] loss 0.98985, dsc 0.01015\n",
      "Batch train [8] loss 0.99025, dsc 0.00975\n",
      "Batch train [9] loss 0.98994, dsc 0.01006\n",
      "Batch train [10] loss 0.99075, dsc 0.00925\n",
      "Batch train [11] loss 0.98749, dsc 0.01251\n",
      "Batch train [12] loss 0.98985, dsc 0.01015\n",
      "Batch train [13] loss 0.98914, dsc 0.01086\n",
      "Batch train [14] loss 0.98671, dsc 0.01329\n",
      "Batch train [15] loss 0.98631, dsc 0.01369\n",
      "Batch train [16] loss 0.99208, dsc 0.00792\n",
      "Batch train [17] loss 0.99010, dsc 0.00990\n",
      "Batch train [18] loss 0.99089, dsc 0.00911\n",
      "Batch train [19] loss 0.98906, dsc 0.01094\n",
      "Batch train [20] loss 0.99142, dsc 0.00858\n",
      "Epoch [34] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 33, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  33, step 0\n",
      "Batch eval [1] loss 0.98727, dsc 0.01273\n",
      "Batch eval [2] loss 0.98955, dsc 0.01045\n",
      "Batch eval [3] loss 0.98846, dsc 0.01154\n",
      "Batch eval [4] loss 0.99146, dsc 0.00854\n",
      "Batch eval [5] loss 0.98788, dsc 0.01212\n",
      "Epoch [34] valid done\n",
      "Epoch [34] T 1024.82s, deltaT 29.92s, loss: train 0.98974, valid 0.98893, dsc: train 0.01026, valid 0.01107\n",
      "DEBUG: Writing to tensorboard before epoch True, 34, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  34, step 0\n",
      "Batch train [1] loss 0.98970, dsc 0.01030\n",
      "Batch train [2] loss 0.99309, dsc 0.00691\n",
      "Batch train [3] loss 0.99001, dsc 0.00999\n",
      "Batch train [4] loss 0.99194, dsc 0.00806\n",
      "Batch train [5] loss 0.98982, dsc 0.01018\n",
      "Batch train [6] loss 0.98898, dsc 0.01102\n",
      "Batch train [7] loss 0.99123, dsc 0.00877\n",
      "Batch train [8] loss 0.99089, dsc 0.00911\n",
      "Batch train [9] loss 0.98901, dsc 0.01099\n",
      "Batch train [10] loss 0.98772, dsc 0.01228\n",
      "Batch train [11] loss 0.99006, dsc 0.00994\n",
      "Batch train [12] loss 0.99092, dsc 0.00908\n",
      "Batch train [13] loss 0.98997, dsc 0.01003\n",
      "Batch train [14] loss 0.98823, dsc 0.01177\n",
      "Batch train [15] loss 0.98654, dsc 0.01346\n",
      "Batch train [16] loss 0.98899, dsc 0.01101\n",
      "Batch train [17] loss 0.98949, dsc 0.01051\n",
      "Batch train [18] loss 0.98841, dsc 0.01159\n",
      "Batch train [19] loss 0.98817, dsc 0.01183\n",
      "Batch train [20] loss 0.99120, dsc 0.00880\n",
      "Epoch [35] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 34, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  34, step 0\n",
      "Batch eval [1] loss 0.98738, dsc 0.01262\n",
      "Batch eval [2] loss 0.98959, dsc 0.01041\n",
      "Batch eval [3] loss 0.98884, dsc 0.01116\n",
      "Batch eval [4] loss 0.99151, dsc 0.00849\n",
      "Batch eval [5] loss 0.98790, dsc 0.01210\n",
      "Epoch [35] valid done\n",
      "Epoch [35] T 1054.61s, deltaT 29.78s, loss: train 0.98972, valid 0.98904, dsc: train 0.01028, valid 0.01096\n",
      "DEBUG: Writing to tensorboard before epoch True, 35, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  35, step 0\n",
      "Batch train [1] loss 0.98963, dsc 0.01037\n",
      "Batch train [2] loss 0.98944, dsc 0.01056\n",
      "Batch train [3] loss 0.99000, dsc 0.01000\n",
      "Batch train [4] loss 0.99009, dsc 0.00991\n",
      "Batch train [5] loss 0.99044, dsc 0.00956\n",
      "Batch train [6] loss 0.98895, dsc 0.01105\n",
      "Batch train [7] loss 0.98912, dsc 0.01088\n",
      "Batch train [8] loss 0.98835, dsc 0.01165\n",
      "Batch train [9] loss 0.99027, dsc 0.00973\n",
      "Batch train [10] loss 0.98976, dsc 0.01024\n",
      "Batch train [11] loss 0.98792, dsc 0.01208\n",
      "Batch train [12] loss 0.99052, dsc 0.00948\n",
      "Batch train [13] loss 0.98980, dsc 0.01020\n",
      "Batch train [14] loss 0.98744, dsc 0.01256\n",
      "Batch train [15] loss 0.98844, dsc 0.01156\n",
      "Batch train [16] loss 0.98790, dsc 0.01210\n",
      "Batch train [17] loss 0.98893, dsc 0.01107\n",
      "Batch train [18] loss 0.99383, dsc 0.00617\n",
      "Batch train [19] loss 0.99059, dsc 0.00941\n",
      "Batch train [20] loss 0.99260, dsc 0.00740\n",
      "Epoch [36] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 35, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  35, step 0\n",
      "Batch eval [1] loss 0.98726, dsc 0.01274\n",
      "Batch eval [2] loss 0.98951, dsc 0.01049\n",
      "Batch eval [3] loss 0.98850, dsc 0.01150\n",
      "Batch eval [4] loss 0.99142, dsc 0.00858\n",
      "Batch eval [5] loss 0.98777, dsc 0.01223\n",
      "Epoch [36] valid done\n",
      "Epoch [36] T 1084.49s, deltaT 29.88s, loss: train 0.98970, valid 0.98889, dsc: train 0.01030, valid 0.01111\n",
      "DEBUG: Writing to tensorboard before epoch True, 36, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  36, step 0\n",
      "Batch train [1] loss 0.99024, dsc 0.00976\n",
      "Batch train [2] loss 0.99213, dsc 0.00787\n",
      "Batch train [3] loss 0.98852, dsc 0.01148\n",
      "Batch train [4] loss 0.99086, dsc 0.00914\n",
      "Batch train [5] loss 0.98670, dsc 0.01330\n",
      "Batch train [6] loss 0.98896, dsc 0.01104\n",
      "Batch train [7] loss 0.98998, dsc 0.01002\n",
      "Batch train [8] loss 0.99140, dsc 0.00860\n",
      "Batch train [9] loss 0.98933, dsc 0.01067\n",
      "Batch train [10] loss 0.98854, dsc 0.01146\n",
      "Batch train [11] loss 0.98737, dsc 0.01263\n",
      "Batch train [12] loss 0.98990, dsc 0.01010\n",
      "Batch train [13] loss 0.99126, dsc 0.00874\n",
      "Batch train [14] loss 0.98933, dsc 0.01067\n",
      "Batch train [15] loss 0.98961, dsc 0.01039\n",
      "Batch train [16] loss 0.98904, dsc 0.01096\n",
      "Batch train [17] loss 0.99122, dsc 0.00878\n",
      "Batch train [18] loss 0.99135, dsc 0.00865\n",
      "Batch train [19] loss 0.99083, dsc 0.00917\n",
      "Batch train [20] loss 0.98699, dsc 0.01301\n",
      "Epoch [37] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 36, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  36, step 0\n",
      "Batch eval [1] loss 0.98725, dsc 0.01275\n",
      "Batch eval [2] loss 0.98947, dsc 0.01053\n",
      "Batch eval [3] loss 0.98859, dsc 0.01141\n",
      "Batch eval [4] loss 0.99144, dsc 0.00856\n",
      "Batch eval [5] loss 0.98780, dsc 0.01220\n",
      "Epoch [37] valid done\n",
      "Epoch [37] T 1114.52s, deltaT 30.03s, loss: train 0.98968, valid 0.98891, dsc: train 0.01032, valid 0.01109\n",
      "DEBUG: Writing to tensorboard before epoch True, 37, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  37, step 0\n",
      "Batch train [1] loss 0.98917, dsc 0.01083\n",
      "Batch train [2] loss 0.99077, dsc 0.00923\n",
      "Batch train [3] loss 0.98928, dsc 0.01072\n",
      "Batch train [4] loss 0.98881, dsc 0.01119\n",
      "Batch train [5] loss 0.98907, dsc 0.01093\n",
      "Batch train [6] loss 0.98750, dsc 0.01250\n",
      "Batch train [7] loss 0.99100, dsc 0.00900\n",
      "Batch train [8] loss 0.98968, dsc 0.01032\n",
      "Batch train [9] loss 0.99045, dsc 0.00955\n",
      "Batch train [10] loss 0.99098, dsc 0.00902\n",
      "Batch train [11] loss 0.98971, dsc 0.01029\n",
      "Batch train [12] loss 0.98991, dsc 0.01009\n",
      "Batch train [13] loss 0.99156, dsc 0.00844\n",
      "Batch train [14] loss 0.98849, dsc 0.01151\n",
      "Batch train [15] loss 0.99067, dsc 0.00933\n",
      "Batch train [16] loss 0.98873, dsc 0.01127\n",
      "Batch train [17] loss 0.98828, dsc 0.01172\n",
      "Batch train [18] loss 0.98999, dsc 0.01001\n",
      "Batch train [19] loss 0.99178, dsc 0.00822\n",
      "Batch train [20] loss 0.98745, dsc 0.01255\n",
      "Epoch [38] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 37, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  37, step 0\n",
      "Batch eval [1] loss 0.98718, dsc 0.01282\n",
      "Batch eval [2] loss 0.98941, dsc 0.01059\n",
      "Batch eval [3] loss 0.98851, dsc 0.01149\n",
      "Batch eval [4] loss 0.99141, dsc 0.00859\n",
      "Batch eval [5] loss 0.98774, dsc 0.01226\n",
      "Epoch [38] valid done\n",
      "Epoch [38] T 1144.43s, deltaT 29.91s, loss: train 0.98966, valid 0.98885, dsc: train 0.01034, valid 0.01115\n",
      "DEBUG: Writing to tensorboard before epoch True, 38, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  38, step 0\n",
      "Batch train [1] loss 0.99163, dsc 0.00837\n",
      "Batch train [2] loss 0.99186, dsc 0.00814\n",
      "Batch train [3] loss 0.98919, dsc 0.01081\n",
      "Batch train [4] loss 0.99088, dsc 0.00912\n",
      "Batch train [5] loss 0.99055, dsc 0.00945\n",
      "Batch train [6] loss 0.98889, dsc 0.01111\n",
      "Batch train [7] loss 0.98559, dsc 0.01441\n",
      "Batch train [8] loss 0.99069, dsc 0.00931\n",
      "Batch train [9] loss 0.99098, dsc 0.00902\n",
      "Batch train [10] loss 0.98879, dsc 0.01121\n",
      "Batch train [11] loss 0.99094, dsc 0.00906\n",
      "Batch train [12] loss 0.99066, dsc 0.00934\n",
      "Batch train [13] loss 0.98860, dsc 0.01140\n",
      "Batch train [14] loss 0.98904, dsc 0.01096\n",
      "Batch train [15] loss 0.99126, dsc 0.00874\n",
      "Batch train [16] loss 0.99007, dsc 0.00993\n",
      "Batch train [17] loss 0.98730, dsc 0.01270\n",
      "Batch train [18] loss 0.98892, dsc 0.01108\n",
      "Batch train [19] loss 0.98994, dsc 0.01006\n",
      "Batch train [20] loss 0.98724, dsc 0.01276\n",
      "Epoch [39] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 38, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  38, step 0\n",
      "Batch eval [1] loss 0.98723, dsc 0.01277\n",
      "Batch eval [2] loss 0.98943, dsc 0.01057\n",
      "Batch eval [3] loss 0.98856, dsc 0.01144\n",
      "Batch eval [4] loss 0.99139, dsc 0.00861\n",
      "Batch eval [5] loss 0.98780, dsc 0.01220\n",
      "Epoch [39] valid done\n",
      "Epoch [39] T 1174.25s, deltaT 29.82s, loss: train 0.98965, valid 0.98888, dsc: train 0.01035, valid 0.01112\n",
      "DEBUG: Writing to tensorboard before epoch True, 39, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  39, step 0\n",
      "Batch train [1] loss 0.99083, dsc 0.00917\n",
      "Batch train [2] loss 0.98987, dsc 0.01013\n",
      "Batch train [3] loss 0.99098, dsc 0.00902\n",
      "Batch train [4] loss 0.98952, dsc 0.01048\n",
      "Batch train [5] loss 0.99015, dsc 0.00985\n",
      "Batch train [6] loss 0.98970, dsc 0.01030\n",
      "Batch train [7] loss 0.99187, dsc 0.00813\n",
      "Batch train [8] loss 0.98981, dsc 0.01019\n",
      "Batch train [9] loss 0.98952, dsc 0.01048\n",
      "Batch train [10] loss 0.99220, dsc 0.00780\n",
      "Batch train [11] loss 0.98621, dsc 0.01379\n",
      "Batch train [12] loss 0.98835, dsc 0.01165\n",
      "Batch train [13] loss 0.99045, dsc 0.00955\n",
      "Batch train [14] loss 0.99015, dsc 0.00985\n",
      "Batch train [15] loss 0.98821, dsc 0.01179\n",
      "Batch train [16] loss 0.98897, dsc 0.01103\n",
      "Batch train [17] loss 0.98808, dsc 0.01192\n",
      "Batch train [18] loss 0.98876, dsc 0.01124\n",
      "Batch train [19] loss 0.99005, dsc 0.00995\n",
      "Batch train [20] loss 0.98894, dsc 0.01106\n",
      "Epoch [40] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 39, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  39, step 0\n",
      "Batch eval [1] loss 0.98709, dsc 0.01291\n",
      "Batch eval [2] loss 0.98937, dsc 0.01063\n",
      "Batch eval [3] loss 0.98821, dsc 0.01179\n",
      "Batch eval [4] loss 0.99139, dsc 0.00861\n",
      "Batch eval [5] loss 0.98771, dsc 0.01229\n",
      "Epoch [40] valid done\n",
      "Epoch [40] T 1204.18s, deltaT 29.93s, loss: train 0.98963, valid 0.98875, dsc: train 0.01037, valid 0.01125\n",
      "DEBUG: Writing to tensorboard before epoch True, 40, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  40, step 0\n",
      "Batch train [1] loss 0.98824, dsc 0.01176\n",
      "Batch train [2] loss 0.99052, dsc 0.00948\n",
      "Batch train [3] loss 0.98926, dsc 0.01074\n",
      "Batch train [4] loss 0.99035, dsc 0.00965\n",
      "Batch train [5] loss 0.99082, dsc 0.00918\n",
      "Batch train [6] loss 0.98986, dsc 0.01014\n",
      "Batch train [7] loss 0.98912, dsc 0.01088\n",
      "Batch train [8] loss 0.98963, dsc 0.01037\n",
      "Batch train [9] loss 0.98646, dsc 0.01354\n",
      "Batch train [10] loss 0.99081, dsc 0.00919\n",
      "Batch train [11] loss 0.99169, dsc 0.00831\n",
      "Batch train [12] loss 0.98536, dsc 0.01464\n",
      "Batch train [13] loss 0.98948, dsc 0.01052\n",
      "Batch train [14] loss 0.98968, dsc 0.01032\n",
      "Batch train [15] loss 0.99019, dsc 0.00981\n",
      "Batch train [16] loss 0.98837, dsc 0.01163\n",
      "Batch train [17] loss 0.99004, dsc 0.00996\n",
      "Batch train [18] loss 0.99047, dsc 0.00953\n",
      "Batch train [19] loss 0.99121, dsc 0.00879\n",
      "Batch train [20] loss 0.99067, dsc 0.00933\n",
      "Epoch [41] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 40, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  40, step 0\n",
      "Batch eval [1] loss 0.98704, dsc 0.01296\n",
      "Batch eval [2] loss 0.98935, dsc 0.01065\n",
      "Batch eval [3] loss 0.98817, dsc 0.01183\n",
      "Batch eval [4] loss 0.99135, dsc 0.00865\n",
      "Batch eval [5] loss 0.98765, dsc 0.01235\n",
      "Epoch [41] valid done\n",
      "Epoch [41] T 1234.07s, deltaT 29.88s, loss: train 0.98961, valid 0.98871, dsc: train 0.01039, valid 0.01129\n",
      "DEBUG: Writing to tensorboard before epoch True, 41, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  41, step 0\n",
      "Batch train [1] loss 0.99105, dsc 0.00895\n",
      "Batch train [2] loss 0.99184, dsc 0.00816\n",
      "Batch train [3] loss 0.98654, dsc 0.01346\n",
      "Batch train [4] loss 0.98958, dsc 0.01042\n",
      "Batch train [5] loss 0.98850, dsc 0.01150\n",
      "Batch train [6] loss 0.99017, dsc 0.00983\n",
      "Batch train [7] loss 0.98803, dsc 0.01197\n",
      "Batch train [8] loss 0.99165, dsc 0.00835\n",
      "Batch train [9] loss 0.99220, dsc 0.00780\n",
      "Batch train [10] loss 0.98692, dsc 0.01308\n",
      "Batch train [11] loss 0.99073, dsc 0.00927\n",
      "Batch train [12] loss 0.98654, dsc 0.01346\n",
      "Batch train [13] loss 0.99033, dsc 0.00967\n",
      "Batch train [14] loss 0.99203, dsc 0.00797\n",
      "Batch train [15] loss 0.98960, dsc 0.01040\n",
      "Batch train [16] loss 0.98788, dsc 0.01212\n",
      "Batch train [17] loss 0.99089, dsc 0.00911\n",
      "Batch train [18] loss 0.98839, dsc 0.01161\n",
      "Batch train [19] loss 0.98983, dsc 0.01017\n",
      "Batch train [20] loss 0.98933, dsc 0.01067\n",
      "Epoch [42] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 41, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  41, step 0\n",
      "Batch eval [1] loss 0.98712, dsc 0.01288\n",
      "Batch eval [2] loss 0.98938, dsc 0.01062\n",
      "Batch eval [3] loss 0.98836, dsc 0.01164\n",
      "Batch eval [4] loss 0.99137, dsc 0.00863\n",
      "Batch eval [5] loss 0.98769, dsc 0.01231\n",
      "Epoch [42] valid done\n",
      "Epoch [42] T 1263.94s, deltaT 29.87s, loss: train 0.98960, valid 0.98878, dsc: train 0.01040, valid 0.01122\n",
      "DEBUG: Writing to tensorboard before epoch True, 42, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  42, step 0\n",
      "Batch train [1] loss 0.98863, dsc 0.01137\n",
      "Batch train [2] loss 0.98719, dsc 0.01281\n",
      "Batch train [3] loss 0.99116, dsc 0.00884\n",
      "Batch train [4] loss 0.98928, dsc 0.01072\n",
      "Batch train [5] loss 0.99074, dsc 0.00926\n",
      "Batch train [6] loss 0.98737, dsc 0.01263\n",
      "Batch train [7] loss 0.99232, dsc 0.00768\n",
      "Batch train [8] loss 0.98935, dsc 0.01065\n",
      "Batch train [9] loss 0.98987, dsc 0.01013\n",
      "Batch train [10] loss 0.98960, dsc 0.01040\n",
      "Batch train [11] loss 0.98776, dsc 0.01224\n",
      "Batch train [12] loss 0.98842, dsc 0.01158\n",
      "Batch train [13] loss 0.99067, dsc 0.00933\n",
      "Batch train [14] loss 0.99008, dsc 0.00992\n",
      "Batch train [15] loss 0.99032, dsc 0.00968\n",
      "Batch train [16] loss 0.98732, dsc 0.01268\n",
      "Batch train [17] loss 0.98921, dsc 0.01079\n",
      "Batch train [18] loss 0.99126, dsc 0.00874\n",
      "Batch train [19] loss 0.99058, dsc 0.00942\n",
      "Batch train [20] loss 0.99042, dsc 0.00958\n",
      "Epoch [43] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 42, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  42, step 0\n",
      "Batch eval [1] loss 0.98705, dsc 0.01295\n",
      "Batch eval [2] loss 0.98933, dsc 0.01067\n",
      "Batch eval [3] loss 0.98821, dsc 0.01179\n",
      "Batch eval [4] loss 0.99133, dsc 0.00867\n",
      "Batch eval [5] loss 0.98766, dsc 0.01234\n",
      "Epoch [43] valid done\n",
      "Epoch [43] T 1293.82s, deltaT 29.88s, loss: train 0.98958, valid 0.98872, dsc: train 0.01042, valid 0.01128\n",
      "DEBUG: Writing to tensorboard before epoch True, 43, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  43, step 0\n",
      "Batch train [1] loss 0.98902, dsc 0.01098\n",
      "Batch train [2] loss 0.98821, dsc 0.01179\n",
      "Batch train [3] loss 0.98981, dsc 0.01019\n",
      "Batch train [4] loss 0.98616, dsc 0.01384\n",
      "Batch train [5] loss 0.98974, dsc 0.01026\n",
      "Batch train [6] loss 0.99270, dsc 0.00730\n",
      "Batch train [7] loss 0.98836, dsc 0.01164\n",
      "Batch train [8] loss 0.99187, dsc 0.00813\n",
      "Batch train [9] loss 0.98883, dsc 0.01117\n",
      "Batch train [10] loss 0.99012, dsc 0.00988\n",
      "Batch train [11] loss 0.98637, dsc 0.01363\n",
      "Batch train [12] loss 0.99023, dsc 0.00977\n",
      "Batch train [13] loss 0.98936, dsc 0.01064\n",
      "Batch train [14] loss 0.99257, dsc 0.00743\n",
      "Batch train [15] loss 0.98938, dsc 0.01062\n",
      "Batch train [16] loss 0.98788, dsc 0.01212\n",
      "Batch train [17] loss 0.99092, dsc 0.00908\n",
      "Batch train [18] loss 0.98994, dsc 0.01006\n",
      "Batch train [19] loss 0.99079, dsc 0.00921\n",
      "Batch train [20] loss 0.98917, dsc 0.01083\n",
      "Epoch [44] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 43, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  43, step 0\n",
      "Batch eval [1] loss 0.98704, dsc 0.01296\n",
      "Batch eval [2] loss 0.98930, dsc 0.01070\n",
      "Batch eval [3] loss 0.98816, dsc 0.01184\n",
      "Batch eval [4] loss 0.99133, dsc 0.00867\n",
      "Batch eval [5] loss 0.98761, dsc 0.01239\n",
      "Epoch [44] valid done\n",
      "Epoch [44] T 1323.80s, deltaT 29.98s, loss: train 0.98957, valid 0.98869, dsc: train 0.01043, valid 0.01131\n",
      "DEBUG: Writing to tensorboard before epoch True, 44, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  44, step 0\n",
      "Batch train [1] loss 0.98917, dsc 0.01083\n",
      "Batch train [2] loss 0.99132, dsc 0.00868\n",
      "Batch train [3] loss 0.98709, dsc 0.01291\n",
      "Batch train [4] loss 0.98714, dsc 0.01286\n",
      "Batch train [5] loss 0.98732, dsc 0.01268\n",
      "Batch train [6] loss 0.99154, dsc 0.00846\n",
      "Batch train [7] loss 0.98945, dsc 0.01055\n",
      "Batch train [8] loss 0.98861, dsc 0.01139\n",
      "Batch train [9] loss 0.99204, dsc 0.00796\n",
      "Batch train [10] loss 0.98879, dsc 0.01121\n",
      "Batch train [11] loss 0.99084, dsc 0.00916\n",
      "Batch train [12] loss 0.99200, dsc 0.00800\n",
      "Batch train [13] loss 0.98934, dsc 0.01066\n",
      "Batch train [14] loss 0.98909, dsc 0.01091\n",
      "Batch train [15] loss 0.98916, dsc 0.01084\n",
      "Batch train [16] loss 0.98639, dsc 0.01361\n",
      "Batch train [17] loss 0.99010, dsc 0.00990\n",
      "Batch train [18] loss 0.98907, dsc 0.01093\n",
      "Batch train [19] loss 0.99116, dsc 0.00884\n",
      "Batch train [20] loss 0.99141, dsc 0.00859\n",
      "Epoch [45] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 44, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  44, step 0\n",
      "Batch eval [1] loss 0.98704, dsc 0.01296\n",
      "Batch eval [2] loss 0.98929, dsc 0.01071\n",
      "Batch eval [3] loss 0.98830, dsc 0.01170\n",
      "Batch eval [4] loss 0.99132, dsc 0.00868\n",
      "Batch eval [5] loss 0.98759, dsc 0.01241\n",
      "Epoch [45] valid done\n",
      "Epoch [45] T 1353.77s, deltaT 29.97s, loss: train 0.98955, valid 0.98871, dsc: train 0.01045, valid 0.01129\n",
      "DEBUG: Writing to tensorboard before epoch True, 45, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  45, step 0\n",
      "Batch train [1] loss 0.98975, dsc 0.01025\n",
      "Batch train [2] loss 0.99051, dsc 0.00949\n",
      "Batch train [3] loss 0.99124, dsc 0.00876\n",
      "Batch train [4] loss 0.99030, dsc 0.00970\n",
      "Batch train [5] loss 0.98952, dsc 0.01048\n",
      "Batch train [6] loss 0.99048, dsc 0.00952\n",
      "Batch train [7] loss 0.99287, dsc 0.00713\n",
      "Batch train [8] loss 0.98745, dsc 0.01255\n",
      "Batch train [9] loss 0.99111, dsc 0.00889\n",
      "Batch train [10] loss 0.98951, dsc 0.01049\n",
      "Batch train [11] loss 0.98814, dsc 0.01186\n",
      "Batch train [12] loss 0.98856, dsc 0.01144\n",
      "Batch train [13] loss 0.98960, dsc 0.01040\n",
      "Batch train [14] loss 0.98822, dsc 0.01178\n",
      "Batch train [15] loss 0.98898, dsc 0.01102\n",
      "Batch train [16] loss 0.98986, dsc 0.01014\n",
      "Batch train [17] loss 0.98795, dsc 0.01205\n",
      "Batch train [18] loss 0.99110, dsc 0.00890\n",
      "Batch train [19] loss 0.98682, dsc 0.01318\n",
      "Batch train [20] loss 0.98876, dsc 0.01124\n",
      "Epoch [46] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 45, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  45, step 0\n",
      "Batch eval [1] loss 0.98711, dsc 0.01289\n",
      "Batch eval [2] loss 0.98935, dsc 0.01065\n",
      "Batch eval [3] loss 0.98835, dsc 0.01165\n",
      "Batch eval [4] loss 0.99131, dsc 0.00869\n",
      "Batch eval [5] loss 0.98766, dsc 0.01234\n",
      "Epoch [46] valid done\n",
      "Epoch [46] T 1383.68s, deltaT 29.91s, loss: train 0.98954, valid 0.98876, dsc: train 0.01046, valid 0.01124\n",
      "DEBUG: Writing to tensorboard before epoch True, 46, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  46, step 0\n",
      "Batch train [1] loss 0.98980, dsc 0.01020\n",
      "Batch train [2] loss 0.99053, dsc 0.00947\n",
      "Batch train [3] loss 0.98978, dsc 0.01022\n",
      "Batch train [4] loss 0.98968, dsc 0.01032\n",
      "Batch train [5] loss 0.98960, dsc 0.01040\n",
      "Batch train [6] loss 0.99093, dsc 0.00907\n",
      "Batch train [7] loss 0.98600, dsc 0.01400\n",
      "Batch train [8] loss 0.98773, dsc 0.01227\n",
      "Batch train [9] loss 0.99001, dsc 0.00999\n",
      "Batch train [10] loss 0.99116, dsc 0.00884\n",
      "Batch train [11] loss 0.98804, dsc 0.01196\n",
      "Batch train [12] loss 0.99037, dsc 0.00963\n",
      "Batch train [13] loss 0.98731, dsc 0.01269\n",
      "Batch train [14] loss 0.99051, dsc 0.00949\n",
      "Batch train [15] loss 0.99052, dsc 0.00948\n",
      "Batch train [16] loss 0.99189, dsc 0.00811\n",
      "Batch train [17] loss 0.98798, dsc 0.01202\n",
      "Batch train [18] loss 0.98912, dsc 0.01088\n",
      "Batch train [19] loss 0.99066, dsc 0.00934\n",
      "Batch train [20] loss 0.98883, dsc 0.01117\n",
      "Epoch [47] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 46, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  46, step 0\n",
      "Batch eval [1] loss 0.98699, dsc 0.01301\n",
      "Batch eval [2] loss 0.98932, dsc 0.01068\n",
      "Batch eval [3] loss 0.98816, dsc 0.01184\n",
      "Batch eval [4] loss 0.99130, dsc 0.00870\n",
      "Batch eval [5] loss 0.98761, dsc 0.01239\n",
      "Epoch [47] valid done\n",
      "Epoch [47] T 1413.59s, deltaT 29.90s, loss: train 0.98952, valid 0.98868, dsc: train 0.01048, valid 0.01132\n",
      "DEBUG: Writing to tensorboard before epoch True, 47, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  47, step 0\n",
      "Batch train [1] loss 0.98603, dsc 0.01397\n",
      "Batch train [2] loss 0.99070, dsc 0.00930\n",
      "Batch train [3] loss 0.98877, dsc 0.01123\n",
      "Batch train [4] loss 0.98799, dsc 0.01201\n",
      "Batch train [5] loss 0.99025, dsc 0.00975\n",
      "Batch train [6] loss 0.98863, dsc 0.01137\n",
      "Batch train [7] loss 0.99008, dsc 0.00992\n",
      "Batch train [8] loss 0.98892, dsc 0.01108\n",
      "Batch train [9] loss 0.99162, dsc 0.00838\n",
      "Batch train [10] loss 0.98801, dsc 0.01199\n",
      "Batch train [11] loss 0.98793, dsc 0.01207\n",
      "Batch train [12] loss 0.98897, dsc 0.01103\n",
      "Batch train [13] loss 0.98812, dsc 0.01188\n",
      "Batch train [14] loss 0.99073, dsc 0.00927\n",
      "Batch train [15] loss 0.98879, dsc 0.01121\n",
      "Batch train [16] loss 0.99143, dsc 0.00857\n",
      "Batch train [17] loss 0.99159, dsc 0.00841\n",
      "Batch train [18] loss 0.98954, dsc 0.01046\n",
      "Batch train [19] loss 0.99286, dsc 0.00714\n",
      "Batch train [20] loss 0.98929, dsc 0.01071\n",
      "Epoch [48] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 47, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  47, step 0\n",
      "Batch eval [1] loss 0.98695, dsc 0.01305\n",
      "Batch eval [2] loss 0.98926, dsc 0.01074\n",
      "Batch eval [3] loss 0.98815, dsc 0.01185\n",
      "Batch eval [4] loss 0.99126, dsc 0.00874\n",
      "Batch eval [5] loss 0.98754, dsc 0.01246\n",
      "Epoch [48] valid done\n",
      "Epoch [48] T 1443.58s, deltaT 29.98s, loss: train 0.98951, valid 0.98863, dsc: train 0.01049, valid 0.01137\n",
      "DEBUG: Writing to tensorboard before epoch True, 48, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  48, step 0\n",
      "Batch train [1] loss 0.99158, dsc 0.00842\n",
      "Batch train [2] loss 0.98828, dsc 0.01172\n",
      "Batch train [3] loss 0.98885, dsc 0.01115\n",
      "Batch train [4] loss 0.98823, dsc 0.01177\n",
      "Batch train [5] loss 0.98727, dsc 0.01273\n",
      "Batch train [6] loss 0.98943, dsc 0.01057\n",
      "Batch train [7] loss 0.98960, dsc 0.01040\n",
      "Batch train [8] loss 0.99133, dsc 0.00867\n",
      "Batch train [9] loss 0.99063, dsc 0.00937\n",
      "Batch train [10] loss 0.98983, dsc 0.01017\n",
      "Batch train [11] loss 0.98862, dsc 0.01138\n",
      "Batch train [12] loss 0.98948, dsc 0.01052\n",
      "Batch train [13] loss 0.98787, dsc 0.01213\n",
      "Batch train [14] loss 0.98724, dsc 0.01276\n",
      "Batch train [15] loss 0.98974, dsc 0.01026\n",
      "Batch train [16] loss 0.99200, dsc 0.00800\n",
      "Batch train [17] loss 0.98839, dsc 0.01161\n",
      "Batch train [18] loss 0.99027, dsc 0.00973\n",
      "Batch train [19] loss 0.99046, dsc 0.00954\n",
      "Batch train [20] loss 0.99080, dsc 0.00920\n",
      "Epoch [49] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 48, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  48, step 0\n",
      "Batch eval [1] loss 0.98699, dsc 0.01301\n",
      "Batch eval [2] loss 0.98927, dsc 0.01073\n",
      "Batch eval [3] loss 0.98815, dsc 0.01185\n",
      "Batch eval [4] loss 0.99126, dsc 0.00874\n",
      "Batch eval [5] loss 0.98753, dsc 0.01247\n",
      "Epoch [49] valid done\n",
      "Epoch [49] T 1473.37s, deltaT 29.79s, loss: train 0.98950, valid 0.98864, dsc: train 0.01050, valid 0.01136\n",
      "DEBUG: Writing to tensorboard before epoch True, 49, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  49, step 0\n",
      "Batch train [1] loss 0.98798, dsc 0.01202\n",
      "Batch train [2] loss 0.99038, dsc 0.00962\n",
      "Batch train [3] loss 0.99004, dsc 0.00996\n",
      "Batch train [4] loss 0.98979, dsc 0.01021\n",
      "Batch train [5] loss 0.98884, dsc 0.01116\n",
      "Batch train [6] loss 0.98796, dsc 0.01204\n",
      "Batch train [7] loss 0.99029, dsc 0.00971\n",
      "Batch train [8] loss 0.98752, dsc 0.01248\n",
      "Batch train [9] loss 0.99006, dsc 0.00994\n",
      "Batch train [10] loss 0.98832, dsc 0.01168\n",
      "Batch train [11] loss 0.99090, dsc 0.00910\n",
      "Batch train [12] loss 0.98713, dsc 0.01287\n",
      "Batch train [13] loss 0.98830, dsc 0.01170\n",
      "Batch train [14] loss 0.98978, dsc 0.01022\n",
      "Batch train [15] loss 0.98891, dsc 0.01109\n",
      "Batch train [16] loss 0.98813, dsc 0.01187\n",
      "Batch train [17] loss 0.98908, dsc 0.01092\n",
      "Batch train [18] loss 0.99119, dsc 0.00881\n",
      "Batch train [19] loss 0.99299, dsc 0.00701\n",
      "Batch train [20] loss 0.99209, dsc 0.00791\n",
      "Epoch [50] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 49, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  49, step 0\n",
      "Batch eval [1] loss 0.98695, dsc 0.01305\n",
      "Batch eval [2] loss 0.98934, dsc 0.01066\n",
      "Batch eval [3] loss 0.98822, dsc 0.01178\n",
      "Batch eval [4] loss 0.99128, dsc 0.00872\n",
      "Batch eval [5] loss 0.98756, dsc 0.01244\n",
      "Epoch [50] valid done\n",
      "Epoch [50] T 1503.37s, deltaT 29.99s, loss: train 0.98948, valid 0.98867, dsc: train 0.01052, valid 0.01133\n",
      "Elapsed time 0:25:03\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<IPython.core.display.Markdown object>,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<IPython.core.display.Markdown object>,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing number 0\n",
      "loss 0.9931997060775757, dsc 0.0068003167398273945, inputs_len 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce99b142fccc4c988ca43f67b90e174c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=90, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a14553e3dc34604a45f2ee8f85e620f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG shapes torch.Size([1, 160, 64, 64]) torch.Size([1, 1, 160, 64, 64]) torch.Size([1, 2, 160, 64, 64])\n",
      "DEBUG prediction max 0.996402382850647, min 0.46286532282829285\n",
      "DEBUG intersection 1156.97900390625\n",
      "DEBUG label sum 1186.0\n",
      "DEBUG prediction sum 339086.09375\n",
      "DEBUG intersection2 1156.97900390625\n",
      "DEBUG dsc 0.0068003167398273945\n",
      "DEBUG MSE 0.26867443323135376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<IPython.core.display.Markdown object>,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing number 0\n",
      "loss 0.9870641231536865, dsc 0.012935851700603962, inputs_len 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04f87f37c674c88a0eff29772431b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=90, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c9a5e1fd024052bd90cb90555e0edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG shapes torch.Size([1, 160, 64, 64]) torch.Size([1, 1, 160, 64, 64]) torch.Size([1, 2, 160, 64, 64])\n",
      "DEBUG prediction max 0.9977138042449951, min 0.4598051905632019\n",
      "DEBUG intersection 2194.7724609375\n",
      "DEBUG label sum 2259.0\n",
      "DEBUG prediction sum 337072.71875\n",
      "DEBUG intersection2 2194.7724609375\n",
      "DEBUG dsc 0.012935851700603962\n",
      "DEBUG MSE 0.2655307650566101\n"
     ]
    }
   ],
   "source": [
    "from src.model_and_training.unet_architecture_v3v2 import UNetV3v2\n",
    "\n",
    "TRAIN_MODEL3=True\n",
    "if TRAIN_MODEL3:\n",
    "    log_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_name = f'{log_date}_3d_unet_model3'\n",
    "\n",
    "    print(f'Training model with dataset MODEL3')\n",
    "    print(f'folder \\'{model_name}\\'')\n",
    "    model_info = prepare_model(epochs=50,\n",
    "                               learning_rate=1e-5,\n",
    "                               in_channels=8,\n",
    "                               input_data_channels=1,\n",
    "                               output_label_channels=1,\n",
    "                               dropout_rate=0.2,\n",
    "                               train_batch_size=2,\n",
    "                               model_name=model_name,\n",
    "                               train_dataset=train_dataset, \n",
    "                               valid_dataset=valid_dataset, \n",
    "                               test_dataset=test_dataset,\n",
    "                               model_class=UNetV3v2) # UNetV3, UNetV3v1\n",
    "    show_model_info(model_info)\n",
    "    print('\\n\\n')\n",
    "    train_loop(model_info)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    # moving model to cpu/cuda with eval mode\n",
    "    model_info['device'] = 'cpu'\n",
    "    model_info['model'] = model_info['model'].to(model_info['device'])\n",
    "    model_info['model'].eval()\n",
    "\n",
    "    # preview\n",
    "    MAX_PADDING_SLICES=160\n",
    "\n",
    "    display((Markdown(\"## Model evaluation\"),))\n",
    "\n",
    "    display((Markdown(\"### Train Eval\"),))\n",
    "    show_model_dataset_pred_preview(model_info, train_dataset, max_slices=MAX_PADDING_SLICES, default_slice=90)\n",
    "\n",
    "    display((Markdown(\"### Valid Eval\"),))\n",
    "    show_model_dataset_pred_preview(model_info, valid_dataset, max_slices=MAX_PADDING_SLICES, default_slice=90)\n",
    "\n",
    "    # display(Markdown(\"### Test Eval\"))\n",
    "    # eval_image_dataset(test_dataset, 78, 'test_plot.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<IPython.core.display.Markdown object>,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<IPython.core.display.Markdown object>,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing number 0\n",
      "loss 0.9931897521018982, dsc 0.006810272578150034, inputs_len 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e300ce46b0447193c7b8cec8665245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=90, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1d7d4627d44f59afb23501a3382e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG shapes torch.Size([1, 160, 64, 64]) torch.Size([1, 1, 160, 64, 64]) torch.Size([1, 2, 160, 64, 64])\n",
      "DEBUG prediction max 0.996263325214386, min 0.46302124857902527\n",
      "DEBUG intersection 1157.6943359375\n",
      "DEBUG label sum 1187.0\n",
      "DEBUG prediction sum 338797.71875\n",
      "DEBUG intersection2 1157.6943359375\n",
      "DEBUG dsc 0.006810272578150034\n",
      "DEBUG MSE 0.26821833848953247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<IPython.core.display.Markdown object>,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing number 0\n",
      "loss 0.9869896173477173, dsc 0.013010363094508648, inputs_len 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d107980809a45ecabea93ca0bd36cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=90, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735e772667714f33ab7f5d29c85478d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG shapes torch.Size([1, 160, 64, 64]) torch.Size([1, 1, 160, 64, 64]) torch.Size([1, 2, 160, 64, 64])\n",
      "DEBUG prediction max 0.9976966977119446, min 0.46006086468696594\n",
      "DEBUG intersection 2204.61572265625\n",
      "DEBUG label sum 2263.0\n",
      "DEBUG prediction sum 336638.5\n",
      "DEBUG intersection2 2204.61572265625\n",
      "DEBUG dsc 0.013010363094508648\n",
      "DEBUG MSE 0.26488131284713745\n"
     ]
    }
   ],
   "source": [
    "MAX_PADDING_SLICES=160\n",
    "\n",
    "display((Markdown(\"## Model evaluation\"),))\n",
    "\n",
    "display((Markdown(\"### Train Eval\"),))\n",
    "show_model_dataset_pred_preview(model_info, train_dataset, max_slices=MAX_PADDING_SLICES, default_slice=90)\n",
    "\n",
    "display((Markdown(\"### Valid Eval\"),))\n",
    "show_model_dataset_pred_preview(model_info, valid_dataset, max_slices=MAX_PADDING_SLICES, default_slice=90)\n",
    "\n",
    "# display(Markdown(\"### Test Eval\"))\n",
    "# eval_image_dataset(test_dataset, 78, 'test_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
