{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Found Google Colab')\n",
    "    !pip3 install torch torchvision torchsummary\n",
    "    !pip3 install simpleitk\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import src.helpers.oars_labels_consts as OARS_LABELS\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from src.training_helpers import loss_batch, show_model_info\n",
    "from src.helpers.prepare_model import prepare_model\n",
    "from src.helpers.train_loop import train_loop\n",
    "from src.helpers.get_dataset import get_dataset, get_dataloaders\n",
    "from src.helpers.get_dataset_info import get_dataset_info\n",
    "from src.helpers.preview_dataset import preview_dataset\n",
    "\n",
    "MAX_PADDING_SLICES = 160\n",
    "torch.manual_seed(20)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 16x dataset\n",
      "train 40, valid_size 5, test 5, full 50\n",
      "train indeces [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indeces [6, 13, 19, 25, 38]\n",
      "test indeces [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "\n",
    "dataset = get_dataset(shrink_factor=16, filter_labels=filter_labels)\n",
    "dataset.dilatate_labels(repeat=1)\n",
    "dataset.to_numpy()\n",
    "dataloaders_obj = get_dataloaders(dataset)\n",
    "\n",
    "get_dataset_info(dataset, dataloaders_obj)\n",
    "train_dataset, valid_dataset, test_dataset = itemgetter('train_dataset', 'valid_dataset', 'test_dataset')(dataloaders_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 11.816096170020396, min -0.4245887227449463\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f5f0e0f2fa484a8a38f41a8be79e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=101, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde0cfd4a41048f19c2cffa8bba46181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(dataset, preview_index=2, show_hist=False, max_padding_slices=MAX_PADDING_SLICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device running \"cuda\"\n",
      "max output channels 128\n",
      "Model number of params: 1193537, trainable 1193537\n",
      "Running training loop\n",
      "Batch eval [1] loss 0.97370, dsc 0.02630\n",
      "Batch eval [2] loss 0.97863, dsc 0.02137\n",
      "Batch eval [3] loss 0.97615, dsc 0.02385\n",
      "Batch eval [4] loss 0.97830, dsc 0.02170\n",
      "Batch eval [5] loss 0.97550, dsc 0.02450\n",
      "Epoch [1] T 7.14s, deltaT 7.14s, loss: train 0.96122, valid 0.97646, dsc: train 0.03878, valid 0.02354\n",
      "Batch eval [1] loss 0.94468, dsc 0.05532\n",
      "Batch eval [2] loss 0.95382, dsc 0.04618\n",
      "Batch eval [3] loss 0.94938, dsc 0.05062\n",
      "Batch eval [4] loss 0.95733, dsc 0.04267\n",
      "Batch eval [5] loss 0.94650, dsc 0.05350\n",
      "Epoch [2] T 14.28s, deltaT 7.13s, loss: train 0.95453, valid 0.95034, dsc: train 0.04547, valid 0.04966\n",
      "Batch eval [1] loss 0.94068, dsc 0.05932\n",
      "Batch eval [2] loss 0.95014, dsc 0.04986\n",
      "Batch eval [3] loss 0.94329, dsc 0.05671\n",
      "Batch eval [4] loss 0.95369, dsc 0.04631\n",
      "Batch eval [5] loss 0.94093, dsc 0.05907\n",
      "Epoch [3] T 21.39s, deltaT 7.12s, loss: train 0.95049, valid 0.94575, dsc: train 0.04951, valid 0.05425\n",
      "Batch eval [1] loss 0.93304, dsc 0.06696\n",
      "Batch eval [2] loss 0.94407, dsc 0.05593\n",
      "Batch eval [3] loss 0.93626, dsc 0.06374\n",
      "Batch eval [4] loss 0.94854, dsc 0.05146\n",
      "Batch eval [5] loss 0.93486, dsc 0.06514\n",
      "Epoch [4] T 28.51s, deltaT 7.12s, loss: train 0.94598, valid 0.93935, dsc: train 0.05402, valid 0.06065\n",
      "Batch eval [1] loss 0.91849, dsc 0.08151\n",
      "Batch eval [2] loss 0.93194, dsc 0.06806\n",
      "Batch eval [3] loss 0.92429, dsc 0.07571\n",
      "Batch eval [4] loss 0.93750, dsc 0.06250\n",
      "Batch eval [5] loss 0.92057, dsc 0.07943\n",
      "Epoch [5] T 35.65s, deltaT 7.13s, loss: train 0.94048, valid 0.92656, dsc: train 0.05952, valid 0.07344\n",
      "Elapsed time 0:00:35\n"
     ]
    }
   ],
   "source": [
    "model_info = prepare_model(epochs=5, in_channels=8, train_dataset=train_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset)\n",
    "show_model_info(model_info, MAX_PADDING_SLICES)\n",
    "\n",
    "train_loop_params = {k:v for k,v in model_info.items() if k not in ['model_total_params', 'model_total_trainable_params']}\n",
    "train_loop(**train_loop_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, device, optimizer, criterion = itemgetter('model', 'device', 'optimizer', 'criterion')(model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 1x dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.han_oars_dataset.HaNOarsDataset at 0x7fd6032042b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_res_dataset = get_dataset(shrink_factor=1, filter_labels=filter_labels)\n",
    "full_res_dataset.to_numpy()\n",
    "\n",
    "dataset.data_list[0].shape, full_res_dataset.data_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 160, 32, 32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 160, 512, 512)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_image(input_img, expand_factor=16): # input numpy shape (1, MAX_PADDING_SLICES, x, x)\n",
    "#     expanded_input_img = np.resize(tmp_output.copy(), (1, 1, 160, 512, 512))\n",
    "#     for i in range(MAX_PADDING_SLICES):\n",
    "#         expanded_input_img[0, 0, i] = scipy.ndimage.zoom(tmp_output[0, 0, i], expand_factor, order=0) # TODO: zoom is using some interpolation, thus its not exact\n",
    "\n",
    "    expanded_input_img = np.repeat(np.repeat(tmp_output, 16, axis=3), 16, axis=4)\n",
    "        \n",
    "    return expanded_input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "tmp = np.expand_dims(dataset.data_list[0], axis=0)\n",
    "tmp_output = model.cpu()(torch.from_numpy(tmp).float())\n",
    "tmp_output = tmp_output.cpu().detach().numpy()\n",
    "threshold = 0.5\n",
    "tmp_output = (tmp_output > threshold) * 1\n",
    "exp_tmp_output = expand_image(tmp_output, expand_factor=16)\n",
    "\n",
    "tmp_output.shape, exp_tmp_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.021978759765625, 0.02318732738494873)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_slice = 100\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(tmp_output[0, 0, img_slice], cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(expanded_input_img[0, 0, img_slice], cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()\n",
    "\n",
    "tmp_output.sum()/tmp_output.size, expanded_input_img.sum()/expanded_input_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Train Eval"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing number 31\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-96c9af2e06e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# noinspection PyTypeChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## Train Eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0meval_image_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;31m# noinspection PyTypeChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## Valid Eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-96c9af2e06e3>\u001b[0m in \u001b[0;36meval_image_dataset\u001b[0;34m(dataset, def_slice, figfile)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mitem_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_dsc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/unet_architecture_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdconv_down1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# print(\"after pool1: \", h.data[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    478\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_triple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                             self.dilation, self.groups)\n\u001b[0;32m--> 480\u001b[0;31m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    481\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "\n",
    "def eval_image_dataset(dataset, def_slice=90, figfile=None):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        aSlider = widgets.IntSlider(min=0, max=MAX_PADDING_SLICES-1, step=1, value=def_slice)\n",
    "        ui = widgets.VBox([\n",
    "            widgets.HBox([aSlider])\n",
    "        ])\n",
    "\n",
    "        model.eval()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f'showing number {dataset.indices[0]}')\n",
    "        inputs, labels = dataset[0]\n",
    "        inputs = torch.from_numpy(np.array([inputs])).to(device).float()\n",
    "        labels = torch.from_numpy(np.array([labels])).to(device).float()\n",
    "        prediction = model(inputs)\n",
    "\n",
    "        item_loss, item_dsc, inputs_len = loss_batch(model, optimizer, criterion, inputs, labels)\n",
    "        print(f'loss {item_loss}, dsc {item_dsc}, inputs_len {inputs_len}')\n",
    "\n",
    "        inputs = inputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "        prediction_np = prediction.cpu().detach().numpy()\n",
    "\n",
    "        plt.hist(prediction_np.flatten(), 20)\n",
    "        plt.title('Distribution of prediction values')\n",
    "        plt.show()\n",
    "\n",
    "        def f(a):\n",
    "            plt.figure(figsize=(30, 16))\n",
    "            tmp_ax = plt.subplot(1, 3, 1)\n",
    "            tmp_ax.title.set_text('Input')\n",
    "            plt.imshow(inputs[0, 0, a], cmap=\"gray\")\n",
    "\n",
    "            tmp_ax = plt.subplot(1, 3, 2)\n",
    "            tmp_ax.title.set_text('Label')\n",
    "            plt.imshow(labels[0, a], cmap=\"gray\")\n",
    "\n",
    "            tmp_ax = plt.subplot(1, 3, 3)\n",
    "            tmp_ax.title.set_text('Prediction')\n",
    "            plt.imshow(prediction_np[0, 0, a], cmap=\"gray\", vmin=0, vmax=1)\n",
    "            #     plt.subplot(2, 2, 4)\n",
    "            #     plt.imshow(prediction_np[0, 0, a], cmap=\"gray\")\n",
    "\n",
    "            if figfile is not None:\n",
    "                plt.savefig(figfile, dpi=96)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        out = widgets.interactive_output(f, {'a': aSlider })\n",
    "        display(ui, out)\n",
    "\n",
    "        print('DEBUG shapes', prediction[:, 0].shape, labels.shape, inputs.shape)\n",
    "        print(f'DEBUG prediction max {prediction.max().item()}, min {prediction.min().item()}')\n",
    "        print('DEBUG intersection', (labels.cpu() *  prediction.cpu()[:,0]).sum().item())\n",
    "        print('DEBUG label sum', labels.cpu().sum().item())\n",
    "        print('DEBUG prediction sum', prediction.cpu()[:,0].sum().item())\n",
    "\n",
    "        smooth = 1e-6\n",
    "        y_pred = prediction.cpu()[:,0].contiguous().view(-1)\n",
    "        y_true = labels.cpu()[:].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + smooth) / (\n",
    "            y_pred.sum() + y_true.sum() + smooth\n",
    "        )\n",
    "\n",
    "        print('DEBUG intersection2', intersection.item())\n",
    "        print('DEBUG dsc', dsc.item())\n",
    "        print('DEBUG MSE', (labels.cpu() - prediction.cpu()[:,0]).pow(2).mean().item())\n",
    "\n",
    "\n",
    "# noinspection PyTypeChecker\n",
    "display(Markdown(\"## Train Eval\"))\n",
    "eval_image_dataset(train_dataset, 90)\n",
    "# noinspection PyTypeChecker\n",
    "display(Markdown(\"## Valid Eval\"))\n",
    "eval_image_dataset(valid_dataset, 90)\n",
    "# display(Markdown(\"## Test Eval\"))\n",
    "# eval_image_dataset(test_dataset, 78, 'test_plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_corners(arr):\n",
    "    display(arr.shape)\n",
    "\n",
    "    ind = np.nonzero(arr.any(axis=0))[0] # indices of non empty columns\n",
    "    ax0_min = ind[0]\n",
    "    ax0_max = ind[-1]\n",
    "    ax0_size = ax0_max - ax0_min + 1\n",
    "\n",
    "    ind = np.nonzero(arr.any(axis=1))[0] # indices of non empty rows\n",
    "    ax1_min = ind[0]\n",
    "    ax1_max = ind[-1]\n",
    "    ax1_size = ax1_max - ax1_min + 1\n",
    "\n",
    "    display(ax0_size, ax1_size, ax0_min, ax0_max, ax1_min, ax1_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
