{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n",
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/dp_tomastik/code')\n",
    "    !bash \"/content/drive/My Drive/dp_tomastik/code/scripts/install_libs.sh\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "from torchio import RandomAffine, Compose, ZNormalization\n",
    "\n",
    "from src.helpers import show_cuda_usage, preview_model_dataset_pred, preview_dataset\n",
    "from src.helpers import get_threshold_info_df, get_rescaled_preds\n",
    "from src.helpers import compare_prediction_with_ground_true, compare_one_prediction_with_ground_true\n",
    "from src.helpers import get_img_outliers_pixels, get_raw_with_prediction\n",
    "from src.helpers import get_rescaled_pred\n",
    "\n",
    "from src.dataset import transform_input, get_norm_transform\n",
    "from src.dataset import get_full_res_cut, get_cut_lists, OARS_LABELS, get_dataset, get_dataset_info, get_dataset_transform\n",
    "from src.dataset import split_dataset, copy_split_dataset\n",
    "from src.consts import DATASET_MAX_BOUNDING_BOX, DESIRE_BOUNDING_BOX_SIZE\n",
    "from src.model_and_training import prepare_model, train_loop, show_model_info, load_checkpoint_model_info\n",
    "from src.model_and_training import iterate_model_v3v2\n",
    "from src.model_and_training.getters.get_device import get_device\n",
    "from src.model_and_training.architectures.unet_architecture_v3v2 import UNetV3v2\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "torch.manual_seed(20)\n",
    "logging.basicConfig(filename='logs/all_organs_jupyter.log', level=logging.DEBUG)\n",
    "\n",
    "print('Dataset biggest bounding box wihtout spinal cord', DATASET_MAX_BOUNDING_BOX)\n",
    "print('Cut target size', DESIRE_BOUNDING_BOX_SIZE)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_models(oar_key):\n",
    "    possible_models = [folder_name for folder_name in os.listdir('./models') if oar_key in folder_name]    \n",
    "    \n",
    "    return possible_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading precourse neural network with datasets:\n",
    "- loading fullres dataset (512x512)\n",
    "- loading lowres dataset (32x32)\n",
    "- loading precourse model\n",
    "- parsing dataset to create cut dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 16x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "dilatating 1x dataset\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n",
      "CUDA using 1x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolas/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'src.losses.dice_loss.DiceLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model number of params: 298881, trainable 298881\n",
      "get_cut_lists: Cutting index 0\n",
      "get_full_res_cut: Removing 10/1335 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1223526 1223526\n",
      "get_cut_lists: Cutting index 1\n",
      "get_full_res_cut: Removing 0/1416 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1326052 1326052\n",
      "get_cut_lists: Cutting index 2\n",
      "get_full_res_cut: Removing 0/1873 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 20   0 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1890464 1890464\n",
      "get_cut_lists: Cutting index 3\n",
      "get_full_res_cut: Removing 0/1545 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [17 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1560217 1560217\n",
      "get_cut_lists: Cutting index 4\n",
      "get_full_res_cut: Removing 9/1510 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 48 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1451227 1451227\n",
      "get_cut_lists: Cutting index 5\n",
      "get_full_res_cut: Removing 0/1390 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1262651 1262651\n",
      "get_cut_lists: Cutting index 6\n",
      "get_full_res_cut: Removing 0/1451 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1566938 1566938\n",
      "get_cut_lists: Cutting index 7\n",
      "get_full_res_cut: Removing 0/958 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [29 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 869847 869847\n",
      "get_cut_lists: Cutting index 8\n",
      "get_full_res_cut: Removing 0/1489 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1397249 1397249\n",
      "get_cut_lists: Cutting index 9\n",
      "get_full_res_cut: Removing 0/1465 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1350330 1350330\n",
      "get_cut_lists: Cutting index 10\n",
      "get_full_res_cut: Removing 0/1650 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20  0 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1635868 1635868\n",
      "get_cut_lists: Cutting index 11\n",
      "get_full_res_cut: Removing 16/1371 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1283062 1283062\n",
      "get_cut_lists: Cutting index 12\n",
      "get_full_res_cut: Removing 0/1594 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1518406 1518406\n",
      "get_cut_lists: Cutting index 13\n",
      "get_full_res_cut: Removing 0/1482 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1504194 1504194\n",
      "get_cut_lists: Cutting index 14\n",
      "get_full_res_cut: Removing 0/1191 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1084254 1084254\n",
      "get_cut_lists: Cutting index 15\n",
      "get_full_res_cut: Removing 0/1267 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1221257 1221257\n",
      "get_cut_lists: Cutting index 16\n",
      "get_full_res_cut: Removing 2/1009 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 64 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 945639 945639\n",
      "get_cut_lists: Cutting index 17\n",
      "get_full_res_cut: Removing 0/1498 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1469035 1469035\n",
      "get_cut_lists: Cutting index 18\n",
      "get_full_res_cut: Removing 7/1371 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1322571 1322571\n",
      "get_cut_lists: Cutting index 19\n",
      "get_full_res_cut: Removing 0/1608 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [17 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1593516 1593516\n",
      "get_cut_lists: Cutting index 20\n",
      "get_full_res_cut: Removing 0/1359 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1390348 1390348\n",
      "get_cut_lists: Cutting index 21\n",
      "get_full_res_cut: Removing 0/1536 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 22  16 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1463017 1463017\n",
      "get_cut_lists: Cutting index 22\n",
      "get_full_res_cut: Removing 0/1231 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [26 32 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1162215 1162215\n",
      "get_cut_lists: Cutting index 23\n",
      "get_full_res_cut: Removing 0/1154 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1029805 1029805\n",
      "get_cut_lists: Cutting index 24\n",
      "get_full_res_cut: Removing 0/1669 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 29 -16   8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1689537 1689537\n",
      "get_cut_lists: Cutting index 25\n",
      "get_full_res_cut: Removing 0/1267 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1141739 1141739\n",
      "get_cut_lists: Cutting index 26\n",
      "get_full_res_cut: Removing 9/1289 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [18 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1167835 1167835\n",
      "get_cut_lists: Cutting index 27\n",
      "get_full_res_cut: Removing 15/1780 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23  0  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1783264 1783264\n",
      "get_cut_lists: Cutting index 28\n",
      "get_full_res_cut: Removing 25/1916 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 22  16 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1944758 1944758\n",
      "get_cut_lists: Cutting index 29\n",
      "get_full_res_cut: Removing 0/1369 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1583396 1583396\n",
      "get_cut_lists: Cutting index 30\n",
      "get_full_res_cut: Removing 11/1390 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1248609 1248609\n",
      "get_cut_lists: Cutting index 31\n",
      "get_full_res_cut: Removing 0/1087 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 947124 947124\n",
      "get_cut_lists: Cutting index 32\n",
      "get_full_res_cut: Removing 39/1798 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [16 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1648187 1648187\n",
      "get_cut_lists: Cutting index 33\n",
      "get_full_res_cut: Removing 0/1327 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1214697 1214697\n",
      "get_cut_lists: Cutting index 34\n",
      "get_full_res_cut: Removing 0/1528 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1445951 1445951\n",
      "get_cut_lists: Cutting index 35\n",
      "get_full_res_cut: Removing 0/1981 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 14  32 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1963068 1963068\n",
      "get_cut_lists: Cutting index 36\n",
      "get_full_res_cut: Removing 0/1403 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [26 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1241941 1241941\n",
      "get_cut_lists: Cutting index 37\n",
      "get_full_res_cut: Removing 0/1417 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 32 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1298886 1298886\n",
      "get_cut_lists: Cutting index 38\n",
      "get_full_res_cut: Removing 0/1567 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1731533 1731533\n",
      "get_cut_lists: Cutting index 39\n",
      "get_full_res_cut: Removing 15/1286 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1067335 1067335\n",
      "get_cut_lists: Cutting index 40\n",
      "get_full_res_cut: Removing 0/1328 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1311715 1311715\n",
      "get_cut_lists: Cutting index 41\n",
      "get_full_res_cut: Removing 0/1559 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [18 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1411792 1411792\n",
      "get_cut_lists: Cutting index 42\n",
      "get_full_res_cut: Removing 10/1102 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 951804 951804\n",
      "get_cut_lists: Cutting index 43\n",
      "get_full_res_cut: Removing 0/1143 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [32 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1024831 1024831\n",
      "get_cut_lists: Cutting index 44\n",
      "get_full_res_cut: Removing 0/1734 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [13 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1763923 1763923\n",
      "get_cut_lists: Cutting index 45\n",
      "get_full_res_cut: Removing 0/1156 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 16 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1115633 1115633\n",
      "get_cut_lists: Cutting index 46\n",
      "get_full_res_cut: Removing 0/1657 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1670156 1670156\n",
      "get_cut_lists: Cutting index 47\n",
      "get_full_res_cut: Removing 0/1436 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1413179 1413179\n",
      "get_cut_lists: Cutting index 48\n",
      "get_full_res_cut: Removing 0/1002 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [28 64 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 781269 781269\n",
      "get_cut_lists: Cutting index 49\n",
      "get_full_res_cut: Removing 0/1705 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1756965 1756965\n"
     ]
    }
   ],
   "source": [
    "datasets_params = ['train_dataset', 'valid_dataset', 'test_dataset']\n",
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "\n",
    "# low res\n",
    "low_res_dataset = get_dataset(dataset_size=50, shrink_factor=16, filter_labels=filter_labels, unify_labels=True)\n",
    "low_res_dataset.dilatate_labels(repeat=1)\n",
    "low_res_dataset.to_numpy()\n",
    "low_res_split_dataset_obj = split_dataset(low_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset = itemgetter(*datasets_params)(low_res_split_dataset_obj)\n",
    "\n",
    "# full res\n",
    "full_res_dataset = get_dataset(dataset_size=50, shrink_factor=1, filter_labels=filter_labels, unify_labels=False)\n",
    "full_res_dataset.to_numpy()\n",
    "full_res_split_dataset_obj = copy_split_dataset(full_res_dataset, low_res_split_dataset_obj)\n",
    "\n",
    "# low res model - precourse model\n",
    "epoch = 500\n",
    "log_date = datetime.datetime(year=2020, month=10, day=27, hour=11, minute=45, second=30).strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f'{log_date}_3d_unet_PRECOURSE'\n",
    "\n",
    "low_res_model_info = load_checkpoint_model_info(model_name, epoch, train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset)\n",
    "show_model_info(low_res_model_info)\n",
    "\n",
    "# moving low res to gpu\n",
    "low_res_model_info['device'] = get_device()\n",
    "# low_res_model_info['device'] = 'cpu'\n",
    "low_res_model_info['model'] = low_res_model_info['model'].to(low_res_model_info['device'])\n",
    "low_res_model_info['model'].eval()\n",
    "\n",
    "# cut res\n",
    "cut_full_res_dataset = full_res_dataset.copy(copy_lists=False)\n",
    "cut_full_res_dataset = get_cut_lists(low_res_model_info['model'],\n",
    "                                     low_res_model_info['device'],\n",
    "                                     low_res_dataset, \n",
    "                                     full_res_dataset, \n",
    "                                     cut_full_res_dataset, \n",
    "                                     low_res_mask_threshold=0.5)\n",
    "cut_full_res_dataset.set_output_label(None)\n",
    "cut_split_dataset_obj = copy_split_dataset(cut_full_res_dataset, low_res_split_dataset_obj)\n",
    "cut_train_dataset, cut_valid_dataset, cut_test_dataset = itemgetter(*datasets_params)(cut_split_dataset_obj)\n",
    "\n",
    "# moving low res model to cpu\n",
    "low_res_model_info['device'] = 'cpu'\n",
    "low_res_model_info['model'] = low_res_model_info['model'].to(low_res_model_info['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(low_res_dataset, low_res_split_dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071, min -1024\n",
      "label max 22, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5e45a00f384729b327881ea313d073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=0, max=0))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cb1f9189ef41fa9f9aca202991a3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(cut_full_res_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding registration to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "from src.helpers import get_registration_transform_np, preview_3d_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 120, 219), (136, 120, 219), (136, 120, 219), (136, 120, 219))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_ri = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/RI.mhd'))\n",
    "atlas_brainstem_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/brain_stem_map.mhd'))\n",
    "atlas_left_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/left_parotid_map.mhd'))\n",
    "atlas_right_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/right_parotid_map.mhd'))\n",
    "\n",
    "atlas_ri.shape, atlas_brainstem_map.shape, atlas_left_parotid_map.shape, atlas_right_parotid_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_input = (atlas_ri[70:], atlas_left_parotid_map[70:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62a6b9a0d2a4872916602756ca1c21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63add7609ed84cd8886e38234432ff6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_input = cut_full_res_dataset.get_raw_item_with_label_filter(0)\n",
    "tmp = get_registration_transform_np(atlas_input, dataset_input, numberOfIterations=500, show=False, preview=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_registration_list(dataset, atlas_input):\n",
    "    merged_list = list()\n",
    "\n",
    "    for dataset_index in range(len(dataset)):\n",
    "        dataset_input = dataset.get_raw_item_with_label_filter(dataset_index)\n",
    "\n",
    "        reg_output = get_registration_transform_np(atlas_input, dataset_input, numberOfIterations=500, show=False, preview=False)\n",
    "        reg_output = reg_output.astype(np.float32)\n",
    "        print(f'Registration done for index: {dataset_index}')\n",
    "        merged_output = np.array([dataset.data_list[dataset_index][0], reg_output])\n",
    "\n",
    "        merged_list.append(merged_output)\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration done for index: 0\n",
      "Registration done for index: 1\n",
      "Registration done for index: 2\n",
      "Registration done for index: 3\n",
      "Registration done for index: 4\n",
      "Registration done for index: 5\n",
      "Registration done for index: 6\n",
      "Registration done for index: 7\n",
      "Registration done for index: 8\n",
      "Registration done for index: 9\n",
      "Registration done for index: 10\n",
      "Registration done for index: 11\n",
      "Registration done for index: 12\n",
      "Registration done for index: 13\n",
      "Registration done for index: 14\n",
      "Registration done for index: 15\n",
      "Registration done for index: 16\n",
      "Registration done for index: 17\n",
      "Registration done for index: 18\n",
      "Registration done for index: 19\n",
      "Registration done for index: 20\n",
      "Registration done for index: 21\n",
      "Registration done for index: 22\n",
      "Registration done for index: 23\n",
      "Registration done for index: 24\n",
      "Registration done for index: 25\n",
      "Registration done for index: 26\n",
      "Registration done for index: 27\n",
      "Registration done for index: 28\n",
      "Registration done for index: 29\n",
      "Registration done for index: 30\n",
      "Registration done for index: 31\n",
      "Registration done for index: 32\n",
      "Registration done for index: 33\n",
      "Registration done for index: 34\n",
      "Registration done for index: 35\n",
      "Registration done for index: 36\n",
      "Registration done for index: 37\n",
      "Registration done for index: 38\n",
      "Registration done for index: 39\n",
      "Registration done for index: 40\n",
      "Registration done for index: 41\n",
      "Registration done for index: 42\n",
      "Registration done for index: 43\n",
      "Registration done for index: 44\n",
      "Registration done for index: 45\n",
      "Registration done for index: 46\n",
      "Registration done for index: 47\n",
      "Registration done for index: 48\n",
      "Registration done for index: 49\n"
     ]
    }
   ],
   "source": [
    "registration_list = create_registration_list(cut_full_res_dataset, atlas_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_full_res_dataset.data_list = registration_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe76ebf3382a4eaeab5ccc8aac307a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eed4ebb947476e9ae82f6613805276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836c315c0c0c43528b4a2a514174b015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5045166004364f008b8db5ef3e8e7dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb043b71ad0468396d67aa077ecbe1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7def3bbb18ac473fa4b86b25f26cdabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_3d_image(registration_list[0][0], figsize=(10, 10))\n",
    "preview_3d_image(registration_list[0][1], figsize=(10, 10))\n",
    "\n",
    "preview_3d_image(cut_full_res_dataset.label_list[1][0] == OARS_LABELS.PAROTID_GLAND_R, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training all organs models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking list used for training single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset label 'BRAIN_STEM', \t value '1'\n",
      "dataset label 'EYE_L', \t value '2'\n",
      "dataset label 'EYE_R', \t value '3'\n",
      "dataset label 'LENS_L', \t value '4'\n",
      "dataset label 'LENS_R', \t value '5'\n",
      "dataset label 'OPT_NERVE_L', \t value '6'\n",
      "dataset label 'OPT_NERVE_R', \t value '7'\n",
      "dataset label 'OPT_CHIASMA', \t value '8'\n",
      "dataset label 'TEMPORAL_LOBES_L', \t value '9'\n",
      "dataset label 'TEMPORAL_LOBES_R', \t value '10'\n",
      "dataset label 'PITUITARY', \t value '11'\n",
      "dataset label 'PAROTID_GLAND_L', \t value '12'\n",
      "dataset label 'PAROTID_GLAND_R', \t value '13'\n",
      "dataset label 'INNER_EAR_L', \t value '14'\n",
      "dataset label 'INNER_EAR_R', \t value '15'\n",
      "dataset label 'MID_EAR_L', \t value '16'\n",
      "dataset label 'MID_EAR_R', \t value '17'\n",
      "dataset label 'T_M_JOINT_L', \t value '18'\n",
      "dataset label 'T_M_JOINT_R', \t value '19'\n",
      "dataset label 'MANDIBLE_L', \t value '21'\n",
      "dataset label 'MANDIBLE_R', \t value '22'\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "for OAR_KEY, OAR_VALUE in list(filter_labels.items())[:]:\n",
    "    cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "    print(f'dataset label \\'{OAR_KEY}\\', \\t value \\'{OAR_VALUE}\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAROTID_GLAND_R, 13\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = [tmp_list[12]]\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with dataset label 'PAROTID_GLAND_R', value '13'\n",
      "folder '20210322-220837_3d_unet_lowres_model3v2_PAROTID_GLAND_R'\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Model number of params: 1221609, trainable 1221609\n",
      "\n",
      "\n",
      "\n",
      "Running training loop\n",
      "DEBUG: Writing to tensorboard before epoch True, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  0, step 0\n",
      "Batch train [1] loss 0.99418, dsc 0.00582\n",
      "Batch train [1] loss 0.98857, dsc 0.01143\n",
      "Batch train [1] loss 0.99229, dsc 0.00771\n",
      "Batch train [1] loss 0.99372, dsc 0.00628\n",
      "Batch train [1] loss 0.98886, dsc 0.01114\n",
      "Batch train [1] loss 0.99217, dsc 0.00783\n",
      "Batch train [1] loss 0.99490, dsc 0.00510\n",
      "Batch train [1] loss 0.99484, dsc 0.00516\n",
      "Batch train [1] loss 0.99229, dsc 0.00771\n",
      "Batch train [1] loss 0.98776, dsc 0.01224\n",
      "Batch train [1] loss 0.99421, dsc 0.00579\n",
      "Batch train [1] loss 0.99505, dsc 0.00495\n",
      "Batch train [1] loss 0.98936, dsc 0.01064\n",
      "Batch train [1] loss 0.98704, dsc 0.01296\n",
      "Batch train [1] loss 0.99503, dsc 0.00497\n",
      "Batch train [1] loss 0.99308, dsc 0.00692\n",
      "Batch train [1] loss 0.99245, dsc 0.00755\n",
      "Batch train [1] loss 0.99302, dsc 0.00698\n",
      "Batch train [1] loss 0.99279, dsc 0.00721\n",
      "Batch train [1] loss 0.99177, dsc 0.00823\n",
      "Batch train [1] loss 0.98199, dsc 0.01801\n",
      "Batch train [1] loss 0.99257, dsc 0.00743\n",
      "Batch train [1] loss 0.99356, dsc 0.00644\n",
      "Batch train [1] loss 0.99398, dsc 0.00602\n",
      "Batch train [1] loss 0.98300, dsc 0.01700\n",
      "Batch train [1] loss 0.98733, dsc 0.01267\n",
      "Batch train [1] loss 0.98536, dsc 0.01464\n",
      "Batch train [1] loss 0.98460, dsc 0.01540\n",
      "Batch train [1] loss 0.97891, dsc 0.02109\n",
      "Batch train [1] loss 0.98447, dsc 0.01553\n",
      "Batch train [1] loss 0.98339, dsc 0.01661\n",
      "Batch train [1] loss 0.99136, dsc 0.00864\n",
      "Batch train [1] loss 0.98729, dsc 0.01271\n",
      "Batch train [1] loss 0.98530, dsc 0.01470\n",
      "Batch train [1] loss 0.98468, dsc 0.01532\n",
      "Batch train [1] loss 0.98493, dsc 0.01507\n",
      "Batch train [1] loss 0.98318, dsc 0.01682\n",
      "Batch train [1] loss 0.98076, dsc 0.01924\n",
      "Batch train [1] loss 0.97877, dsc 0.02123\n",
      "Batch train [1] loss 0.98142, dsc 0.01858\n",
      "Epoch [1] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Batch eval [1] loss 0.98614, dsc 0.01386\n",
      "Batch eval [1] loss 0.98982, dsc 0.01018\n",
      "Batch eval [1] loss 0.98475, dsc 0.01525\n",
      "Batch eval [1] loss 0.99010, dsc 0.00990\n",
      "Batch eval [1] loss 0.99228, dsc 0.00772\n",
      "Epoch [1] valid done\n",
      "Epoch [1] T 128.94s, deltaT 128.94s, loss: train 0.98876, valid 0.98862, dsc: train 0.01124, valid 0.01138\n",
      "DEBUG: Writing to tensorboard before epoch True, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  1, step 0\n",
      "Batch train [1] loss 0.97984, dsc 0.02016\n",
      "Batch train [1] loss 0.98576, dsc 0.01424\n",
      "Batch train [1] loss 0.98273, dsc 0.01727\n",
      "Batch train [1] loss 0.98677, dsc 0.01323\n",
      "Batch train [1] loss 0.98444, dsc 0.01556\n",
      "Batch train [1] loss 0.98091, dsc 0.01909\n",
      "Batch train [1] loss 0.98001, dsc 0.01999\n",
      "Batch train [1] loss 0.98984, dsc 0.01016\n",
      "Batch train [1] loss 0.97765, dsc 0.02235\n",
      "Batch train [1] loss 0.98360, dsc 0.01640\n",
      "Batch train [1] loss 0.98845, dsc 0.01155\n",
      "Batch train [1] loss 0.98573, dsc 0.01427\n",
      "Batch train [1] loss 0.98252, dsc 0.01748\n",
      "Batch train [1] loss 0.99198, dsc 0.00802\n",
      "Batch train [1] loss 0.98821, dsc 0.01179\n",
      "Batch train [1] loss 0.97604, dsc 0.02396\n",
      "Batch train [1] loss 0.97343, dsc 0.02657\n",
      "Batch train [1] loss 0.98959, dsc 0.01041\n",
      "Batch train [1] loss 0.97544, dsc 0.02456\n",
      "Batch train [1] loss 0.98169, dsc 0.01831\n",
      "Batch train [1] loss 0.99098, dsc 0.00902\n",
      "Batch train [1] loss 0.98214, dsc 0.01786\n",
      "Batch train [1] loss 0.98155, dsc 0.01845\n",
      "Batch train [1] loss 0.98936, dsc 0.01064\n",
      "Batch train [1] loss 0.97751, dsc 0.02249\n",
      "Batch train [1] loss 0.97589, dsc 0.02411\n",
      "Batch train [1] loss 0.98990, dsc 0.01010\n",
      "Batch train [1] loss 0.97465, dsc 0.02535\n",
      "Batch train [1] loss 0.98340, dsc 0.01660\n",
      "Batch train [1] loss 0.98992, dsc 0.01008\n",
      "Batch train [1] loss 0.98856, dsc 0.01144\n",
      "Batch train [1] loss 0.98423, dsc 0.01577\n",
      "Batch train [1] loss 0.98783, dsc 0.01217\n",
      "Batch train [1] loss 0.98355, dsc 0.01645\n",
      "Batch train [1] loss 0.99122, dsc 0.00878\n",
      "Batch train [1] loss 0.98024, dsc 0.01976\n",
      "Batch train [1] loss 0.99040, dsc 0.00960\n",
      "Batch train [1] loss 0.99157, dsc 0.00843\n",
      "Batch train [1] loss 0.98210, dsc 0.01790\n",
      "Batch train [1] loss 0.98588, dsc 0.01412\n",
      "Epoch [2] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  1, step 0\n",
      "Batch eval [1] loss 0.98329, dsc 0.01671\n",
      "Batch eval [1] loss 0.98769, dsc 0.01231\n",
      "Batch eval [1] loss 0.98152, dsc 0.01848\n",
      "Batch eval [1] loss 0.98805, dsc 0.01195\n",
      "Batch eval [1] loss 0.99088, dsc 0.00912\n",
      "Epoch [2] valid done\n",
      "Epoch [2] T 259.45s, deltaT 130.50s, loss: train 0.98414, valid 0.98629, dsc: train 0.01586, valid 0.01371\n",
      "DEBUG: Writing to tensorboard before epoch True, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  2, step 0\n",
      "Batch train [1] loss 0.98140, dsc 0.01860\n",
      "Batch train [1] loss 0.98176, dsc 0.01824\n",
      "Batch train [1] loss 0.97991, dsc 0.02009\n",
      "Batch train [1] loss 0.97702, dsc 0.02298\n",
      "Batch train [1] loss 0.97859, dsc 0.02141\n",
      "Batch train [1] loss 0.99109, dsc 0.00891\n",
      "Batch train [1] loss 0.97693, dsc 0.02307\n",
      "Batch train [1] loss 0.97465, dsc 0.02535\n",
      "Batch train [1] loss 0.98151, dsc 0.01849\n",
      "Batch train [1] loss 0.98921, dsc 0.01079\n",
      "Batch train [1] loss 0.97237, dsc 0.02763\n",
      "Batch train [1] loss 0.99144, dsc 0.00856\n",
      "Batch train [1] loss 0.98736, dsc 0.01264\n",
      "Batch train [1] loss 0.97515, dsc 0.02485\n",
      "Batch train [1] loss 0.98794, dsc 0.01206\n",
      "Batch train [1] loss 0.98502, dsc 0.01498\n",
      "Batch train [1] loss 0.98730, dsc 0.01270\n",
      "Batch train [1] loss 0.98254, dsc 0.01746\n",
      "Batch train [1] loss 0.98585, dsc 0.01415\n",
      "Batch train [1] loss 0.98461, dsc 0.01539\n",
      "Batch train [1] loss 0.98943, dsc 0.01057\n",
      "Batch train [1] loss 0.99164, dsc 0.00836\n",
      "Batch train [1] loss 0.98271, dsc 0.01729\n",
      "Batch train [1] loss 0.98957, dsc 0.01043\n",
      "Batch train [1] loss 0.98287, dsc 0.01713\n",
      "Batch train [1] loss 0.98794, dsc 0.01206\n",
      "Batch train [1] loss 0.98069, dsc 0.01931\n",
      "Batch train [1] loss 0.98537, dsc 0.01463\n",
      "Batch train [1] loss 0.98331, dsc 0.01669\n",
      "Batch train [1] loss 0.99006, dsc 0.00994\n",
      "Batch train [1] loss 0.98892, dsc 0.01108\n",
      "Batch train [1] loss 0.98143, dsc 0.01857\n",
      "Batch train [1] loss 0.98182, dsc 0.01818\n",
      "Batch train [1] loss 0.99047, dsc 0.00953\n",
      "Batch train [1] loss 0.97462, dsc 0.02538\n",
      "Batch train [1] loss 0.98901, dsc 0.01099\n",
      "Batch train [1] loss 0.98232, dsc 0.01768\n",
      "Batch train [1] loss 0.97170, dsc 0.02830\n",
      "Batch train [1] loss 0.97838, dsc 0.02162\n",
      "Batch train [1] loss 0.97932, dsc 0.02068\n",
      "Epoch [3] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  2, step 0\n",
      "Batch eval [1] loss 0.97856, dsc 0.02144\n",
      "Batch eval [1] loss 0.98441, dsc 0.01559\n",
      "Batch eval [1] loss 0.97657, dsc 0.02343\n",
      "Batch eval [1] loss 0.98467, dsc 0.01533\n",
      "Batch eval [1] loss 0.98843, dsc 0.01157\n",
      "Epoch [3] valid done\n",
      "Epoch [3] T 382.66s, deltaT 123.21s, loss: train 0.98333, valid 0.98253, dsc: train 0.01667, valid 0.01747\n",
      "DEBUG: Writing to tensorboard before epoch True, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  3, step 0\n",
      "Batch train [1] loss 0.97927, dsc 0.02073\n",
      "Batch train [1] loss 0.98237, dsc 0.01763\n",
      "Batch train [1] loss 0.98462, dsc 0.01538\n",
      "Batch train [1] loss 0.98899, dsc 0.01101\n",
      "Batch train [1] loss 0.98934, dsc 0.01066\n",
      "Batch train [1] loss 0.98991, dsc 0.01009\n",
      "Batch train [1] loss 0.98049, dsc 0.01951\n",
      "Batch train [1] loss 0.97777, dsc 0.02223\n",
      "Batch train [1] loss 0.98426, dsc 0.01574\n",
      "Batch train [1] loss 0.98077, dsc 0.01923\n",
      "Batch train [1] loss 0.98756, dsc 0.01244\n",
      "Batch train [1] loss 0.99063, dsc 0.00937\n",
      "Batch train [1] loss 0.97531, dsc 0.02469\n",
      "Batch train [1] loss 0.98886, dsc 0.01114\n",
      "Batch train [1] loss 0.97116, dsc 0.02884\n",
      "Batch train [1] loss 0.97787, dsc 0.02213\n",
      "Batch train [1] loss 0.98499, dsc 0.01501\n",
      "Batch train [1] loss 0.98683, dsc 0.01317\n",
      "Batch train [1] loss 0.98860, dsc 0.01140\n",
      "Batch train [1] loss 0.98286, dsc 0.01714\n",
      "Batch train [1] loss 0.98001, dsc 0.01999\n",
      "Batch train [1] loss 0.98182, dsc 0.01818\n",
      "Batch train [1] loss 0.98221, dsc 0.01779\n",
      "Batch train [1] loss 0.98064, dsc 0.01936\n",
      "Batch train [1] loss 0.98748, dsc 0.01252\n",
      "Batch train [1] loss 0.98188, dsc 0.01812\n",
      "Batch train [1] loss 0.99125, dsc 0.00875\n",
      "Batch train [1] loss 0.97383, dsc 0.02617\n",
      "Batch train [1] loss 0.98510, dsc 0.01490\n",
      "Batch train [1] loss 0.98736, dsc 0.01264\n",
      "Batch train [1] loss 0.97083, dsc 0.02917\n",
      "Batch train [1] loss 0.98046, dsc 0.01954\n",
      "Batch train [1] loss 0.99087, dsc 0.00913\n",
      "Batch train [1] loss 0.98081, dsc 0.01919\n",
      "Batch train [1] loss 0.97295, dsc 0.02705\n",
      "Batch train [1] loss 0.97352, dsc 0.02648\n",
      "Batch train [1] loss 0.97850, dsc 0.02150\n",
      "Batch train [1] loss 0.99008, dsc 0.00992\n",
      "Batch train [1] loss 0.98835, dsc 0.01165\n",
      "Batch train [1] loss 0.97526, dsc 0.02474\n",
      "Epoch [4] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  3, step 0\n",
      "Batch eval [1] loss 0.98042, dsc 0.01958\n",
      "Batch eval [1] loss 0.98550, dsc 0.01450\n",
      "Batch eval [1] loss 0.97815, dsc 0.02185\n",
      "Batch eval [1] loss 0.98585, dsc 0.01415\n",
      "Batch eval [1] loss 0.98931, dsc 0.01069\n",
      "Epoch [4] valid done\n",
      "Epoch [4] T 500.51s, deltaT 117.84s, loss: train 0.98264, valid 0.98384, dsc: train 0.01736, valid 0.01616\n",
      "DEBUG: Writing to tensorboard before epoch True, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  4, step 0\n",
      "Batch train [1] loss 0.98025, dsc 0.01975\n",
      "Batch train [1] loss 0.98453, dsc 0.01547\n",
      "Batch train [1] loss 0.98706, dsc 0.01294\n",
      "Batch train [1] loss 0.97254, dsc 0.02746\n",
      "Batch train [1] loss 0.98005, dsc 0.01995\n",
      "Batch train [1] loss 0.97305, dsc 0.02695\n",
      "Batch train [1] loss 0.98127, dsc 0.01873\n",
      "Batch train [1] loss 0.98129, dsc 0.01871\n",
      "Batch train [1] loss 0.98942, dsc 0.01058\n",
      "Batch train [1] loss 0.98815, dsc 0.01185\n",
      "Batch train [1] loss 0.97712, dsc 0.02288\n",
      "Batch train [1] loss 0.97943, dsc 0.02057\n",
      "Batch train [1] loss 0.97314, dsc 0.02686\n",
      "Batch train [1] loss 0.98133, dsc 0.01867\n",
      "Batch train [1] loss 0.98632, dsc 0.01368\n",
      "Batch train [1] loss 0.97012, dsc 0.02988\n",
      "Batch train [1] loss 0.96979, dsc 0.03021\n",
      "Batch train [1] loss 0.97658, dsc 0.02342\n",
      "Batch train [1] loss 0.97410, dsc 0.02590\n",
      "Batch train [1] loss 0.99095, dsc 0.00905\n",
      "Batch train [1] loss 0.98809, dsc 0.01191\n",
      "Batch train [1] loss 0.97962, dsc 0.02038\n",
      "Batch train [1] loss 0.99009, dsc 0.00991\n",
      "Batch train [1] loss 0.98597, dsc 0.01403\n",
      "Batch train [1] loss 0.98205, dsc 0.01795\n",
      "Batch train [1] loss 0.97768, dsc 0.02232\n",
      "Batch train [1] loss 0.97454, dsc 0.02546\n",
      "Batch train [1] loss 0.98860, dsc 0.01140\n",
      "Batch train [1] loss 0.98813, dsc 0.01187\n",
      "Batch train [1] loss 0.98438, dsc 0.01562\n",
      "Batch train [1] loss 0.98682, dsc 0.01318\n",
      "Batch train [1] loss 0.98116, dsc 0.01884\n",
      "Batch train [1] loss 0.97987, dsc 0.02013\n",
      "Batch train [1] loss 0.98314, dsc 0.01686\n",
      "Batch train [1] loss 0.99045, dsc 0.00955\n",
      "Batch train [1] loss 0.98335, dsc 0.01665\n",
      "Batch train [1] loss 0.97747, dsc 0.02253\n",
      "Batch train [1] loss 0.97867, dsc 0.02133\n",
      "Batch train [1] loss 0.98810, dsc 0.01190\n",
      "Batch train [1] loss 0.98955, dsc 0.01045\n",
      "Epoch [5] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  4, step 0\n",
      "Batch eval [1] loss 0.97721, dsc 0.02279\n",
      "Batch eval [1] loss 0.98290, dsc 0.01710\n",
      "Batch eval [1] loss 0.97452, dsc 0.02548\n",
      "Batch eval [1] loss 0.98318, dsc 0.01682\n",
      "Batch eval [1] loss 0.98709, dsc 0.01291\n",
      "Epoch [5] valid done\n",
      "Epoch [5] T 617.28s, deltaT 116.76s, loss: train 0.98186, valid 0.98098, dsc: train 0.01814, valid 0.01902\n",
      "DEBUG: Writing to tensorboard before epoch True, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  5, step 0\n",
      "Batch train [1] loss 0.97411, dsc 0.02589\n",
      "Batch train [1] loss 0.98048, dsc 0.01952\n",
      "Batch train [1] loss 0.99067, dsc 0.00933\n",
      "Batch train [1] loss 0.97201, dsc 0.02799\n",
      "Batch train [1] loss 0.98894, dsc 0.01106\n",
      "Batch train [1] loss 0.98946, dsc 0.01054\n",
      "Batch train [1] loss 0.98062, dsc 0.01938\n",
      "Batch train [1] loss 0.98368, dsc 0.01632\n",
      "Batch train [1] loss 0.96880, dsc 0.03120\n",
      "Batch train [1] loss 0.98776, dsc 0.01224\n",
      "Batch train [1] loss 0.99023, dsc 0.00977\n",
      "Batch train [1] loss 0.97591, dsc 0.02409\n",
      "Batch train [1] loss 0.97836, dsc 0.02164\n",
      "Batch train [1] loss 0.97565, dsc 0.02435\n",
      "Batch train [1] loss 0.97104, dsc 0.02896\n",
      "Batch train [1] loss 0.98785, dsc 0.01215\n",
      "Batch train [1] loss 0.98391, dsc 0.01609\n",
      "Batch train [1] loss 0.98965, dsc 0.01035\n",
      "Batch train [1] loss 0.98242, dsc 0.01758\n",
      "Batch train [1] loss 0.97178, dsc 0.02822\n",
      "Batch train [1] loss 0.97883, dsc 0.02117\n",
      "Batch train [1] loss 0.98815, dsc 0.01185\n",
      "Batch train [1] loss 0.98039, dsc 0.01961\n",
      "Batch train [1] loss 0.98739, dsc 0.01261\n",
      "Batch train [1] loss 0.98120, dsc 0.01880\n",
      "Batch train [1] loss 0.98020, dsc 0.01980\n",
      "Batch train [1] loss 0.98526, dsc 0.01474\n",
      "Batch train [1] loss 0.97671, dsc 0.02329\n",
      "Batch train [1] loss 0.98756, dsc 0.01244\n",
      "Batch train [1] loss 0.98623, dsc 0.01377\n",
      "Batch train [1] loss 0.97252, dsc 0.02748\n",
      "Batch train [1] loss 0.97791, dsc 0.02209\n",
      "Batch train [1] loss 0.98542, dsc 0.01458\n",
      "Batch train [1] loss 0.98261, dsc 0.01739\n",
      "Batch train [1] loss 0.97638, dsc 0.02362\n",
      "Batch train [1] loss 0.98587, dsc 0.01413\n",
      "Batch train [1] loss 0.97840, dsc 0.02160\n",
      "Batch train [1] loss 0.96737, dsc 0.03263\n",
      "Batch train [1] loss 0.97813, dsc 0.02187\n",
      "Batch train [1] loss 0.97867, dsc 0.02133\n",
      "Epoch [6] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  5, step 0\n",
      "Batch eval [1] loss 0.97454, dsc 0.02546\n",
      "Batch eval [1] loss 0.98101, dsc 0.01899\n",
      "Batch eval [1] loss 0.97258, dsc 0.02742\n",
      "Batch eval [1] loss 0.98143, dsc 0.01857\n",
      "Batch eval [1] loss 0.98553, dsc 0.01447\n",
      "Epoch [6] valid done\n",
      "Epoch [6] T 733.98s, deltaT 116.70s, loss: train 0.98096, valid 0.97902, dsc: train 0.01904, valid 0.02098\n",
      "DEBUG: Writing to tensorboard before epoch True, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  6, step 0\n",
      "Batch train [1] loss 0.97796, dsc 0.02204\n",
      "Batch train [1] loss 0.98575, dsc 0.01425\n",
      "Batch train [1] loss 0.96700, dsc 0.03300\n",
      "Batch train [1] loss 0.97246, dsc 0.02754\n",
      "Batch train [1] loss 0.97985, dsc 0.02015\n",
      "Batch train [1] loss 0.97610, dsc 0.02390\n",
      "Batch train [1] loss 0.97804, dsc 0.02196\n",
      "Batch train [1] loss 0.98976, dsc 0.01024\n",
      "Batch train [1] loss 0.96998, dsc 0.03002\n",
      "Batch train [1] loss 0.98584, dsc 0.01416\n",
      "Batch train [1] loss 0.97070, dsc 0.02930\n",
      "Batch train [1] loss 0.98467, dsc 0.01533\n",
      "Batch train [1] loss 0.97785, dsc 0.02215\n",
      "Batch train [1] loss 0.98758, dsc 0.01242\n",
      "Batch train [1] loss 0.98035, dsc 0.01965\n",
      "Batch train [1] loss 0.98253, dsc 0.01747\n",
      "Batch train [1] loss 0.96694, dsc 0.03306\n",
      "Batch train [1] loss 0.98990, dsc 0.01010\n",
      "Batch train [1] loss 0.98287, dsc 0.01713\n",
      "Batch train [1] loss 0.97591, dsc 0.02409\n",
      "Batch train [1] loss 0.97696, dsc 0.02304\n",
      "Batch train [1] loss 0.98683, dsc 0.01317\n",
      "Batch train [1] loss 0.98802, dsc 0.01198\n",
      "Batch train [1] loss 0.97216, dsc 0.02784\n",
      "Batch train [1] loss 0.97428, dsc 0.02572\n",
      "Batch train [1] loss 0.98673, dsc 0.01327\n",
      "Batch train [1] loss 0.98175, dsc 0.01825\n",
      "Batch train [1] loss 0.98903, dsc 0.01097\n",
      "Batch train [1] loss 0.98849, dsc 0.01151\n",
      "Batch train [1] loss 0.98435, dsc 0.01565\n",
      "Batch train [1] loss 0.98676, dsc 0.01324\n",
      "Batch train [1] loss 0.97844, dsc 0.02156\n",
      "Batch train [1] loss 0.97388, dsc 0.02612\n",
      "Batch train [1] loss 0.96978, dsc 0.03022\n",
      "Batch train [1] loss 0.97768, dsc 0.02232\n",
      "Batch train [1] loss 0.98095, dsc 0.01905\n",
      "Batch train [1] loss 0.97862, dsc 0.02138\n",
      "Batch train [1] loss 0.97646, dsc 0.02354\n",
      "Batch train [1] loss 0.97842, dsc 0.02158\n",
      "Batch train [1] loss 0.98642, dsc 0.01358\n",
      "Epoch [7] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  6, step 0\n",
      "Batch eval [1] loss 0.97692, dsc 0.02308\n",
      "Batch eval [1] loss 0.98264, dsc 0.01736\n",
      "Batch eval [1] loss 0.97555, dsc 0.02445\n",
      "Batch eval [1] loss 0.98358, dsc 0.01642\n",
      "Batch eval [1] loss 0.98761, dsc 0.01239\n",
      "Epoch [7] valid done\n",
      "Epoch [7] T 850.93s, deltaT 116.94s, loss: train 0.97995, valid 0.98126, dsc: train 0.02005, valid 0.01874\n",
      "DEBUG: Writing to tensorboard before epoch True, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  7, step 0\n",
      "Batch train [1] loss 0.98400, dsc 0.01600\n",
      "Batch train [1] loss 0.98486, dsc 0.01514\n",
      "Batch train [1] loss 0.97617, dsc 0.02383\n",
      "Batch train [1] loss 0.98611, dsc 0.01389\n",
      "Batch train [1] loss 0.98910, dsc 0.01090\n",
      "Batch train [1] loss 0.98645, dsc 0.01355\n",
      "Batch train [1] loss 0.98940, dsc 0.01060\n",
      "Batch train [1] loss 0.98382, dsc 0.01618\n",
      "Batch train [1] loss 0.97595, dsc 0.02405\n",
      "Batch train [1] loss 0.98656, dsc 0.01344\n",
      "Batch train [1] loss 0.96885, dsc 0.03115\n",
      "Batch train [1] loss 0.96560, dsc 0.03440\n",
      "Batch train [1] loss 0.97462, dsc 0.02538\n",
      "Batch train [1] loss 0.97651, dsc 0.02349\n",
      "Batch train [1] loss 0.98844, dsc 0.01156\n",
      "Batch train [1] loss 0.97796, dsc 0.02204\n",
      "Batch train [1] loss 0.97941, dsc 0.02059\n",
      "Batch train [1] loss 0.97833, dsc 0.02167\n",
      "Batch train [1] loss 0.98797, dsc 0.01203\n",
      "Batch train [1] loss 0.98194, dsc 0.01806\n",
      "Batch train [1] loss 0.97631, dsc 0.02369\n",
      "Batch train [1] loss 0.96778, dsc 0.03222\n",
      "Batch train [1] loss 0.97391, dsc 0.02609\n",
      "Batch train [1] loss 0.98117, dsc 0.01883\n",
      "Batch train [1] loss 0.97679, dsc 0.02321\n",
      "Batch train [1] loss 0.96920, dsc 0.03080\n",
      "Batch train [1] loss 0.97317, dsc 0.02683\n",
      "Batch train [1] loss 0.97833, dsc 0.02167\n",
      "Batch train [1] loss 0.98709, dsc 0.01291\n",
      "Batch train [1] loss 0.96812, dsc 0.03188\n",
      "Batch train [1] loss 0.98650, dsc 0.01350\n",
      "Batch train [1] loss 0.97030, dsc 0.02970\n",
      "Batch train [1] loss 0.98453, dsc 0.01547\n",
      "Batch train [1] loss 0.97974, dsc 0.02026\n",
      "Batch train [1] loss 0.97766, dsc 0.02234\n",
      "Batch train [1] loss 0.97534, dsc 0.02466\n",
      "Batch train [1] loss 0.98041, dsc 0.01959\n",
      "Batch train [1] loss 0.97183, dsc 0.02817\n",
      "Batch train [1] loss 0.98580, dsc 0.01420\n",
      "Batch train [1] loss 0.96425, dsc 0.03575\n",
      "Epoch [8] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  7, step 0\n",
      "Batch eval [1] loss 0.97508, dsc 0.02492\n",
      "Batch eval [1] loss 0.98126, dsc 0.01874\n",
      "Batch eval [1] loss 0.97252, dsc 0.02748\n",
      "Batch eval [1] loss 0.98153, dsc 0.01847\n",
      "Batch eval [1] loss 0.98589, dsc 0.01411\n",
      "Epoch [8] valid done\n",
      "Epoch [8] T 967.96s, deltaT 117.03s, loss: train 0.97876, valid 0.97926, dsc: train 0.02124, valid 0.02074\n",
      "DEBUG: Writing to tensorboard before epoch True, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  8, step 0\n",
      "Batch train [1] loss 0.96757, dsc 0.03243\n",
      "Batch train [1] loss 0.96385, dsc 0.03615\n",
      "Batch train [1] loss 0.97319, dsc 0.02681\n",
      "Batch train [1] loss 0.98326, dsc 0.01674\n",
      "Batch train [1] loss 0.97822, dsc 0.02178\n",
      "Batch train [1] loss 0.98832, dsc 0.01168\n",
      "Batch train [1] loss 0.98515, dsc 0.01485\n",
      "Batch train [1] loss 0.97186, dsc 0.02814\n",
      "Batch train [1] loss 0.98769, dsc 0.01231\n",
      "Batch train [1] loss 0.97311, dsc 0.02689\n",
      "Batch train [1] loss 0.98728, dsc 0.01272\n",
      "Batch train [1] loss 0.98607, dsc 0.01393\n",
      "Batch train [1] loss 0.97110, dsc 0.02890\n",
      "Batch train [1] loss 0.97641, dsc 0.02359\n",
      "Batch train [1] loss 0.97546, dsc 0.02454\n",
      "Batch train [1] loss 0.96900, dsc 0.03100\n",
      "Batch train [1] loss 0.98857, dsc 0.01143\n",
      "Batch train [1] loss 0.97480, dsc 0.02520\n",
      "Batch train [1] loss 0.97882, dsc 0.02118\n",
      "Batch train [1] loss 0.98249, dsc 0.01751\n",
      "Batch train [1] loss 0.98517, dsc 0.01483\n",
      "Batch train [1] loss 0.97409, dsc 0.02591\n",
      "Batch train [1] loss 0.97392, dsc 0.02608\n",
      "Batch train [1] loss 0.98498, dsc 0.01502\n",
      "Batch train [1] loss 0.97600, dsc 0.02400\n",
      "Batch train [1] loss 0.98508, dsc 0.01492\n",
      "Batch train [1] loss 0.98353, dsc 0.01647\n",
      "Batch train [1] loss 0.96740, dsc 0.03260\n",
      "Batch train [1] loss 0.97454, dsc 0.02546\n",
      "Batch train [1] loss 0.97971, dsc 0.02029\n",
      "Batch train [1] loss 0.98038, dsc 0.01962\n",
      "Batch train [1] loss 0.96597, dsc 0.03403\n",
      "Batch train [1] loss 0.96526, dsc 0.03474\n",
      "Batch train [1] loss 0.97903, dsc 0.02097\n",
      "Batch train [1] loss 0.98610, dsc 0.01390\n",
      "Batch train [1] loss 0.97350, dsc 0.02650\n",
      "Batch train [1] loss 0.97582, dsc 0.02418\n",
      "Batch train [1] loss 0.96094, dsc 0.03906\n",
      "Batch train [1] loss 0.97531, dsc 0.02469\n",
      "Batch train [1] loss 0.98320, dsc 0.01680\n",
      "Epoch [9] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  8, step 0\n",
      "Batch eval [1] loss 0.97469, dsc 0.02531\n",
      "Batch eval [1] loss 0.98028, dsc 0.01972\n",
      "Batch eval [1] loss 0.97196, dsc 0.02804\n",
      "Batch eval [1] loss 0.98013, dsc 0.01987\n",
      "Batch eval [1] loss 0.98514, dsc 0.01486\n",
      "Epoch [9] valid done\n",
      "Epoch [9] T 1085.02s, deltaT 117.05s, loss: train 0.97730, valid 0.97844, dsc: train 0.02270, valid 0.02156\n",
      "DEBUG: Writing to tensorboard before epoch True, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  9, step 0\n",
      "Batch train [1] loss 0.98434, dsc 0.01566\n",
      "Batch train [1] loss 0.96510, dsc 0.03490\n",
      "Batch train [1] loss 0.97363, dsc 0.02637\n",
      "Batch train [1] loss 0.96625, dsc 0.03375\n",
      "Batch train [1] loss 0.98761, dsc 0.01239\n",
      "Batch train [1] loss 0.97128, dsc 0.02872\n",
      "Batch train [1] loss 0.97289, dsc 0.02711\n",
      "Batch train [1] loss 0.98469, dsc 0.01531\n",
      "Batch train [1] loss 0.97292, dsc 0.02708\n",
      "Batch train [1] loss 0.96055, dsc 0.03945\n",
      "Batch train [1] loss 0.98242, dsc 0.01758\n",
      "Batch train [1] loss 0.97956, dsc 0.02044\n",
      "Batch train [1] loss 0.98413, dsc 0.01587\n",
      "Batch train [1] loss 0.96927, dsc 0.03073\n",
      "Batch train [1] loss 0.97868, dsc 0.02132\n",
      "Batch train [1] loss 0.97636, dsc 0.02364\n",
      "Batch train [1] loss 0.98621, dsc 0.01379\n",
      "Batch train [1] loss 0.98193, dsc 0.01807\n",
      "Batch train [1] loss 0.98648, dsc 0.01352\n",
      "Batch train [1] loss 0.97054, dsc 0.02946\n",
      "Batch train [1] loss 0.96344, dsc 0.03656\n",
      "Batch train [1] loss 0.96860, dsc 0.03140\n",
      "Batch train [1] loss 0.97493, dsc 0.02507\n",
      "Batch train [1] loss 0.96663, dsc 0.03337\n",
      "Batch train [1] loss 0.98757, dsc 0.01243\n",
      "Batch train [1] loss 0.97427, dsc 0.02573\n",
      "Batch train [1] loss 0.98241, dsc 0.01759\n",
      "Batch train [1] loss 0.97714, dsc 0.02286\n",
      "Batch train [1] loss 0.97320, dsc 0.02680\n",
      "Batch train [1] loss 0.97245, dsc 0.02755\n",
      "Batch train [1] loss 0.98371, dsc 0.01629\n",
      "Batch train [1] loss 0.98069, dsc 0.01931\n",
      "Batch train [1] loss 0.97199, dsc 0.02801\n",
      "Batch train [1] loss 0.97406, dsc 0.02594\n",
      "Batch train [1] loss 0.96381, dsc 0.03619\n",
      "Batch train [1] loss 0.98428, dsc 0.01572\n",
      "Batch train [1] loss 0.95854, dsc 0.04146\n",
      "Batch train [1] loss 0.98507, dsc 0.01493\n",
      "Batch train [1] loss 0.97767, dsc 0.02233\n",
      "Batch train [1] loss 0.97379, dsc 0.02621\n",
      "Epoch [10] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  9, step 0\n",
      "Batch eval [1] loss 0.96854, dsc 0.03146\n",
      "Batch eval [1] loss 0.97660, dsc 0.02340\n",
      "Batch eval [1] loss 0.96835, dsc 0.03165\n",
      "Batch eval [1] loss 0.97732, dsc 0.02268\n",
      "Batch eval [1] loss 0.98312, dsc 0.01688\n",
      "Epoch [10] valid done\n",
      "Epoch [10] T 1201.90s, deltaT 116.87s, loss: train 0.97573, valid 0.97479, dsc: train 0.02427, valid 0.02521\n",
      "DEBUG: Writing to tensorboard before epoch True, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  10, step 0\n",
      "Batch train [1] loss 0.98610, dsc 0.01390\n",
      "Batch train [1] loss 0.97219, dsc 0.02781\n",
      "Batch train [1] loss 0.97401, dsc 0.02599\n",
      "Batch train [1] loss 0.98075, dsc 0.01925\n",
      "Batch train [1] loss 0.97153, dsc 0.02847\n",
      "Batch train [1] loss 0.96991, dsc 0.03009\n",
      "Batch train [1] loss 0.98587, dsc 0.01413\n",
      "Batch train [1] loss 0.97397, dsc 0.02603\n",
      "Batch train [1] loss 0.96980, dsc 0.03020\n",
      "Batch train [1] loss 0.96241, dsc 0.03759\n",
      "Batch train [1] loss 0.98341, dsc 0.01659\n",
      "Batch train [1] loss 0.98277, dsc 0.01723\n",
      "Batch train [1] loss 0.97600, dsc 0.02400\n",
      "Batch train [1] loss 0.95897, dsc 0.04103\n",
      "Batch train [1] loss 0.97089, dsc 0.02911\n",
      "Batch train [1] loss 0.98688, dsc 0.01312\n",
      "Batch train [1] loss 0.97687, dsc 0.02313\n",
      "Batch train [1] loss 0.95735, dsc 0.04265\n",
      "Batch train [1] loss 0.98011, dsc 0.01989\n",
      "Batch train [1] loss 0.98636, dsc 0.01364\n",
      "Batch train [1] loss 0.96198, dsc 0.03802\n",
      "Batch train [1] loss 0.96320, dsc 0.03680\n",
      "Batch train [1] loss 0.96665, dsc 0.03335\n",
      "Batch train [1] loss 0.98112, dsc 0.01888\n",
      "Batch train [1] loss 0.97257, dsc 0.02743\n",
      "Batch train [1] loss 0.98509, dsc 0.01491\n",
      "Batch train [1] loss 0.96451, dsc 0.03549\n",
      "Batch train [1] loss 0.97020, dsc 0.02980\n",
      "Batch train [1] loss 0.96130, dsc 0.03870\n",
      "Batch train [1] loss 0.97069, dsc 0.02931\n",
      "Batch train [1] loss 0.98417, dsc 0.01583\n",
      "Batch train [1] loss 0.97227, dsc 0.02773\n",
      "Batch train [1] loss 0.97728, dsc 0.02272\n",
      "Batch train [1] loss 0.98089, dsc 0.01911\n",
      "Batch train [1] loss 0.98317, dsc 0.01683\n",
      "Batch train [1] loss 0.97101, dsc 0.02899\n",
      "Batch train [1] loss 0.97641, dsc 0.02359\n",
      "Batch train [1] loss 0.98227, dsc 0.01773\n",
      "Batch train [1] loss 0.97367, dsc 0.02633\n",
      "Batch train [1] loss 0.96602, dsc 0.03398\n",
      "Epoch [11] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  10, step 0\n",
      "Batch eval [1] loss 0.96589, dsc 0.03411\n",
      "Batch eval [1] loss 0.97274, dsc 0.02726\n",
      "Batch eval [1] loss 0.96782, dsc 0.03218\n",
      "Batch eval [1] loss 0.97289, dsc 0.02711\n",
      "Batch eval [1] loss 0.97949, dsc 0.02051\n",
      "Epoch [11] valid done\n",
      "Epoch [11] T 1318.74s, deltaT 116.84s, loss: train 0.97427, valid 0.97177, dsc: train 0.02573, valid 0.02823\n",
      "DEBUG: Writing to tensorboard before epoch True, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  11, step 0\n",
      "Batch train [1] loss 0.96598, dsc 0.03402\n",
      "Batch train [1] loss 0.95650, dsc 0.04350\n",
      "Batch train [1] loss 0.97913, dsc 0.02087\n",
      "Batch train [1] loss 0.97562, dsc 0.02438\n",
      "Batch train [1] loss 0.96921, dsc 0.03079\n",
      "Batch train [1] loss 0.97194, dsc 0.02806\n",
      "Batch train [1] loss 0.97136, dsc 0.02864\n",
      "Batch train [1] loss 0.98229, dsc 0.01771\n",
      "Batch train [1] loss 0.97873, dsc 0.02127\n",
      "Batch train [1] loss 0.97449, dsc 0.02551\n",
      "Batch train [1] loss 0.96485, dsc 0.03515\n",
      "Batch train [1] loss 0.96941, dsc 0.03059\n",
      "Batch train [1] loss 0.96864, dsc 0.03136\n",
      "Batch train [1] loss 0.98193, dsc 0.01807\n",
      "Batch train [1] loss 0.95484, dsc 0.04516\n",
      "Batch train [1] loss 0.98455, dsc 0.01545\n",
      "Batch train [1] loss 0.98416, dsc 0.01584\n",
      "Batch train [1] loss 0.96171, dsc 0.03829\n",
      "Batch train [1] loss 0.98227, dsc 0.01773\n",
      "Batch train [1] loss 0.97978, dsc 0.02022\n",
      "Batch train [1] loss 0.95828, dsc 0.04172\n",
      "Batch train [1] loss 0.95708, dsc 0.04292\n",
      "Batch train [1] loss 0.95982, dsc 0.04018\n",
      "Batch train [1] loss 0.98561, dsc 0.01439\n",
      "Batch train [1] loss 0.96543, dsc 0.03457\n",
      "Batch train [1] loss 0.96852, dsc 0.03148\n",
      "Batch train [1] loss 0.96533, dsc 0.03467\n",
      "Batch train [1] loss 0.97506, dsc 0.02494\n",
      "Batch train [1] loss 0.96710, dsc 0.03290\n",
      "Batch train [1] loss 0.98294, dsc 0.01706\n",
      "Batch train [1] loss 0.97561, dsc 0.02439\n",
      "Batch train [1] loss 0.98109, dsc 0.01891\n",
      "Batch train [1] loss 0.96981, dsc 0.03019\n",
      "Batch train [1] loss 0.96828, dsc 0.03172\n",
      "Batch train [1] loss 0.97886, dsc 0.02114\n",
      "Batch train [1] loss 0.98477, dsc 0.01523\n",
      "Batch train [1] loss 0.97128, dsc 0.02872\n",
      "Batch train [1] loss 0.95945, dsc 0.04055\n",
      "Batch train [1] loss 0.98039, dsc 0.01961\n",
      "Batch train [1] loss 0.96993, dsc 0.03007\n",
      "Epoch [12] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  11, step 0\n",
      "Batch eval [1] loss 0.95063, dsc 0.04937\n",
      "Batch eval [1] loss 0.96973, dsc 0.03027\n",
      "Batch eval [1] loss 0.95404, dsc 0.04596\n",
      "Batch eval [1] loss 0.96850, dsc 0.03150\n",
      "Batch eval [1] loss 0.97772, dsc 0.02228\n",
      "Epoch [12] valid done\n",
      "Epoch [12] T 1436.00s, deltaT 117.25s, loss: train 0.97205, valid 0.96412, dsc: train 0.02795, valid 0.03588\n",
      "DEBUG: Writing to tensorboard before epoch True, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  12, step 0\n",
      "Batch train [1] loss 0.97134, dsc 0.02866\n",
      "Batch train [1] loss 0.96672, dsc 0.03328\n",
      "Batch train [1] loss 0.98174, dsc 0.01826\n",
      "Batch train [1] loss 0.95695, dsc 0.04305\n",
      "Batch train [1] loss 0.98094, dsc 0.01906\n",
      "Batch train [1] loss 0.96422, dsc 0.03578\n",
      "Batch train [1] loss 0.96694, dsc 0.03306\n",
      "Batch train [1] loss 0.97835, dsc 0.02165\n",
      "Batch train [1] loss 0.98096, dsc 0.01904\n",
      "Batch train [1] loss 0.96190, dsc 0.03810\n",
      "Batch train [1] loss 0.98351, dsc 0.01649\n",
      "Batch train [1] loss 0.96881, dsc 0.03119\n",
      "Batch train [1] loss 0.96879, dsc 0.03121\n",
      "Batch train [1] loss 0.95097, dsc 0.04903\n",
      "Batch train [1] loss 0.97693, dsc 0.02307\n",
      "Batch train [1] loss 0.95452, dsc 0.04548\n",
      "Batch train [1] loss 0.96709, dsc 0.03291\n",
      "Batch train [1] loss 0.98185, dsc 0.01815\n",
      "Batch train [1] loss 0.98464, dsc 0.01536\n",
      "Batch train [1] loss 0.98400, dsc 0.01600\n",
      "Batch train [1] loss 0.96297, dsc 0.03703\n",
      "Batch train [1] loss 0.98261, dsc 0.01739\n",
      "Batch train [1] loss 0.96826, dsc 0.03174\n",
      "Batch train [1] loss 0.97997, dsc 0.02003\n",
      "Batch train [1] loss 0.95740, dsc 0.04260\n",
      "Batch train [1] loss 0.96042, dsc 0.03958\n",
      "Batch train [1] loss 0.96541, dsc 0.03459\n",
      "Batch train [1] loss 0.96546, dsc 0.03454\n",
      "Batch train [1] loss 0.97346, dsc 0.02654\n",
      "Batch train [1] loss 0.97191, dsc 0.02809\n",
      "Batch train [1] loss 0.95286, dsc 0.04714\n",
      "Batch train [1] loss 0.97735, dsc 0.02265\n",
      "Batch train [1] loss 0.97656, dsc 0.02344\n",
      "Batch train [1] loss 0.96494, dsc 0.03506\n",
      "Batch train [1] loss 0.96696, dsc 0.03304\n",
      "Batch train [1] loss 0.97061, dsc 0.02939\n",
      "Batch train [1] loss 0.97244, dsc 0.02756\n",
      "Batch train [1] loss 0.95487, dsc 0.04513\n",
      "Batch train [1] loss 0.97881, dsc 0.02119\n",
      "Batch train [1] loss 0.94713, dsc 0.05287\n",
      "Epoch [13] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  12, step 0\n",
      "Batch eval [1] loss 0.96209, dsc 0.03791\n",
      "Batch eval [1] loss 0.97028, dsc 0.02972\n",
      "Batch eval [1] loss 0.97079, dsc 0.02921\n",
      "Batch eval [1] loss 0.97121, dsc 0.02879\n",
      "Batch eval [1] loss 0.97834, dsc 0.02166\n",
      "Epoch [13] valid done\n",
      "Epoch [13] T 1553.42s, deltaT 117.42s, loss: train 0.96954, valid 0.97054, dsc: train 0.03046, valid 0.02946\n",
      "DEBUG: Writing to tensorboard before epoch True, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  13, step 0\n",
      "Batch train [1] loss 0.97518, dsc 0.02482\n",
      "Batch train [1] loss 0.97863, dsc 0.02137\n",
      "Batch train [1] loss 0.97254, dsc 0.02746\n",
      "Batch train [1] loss 0.97969, dsc 0.02031\n",
      "Batch train [1] loss 0.96396, dsc 0.03604\n",
      "Batch train [1] loss 0.96603, dsc 0.03397\n",
      "Batch train [1] loss 0.97848, dsc 0.02152\n",
      "Batch train [1] loss 0.97655, dsc 0.02345\n",
      "Batch train [1] loss 0.98204, dsc 0.01796\n",
      "Batch train [1] loss 0.96264, dsc 0.03736\n",
      "Batch train [1] loss 0.95488, dsc 0.04512\n",
      "Batch train [1] loss 0.95021, dsc 0.04979\n",
      "Batch train [1] loss 0.97590, dsc 0.02410\n",
      "Batch train [1] loss 0.95984, dsc 0.04016\n",
      "Batch train [1] loss 0.96597, dsc 0.03403\n",
      "Batch train [1] loss 0.98271, dsc 0.01729\n",
      "Batch train [1] loss 0.96201, dsc 0.03799\n",
      "Batch train [1] loss 0.98319, dsc 0.01681\n",
      "Batch train [1] loss 0.97464, dsc 0.02536\n",
      "Batch train [1] loss 0.95975, dsc 0.04025\n",
      "Batch train [1] loss 0.96869, dsc 0.03131\n",
      "Batch train [1] loss 0.95196, dsc 0.04804\n",
      "Batch train [1] loss 0.98082, dsc 0.01918\n",
      "Batch train [1] loss 0.97977, dsc 0.02023\n",
      "Batch train [1] loss 0.95619, dsc 0.04381\n",
      "Batch train [1] loss 0.96438, dsc 0.03562\n",
      "Batch train [1] loss 0.96458, dsc 0.03542\n",
      "Batch train [1] loss 0.97783, dsc 0.02217\n",
      "Batch train [1] loss 0.95613, dsc 0.04387\n",
      "Batch train [1] loss 0.96261, dsc 0.03739\n",
      "Batch train [1] loss 0.96882, dsc 0.03118\n",
      "Batch train [1] loss 0.94306, dsc 0.05694\n",
      "Batch train [1] loss 0.96562, dsc 0.03438\n",
      "Batch train [1] loss 0.94248, dsc 0.05752\n",
      "Batch train [1] loss 0.94824, dsc 0.05176\n",
      "Batch train [1] loss 0.94719, dsc 0.05281\n",
      "Batch train [1] loss 0.96110, dsc 0.03890\n",
      "Batch train [1] loss 0.96933, dsc 0.03067\n",
      "Batch train [1] loss 0.97697, dsc 0.02303\n",
      "Batch train [1] loss 0.96053, dsc 0.03947\n",
      "Epoch [14] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  13, step 0\n",
      "Batch eval [1] loss 0.95342, dsc 0.04658\n",
      "Batch eval [1] loss 0.96341, dsc 0.03659\n",
      "Batch eval [1] loss 0.95400, dsc 0.04600\n",
      "Batch eval [1] loss 0.96302, dsc 0.03698\n",
      "Batch eval [1] loss 0.97260, dsc 0.02740\n",
      "Epoch [14] valid done\n",
      "Epoch [14] T 1670.28s, deltaT 116.85s, loss: train 0.96628, valid 0.96129, dsc: train 0.03372, valid 0.03871\n",
      "DEBUG: Writing to tensorboard before epoch True, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  14, step 0\n",
      "Batch train [1] loss 0.98136, dsc 0.01864\n",
      "Batch train [1] loss 0.96325, dsc 0.03675\n",
      "Batch train [1] loss 0.96882, dsc 0.03118\n",
      "Batch train [1] loss 0.95935, dsc 0.04065\n",
      "Batch train [1] loss 0.97384, dsc 0.02616\n",
      "Batch train [1] loss 0.97734, dsc 0.02266\n",
      "Batch train [1] loss 0.94067, dsc 0.05933\n",
      "Batch train [1] loss 0.97400, dsc 0.02600\n",
      "Batch train [1] loss 0.95953, dsc 0.04047\n",
      "Batch train [1] loss 0.97674, dsc 0.02326\n",
      "Batch train [1] loss 0.97562, dsc 0.02438\n",
      "Batch train [1] loss 0.96875, dsc 0.03125\n",
      "Batch train [1] loss 0.96229, dsc 0.03771\n",
      "Batch train [1] loss 0.95598, dsc 0.04402\n",
      "Batch train [1] loss 0.95899, dsc 0.04101\n",
      "Batch train [1] loss 0.97958, dsc 0.02042\n",
      "Batch train [1] loss 0.95579, dsc 0.04421\n",
      "Batch train [1] loss 0.95883, dsc 0.04117\n",
      "Batch train [1] loss 0.94518, dsc 0.05482\n",
      "Batch train [1] loss 0.97933, dsc 0.02067\n",
      "Batch train [1] loss 0.97809, dsc 0.02191\n",
      "Batch train [1] loss 0.95914, dsc 0.04086\n",
      "Batch train [1] loss 0.97144, dsc 0.02856\n",
      "Batch train [1] loss 0.95244, dsc 0.04756\n",
      "Batch train [1] loss 0.98095, dsc 0.01905\n",
      "Batch train [1] loss 0.95890, dsc 0.04110\n",
      "Batch train [1] loss 0.94417, dsc 0.05583\n",
      "Batch train [1] loss 0.96055, dsc 0.03945\n",
      "Batch train [1] loss 0.96425, dsc 0.03575\n",
      "Batch train [1] loss 0.94283, dsc 0.05717\n",
      "Batch train [1] loss 0.96542, dsc 0.03458\n",
      "Batch train [1] loss 0.94557, dsc 0.05443\n",
      "Batch train [1] loss 0.97481, dsc 0.02519\n",
      "Batch train [1] loss 0.95028, dsc 0.04972\n",
      "Batch train [1] loss 0.93554, dsc 0.06446\n",
      "Batch train [1] loss 0.95955, dsc 0.04045\n",
      "Batch train [1] loss 0.96953, dsc 0.03047\n",
      "Batch train [1] loss 0.94580, dsc 0.05420\n",
      "Batch train [1] loss 0.96108, dsc 0.03892\n",
      "Batch train [1] loss 0.97406, dsc 0.02594\n",
      "Epoch [15] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  14, step 0\n",
      "Batch eval [1] loss 0.93933, dsc 0.06067\n",
      "Batch eval [1] loss 0.95417, dsc 0.04583\n",
      "Batch eval [1] loss 0.93466, dsc 0.06534\n",
      "Batch eval [1] loss 0.95441, dsc 0.04559\n",
      "Batch eval [1] loss 0.96531, dsc 0.03469\n",
      "Epoch [15] valid done\n",
      "Epoch [15] T 1787.18s, deltaT 116.89s, loss: train 0.96274, valid 0.94958, dsc: train 0.03726, valid 0.05042\n",
      "DEBUG: Writing to tensorboard before epoch True, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  15, step 0\n",
      "Batch train [1] loss 0.95679, dsc 0.04321\n",
      "Batch train [1] loss 0.97740, dsc 0.02260\n",
      "Batch train [1] loss 0.97910, dsc 0.02090\n",
      "Batch train [1] loss 0.95867, dsc 0.04133\n",
      "Batch train [1] loss 0.95412, dsc 0.04588\n",
      "Batch train [1] loss 0.97351, dsc 0.02649\n",
      "Batch train [1] loss 0.97053, dsc 0.02947\n",
      "Batch train [1] loss 0.97085, dsc 0.02915\n",
      "Batch train [1] loss 0.95988, dsc 0.04012\n",
      "Batch train [1] loss 0.94867, dsc 0.05133\n",
      "Batch train [1] loss 0.96216, dsc 0.03784\n",
      "Batch train [1] loss 0.95753, dsc 0.04247\n",
      "Batch train [1] loss 0.97730, dsc 0.02270\n",
      "Batch train [1] loss 0.97267, dsc 0.02733\n",
      "Batch train [1] loss 0.93945, dsc 0.06055\n",
      "Batch train [1] loss 0.94701, dsc 0.05299\n",
      "Batch train [1] loss 0.97257, dsc 0.02743\n",
      "Batch train [1] loss 0.97436, dsc 0.02564\n",
      "Batch train [1] loss 0.93465, dsc 0.06535\n",
      "Batch train [1] loss 0.96785, dsc 0.03215\n",
      "Batch train [1] loss 0.95435, dsc 0.04565\n",
      "Batch train [1] loss 0.96497, dsc 0.03503\n",
      "Batch train [1] loss 0.96280, dsc 0.03720\n",
      "Batch train [1] loss 0.95382, dsc 0.04618\n",
      "Batch train [1] loss 0.94926, dsc 0.05074\n",
      "Batch train [1] loss 0.97263, dsc 0.02737\n",
      "Batch train [1] loss 0.96313, dsc 0.03687\n",
      "Batch train [1] loss 0.95626, dsc 0.04374\n",
      "Batch train [1] loss 0.97459, dsc 0.02541\n",
      "Batch train [1] loss 0.93035, dsc 0.06965\n",
      "Batch train [1] loss 0.93924, dsc 0.06076\n",
      "Batch train [1] loss 0.97812, dsc 0.02188\n",
      "Batch train [1] loss 0.93599, dsc 0.06401\n",
      "Batch train [1] loss 0.95490, dsc 0.04510\n",
      "Batch train [1] loss 0.93465, dsc 0.06535\n",
      "Batch train [1] loss 0.93990, dsc 0.06010\n",
      "Batch train [1] loss 0.96733, dsc 0.03267\n",
      "Batch train [1] loss 0.95007, dsc 0.04993\n",
      "Batch train [1] loss 0.94650, dsc 0.05350\n",
      "Batch train [1] loss 0.95042, dsc 0.04958\n",
      "Epoch [16] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  15, step 0\n",
      "Batch eval [1] loss 0.92275, dsc 0.07725\n",
      "Batch eval [1] loss 0.94314, dsc 0.05686\n",
      "Batch eval [1] loss 0.93303, dsc 0.06697\n",
      "Batch eval [1] loss 0.94442, dsc 0.05558\n",
      "Batch eval [1] loss 0.95745, dsc 0.04255\n",
      "Epoch [16] valid done\n",
      "Epoch [16] T 1904.36s, deltaT 117.18s, loss: train 0.95836, valid 0.94016, dsc: train 0.04164, valid 0.05984\n",
      "DEBUG: Writing to tensorboard before epoch True, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  16, step 0\n",
      "Batch train [1] loss 0.97112, dsc 0.02888\n",
      "Batch train [1] loss 0.93877, dsc 0.06123\n",
      "Batch train [1] loss 0.95624, dsc 0.04376\n",
      "Batch train [1] loss 0.94322, dsc 0.05678\n",
      "Batch train [1] loss 0.93377, dsc 0.06623\n",
      "Batch train [1] loss 0.96169, dsc 0.03831\n",
      "Batch train [1] loss 0.97701, dsc 0.02299\n",
      "Batch train [1] loss 0.96684, dsc 0.03316\n",
      "Batch train [1] loss 0.92471, dsc 0.07529\n",
      "Batch train [1] loss 0.95927, dsc 0.04073\n",
      "Batch train [1] loss 0.94448, dsc 0.05552\n",
      "Batch train [1] loss 0.97389, dsc 0.02611\n",
      "Batch train [1] loss 0.96430, dsc 0.03570\n",
      "Batch train [1] loss 0.94982, dsc 0.05018\n",
      "Batch train [1] loss 0.94782, dsc 0.05218\n",
      "Batch train [1] loss 0.95936, dsc 0.04064\n",
      "Batch train [1] loss 0.97209, dsc 0.02791\n",
      "Batch train [1] loss 0.95133, dsc 0.04867\n",
      "Batch train [1] loss 0.93360, dsc 0.06640\n",
      "Batch train [1] loss 0.95636, dsc 0.04364\n",
      "Batch train [1] loss 0.96836, dsc 0.03164\n",
      "Batch train [1] loss 0.94722, dsc 0.05278\n",
      "Batch train [1] loss 0.95053, dsc 0.04947\n",
      "Batch train [1] loss 0.96567, dsc 0.03433\n",
      "Batch train [1] loss 0.97466, dsc 0.02534\n",
      "Batch train [1] loss 0.95061, dsc 0.04939\n",
      "Batch train [1] loss 0.94530, dsc 0.05470\n",
      "Batch train [1] loss 0.96945, dsc 0.03055\n",
      "Batch train [1] loss 0.92822, dsc 0.07178\n",
      "Batch train [1] loss 0.96928, dsc 0.03072\n",
      "Batch train [1] loss 0.96269, dsc 0.03731\n",
      "Batch train [1] loss 0.94685, dsc 0.05315\n",
      "Batch train [1] loss 0.92202, dsc 0.07798\n",
      "Batch train [1] loss 0.94395, dsc 0.05605\n",
      "Batch train [1] loss 0.92609, dsc 0.07391\n",
      "Batch train [1] loss 0.94022, dsc 0.05978\n",
      "Batch train [1] loss 0.96729, dsc 0.03271\n",
      "Batch train [1] loss 0.94925, dsc 0.05075\n",
      "Batch train [1] loss 0.93553, dsc 0.06447\n",
      "Batch train [1] loss 0.97230, dsc 0.02770\n",
      "Epoch [17] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  16, step 0\n",
      "Batch eval [1] loss 0.90121, dsc 0.09879\n",
      "Batch eval [1] loss 0.92696, dsc 0.07304\n",
      "Batch eval [1] loss 0.91300, dsc 0.08700\n",
      "Batch eval [1] loss 0.92914, dsc 0.07086\n",
      "Batch eval [1] loss 0.94523, dsc 0.05477\n",
      "Epoch [17] valid done\n",
      "Epoch [17] T 2021.22s, deltaT 116.86s, loss: train 0.95303, valid 0.92311, dsc: train 0.04697, valid 0.07689\n",
      "DEBUG: Writing to tensorboard before epoch True, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  17, step 0\n",
      "Batch train [1] loss 0.95042, dsc 0.04958\n",
      "Batch train [1] loss 0.94448, dsc 0.05552\n",
      "Batch train [1] loss 0.96968, dsc 0.03032\n",
      "Batch train [1] loss 0.91953, dsc 0.08047\n",
      "Batch train [1] loss 0.95266, dsc 0.04734\n",
      "Batch train [1] loss 0.94731, dsc 0.05269\n",
      "Batch train [1] loss 0.92544, dsc 0.07456\n",
      "Batch train [1] loss 0.97104, dsc 0.02896\n",
      "Batch train [1] loss 0.97191, dsc 0.02809\n",
      "Batch train [1] loss 0.96680, dsc 0.03320\n",
      "Batch train [1] loss 0.91903, dsc 0.08097\n",
      "Batch train [1] loss 0.96631, dsc 0.03369\n",
      "Batch train [1] loss 0.96027, dsc 0.03973\n",
      "Batch train [1] loss 0.92501, dsc 0.07499\n",
      "Batch train [1] loss 0.94301, dsc 0.05699\n",
      "Batch train [1] loss 0.94013, dsc 0.05987\n",
      "Batch train [1] loss 0.96262, dsc 0.03738\n",
      "Batch train [1] loss 0.92869, dsc 0.07131\n",
      "Batch train [1] loss 0.95267, dsc 0.04733\n",
      "Batch train [1] loss 0.92580, dsc 0.07420\n",
      "Batch train [1] loss 0.94571, dsc 0.05429\n",
      "Batch train [1] loss 0.94087, dsc 0.05913\n",
      "Batch train [1] loss 0.93224, dsc 0.06776\n",
      "Batch train [1] loss 0.93539, dsc 0.06461\n",
      "Batch train [1] loss 0.95278, dsc 0.04722\n",
      "Batch train [1] loss 0.96587, dsc 0.03413\n",
      "Batch train [1] loss 0.93437, dsc 0.06563\n",
      "Batch train [1] loss 0.96540, dsc 0.03460\n",
      "Batch train [1] loss 0.94053, dsc 0.05947\n",
      "Batch train [1] loss 0.94273, dsc 0.05727\n",
      "Batch train [1] loss 0.93842, dsc 0.06158\n",
      "Batch train [1] loss 0.94325, dsc 0.05675\n",
      "Batch train [1] loss 0.97110, dsc 0.02890\n",
      "Batch train [1] loss 0.95313, dsc 0.04687\n",
      "Batch train [1] loss 0.91601, dsc 0.08399\n",
      "Batch train [1] loss 0.96225, dsc 0.03775\n",
      "Batch train [1] loss 0.95887, dsc 0.04113\n",
      "Batch train [1] loss 0.92865, dsc 0.07135\n",
      "Batch train [1] loss 0.97105, dsc 0.02895\n",
      "Batch train [1] loss 0.95942, dsc 0.04058\n",
      "Epoch [18] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  17, step 0\n",
      "Batch eval [1] loss 0.90794, dsc 0.09206\n",
      "Batch eval [1] loss 0.92786, dsc 0.07214\n",
      "Batch eval [1] loss 0.91262, dsc 0.08738\n",
      "Batch eval [1] loss 0.93012, dsc 0.06988\n",
      "Batch eval [1] loss 0.94537, dsc 0.05463\n",
      "Epoch [18] valid done\n",
      "Epoch [18] T 2138.10s, deltaT 116.87s, loss: train 0.94752, valid 0.92478, dsc: train 0.05248, valid 0.07522\n",
      "DEBUG: Writing to tensorboard before epoch True, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  18, step 0\n",
      "Batch train [1] loss 0.94100, dsc 0.05900\n",
      "Batch train [1] loss 0.96128, dsc 0.03872\n",
      "Batch train [1] loss 0.95719, dsc 0.04281\n",
      "Batch train [1] loss 0.95001, dsc 0.04999\n",
      "Batch train [1] loss 0.90615, dsc 0.09385\n",
      "Batch train [1] loss 0.96934, dsc 0.03066\n",
      "Batch train [1] loss 0.94766, dsc 0.05234\n",
      "Batch train [1] loss 0.91185, dsc 0.08815\n",
      "Batch train [1] loss 0.90397, dsc 0.09603\n",
      "Batch train [1] loss 0.93244, dsc 0.06756\n",
      "Batch train [1] loss 0.91696, dsc 0.08304\n",
      "Batch train [1] loss 0.91911, dsc 0.08089\n",
      "Batch train [1] loss 0.93702, dsc 0.06298\n",
      "Batch train [1] loss 0.93847, dsc 0.06153\n",
      "Batch train [1] loss 0.93326, dsc 0.06674\n",
      "Batch train [1] loss 0.95979, dsc 0.04021\n",
      "Batch train [1] loss 0.94332, dsc 0.05668\n",
      "Batch train [1] loss 0.92134, dsc 0.07866\n",
      "Batch train [1] loss 0.93245, dsc 0.06755\n",
      "Batch train [1] loss 0.90989, dsc 0.09011\n",
      "Batch train [1] loss 0.93020, dsc 0.06980\n",
      "Batch train [1] loss 0.92502, dsc 0.07498\n",
      "Batch train [1] loss 0.96778, dsc 0.03222\n",
      "Batch train [1] loss 0.92379, dsc 0.07621\n",
      "Batch train [1] loss 0.93094, dsc 0.06906\n",
      "Batch train [1] loss 0.96326, dsc 0.03674\n",
      "Batch train [1] loss 0.92727, dsc 0.07273\n",
      "Batch train [1] loss 0.90461, dsc 0.09539\n",
      "Batch train [1] loss 0.91872, dsc 0.08128\n",
      "Batch train [1] loss 0.95238, dsc 0.04762\n",
      "Batch train [1] loss 0.94951, dsc 0.05049\n",
      "Batch train [1] loss 0.93187, dsc 0.06813\n",
      "Batch train [1] loss 0.95831, dsc 0.04169\n",
      "Batch train [1] loss 0.95633, dsc 0.04367\n",
      "Batch train [1] loss 0.95968, dsc 0.04032\n",
      "Batch train [1] loss 0.93488, dsc 0.06512\n",
      "Batch train [1] loss 0.94275, dsc 0.05725\n",
      "Batch train [1] loss 0.96218, dsc 0.03782\n",
      "Batch train [1] loss 0.95736, dsc 0.04264\n",
      "Batch train [1] loss 0.95002, dsc 0.04998\n",
      "Epoch [19] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  18, step 0\n",
      "Batch eval [1] loss 0.88619, dsc 0.11381\n",
      "Batch eval [1] loss 0.91570, dsc 0.08430\n",
      "Batch eval [1] loss 0.90707, dsc 0.09293\n",
      "Batch eval [1] loss 0.91888, dsc 0.08112\n",
      "Batch eval [1] loss 0.94001, dsc 0.05999\n",
      "Epoch [19] valid done\n",
      "Epoch [19] T 2255.08s, deltaT 116.98s, loss: train 0.93848, valid 0.91357, dsc: train 0.06152, valid 0.08643\n",
      "DEBUG: Writing to tensorboard before epoch True, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  19, step 0\n",
      "Batch train [1] loss 0.91395, dsc 0.08605\n",
      "Batch train [1] loss 0.88920, dsc 0.11080\n",
      "Batch train [1] loss 0.93238, dsc 0.06762\n",
      "Batch train [1] loss 0.91196, dsc 0.08804\n",
      "Batch train [1] loss 0.96023, dsc 0.03977\n",
      "Batch train [1] loss 0.95809, dsc 0.04191\n",
      "Batch train [1] loss 0.95410, dsc 0.04590\n",
      "Batch train [1] loss 0.94920, dsc 0.05080\n",
      "Batch train [1] loss 0.93671, dsc 0.06329\n",
      "Batch train [1] loss 0.95424, dsc 0.04576\n",
      "Batch train [1] loss 0.92576, dsc 0.07424\n",
      "Batch train [1] loss 0.96045, dsc 0.03955\n",
      "Batch train [1] loss 0.95453, dsc 0.04547\n",
      "Batch train [1] loss 0.91399, dsc 0.08601\n",
      "Batch train [1] loss 0.88635, dsc 0.11365\n",
      "Batch train [1] loss 0.92006, dsc 0.07994\n",
      "Batch train [1] loss 0.92133, dsc 0.07867\n",
      "Batch train [1] loss 0.91964, dsc 0.08036\n",
      "Batch train [1] loss 0.89412, dsc 0.10588\n",
      "Batch train [1] loss 0.92488, dsc 0.07512\n",
      "Batch train [1] loss 0.95059, dsc 0.04941\n",
      "Batch train [1] loss 0.95224, dsc 0.04776\n",
      "Batch train [1] loss 0.92156, dsc 0.07844\n",
      "Batch train [1] loss 0.91162, dsc 0.08838\n",
      "Batch train [1] loss 0.92163, dsc 0.07837\n",
      "Batch train [1] loss 0.94475, dsc 0.05525\n",
      "Batch train [1] loss 0.91849, dsc 0.08151\n",
      "Batch train [1] loss 0.93419, dsc 0.06581\n",
      "Batch train [1] loss 0.91337, dsc 0.08663\n",
      "Batch train [1] loss 0.95878, dsc 0.04122\n",
      "Batch train [1] loss 0.89655, dsc 0.10345\n",
      "Batch train [1] loss 0.93932, dsc 0.06068\n",
      "Batch train [1] loss 0.94055, dsc 0.05945\n",
      "Batch train [1] loss 0.91237, dsc 0.08763\n",
      "Batch train [1] loss 0.89463, dsc 0.10537\n",
      "Batch train [1] loss 0.88173, dsc 0.11827\n",
      "Batch train [1] loss 0.88739, dsc 0.11261\n",
      "Batch train [1] loss 0.92695, dsc 0.07305\n",
      "Batch train [1] loss 0.92866, dsc 0.07134\n",
      "Batch train [1] loss 0.95814, dsc 0.04186\n",
      "Epoch [20] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  19, step 0\n",
      "Batch eval [1] loss 0.86644, dsc 0.13356\n",
      "Batch eval [1] loss 0.89931, dsc 0.10069\n",
      "Batch eval [1] loss 0.87751, dsc 0.12249\n",
      "Batch eval [1] loss 0.90250, dsc 0.09750\n",
      "Batch eval [1] loss 0.92465, dsc 0.07535\n",
      "Epoch [20] valid done\n",
      "Epoch [20] T 2372.57s, deltaT 117.48s, loss: train 0.92687, valid 0.89408, dsc: train 0.07313, valid 0.10592\n",
      "DEBUG: Writing to tensorboard before epoch True, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  20, step 0\n",
      "Batch train [1] loss 0.91573, dsc 0.08427\n",
      "Batch train [1] loss 0.93251, dsc 0.06749\n",
      "Batch train [1] loss 0.95740, dsc 0.04260\n",
      "Batch train [1] loss 0.90703, dsc 0.09297\n",
      "Batch train [1] loss 0.88340, dsc 0.11660\n",
      "Batch train [1] loss 0.88896, dsc 0.11104\n",
      "Batch train [1] loss 0.92184, dsc 0.07816\n",
      "Batch train [1] loss 0.89793, dsc 0.10207\n",
      "Batch train [1] loss 0.94502, dsc 0.05498\n",
      "Batch train [1] loss 0.93534, dsc 0.06466\n",
      "Batch train [1] loss 0.90845, dsc 0.09155\n",
      "Batch train [1] loss 0.87891, dsc 0.12109\n",
      "Batch train [1] loss 0.93831, dsc 0.06169\n",
      "Batch train [1] loss 0.89337, dsc 0.10663\n",
      "Batch train [1] loss 0.95031, dsc 0.04969\n",
      "Batch train [1] loss 0.93347, dsc 0.06653\n",
      "Batch train [1] loss 0.90387, dsc 0.09613\n",
      "Batch train [1] loss 0.91909, dsc 0.08091\n",
      "Batch train [1] loss 0.94154, dsc 0.05846\n",
      "Batch train [1] loss 0.87284, dsc 0.12716\n",
      "Batch train [1] loss 0.94519, dsc 0.05481\n",
      "Batch train [1] loss 0.93263, dsc 0.06737\n",
      "Batch train [1] loss 0.86546, dsc 0.13454\n",
      "Batch train [1] loss 0.89864, dsc 0.10136\n",
      "Batch train [1] loss 0.85525, dsc 0.14475\n",
      "Batch train [1] loss 0.90349, dsc 0.09651\n",
      "Batch train [1] loss 0.93637, dsc 0.06363\n",
      "Batch train [1] loss 0.94938, dsc 0.05062\n",
      "Batch train [1] loss 0.91774, dsc 0.08226\n",
      "Batch train [1] loss 0.86972, dsc 0.13028\n",
      "Batch train [1] loss 0.90861, dsc 0.09139\n",
      "Batch train [1] loss 0.90294, dsc 0.09706\n",
      "Batch train [1] loss 0.93778, dsc 0.06222\n",
      "Batch train [1] loss 0.93749, dsc 0.06251\n",
      "Batch train [1] loss 0.89396, dsc 0.10604\n",
      "Batch train [1] loss 0.94348, dsc 0.05652\n",
      "Batch train [1] loss 0.87683, dsc 0.12317\n",
      "Batch train [1] loss 0.88882, dsc 0.11118\n",
      "Batch train [1] loss 0.88189, dsc 0.11811\n",
      "Batch train [1] loss 0.90104, dsc 0.09896\n",
      "Epoch [21] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  20, step 0\n",
      "Batch eval [1] loss 0.87392, dsc 0.12608\n",
      "Batch eval [1] loss 0.90266, dsc 0.09734\n",
      "Batch eval [1] loss 0.87060, dsc 0.12940\n",
      "Batch eval [1] loss 0.90666, dsc 0.09334\n",
      "Batch eval [1] loss 0.92972, dsc 0.07028\n",
      "Epoch [21] valid done\n",
      "Epoch [21] T 2489.52s, deltaT 116.94s, loss: train 0.91180, valid 0.89671, dsc: train 0.08820, valid 0.10329\n",
      "DEBUG: Writing to tensorboard before epoch True, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  21, step 0\n",
      "Batch train [1] loss 0.93839, dsc 0.06161\n",
      "Batch train [1] loss 0.89483, dsc 0.10517\n",
      "Batch train [1] loss 0.93096, dsc 0.06904\n",
      "Batch train [1] loss 0.89512, dsc 0.10488\n",
      "Batch train [1] loss 0.85329, dsc 0.14671\n",
      "Batch train [1] loss 0.88785, dsc 0.11215\n",
      "Batch train [1] loss 0.91011, dsc 0.08989\n",
      "Batch train [1] loss 0.92260, dsc 0.07740\n",
      "Batch train [1] loss 0.88249, dsc 0.11751\n",
      "Batch train [1] loss 0.86810, dsc 0.13190\n",
      "Batch train [1] loss 0.93708, dsc 0.06292\n",
      "Batch train [1] loss 0.91672, dsc 0.08328\n",
      "Batch train [1] loss 0.91952, dsc 0.08048\n",
      "Batch train [1] loss 0.92643, dsc 0.07357\n",
      "Batch train [1] loss 0.94089, dsc 0.05911\n",
      "Batch train [1] loss 0.83274, dsc 0.16726\n",
      "Batch train [1] loss 0.83097, dsc 0.16903\n",
      "Batch train [1] loss 0.89707, dsc 0.10293\n",
      "Batch train [1] loss 0.89219, dsc 0.10781\n",
      "Batch train [1] loss 0.86072, dsc 0.13928\n",
      "Batch train [1] loss 0.91410, dsc 0.08590\n",
      "Batch train [1] loss 0.89912, dsc 0.10088\n",
      "Batch train [1] loss 0.84128, dsc 0.15872\n",
      "Batch train [1] loss 0.87338, dsc 0.12662\n",
      "Batch train [1] loss 0.87435, dsc 0.12565\n",
      "Batch train [1] loss 0.84214, dsc 0.15786\n",
      "Batch train [1] loss 0.86596, dsc 0.13404\n",
      "Batch train [1] loss 0.88223, dsc 0.11777\n",
      "Batch train [1] loss 0.93834, dsc 0.06166\n",
      "Batch train [1] loss 0.92347, dsc 0.07653\n",
      "Batch train [1] loss 0.92740, dsc 0.07260\n",
      "Batch train [1] loss 0.86756, dsc 0.13244\n",
      "Batch train [1] loss 0.85801, dsc 0.14199\n",
      "Batch train [1] loss 0.84092, dsc 0.15908\n",
      "Batch train [1] loss 0.87959, dsc 0.12041\n",
      "Batch train [1] loss 0.85324, dsc 0.14676\n",
      "Batch train [1] loss 0.86636, dsc 0.13364\n",
      "Batch train [1] loss 0.93046, dsc 0.06954\n",
      "Batch train [1] loss 0.92071, dsc 0.07929\n",
      "Batch train [1] loss 0.89641, dsc 0.10358\n",
      "Epoch [22] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  21, step 0\n",
      "Batch eval [1] loss 0.95989, dsc 0.04011\n",
      "Batch eval [1] loss 0.97183, dsc 0.02817\n",
      "Batch eval [1] loss 0.98855, dsc 0.01145\n",
      "Batch eval [1] loss 0.97579, dsc 0.02421\n",
      "Batch eval [1] loss 0.97604, dsc 0.02396\n",
      "Epoch [22] valid done\n",
      "Epoch [22] T 2606.53s, deltaT 117.00s, loss: train 0.89083, valid 0.97442, dsc: train 0.10917, valid 0.02558\n",
      "DEBUG: Writing to tensorboard before epoch True, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  22, step 0\n",
      "Batch train [1] loss 0.90678, dsc 0.09322\n",
      "Batch train [1] loss 0.92004, dsc 0.07996\n",
      "Batch train [1] loss 0.87294, dsc 0.12706\n",
      "Batch train [1] loss 0.89323, dsc 0.10677\n",
      "Batch train [1] loss 0.83432, dsc 0.16568\n",
      "Batch train [1] loss 0.86502, dsc 0.13498\n",
      "Batch train [1] loss 0.82790, dsc 0.17210\n",
      "Batch train [1] loss 0.89328, dsc 0.10672\n",
      "Batch train [1] loss 0.92686, dsc 0.07314\n",
      "Batch train [1] loss 0.90613, dsc 0.09387\n",
      "Batch train [1] loss 0.92855, dsc 0.07145\n",
      "Batch train [1] loss 0.91693, dsc 0.08307\n",
      "Batch train [1] loss 0.91891, dsc 0.08109\n",
      "Batch train [1] loss 0.84711, dsc 0.15289\n",
      "Batch train [1] loss 0.86971, dsc 0.13029\n",
      "Batch train [1] loss 0.86614, dsc 0.13386\n",
      "Batch train [1] loss 0.80399, dsc 0.19601\n",
      "Batch train [1] loss 0.86889, dsc 0.13111\n",
      "Batch train [1] loss 0.90237, dsc 0.09763\n",
      "Batch train [1] loss 0.86079, dsc 0.13921\n",
      "Batch train [1] loss 0.91840, dsc 0.08160\n",
      "Batch train [1] loss 0.90831, dsc 0.09169\n",
      "Batch train [1] loss 0.87884, dsc 0.12116\n",
      "Batch train [1] loss 0.90445, dsc 0.09555\n",
      "Batch train [1] loss 0.84544, dsc 0.15456\n",
      "Batch train [1] loss 0.82409, dsc 0.17591\n",
      "Batch train [1] loss 0.91835, dsc 0.08165\n",
      "Batch train [1] loss 0.80250, dsc 0.19750\n",
      "Batch train [1] loss 0.85487, dsc 0.14513\n",
      "Batch train [1] loss 0.86682, dsc 0.13318\n",
      "Batch train [1] loss 0.90818, dsc 0.09182\n",
      "Batch train [1] loss 0.84062, dsc 0.15938\n",
      "Batch train [1] loss 0.85768, dsc 0.14232\n",
      "Batch train [1] loss 0.77368, dsc 0.22632\n",
      "Batch train [1] loss 0.79844, dsc 0.20156\n",
      "Batch train [1] loss 0.92079, dsc 0.07921\n",
      "Batch train [1] loss 0.81667, dsc 0.18333\n",
      "Batch train [1] loss 0.85838, dsc 0.14162\n",
      "Batch train [1] loss 0.84187, dsc 0.15813\n",
      "Batch train [1] loss 0.81043, dsc 0.18957\n",
      "Epoch [23] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  22, step 0\n",
      "Batch eval [1] loss 0.77567, dsc 0.22433\n",
      "Batch eval [1] loss 0.82039, dsc 0.17961\n",
      "Batch eval [1] loss 0.78542, dsc 0.21458\n",
      "Batch eval [1] loss 0.83786, dsc 0.16214\n",
      "Batch eval [1] loss 0.87352, dsc 0.12648\n",
      "Epoch [23] valid done\n",
      "Epoch [23] T 2723.49s, deltaT 116.96s, loss: train 0.86947, valid 0.81857, dsc: train 0.13053, valid 0.18143\n",
      "DEBUG: Writing to tensorboard before epoch True, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  23, step 0\n",
      "Batch train [1] loss 0.84349, dsc 0.15651\n",
      "Batch train [1] loss 0.86043, dsc 0.13957\n",
      "Batch train [1] loss 0.82515, dsc 0.17485\n",
      "Batch train [1] loss 0.89333, dsc 0.10667\n",
      "Batch train [1] loss 0.89895, dsc 0.10105\n",
      "Batch train [1] loss 0.86138, dsc 0.13862\n",
      "Batch train [1] loss 0.77961, dsc 0.22039\n",
      "Batch train [1] loss 0.81805, dsc 0.18195\n",
      "Batch train [1] loss 0.83382, dsc 0.16618\n",
      "Batch train [1] loss 0.91461, dsc 0.08539\n",
      "Batch train [1] loss 0.91399, dsc 0.08601\n",
      "Batch train [1] loss 0.82995, dsc 0.17005\n",
      "Batch train [1] loss 0.88168, dsc 0.11832\n",
      "Batch train [1] loss 0.79704, dsc 0.20296\n",
      "Batch train [1] loss 0.81348, dsc 0.18652\n",
      "Batch train [1] loss 0.75600, dsc 0.24400\n",
      "Batch train [1] loss 0.82257, dsc 0.17743\n",
      "Batch train [1] loss 0.88870, dsc 0.11130\n",
      "Batch train [1] loss 0.82346, dsc 0.17654\n",
      "Batch train [1] loss 0.83634, dsc 0.16366\n",
      "Batch train [1] loss 0.76909, dsc 0.23091\n",
      "Batch train [1] loss 0.88782, dsc 0.11218\n",
      "Batch train [1] loss 0.88137, dsc 0.11863\n",
      "Batch train [1] loss 0.86615, dsc 0.13385\n",
      "Batch train [1] loss 0.76983, dsc 0.23017\n",
      "Batch train [1] loss 0.83288, dsc 0.16712\n",
      "Batch train [1] loss 0.81856, dsc 0.18144\n",
      "Batch train [1] loss 0.84157, dsc 0.15843\n",
      "Batch train [1] loss 0.85932, dsc 0.14068\n",
      "Batch train [1] loss 0.80454, dsc 0.19546\n",
      "Batch train [1] loss 0.74707, dsc 0.25293\n",
      "Batch train [1] loss 0.81050, dsc 0.18950\n",
      "Batch train [1] loss 0.88722, dsc 0.11278\n",
      "Batch train [1] loss 0.79433, dsc 0.20567\n",
      "Batch train [1] loss 0.85846, dsc 0.14154\n",
      "Batch train [1] loss 0.89701, dsc 0.10299\n",
      "Batch train [1] loss 0.77569, dsc 0.22431\n",
      "Batch train [1] loss 0.78702, dsc 0.21298\n",
      "Batch train [1] loss 0.87374, dsc 0.12626\n",
      "Batch train [1] loss 0.73786, dsc 0.26214\n",
      "Epoch [24] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  23, step 0\n",
      "Batch eval [1] loss 0.72935, dsc 0.27065\n",
      "Batch eval [1] loss 0.77344, dsc 0.22656\n",
      "Batch eval [1] loss 0.76057, dsc 0.23943\n",
      "Batch eval [1] loss 0.77707, dsc 0.22293\n",
      "Batch eval [1] loss 0.82691, dsc 0.17309\n",
      "Epoch [24] valid done\n",
      "Epoch [24] T 2840.32s, deltaT 116.82s, loss: train 0.83480, valid 0.77347, dsc: train 0.16520, valid 0.22653\n",
      "DEBUG: Writing to tensorboard before epoch True, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  24, step 0\n",
      "Batch train [1] loss 0.83173, dsc 0.16827\n",
      "Batch train [1] loss 0.88115, dsc 0.11885\n",
      "Batch train [1] loss 0.88455, dsc 0.11545\n",
      "Batch train [1] loss 0.85864, dsc 0.14136\n",
      "Batch train [1] loss 0.78407, dsc 0.21593\n",
      "Batch train [1] loss 0.78530, dsc 0.21470\n",
      "Batch train [1] loss 0.75910, dsc 0.24090\n",
      "Batch train [1] loss 0.88226, dsc 0.11774\n",
      "Batch train [1] loss 0.76588, dsc 0.23412\n",
      "Batch train [1] loss 0.71488, dsc 0.28512\n",
      "Batch train [1] loss 0.79665, dsc 0.20335\n",
      "Batch train [1] loss 0.72917, dsc 0.27083\n",
      "Batch train [1] loss 0.86121, dsc 0.13879\n",
      "Batch train [1] loss 0.71007, dsc 0.28993\n",
      "Batch train [1] loss 0.78273, dsc 0.21727\n",
      "Batch train [1] loss 0.84369, dsc 0.15631\n",
      "Batch train [1] loss 0.85969, dsc 0.14031\n",
      "Batch train [1] loss 0.78351, dsc 0.21649\n",
      "Batch train [1] loss 0.69334, dsc 0.30666\n",
      "Batch train [1] loss 0.87912, dsc 0.12088\n",
      "Batch train [1] loss 0.85206, dsc 0.14794\n",
      "Batch train [1] loss 0.85206, dsc 0.14794\n",
      "Batch train [1] loss 0.77900, dsc 0.22100\n",
      "Batch train [1] loss 0.75910, dsc 0.24090\n",
      "Batch train [1] loss 0.72317, dsc 0.27683\n",
      "Batch train [1] loss 0.78040, dsc 0.21960\n",
      "Batch train [1] loss 0.79586, dsc 0.20414\n",
      "Batch train [1] loss 0.82407, dsc 0.17593\n",
      "Batch train [1] loss 0.72635, dsc 0.27365\n",
      "Batch train [1] loss 0.78277, dsc 0.21723\n",
      "Batch train [1] loss 0.82177, dsc 0.17823\n",
      "Batch train [1] loss 0.69465, dsc 0.30535\n",
      "Batch train [1] loss 0.83883, dsc 0.16117\n",
      "Batch train [1] loss 0.75359, dsc 0.24641\n",
      "Batch train [1] loss 0.72787, dsc 0.27213\n",
      "Batch train [1] loss 0.82091, dsc 0.17909\n",
      "Batch train [1] loss 0.74169, dsc 0.25831\n",
      "Batch train [1] loss 0.79474, dsc 0.20526\n",
      "Batch train [1] loss 0.74067, dsc 0.25933\n",
      "Batch train [1] loss 0.67399, dsc 0.32601\n",
      "Epoch [25] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  24, step 0\n",
      "Batch eval [1] loss 0.64974, dsc 0.35026\n",
      "Batch eval [1] loss 0.71066, dsc 0.28934\n",
      "Batch eval [1] loss 0.70189, dsc 0.29811\n",
      "Batch eval [1] loss 0.71756, dsc 0.28244\n",
      "Batch eval [1] loss 0.77704, dsc 0.22296\n",
      "Epoch [25] valid done\n",
      "Epoch [25] T 2957.32s, deltaT 117.00s, loss: train 0.78926, valid 0.71138, dsc: train 0.21074, valid 0.28862\n",
      "DEBUG: Writing to tensorboard before epoch True, 25, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  25, step 0\n",
      "Batch train [1] loss 0.80342, dsc 0.19658\n",
      "Batch train [1] loss 0.74838, dsc 0.25162\n",
      "Batch train [1] loss 0.83267, dsc 0.16733\n",
      "Batch train [1] loss 0.82302, dsc 0.17698\n",
      "Batch train [1] loss 0.84517, dsc 0.15483\n",
      "Batch train [1] loss 0.73761, dsc 0.26239\n",
      "Batch train [1] loss 0.65755, dsc 0.34245\n",
      "Batch train [1] loss 0.74747, dsc 0.25253\n",
      "Batch train [1] loss 0.69264, dsc 0.30736\n",
      "Batch train [1] loss 0.82626, dsc 0.17374\n",
      "Batch train [1] loss 0.79625, dsc 0.20375\n",
      "Batch train [1] loss 0.81335, dsc 0.18665\n",
      "Batch train [1] loss 0.75075, dsc 0.24925\n",
      "Batch train [1] loss 0.83656, dsc 0.16344\n",
      "Batch train [1] loss 0.69415, dsc 0.30585\n",
      "Batch train [1] loss 0.80551, dsc 0.19449\n",
      "Batch train [1] loss 0.80773, dsc 0.19227\n",
      "Batch train [1] loss 0.73163, dsc 0.26837\n",
      "Batch train [1] loss 0.63018, dsc 0.36982\n",
      "Batch train [1] loss 0.75853, dsc 0.24147\n",
      "Batch train [1] loss 0.72416, dsc 0.27584\n",
      "Batch train [1] loss 0.70038, dsc 0.29962\n",
      "Batch train [1] loss 0.69618, dsc 0.30382\n",
      "Batch train [1] loss 0.83385, dsc 0.16615\n",
      "Batch train [1] loss 0.67211, dsc 0.32789\n",
      "Batch train [1] loss 0.81091, dsc 0.18909\n",
      "Batch train [1] loss 0.68795, dsc 0.31205\n",
      "Batch train [1] loss 0.69554, dsc 0.30446\n",
      "Batch train [1] loss 0.78484, dsc 0.21516\n",
      "Batch train [1] loss 0.73319, dsc 0.26681\n",
      "Batch train [1] loss 0.83057, dsc 0.16943\n",
      "Batch train [1] loss 0.73953, dsc 0.26047\n",
      "Batch train [1] loss 0.67356, dsc 0.32644\n",
      "Batch train [1] loss 0.70780, dsc 0.29220\n",
      "Batch train [1] loss 0.64258, dsc 0.35742\n",
      "Batch train [1] loss 0.60238, dsc 0.39762\n",
      "Batch train [1] loss 0.67967, dsc 0.32033\n",
      "Batch train [1] loss 0.61943, dsc 0.38057\n",
      "Batch train [1] loss 0.67334, dsc 0.32666\n",
      "Batch train [1] loss 0.61103, dsc 0.38897\n",
      "Epoch [26] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 25, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  25, step 0\n",
      "Batch eval [1] loss 0.55333, dsc 0.44667\n",
      "Batch eval [1] loss 0.62165, dsc 0.37835\n",
      "Batch eval [1] loss 0.63425, dsc 0.36575\n",
      "Batch eval [1] loss 0.61924, dsc 0.38076\n",
      "Batch eval [1] loss 0.68909, dsc 0.31091\n",
      "Epoch [26] valid done\n",
      "Epoch [26] T 3074.09s, deltaT 116.77s, loss: train 0.73645, valid 0.62351, dsc: train 0.26355, valid 0.37649\n",
      "DEBUG: Writing to tensorboard before epoch True, 26, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  26, step 0\n",
      "Batch train [1] loss 0.60715, dsc 0.39285\n",
      "Batch train [1] loss 0.79429, dsc 0.20571\n",
      "Batch train [1] loss 0.68133, dsc 0.31867\n",
      "Batch train [1] loss 0.61828, dsc 0.38172\n",
      "Batch train [1] loss 0.71769, dsc 0.28231\n",
      "Batch train [1] loss 0.78643, dsc 0.21357\n",
      "Batch train [1] loss 0.65772, dsc 0.34228\n",
      "Batch train [1] loss 0.69527, dsc 0.30473\n",
      "Batch train [1] loss 0.77400, dsc 0.22600\n",
      "Batch train [1] loss 0.61366, dsc 0.38634\n",
      "Batch train [1] loss 0.79030, dsc 0.20970\n",
      "Batch train [1] loss 0.66862, dsc 0.33138\n",
      "Batch train [1] loss 0.68278, dsc 0.31722\n",
      "Batch train [1] loss 0.67799, dsc 0.32201\n",
      "Batch train [1] loss 0.81250, dsc 0.18750\n",
      "Batch train [1] loss 0.77738, dsc 0.22262\n",
      "Batch train [1] loss 0.69039, dsc 0.30961\n",
      "Batch train [1] loss 0.71812, dsc 0.28188\n",
      "Batch train [1] loss 0.74988, dsc 0.25012\n",
      "Batch train [1] loss 0.69489, dsc 0.30511\n",
      "Batch train [1] loss 0.79476, dsc 0.20524\n",
      "Batch train [1] loss 0.54535, dsc 0.45465\n",
      "Batch train [1] loss 0.66289, dsc 0.33711\n",
      "Batch train [1] loss 0.74839, dsc 0.25161\n",
      "Batch train [1] loss 0.61269, dsc 0.38731\n",
      "Batch train [1] loss 0.64195, dsc 0.35805\n",
      "Batch train [1] loss 0.62603, dsc 0.37397\n",
      "Batch train [1] loss 0.63208, dsc 0.36792\n",
      "Batch train [1] loss 0.63509, dsc 0.36491\n",
      "Batch train [1] loss 0.72887, dsc 0.27113\n",
      "Batch train [1] loss 0.62374, dsc 0.37626\n",
      "Batch train [1] loss 0.71366, dsc 0.28634\n",
      "Batch train [1] loss 0.79128, dsc 0.20872\n",
      "Batch train [1] loss 0.59531, dsc 0.40469\n",
      "Batch train [1] loss 0.55914, dsc 0.44086\n",
      "Batch train [1] loss 0.77314, dsc 0.22686\n",
      "Batch train [1] loss 0.61707, dsc 0.38293\n",
      "Batch train [1] loss 0.73228, dsc 0.26772\n",
      "Batch train [1] loss 0.66990, dsc 0.33010\n",
      "Batch train [1] loss 0.52712, dsc 0.47288\n",
      "Epoch [27] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 26, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  26, step 0\n",
      "Batch eval [1] loss 0.51806, dsc 0.48194\n",
      "Batch eval [1] loss 0.56814, dsc 0.43186\n",
      "Batch eval [1] loss 0.67839, dsc 0.32161\n",
      "Batch eval [1] loss 0.56999, dsc 0.43001\n",
      "Batch eval [1] loss 0.64376, dsc 0.35624\n",
      "Epoch [27] valid done\n",
      "Epoch [27] T 3190.67s, deltaT 116.57s, loss: train 0.68599, valid 0.59567, dsc: train 0.31401, valid 0.40433\n",
      "DEBUG: Writing to tensorboard before epoch True, 27, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  27, step 0\n",
      "Batch train [1] loss 0.52882, dsc 0.47118\n",
      "Batch train [1] loss 0.75023, dsc 0.24977\n",
      "Batch train [1] loss 0.62547, dsc 0.37453\n",
      "Batch train [1] loss 0.54400, dsc 0.45600\n",
      "Batch train [1] loss 0.54108, dsc 0.45892\n",
      "Batch train [1] loss 0.74980, dsc 0.25020\n",
      "Batch train [1] loss 0.59910, dsc 0.40090\n",
      "Batch train [1] loss 0.57353, dsc 0.42647\n",
      "Batch train [1] loss 0.68348, dsc 0.31652\n",
      "Batch train [1] loss 0.54095, dsc 0.45905\n",
      "Batch train [1] loss 0.59667, dsc 0.40333\n",
      "Batch train [1] loss 0.69436, dsc 0.30564\n",
      "Batch train [1] loss 0.72007, dsc 0.27993\n",
      "Batch train [1] loss 0.69980, dsc 0.30020\n",
      "Batch train [1] loss 0.59502, dsc 0.40498\n",
      "Batch train [1] loss 0.62042, dsc 0.37958\n",
      "Batch train [1] loss 0.59167, dsc 0.40833\n",
      "Batch train [1] loss 0.65421, dsc 0.34579\n",
      "Batch train [1] loss 0.60718, dsc 0.39282\n",
      "Batch train [1] loss 0.56763, dsc 0.43237\n",
      "Batch train [1] loss 0.59262, dsc 0.40738\n",
      "Batch train [1] loss 0.59180, dsc 0.40820\n",
      "Batch train [1] loss 0.56828, dsc 0.43172\n",
      "Batch train [1] loss 0.54206, dsc 0.45794\n",
      "Batch train [1] loss 0.63211, dsc 0.36789\n",
      "Batch train [1] loss 0.70132, dsc 0.29868\n",
      "Batch train [1] loss 0.72041, dsc 0.27959\n",
      "Batch train [1] loss 0.56390, dsc 0.43610\n",
      "Batch train [1] loss 0.60583, dsc 0.39417\n",
      "Batch train [1] loss 0.74375, dsc 0.25625\n",
      "Batch train [1] loss 0.69258, dsc 0.30742\n",
      "Batch train [1] loss 0.69440, dsc 0.30560\n",
      "Batch train [1] loss 0.48925, dsc 0.51075\n",
      "Batch train [1] loss 0.53819, dsc 0.46181\n",
      "Batch train [1] loss 0.56208, dsc 0.43792\n",
      "Batch train [1] loss 0.55979, dsc 0.44021\n",
      "Batch train [1] loss 0.67607, dsc 0.32393\n",
      "Batch train [1] loss 0.72532, dsc 0.27468\n",
      "Batch train [1] loss 0.71173, dsc 0.28827\n",
      "Batch train [1] loss 0.50557, dsc 0.49443\n",
      "Epoch [28] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 27, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  27, step 0\n",
      "Batch eval [1] loss 0.48617, dsc 0.51383\n",
      "Batch eval [1] loss 0.57163, dsc 0.42837\n",
      "Batch eval [1] loss 0.70556, dsc 0.29444\n",
      "Batch eval [1] loss 0.59980, dsc 0.40020\n",
      "Batch eval [1] loss 0.65624, dsc 0.34376\n",
      "Epoch [28] valid done\n",
      "Epoch [28] T 3307.70s, deltaT 117.02s, loss: train 0.62251, valid 0.60388, dsc: train 0.37749, valid 0.39612\n",
      "DEBUG: Writing to tensorboard before epoch True, 28, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  28, step 0\n",
      "Batch train [1] loss 0.68103, dsc 0.31897\n",
      "Batch train [1] loss 0.55964, dsc 0.44036\n",
      "Batch train [1] loss 0.59349, dsc 0.40651\n",
      "Batch train [1] loss 0.45985, dsc 0.54015\n",
      "Batch train [1] loss 0.53419, dsc 0.46581\n",
      "Batch train [1] loss 0.65698, dsc 0.34302\n",
      "Batch train [1] loss 0.49256, dsc 0.50744\n",
      "Batch train [1] loss 0.53987, dsc 0.46013\n",
      "Batch train [1] loss 0.46782, dsc 0.53218\n",
      "Batch train [1] loss 0.49837, dsc 0.50163\n",
      "Batch train [1] loss 0.52321, dsc 0.47679\n",
      "Batch train [1] loss 0.63839, dsc 0.36161\n",
      "Batch train [1] loss 0.53065, dsc 0.46935\n",
      "Batch train [1] loss 0.46368, dsc 0.53632\n",
      "Batch train [1] loss 0.59018, dsc 0.40982\n",
      "Batch train [1] loss 0.63790, dsc 0.36210\n",
      "Batch train [1] loss 0.57904, dsc 0.42096\n",
      "Batch train [1] loss 0.52240, dsc 0.47760\n",
      "Batch train [1] loss 0.50361, dsc 0.49639\n",
      "Batch train [1] loss 0.52970, dsc 0.47030\n",
      "Batch train [1] loss 0.62153, dsc 0.37847\n",
      "Batch train [1] loss 0.67812, dsc 0.32188\n",
      "Batch train [1] loss 0.65378, dsc 0.34622\n",
      "Batch train [1] loss 0.67013, dsc 0.32987\n",
      "Batch train [1] loss 0.54309, dsc 0.45691\n",
      "Batch train [1] loss 0.52788, dsc 0.47212\n",
      "Batch train [1] loss 0.44866, dsc 0.55134\n",
      "Batch train [1] loss 0.45353, dsc 0.54647\n",
      "Batch train [1] loss 0.66139, dsc 0.33861\n",
      "Batch train [1] loss 0.58688, dsc 0.41312\n",
      "Batch train [1] loss 0.51391, dsc 0.48609\n",
      "Batch train [1] loss 0.52970, dsc 0.47030\n",
      "Batch train [1] loss 0.62747, dsc 0.37253\n",
      "Batch train [1] loss 0.66968, dsc 0.33032\n",
      "Batch train [1] loss 0.53492, dsc 0.46508\n",
      "Batch train [1] loss 0.60184, dsc 0.39816\n",
      "Batch train [1] loss 0.51181, dsc 0.48819\n",
      "Batch train [1] loss 0.67585, dsc 0.32415\n",
      "Batch train [1] loss 0.48666, dsc 0.51334\n",
      "Batch train [1] loss 0.46515, dsc 0.53485\n",
      "Epoch [29] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 28, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  28, step 0\n",
      "Batch eval [1] loss 0.41355, dsc 0.58645\n",
      "Batch eval [1] loss 0.45176, dsc 0.54824\n",
      "Batch eval [1] loss 0.69299, dsc 0.30701\n",
      "Batch eval [1] loss 0.48101, dsc 0.51899\n",
      "Batch eval [1] loss 0.56235, dsc 0.43765\n",
      "Epoch [29] valid done\n",
      "Epoch [29] T 3424.63s, deltaT 116.93s, loss: train 0.56161, valid 0.52033, dsc: train 0.43839, valid 0.47967\n",
      "DEBUG: Writing to tensorboard before epoch True, 29, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  29, step 0\n",
      "Batch train [1] loss 0.54371, dsc 0.45629\n",
      "Batch train [1] loss 0.59568, dsc 0.40432\n",
      "Batch train [1] loss 0.41590, dsc 0.58410\n",
      "Batch train [1] loss 0.48393, dsc 0.51607\n",
      "Batch train [1] loss 0.40923, dsc 0.59077\n",
      "Batch train [1] loss 0.53225, dsc 0.46775\n",
      "Batch train [1] loss 0.63328, dsc 0.36672\n",
      "Batch train [1] loss 0.67341, dsc 0.32659\n",
      "Batch train [1] loss 0.51236, dsc 0.48764\n",
      "Batch train [1] loss 0.47913, dsc 0.52087\n",
      "Batch train [1] loss 0.46383, dsc 0.53617\n",
      "Batch train [1] loss 0.45992, dsc 0.54008\n",
      "Batch train [1] loss 0.41677, dsc 0.58323\n",
      "Batch train [1] loss 0.39568, dsc 0.60432\n",
      "Batch train [1] loss 0.48109, dsc 0.51891\n",
      "Batch train [1] loss 0.57513, dsc 0.42487\n",
      "Batch train [1] loss 0.38866, dsc 0.61134\n",
      "Batch train [1] loss 0.47516, dsc 0.52484\n",
      "Batch train [1] loss 0.60583, dsc 0.39417\n",
      "Batch train [1] loss 0.58376, dsc 0.41624\n",
      "Batch train [1] loss 0.63965, dsc 0.36035\n",
      "Batch train [1] loss 0.42243, dsc 0.57757\n",
      "Batch train [1] loss 0.47265, dsc 0.52735\n",
      "Batch train [1] loss 0.61896, dsc 0.38104\n",
      "Batch train [1] loss 0.53598, dsc 0.46402\n",
      "Batch train [1] loss 0.51171, dsc 0.48829\n",
      "Batch train [1] loss 0.43483, dsc 0.56517\n",
      "Batch train [1] loss 0.43640, dsc 0.56360\n",
      "Batch train [1] loss 0.44069, dsc 0.55931\n",
      "Batch train [1] loss 0.56266, dsc 0.43734\n",
      "Batch train [1] loss 0.57399, dsc 0.42601\n",
      "Batch train [1] loss 0.55095, dsc 0.44905\n",
      "Batch train [1] loss 0.57042, dsc 0.42958\n",
      "Batch train [1] loss 0.41751, dsc 0.58249\n",
      "Batch train [1] loss 0.44393, dsc 0.55607\n",
      "Batch train [1] loss 0.40119, dsc 0.59881\n",
      "Batch train [1] loss 0.40927, dsc 0.59073\n",
      "Batch train [1] loss 0.55487, dsc 0.44513\n",
      "Batch train [1] loss 0.42929, dsc 0.57071\n",
      "Batch train [1] loss 0.43352, dsc 0.56648\n",
      "Epoch [30] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 29, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  29, step 0\n",
      "Batch eval [1] loss 0.38564, dsc 0.61436\n",
      "Batch eval [1] loss 0.37350, dsc 0.62650\n",
      "Batch eval [1] loss 0.40907, dsc 0.59093\n",
      "Batch eval [1] loss 0.42050, dsc 0.57950\n",
      "Batch eval [1] loss 0.48230, dsc 0.51770\n",
      "Epoch [30] valid done\n",
      "Epoch [30] T 3541.10s, deltaT 116.46s, loss: train 0.49964, valid 0.41420, dsc: train 0.50036, valid 0.58580\n",
      "DEBUG: Writing to tensorboard before epoch True, 30, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  30, step 0\n",
      "Batch train [1] loss 0.39844, dsc 0.60156\n",
      "Batch train [1] loss 0.47259, dsc 0.52741\n",
      "Batch train [1] loss 0.41316, dsc 0.58684\n",
      "Batch train [1] loss 0.37868, dsc 0.62132\n",
      "Batch train [1] loss 0.58601, dsc 0.41399\n",
      "Batch train [1] loss 0.46617, dsc 0.53383\n",
      "Batch train [1] loss 0.37767, dsc 0.62233\n",
      "Batch train [1] loss 0.42568, dsc 0.57432\n",
      "Batch train [1] loss 0.53888, dsc 0.46112\n",
      "Batch train [1] loss 0.32903, dsc 0.67097\n",
      "Batch train [1] loss 0.57778, dsc 0.42222\n",
      "Batch train [1] loss 0.51851, dsc 0.48149\n",
      "Batch train [1] loss 0.56884, dsc 0.43116\n",
      "Batch train [1] loss 0.41775, dsc 0.58225\n",
      "Batch train [1] loss 0.52571, dsc 0.47429\n",
      "Batch train [1] loss 0.41461, dsc 0.58539\n",
      "Batch train [1] loss 0.50748, dsc 0.49252\n",
      "Batch train [1] loss 0.45292, dsc 0.54708\n",
      "Batch train [1] loss 0.39793, dsc 0.60207\n",
      "Batch train [1] loss 0.46738, dsc 0.53262\n",
      "Batch train [1] loss 0.32897, dsc 0.67103\n",
      "Batch train [1] loss 0.52711, dsc 0.47289\n",
      "Batch train [1] loss 0.53803, dsc 0.46197\n",
      "Batch train [1] loss 0.32180, dsc 0.67820\n",
      "Batch train [1] loss 0.40772, dsc 0.59228\n",
      "Batch train [1] loss 0.40968, dsc 0.59032\n",
      "Batch train [1] loss 0.51189, dsc 0.48811\n",
      "Batch train [1] loss 0.43159, dsc 0.56841\n",
      "Batch train [1] loss 0.33754, dsc 0.66246\n",
      "Batch train [1] loss 0.38785, dsc 0.61215\n",
      "Batch train [1] loss 0.39140, dsc 0.60860\n",
      "Batch train [1] loss 0.50107, dsc 0.49893\n",
      "Batch train [1] loss 0.39373, dsc 0.60627\n",
      "Batch train [1] loss 0.54863, dsc 0.45137\n",
      "Batch train [1] loss 0.37628, dsc 0.62372\n",
      "Batch train [1] loss 0.45963, dsc 0.54037\n",
      "Batch train [1] loss 0.32397, dsc 0.67603\n",
      "Batch train [1] loss 0.37128, dsc 0.62872\n",
      "Batch train [1] loss 0.54619, dsc 0.45381\n",
      "Batch train [1] loss 0.36259, dsc 0.63741\n",
      "Epoch [31] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 30, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  30, step 0\n",
      "Batch eval [1] loss 0.51341, dsc 0.48659\n",
      "Batch eval [1] loss 0.57088, dsc 0.42912\n",
      "Batch eval [1] loss 0.68735, dsc 0.31265\n",
      "Batch eval [1] loss 0.59085, dsc 0.40915\n",
      "Batch eval [1] loss 0.66899, dsc 0.33101\n",
      "Epoch [31] valid done\n",
      "Epoch [31] T 3657.58s, deltaT 116.47s, loss: train 0.44280, valid 0.60630, dsc: train 0.55720, valid 0.39370\n",
      "DEBUG: Writing to tensorboard before epoch True, 31, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  31, step 0\n",
      "Batch train [1] loss 0.40487, dsc 0.59513\n",
      "Batch train [1] loss 0.39376, dsc 0.60624\n",
      "Batch train [1] loss 0.49663, dsc 0.50337\n",
      "Batch train [1] loss 0.46807, dsc 0.53193\n",
      "Batch train [1] loss 0.32740, dsc 0.67260\n",
      "Batch train [1] loss 0.53059, dsc 0.46941\n",
      "Batch train [1] loss 0.37287, dsc 0.62713\n",
      "Batch train [1] loss 0.35695, dsc 0.64305\n",
      "Batch train [1] loss 0.31037, dsc 0.68963\n",
      "Batch train [1] loss 0.53166, dsc 0.46834\n",
      "Batch train [1] loss 0.45249, dsc 0.54751\n",
      "Batch train [1] loss 0.50383, dsc 0.49617\n",
      "Batch train [1] loss 0.37962, dsc 0.62038\n",
      "Batch train [1] loss 0.38661, dsc 0.61339\n",
      "Batch train [1] loss 0.41922, dsc 0.58078\n",
      "Batch train [1] loss 0.37674, dsc 0.62326\n",
      "Batch train [1] loss 0.36405, dsc 0.63595\n",
      "Batch train [1] loss 0.31024, dsc 0.68976\n",
      "Batch train [1] loss 0.34004, dsc 0.65996\n",
      "Batch train [1] loss 0.28843, dsc 0.71157\n",
      "Batch train [1] loss 0.47402, dsc 0.52598\n",
      "Batch train [1] loss 0.35059, dsc 0.64941\n",
      "Batch train [1] loss 0.50303, dsc 0.49697\n",
      "Batch train [1] loss 0.42622, dsc 0.57378\n",
      "Batch train [1] loss 0.34062, dsc 0.65938\n",
      "Batch train [1] loss 0.41470, dsc 0.58530\n",
      "Batch train [1] loss 0.36449, dsc 0.63551\n",
      "Batch train [1] loss 0.36815, dsc 0.63185\n",
      "Batch train [1] loss 0.29891, dsc 0.70109\n",
      "Batch train [1] loss 0.31613, dsc 0.68387\n",
      "Batch train [1] loss 0.48918, dsc 0.51082\n",
      "Batch train [1] loss 0.35928, dsc 0.64072\n",
      "Batch train [1] loss 0.43870, dsc 0.56130\n",
      "Batch train [1] loss 0.47114, dsc 0.52886\n",
      "Batch train [1] loss 0.44856, dsc 0.55144\n",
      "Batch train [1] loss 0.31940, dsc 0.68060\n",
      "Batch train [1] loss 0.37911, dsc 0.62089\n",
      "Batch train [1] loss 0.26989, dsc 0.73011\n",
      "Batch train [1] loss 0.47926, dsc 0.52074\n",
      "Batch train [1] loss 0.31062, dsc 0.68938\n",
      "Epoch [32] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 31, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  31, step 0\n",
      "Batch eval [1] loss 0.33101, dsc 0.66899\n",
      "Batch eval [1] loss 0.36797, dsc 0.63203\n",
      "Batch eval [1] loss 0.41810, dsc 0.58190\n",
      "Batch eval [1] loss 0.39045, dsc 0.60955\n",
      "Batch eval [1] loss 0.50269, dsc 0.49731\n",
      "Epoch [32] valid done\n",
      "Epoch [32] T 3773.97s, deltaT 116.39s, loss: train 0.39591, valid 0.40205, dsc: train 0.60409, valid 0.59795\n",
      "DEBUG: Writing to tensorboard before epoch True, 32, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  32, step 0\n",
      "Batch train [1] loss 0.30963, dsc 0.69037\n",
      "Batch train [1] loss 0.30976, dsc 0.69024\n",
      "Batch train [1] loss 0.40902, dsc 0.59098\n",
      "Batch train [1] loss 0.35046, dsc 0.64954\n",
      "Batch train [1] loss 0.31863, dsc 0.68137\n",
      "Batch train [1] loss 0.37132, dsc 0.62868\n",
      "Batch train [1] loss 0.44725, dsc 0.55275\n",
      "Batch train [1] loss 0.31110, dsc 0.68890\n",
      "Batch train [1] loss 0.29142, dsc 0.70858\n",
      "Batch train [1] loss 0.30984, dsc 0.69016\n",
      "Batch train [1] loss 0.27252, dsc 0.72748\n",
      "Batch train [1] loss 0.35495, dsc 0.64505\n",
      "Batch train [1] loss 0.34544, dsc 0.65456\n",
      "Batch train [1] loss 0.26772, dsc 0.73228\n",
      "Batch train [1] loss 0.48140, dsc 0.51860\n",
      "Batch train [1] loss 0.45995, dsc 0.54005\n",
      "Batch train [1] loss 0.48863, dsc 0.51137\n",
      "Batch train [1] loss 0.36707, dsc 0.63293\n",
      "Batch train [1] loss 0.50103, dsc 0.49897\n",
      "Batch train [1] loss 0.35014, dsc 0.64986\n",
      "Batch train [1] loss 0.41287, dsc 0.58713\n",
      "Batch train [1] loss 0.34235, dsc 0.65765\n",
      "Batch train [1] loss 0.28887, dsc 0.71113\n",
      "Batch train [1] loss 0.36507, dsc 0.63493\n",
      "Batch train [1] loss 0.43438, dsc 0.56562\n",
      "Batch train [1] loss 0.27183, dsc 0.72817\n",
      "Batch train [1] loss 0.35165, dsc 0.64835\n",
      "Batch train [1] loss 0.32386, dsc 0.67614\n",
      "Batch train [1] loss 0.29150, dsc 0.70850\n",
      "Batch train [1] loss 0.35206, dsc 0.64794\n",
      "Batch train [1] loss 0.41360, dsc 0.58640\n",
      "Batch train [1] loss 0.42723, dsc 0.57277\n",
      "Batch train [1] loss 0.44661, dsc 0.55339\n",
      "Batch train [1] loss 0.29065, dsc 0.70935\n",
      "Batch train [1] loss 0.33009, dsc 0.66991\n",
      "Batch train [1] loss 0.41523, dsc 0.58477\n",
      "Batch train [1] loss 0.46497, dsc 0.53503\n",
      "Batch train [1] loss 0.29069, dsc 0.70931\n",
      "Batch train [1] loss 0.42237, dsc 0.57763\n",
      "Batch train [1] loss 0.28605, dsc 0.71395\n",
      "Epoch [33] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 32, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  32, step 0\n",
      "Batch eval [1] loss 0.39209, dsc 0.60791\n",
      "Batch eval [1] loss 0.39812, dsc 0.60188\n",
      "Batch eval [1] loss 0.43272, dsc 0.56728\n",
      "Batch eval [1] loss 0.41744, dsc 0.58256\n",
      "Batch eval [1] loss 0.53391, dsc 0.46609\n",
      "Epoch [33] valid done\n",
      "Epoch [33] T 3890.33s, deltaT 116.35s, loss: train 0.36348, valid 0.43486, dsc: train 0.63652, valid 0.56514\n",
      "DEBUG: Writing to tensorboard before epoch True, 33, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  33, step 0\n",
      "Batch train [1] loss 0.30535, dsc 0.69465\n",
      "Batch train [1] loss 0.32081, dsc 0.67919\n",
      "Batch train [1] loss 0.39203, dsc 0.60797\n",
      "Batch train [1] loss 0.33863, dsc 0.66137\n",
      "Batch train [1] loss 0.30446, dsc 0.69554\n",
      "Batch train [1] loss 0.27147, dsc 0.72853\n",
      "Batch train [1] loss 0.30108, dsc 0.69892\n",
      "Batch train [1] loss 0.32208, dsc 0.67792\n",
      "Batch train [1] loss 0.29448, dsc 0.70552\n",
      "Batch train [1] loss 0.29051, dsc 0.70949\n",
      "Batch train [1] loss 0.43947, dsc 0.56053\n",
      "Batch train [1] loss 0.26145, dsc 0.73855\n",
      "Batch train [1] loss 0.28862, dsc 0.71138\n",
      "Batch train [1] loss 0.41030, dsc 0.58970\n",
      "Batch train [1] loss 0.38265, dsc 0.61735\n",
      "Batch train [1] loss 0.27987, dsc 0.72013\n",
      "Batch train [1] loss 0.23761, dsc 0.76239\n",
      "Batch train [1] loss 0.27037, dsc 0.72963\n",
      "Batch train [1] loss 0.39336, dsc 0.60664\n",
      "Batch train [1] loss 0.27306, dsc 0.72694\n",
      "Batch train [1] loss 0.29052, dsc 0.70948\n",
      "Batch train [1] loss 0.27404, dsc 0.72596\n",
      "Batch train [1] loss 0.31666, dsc 0.68334\n",
      "Batch train [1] loss 0.39525, dsc 0.60475\n",
      "Batch train [1] loss 0.34634, dsc 0.65366\n",
      "Batch train [1] loss 0.41153, dsc 0.58847\n",
      "Batch train [1] loss 0.25638, dsc 0.74362\n",
      "Batch train [1] loss 0.28165, dsc 0.71835\n",
      "Batch train [1] loss 0.26509, dsc 0.73491\n",
      "Batch train [1] loss 0.27965, dsc 0.72035\n",
      "Batch train [1] loss 0.36203, dsc 0.63797\n",
      "Batch train [1] loss 0.25675, dsc 0.74325\n",
      "Batch train [1] loss 0.38624, dsc 0.61376\n",
      "Batch train [1] loss 0.21687, dsc 0.78313\n",
      "Batch train [1] loss 0.31320, dsc 0.68680\n",
      "Batch train [1] loss 0.34319, dsc 0.65681\n",
      "Batch train [1] loss 0.22212, dsc 0.77788\n",
      "Batch train [1] loss 0.36662, dsc 0.63338\n",
      "Batch train [1] loss 0.39698, dsc 0.60302\n",
      "Batch train [1] loss 0.35291, dsc 0.64709\n",
      "Epoch [34] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 33, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  33, step 0\n",
      "Batch eval [1] loss 0.32544, dsc 0.67456\n",
      "Batch eval [1] loss 0.30630, dsc 0.69370\n",
      "Batch eval [1] loss 0.35004, dsc 0.64996\n",
      "Batch eval [1] loss 0.31407, dsc 0.68593\n",
      "Batch eval [1] loss 0.40629, dsc 0.59371\n",
      "Epoch [34] valid done\n",
      "Epoch [34] T 4006.68s, deltaT 116.35s, loss: train 0.31779, valid 0.34043, dsc: train 0.68221, valid 0.65957\n",
      "DEBUG: Writing to tensorboard before epoch True, 34, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  34, step 0\n",
      "Batch train [1] loss 0.27079, dsc 0.72921\n",
      "Batch train [1] loss 0.26917, dsc 0.73083\n",
      "Batch train [1] loss 0.26510, dsc 0.73490\n",
      "Batch train [1] loss 0.23028, dsc 0.76972\n",
      "Batch train [1] loss 0.27342, dsc 0.72658\n",
      "Batch train [1] loss 0.20357, dsc 0.79643\n",
      "Batch train [1] loss 0.26796, dsc 0.73204\n",
      "Batch train [1] loss 0.24443, dsc 0.75557\n",
      "Batch train [1] loss 0.19796, dsc 0.80204\n",
      "Batch train [1] loss 0.38429, dsc 0.61571\n",
      "Batch train [1] loss 0.23899, dsc 0.76101\n",
      "Batch train [1] loss 0.33209, dsc 0.66791\n",
      "Batch train [1] loss 0.42374, dsc 0.57626\n",
      "Batch train [1] loss 0.24759, dsc 0.75241\n",
      "Batch train [1] loss 0.25451, dsc 0.74549\n",
      "Batch train [1] loss 0.28069, dsc 0.71931\n",
      "Batch train [1] loss 0.22170, dsc 0.77830\n",
      "Batch train [1] loss 0.30948, dsc 0.69052\n",
      "Batch train [1] loss 0.26779, dsc 0.73221\n",
      "Batch train [1] loss 0.35421, dsc 0.64579\n",
      "Batch train [1] loss 0.25028, dsc 0.74972\n",
      "Batch train [1] loss 0.35932, dsc 0.64068\n",
      "Batch train [1] loss 0.29556, dsc 0.70444\n",
      "Batch train [1] loss 0.32365, dsc 0.67635\n",
      "Batch train [1] loss 0.22051, dsc 0.77949\n",
      "Batch train [1] loss 0.23337, dsc 0.76663\n",
      "Batch train [1] loss 0.27675, dsc 0.72325\n",
      "Batch train [1] loss 0.23710, dsc 0.76290\n",
      "Batch train [1] loss 0.38287, dsc 0.61713\n",
      "Batch train [1] loss 0.36333, dsc 0.63667\n",
      "Batch train [1] loss 0.34710, dsc 0.65290\n",
      "Batch train [1] loss 0.24110, dsc 0.75890\n",
      "Batch train [1] loss 0.37220, dsc 0.62780\n",
      "Batch train [1] loss 0.25511, dsc 0.74489\n",
      "Batch train [1] loss 0.38554, dsc 0.61446\n",
      "Batch train [1] loss 0.27029, dsc 0.72971\n",
      "Batch train [1] loss 0.31312, dsc 0.68688\n",
      "Batch train [1] loss 0.21646, dsc 0.78354\n",
      "Batch train [1] loss 0.38193, dsc 0.61807\n",
      "Batch train [1] loss 0.27731, dsc 0.72269\n",
      "Epoch [35] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 34, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  34, step 0\n",
      "Batch eval [1] loss 0.25578, dsc 0.74422\n",
      "Batch eval [1] loss 0.23842, dsc 0.76158\n",
      "Batch eval [1] loss 0.33529, dsc 0.66471\n",
      "Batch eval [1] loss 0.26291, dsc 0.73709\n",
      "Batch eval [1] loss 0.35692, dsc 0.64308\n",
      "Epoch [35] valid done\n",
      "Epoch [35] T 4123.37s, deltaT 116.68s, loss: train 0.28852, valid 0.28986, dsc: train 0.71148, valid 0.71014\n",
      "DEBUG: Writing to tensorboard before epoch True, 35, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  35, step 0\n",
      "Batch train [1] loss 0.24670, dsc 0.75330\n",
      "Batch train [1] loss 0.20420, dsc 0.79580\n",
      "Batch train [1] loss 0.23594, dsc 0.76406\n",
      "Batch train [1] loss 0.24701, dsc 0.75299\n",
      "Batch train [1] loss 0.25791, dsc 0.74209\n",
      "Batch train [1] loss 0.32425, dsc 0.67575\n",
      "Batch train [1] loss 0.22380, dsc 0.77620\n",
      "Batch train [1] loss 0.20683, dsc 0.79317\n",
      "Batch train [1] loss 0.21936, dsc 0.78064\n",
      "Batch train [1] loss 0.31917, dsc 0.68083\n",
      "Batch train [1] loss 0.33685, dsc 0.66315\n",
      "Batch train [1] loss 0.25289, dsc 0.74711\n",
      "Batch train [1] loss 0.24524, dsc 0.75476\n",
      "Batch train [1] loss 0.23786, dsc 0.76214\n",
      "Batch train [1] loss 0.25003, dsc 0.74997\n",
      "Batch train [1] loss 0.25518, dsc 0.74482\n",
      "Batch train [1] loss 0.23692, dsc 0.76308\n",
      "Batch train [1] loss 0.21657, dsc 0.78343\n",
      "Batch train [1] loss 0.29329, dsc 0.70671\n",
      "Batch train [1] loss 0.33986, dsc 0.66014\n",
      "Batch train [1] loss 0.24708, dsc 0.75292\n",
      "Batch train [1] loss 0.25976, dsc 0.74024\n",
      "Batch train [1] loss 0.33595, dsc 0.66405\n",
      "Batch train [1] loss 0.24607, dsc 0.75393\n",
      "Batch train [1] loss 0.29495, dsc 0.70505\n",
      "Batch train [1] loss 0.22100, dsc 0.77900\n",
      "Batch train [1] loss 0.16489, dsc 0.83511\n",
      "Batch train [1] loss 0.29716, dsc 0.70284\n",
      "Batch train [1] loss 0.21416, dsc 0.78584\n",
      "Batch train [1] loss 0.20979, dsc 0.79021\n",
      "Batch train [1] loss 0.29906, dsc 0.70094\n",
      "Batch train [1] loss 0.33688, dsc 0.66312\n",
      "Batch train [1] loss 0.29254, dsc 0.70746\n",
      "Batch train [1] loss 0.33039, dsc 0.66961\n",
      "Batch train [1] loss 0.23115, dsc 0.76885\n",
      "Batch train [1] loss 0.24908, dsc 0.75092\n",
      "Batch train [1] loss 0.27356, dsc 0.72644\n",
      "Batch train [1] loss 0.19818, dsc 0.80182\n",
      "Batch train [1] loss 0.29636, dsc 0.70364\n",
      "Batch train [1] loss 0.21015, dsc 0.78985\n",
      "Epoch [36] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 35, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  35, step 0\n",
      "Batch eval [1] loss 0.25206, dsc 0.74794\n",
      "Batch eval [1] loss 0.34307, dsc 0.65693\n",
      "Batch eval [1] loss 0.38433, dsc 0.61567\n",
      "Batch eval [1] loss 0.27915, dsc 0.72085\n",
      "Batch eval [1] loss 0.37518, dsc 0.62482\n",
      "Epoch [36] valid done\n",
      "Epoch [36] T 4239.68s, deltaT 116.30s, loss: train 0.25895, valid 0.32676, dsc: train 0.74105, valid 0.67324\n",
      "DEBUG: Writing to tensorboard before epoch True, 36, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  36, step 0\n",
      "Batch train [1] loss 0.18582, dsc 0.81418\n",
      "Batch train [1] loss 0.31476, dsc 0.68524\n",
      "Batch train [1] loss 0.20601, dsc 0.79399\n",
      "Batch train [1] loss 0.19705, dsc 0.80295\n",
      "Batch train [1] loss 0.17768, dsc 0.82232\n",
      "Batch train [1] loss 0.21148, dsc 0.78852\n",
      "Batch train [1] loss 0.23253, dsc 0.76747\n",
      "Batch train [1] loss 0.32857, dsc 0.67143\n",
      "Batch train [1] loss 0.25436, dsc 0.74564\n",
      "Batch train [1] loss 0.21223, dsc 0.78777\n",
      "Batch train [1] loss 0.21796, dsc 0.78204\n",
      "Batch train [1] loss 0.32658, dsc 0.67342\n",
      "Batch train [1] loss 0.25113, dsc 0.74887\n",
      "Batch train [1] loss 0.26630, dsc 0.73370\n",
      "Batch train [1] loss 0.30100, dsc 0.69900\n",
      "Batch train [1] loss 0.32361, dsc 0.67639\n",
      "Batch train [1] loss 0.20855, dsc 0.79145\n",
      "Batch train [1] loss 0.21713, dsc 0.78287\n",
      "Batch train [1] loss 0.24922, dsc 0.75078\n",
      "Batch train [1] loss 0.22347, dsc 0.77653\n",
      "Batch train [1] loss 0.24531, dsc 0.75469\n",
      "Batch train [1] loss 0.20033, dsc 0.79967\n",
      "Batch train [1] loss 0.19223, dsc 0.80777\n",
      "Batch train [1] loss 0.18485, dsc 0.81515\n",
      "Batch train [1] loss 0.26006, dsc 0.73994\n",
      "Batch train [1] loss 0.30274, dsc 0.69726\n",
      "Batch train [1] loss 0.17548, dsc 0.82452\n",
      "Batch train [1] loss 0.28458, dsc 0.71542\n",
      "Batch train [1] loss 0.31603, dsc 0.68397\n",
      "Batch train [1] loss 0.27622, dsc 0.72378\n",
      "Batch train [1] loss 0.23167, dsc 0.76833\n",
      "Batch train [1] loss 0.29470, dsc 0.70530\n",
      "Batch train [1] loss 0.16281, dsc 0.83719\n",
      "Batch train [1] loss 0.26809, dsc 0.73191\n",
      "Batch train [1] loss 0.23018, dsc 0.76982\n",
      "Batch train [1] loss 0.20744, dsc 0.79256\n",
      "Batch train [1] loss 0.34430, dsc 0.65570\n",
      "Batch train [1] loss 0.18411, dsc 0.81589\n",
      "Batch train [1] loss 0.18086, dsc 0.81914\n",
      "Batch train [1] loss 0.22541, dsc 0.77459\n",
      "Epoch [37] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 36, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  36, step 0\n",
      "Batch eval [1] loss 0.22083, dsc 0.77917\n",
      "Batch eval [1] loss 0.20314, dsc 0.79686\n",
      "Batch eval [1] loss 0.30369, dsc 0.69631\n",
      "Batch eval [1] loss 0.23740, dsc 0.76260\n",
      "Batch eval [1] loss 0.34385, dsc 0.65615\n",
      "Epoch [37] valid done\n",
      "Epoch [37] T 4355.83s, deltaT 116.15s, loss: train 0.24182, valid 0.26178, dsc: train 0.75818, valid 0.73822\n",
      "DEBUG: Writing to tensorboard before epoch True, 37, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  37, step 0\n",
      "Batch train [1] loss 0.29704, dsc 0.70296\n",
      "Batch train [1] loss 0.22117, dsc 0.77883\n",
      "Batch train [1] loss 0.32069, dsc 0.67931\n",
      "Batch train [1] loss 0.20186, dsc 0.79814\n",
      "Batch train [1] loss 0.19912, dsc 0.80088\n",
      "Batch train [1] loss 0.14214, dsc 0.85786\n",
      "Batch train [1] loss 0.27253, dsc 0.72747\n",
      "Batch train [1] loss 0.19129, dsc 0.80871\n",
      "Batch train [1] loss 0.28325, dsc 0.71675\n",
      "Batch train [1] loss 0.28288, dsc 0.71712\n",
      "Batch train [1] loss 0.17950, dsc 0.82050\n",
      "Batch train [1] loss 0.22760, dsc 0.77240\n",
      "Batch train [1] loss 0.21101, dsc 0.78899\n",
      "Batch train [1] loss 0.26430, dsc 0.73570\n",
      "Batch train [1] loss 0.17610, dsc 0.82390\n",
      "Batch train [1] loss 0.26095, dsc 0.73905\n",
      "Batch train [1] loss 0.20497, dsc 0.79503\n",
      "Batch train [1] loss 0.17985, dsc 0.82015\n",
      "Batch train [1] loss 0.22970, dsc 0.77030\n",
      "Batch train [1] loss 0.27935, dsc 0.72065\n",
      "Batch train [1] loss 0.19439, dsc 0.80561\n",
      "Batch train [1] loss 0.18087, dsc 0.81913\n",
      "Batch train [1] loss 0.24339, dsc 0.75661\n",
      "Batch train [1] loss 0.17835, dsc 0.82165\n",
      "Batch train [1] loss 0.18532, dsc 0.81468\n",
      "Batch train [1] loss 0.29196, dsc 0.70804\n",
      "Batch train [1] loss 0.20374, dsc 0.79626\n",
      "Batch train [1] loss 0.25587, dsc 0.74413\n",
      "Batch train [1] loss 0.19336, dsc 0.80664\n",
      "Batch train [1] loss 0.24356, dsc 0.75644\n",
      "Batch train [1] loss 0.23894, dsc 0.76106\n",
      "Batch train [1] loss 0.19557, dsc 0.80443\n",
      "Batch train [1] loss 0.17644, dsc 0.82356\n",
      "Batch train [1] loss 0.25413, dsc 0.74587\n",
      "Batch train [1] loss 0.15733, dsc 0.84267\n",
      "Batch train [1] loss 0.24425, dsc 0.75575\n",
      "Batch train [1] loss 0.16856, dsc 0.83144\n",
      "Batch train [1] loss 0.17166, dsc 0.82834\n",
      "Batch train [1] loss 0.27415, dsc 0.72585\n",
      "Batch train [1] loss 0.20590, dsc 0.79410\n",
      "Epoch [38] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 37, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  37, step 0\n",
      "Batch eval [1] loss 0.23758, dsc 0.76242\n",
      "Batch eval [1] loss 0.21696, dsc 0.78304\n",
      "Batch eval [1] loss 0.31319, dsc 0.68681\n",
      "Batch eval [1] loss 0.25644, dsc 0.74356\n",
      "Batch eval [1] loss 0.33598, dsc 0.66402\n",
      "Epoch [38] valid done\n",
      "Epoch [38] T 4472.05s, deltaT 116.21s, loss: train 0.22208, valid 0.27203, dsc: train 0.77792, valid 0.72797\n",
      "DEBUG: Writing to tensorboard before epoch True, 38, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  38, step 0\n",
      "Batch train [1] loss 0.27547, dsc 0.72453\n",
      "Batch train [1] loss 0.28175, dsc 0.71825\n",
      "Batch train [1] loss 0.23434, dsc 0.76566\n",
      "Batch train [1] loss 0.17416, dsc 0.82584\n",
      "Batch train [1] loss 0.21585, dsc 0.78415\n",
      "Batch train [1] loss 0.26453, dsc 0.73547\n",
      "Batch train [1] loss 0.21143, dsc 0.78857\n",
      "Batch train [1] loss 0.16469, dsc 0.83531\n",
      "Batch train [1] loss 0.25972, dsc 0.74028\n",
      "Batch train [1] loss 0.19531, dsc 0.80469\n",
      "Batch train [1] loss 0.17743, dsc 0.82257\n",
      "Batch train [1] loss 0.15888, dsc 0.84112\n",
      "Batch train [1] loss 0.21692, dsc 0.78308\n",
      "Batch train [1] loss 0.17670, dsc 0.82330\n",
      "Batch train [1] loss 0.20972, dsc 0.79028\n",
      "Batch train [1] loss 0.23557, dsc 0.76443\n",
      "Batch train [1] loss 0.17663, dsc 0.82337\n",
      "Batch train [1] loss 0.24568, dsc 0.75432\n",
      "Batch train [1] loss 0.15735, dsc 0.84265\n",
      "Batch train [1] loss 0.17366, dsc 0.82634\n",
      "Batch train [1] loss 0.21261, dsc 0.78739\n",
      "Batch train [1] loss 0.25882, dsc 0.74118\n",
      "Batch train [1] loss 0.17938, dsc 0.82062\n",
      "Batch train [1] loss 0.21537, dsc 0.78463\n",
      "Batch train [1] loss 0.18228, dsc 0.81772\n",
      "Batch train [1] loss 0.28794, dsc 0.71206\n",
      "Batch train [1] loss 0.21080, dsc 0.78920\n",
      "Batch train [1] loss 0.19176, dsc 0.80824\n",
      "Batch train [1] loss 0.25155, dsc 0.74845\n",
      "Batch train [1] loss 0.22487, dsc 0.77513\n",
      "Batch train [1] loss 0.22429, dsc 0.77571\n",
      "Batch train [1] loss 0.19370, dsc 0.80630\n",
      "Batch train [1] loss 0.19324, dsc 0.80676\n",
      "Batch train [1] loss 0.18197, dsc 0.81803\n",
      "Batch train [1] loss 0.23104, dsc 0.76896\n",
      "Batch train [1] loss 0.17132, dsc 0.82868\n",
      "Batch train [1] loss 0.24125, dsc 0.75875\n",
      "Batch train [1] loss 0.27277, dsc 0.72723\n",
      "Batch train [1] loss 0.22499, dsc 0.77501\n",
      "Batch train [1] loss 0.19178, dsc 0.80822\n",
      "Epoch [39] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 38, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  38, step 0\n",
      "Batch eval [1] loss 0.27214, dsc 0.72786\n",
      "Batch eval [1] loss 0.24366, dsc 0.75634\n",
      "Batch eval [1] loss 0.30975, dsc 0.69025\n",
      "Batch eval [1] loss 0.25870, dsc 0.74130\n",
      "Batch eval [1] loss 0.34880, dsc 0.65120\n",
      "Epoch [39] valid done\n",
      "Epoch [39] T 4588.20s, deltaT 116.14s, loss: train 0.21369, valid 0.28661, dsc: train 0.78631, valid 0.71339\n",
      "DEBUG: Writing to tensorboard before epoch True, 39, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  39, step 0\n",
      "Batch train [1] loss 0.30837, dsc 0.69163\n",
      "Batch train [1] loss 0.23345, dsc 0.76655\n",
      "Batch train [1] loss 0.14498, dsc 0.85502\n",
      "Batch train [1] loss 0.19272, dsc 0.80728\n",
      "Batch train [1] loss 0.31372, dsc 0.68628\n",
      "Batch train [1] loss 0.18305, dsc 0.81695\n",
      "Batch train [1] loss 0.19884, dsc 0.80116\n",
      "Batch train [1] loss 0.26004, dsc 0.73996\n",
      "Batch train [1] loss 0.16777, dsc 0.83223\n",
      "Batch train [1] loss 0.21347, dsc 0.78653\n",
      "Batch train [1] loss 0.23039, dsc 0.76961\n",
      "Batch train [1] loss 0.26548, dsc 0.73452\n",
      "Batch train [1] loss 0.18191, dsc 0.81809\n",
      "Batch train [1] loss 0.29666, dsc 0.70334\n",
      "Batch train [1] loss 0.20707, dsc 0.79293\n",
      "Batch train [1] loss 0.24575, dsc 0.75425\n",
      "Batch train [1] loss 0.15427, dsc 0.84573\n",
      "Batch train [1] loss 0.19091, dsc 0.80909\n",
      "Batch train [1] loss 0.17633, dsc 0.82367\n",
      "Batch train [1] loss 0.19511, dsc 0.80489\n",
      "Batch train [1] loss 0.26447, dsc 0.73553\n",
      "Batch train [1] loss 0.18843, dsc 0.81157\n",
      "Batch train [1] loss 0.24557, dsc 0.75443\n",
      "Batch train [1] loss 0.15865, dsc 0.84135\n",
      "Batch train [1] loss 0.26106, dsc 0.73894\n",
      "Batch train [1] loss 0.15863, dsc 0.84137\n",
      "Batch train [1] loss 0.20910, dsc 0.79090\n",
      "Batch train [1] loss 0.14266, dsc 0.85734\n",
      "Batch train [1] loss 0.16684, dsc 0.83316\n",
      "Batch train [1] loss 0.23206, dsc 0.76794\n",
      "Batch train [1] loss 0.19386, dsc 0.80614\n",
      "Batch train [1] loss 0.19335, dsc 0.80665\n",
      "Batch train [1] loss 0.25718, dsc 0.74282\n",
      "Batch train [1] loss 0.18568, dsc 0.81432\n",
      "Batch train [1] loss 0.19225, dsc 0.80775\n",
      "Batch train [1] loss 0.20279, dsc 0.79721\n",
      "Batch train [1] loss 0.14010, dsc 0.85990\n",
      "Batch train [1] loss 0.21395, dsc 0.78605\n",
      "Batch train [1] loss 0.17250, dsc 0.82750\n",
      "Batch train [1] loss 0.17013, dsc 0.82987\n",
      "Epoch [40] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 39, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  39, step 0\n",
      "Batch eval [1] loss 0.18868, dsc 0.81132\n",
      "Batch eval [1] loss 0.18919, dsc 0.81081\n",
      "Batch eval [1] loss 0.28908, dsc 0.71092\n",
      "Batch eval [1] loss 0.22356, dsc 0.77644\n",
      "Batch eval [1] loss 0.30842, dsc 0.69158\n",
      "Epoch [40] valid done\n",
      "Epoch [40] T 4704.20s, deltaT 116.00s, loss: train 0.20774, valid 0.23979, dsc: train 0.79226, valid 0.76021\n",
      "DEBUG: Writing to tensorboard before epoch True, 40, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  40, step 0\n",
      "Batch train [1] loss 0.19934, dsc 0.80066\n",
      "Batch train [1] loss 0.18777, dsc 0.81223\n",
      "Batch train [1] loss 0.20997, dsc 0.79003\n",
      "Batch train [1] loss 0.19160, dsc 0.80840\n",
      "Batch train [1] loss 0.21225, dsc 0.78775\n",
      "Batch train [1] loss 0.23556, dsc 0.76444\n",
      "Batch train [1] loss 0.22016, dsc 0.77984\n",
      "Batch train [1] loss 0.17897, dsc 0.82103\n",
      "Batch train [1] loss 0.22472, dsc 0.77528\n",
      "Batch train [1] loss 0.17244, dsc 0.82756\n",
      "Batch train [1] loss 0.16921, dsc 0.83079\n",
      "Batch train [1] loss 0.18524, dsc 0.81476\n",
      "Batch train [1] loss 0.16502, dsc 0.83498\n",
      "Batch train [1] loss 0.27064, dsc 0.72936\n",
      "Batch train [1] loss 0.17769, dsc 0.82231\n",
      "Batch train [1] loss 0.23741, dsc 0.76259\n",
      "Batch train [1] loss 0.20373, dsc 0.79627\n",
      "Batch train [1] loss 0.22148, dsc 0.77852\n",
      "Batch train [1] loss 0.26661, dsc 0.73339\n",
      "Batch train [1] loss 0.26011, dsc 0.73989\n",
      "Batch train [1] loss 0.22471, dsc 0.77529\n",
      "Batch train [1] loss 0.15673, dsc 0.84327\n",
      "Batch train [1] loss 0.15664, dsc 0.84336\n",
      "Batch train [1] loss 0.14047, dsc 0.85953\n",
      "Batch train [1] loss 0.15402, dsc 0.84598\n",
      "Batch train [1] loss 0.16557, dsc 0.83443\n",
      "Batch train [1] loss 0.16585, dsc 0.83415\n",
      "Batch train [1] loss 0.21456, dsc 0.78544\n",
      "Batch train [1] loss 0.22533, dsc 0.77467\n",
      "Batch train [1] loss 0.23926, dsc 0.76074\n",
      "Batch train [1] loss 0.18611, dsc 0.81389\n",
      "Batch train [1] loss 0.15943, dsc 0.84057\n",
      "Batch train [1] loss 0.22560, dsc 0.77440\n",
      "Batch train [1] loss 0.23307, dsc 0.76693\n",
      "Batch train [1] loss 0.16165, dsc 0.83835\n",
      "Batch train [1] loss 0.24256, dsc 0.75744\n",
      "Batch train [1] loss 0.21230, dsc 0.78770\n",
      "Batch train [1] loss 0.19317, dsc 0.80683\n",
      "Batch train [1] loss 0.16140, dsc 0.83860\n",
      "Batch train [1] loss 0.22135, dsc 0.77865\n",
      "Epoch [41] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 40, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  40, step 0\n",
      "Batch eval [1] loss 0.21994, dsc 0.78006\n",
      "Batch eval [1] loss 0.16980, dsc 0.83020\n",
      "Batch eval [1] loss 0.27841, dsc 0.72159\n",
      "Batch eval [1] loss 0.22845, dsc 0.77155\n",
      "Batch eval [1] loss 0.29873, dsc 0.70127\n",
      "Epoch [41] valid done\n",
      "Epoch [41] T 4820.23s, deltaT 116.02s, loss: train 0.20074, valid 0.23907, dsc: train 0.79926, valid 0.76093\n",
      "DEBUG: Writing to tensorboard before epoch True, 41, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  41, step 0\n",
      "Batch train [1] loss 0.21621, dsc 0.78379\n",
      "Batch train [1] loss 0.20454, dsc 0.79546\n",
      "Batch train [1] loss 0.17570, dsc 0.82430\n",
      "Batch train [1] loss 0.15384, dsc 0.84616\n",
      "Batch train [1] loss 0.22683, dsc 0.77317\n",
      "Batch train [1] loss 0.21533, dsc 0.78467\n",
      "Batch train [1] loss 0.17083, dsc 0.82917\n",
      "Batch train [1] loss 0.18200, dsc 0.81800\n",
      "Batch train [1] loss 0.17456, dsc 0.82544\n",
      "Batch train [1] loss 0.21365, dsc 0.78635\n",
      "Batch train [1] loss 0.13747, dsc 0.86253\n",
      "Batch train [1] loss 0.14101, dsc 0.85899\n",
      "Batch train [1] loss 0.15494, dsc 0.84506\n",
      "Batch train [1] loss 0.18310, dsc 0.81690\n",
      "Batch train [1] loss 0.14041, dsc 0.85959\n",
      "Batch train [1] loss 0.20596, dsc 0.79404\n",
      "Batch train [1] loss 0.25728, dsc 0.74272\n",
      "Batch train [1] loss 0.14883, dsc 0.85117\n",
      "Batch train [1] loss 0.22573, dsc 0.77427\n",
      "Batch train [1] loss 0.14847, dsc 0.85153\n",
      "Batch train [1] loss 0.16018, dsc 0.83982\n",
      "Batch train [1] loss 0.18802, dsc 0.81198\n",
      "Batch train [1] loss 0.15986, dsc 0.84014\n",
      "Batch train [1] loss 0.16352, dsc 0.83648\n",
      "Batch train [1] loss 0.25180, dsc 0.74820\n",
      "Batch train [1] loss 0.13192, dsc 0.86808\n",
      "Batch train [1] loss 0.23498, dsc 0.76502\n",
      "Batch train [1] loss 0.17494, dsc 0.82506\n",
      "Batch train [1] loss 0.18943, dsc 0.81057\n",
      "Batch train [1] loss 0.17039, dsc 0.82961\n",
      "Batch train [1] loss 0.16531, dsc 0.83469\n",
      "Batch train [1] loss 0.21255, dsc 0.78745\n",
      "Batch train [1] loss 0.14209, dsc 0.85791\n",
      "Batch train [1] loss 0.18880, dsc 0.81120\n",
      "Batch train [1] loss 0.15559, dsc 0.84441\n",
      "Batch train [1] loss 0.18861, dsc 0.81139\n",
      "Batch train [1] loss 0.19533, dsc 0.80467\n",
      "Batch train [1] loss 0.23371, dsc 0.76629\n",
      "Batch train [1] loss 0.14648, dsc 0.85352\n",
      "Batch train [1] loss 0.20726, dsc 0.79274\n",
      "Epoch [42] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 41, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  41, step 0\n",
      "Batch eval [1] loss 0.18500, dsc 0.81500\n",
      "Batch eval [1] loss 0.21100, dsc 0.78900\n",
      "Batch eval [1] loss 0.33095, dsc 0.66905\n",
      "Batch eval [1] loss 0.22159, dsc 0.77841\n",
      "Batch eval [1] loss 0.30969, dsc 0.69031\n",
      "Epoch [42] valid done\n",
      "Epoch [42] T 4936.53s, deltaT 116.30s, loss: train 0.18344, valid 0.25165, dsc: train 0.81656, valid 0.74835\n",
      "DEBUG: Writing to tensorboard before epoch True, 42, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  42, step 0\n",
      "Batch train [1] loss 0.16806, dsc 0.83194\n",
      "Batch train [1] loss 0.17496, dsc 0.82504\n",
      "Batch train [1] loss 0.17242, dsc 0.82758\n",
      "Batch train [1] loss 0.20356, dsc 0.79644\n",
      "Batch train [1] loss 0.13378, dsc 0.86622\n",
      "Batch train [1] loss 0.14931, dsc 0.85069\n",
      "Batch train [1] loss 0.20703, dsc 0.79297\n",
      "Batch train [1] loss 0.24372, dsc 0.75628\n",
      "Batch train [1] loss 0.17208, dsc 0.82792\n",
      "Batch train [1] loss 0.18635, dsc 0.81365\n",
      "Batch train [1] loss 0.20886, dsc 0.79114\n",
      "Batch train [1] loss 0.18247, dsc 0.81753\n",
      "Batch train [1] loss 0.23417, dsc 0.76583\n",
      "Batch train [1] loss 0.13645, dsc 0.86355\n",
      "Batch train [1] loss 0.23469, dsc 0.76531\n",
      "Batch train [1] loss 0.19672, dsc 0.80328\n",
      "Batch train [1] loss 0.20624, dsc 0.79376\n",
      "Batch train [1] loss 0.19996, dsc 0.80004\n",
      "Batch train [1] loss 0.15504, dsc 0.84496\n",
      "Batch train [1] loss 0.14549, dsc 0.85451\n",
      "Batch train [1] loss 0.14452, dsc 0.85548\n",
      "Batch train [1] loss 0.19332, dsc 0.80668\n",
      "Batch train [1] loss 0.15830, dsc 0.84170\n",
      "Batch train [1] loss 0.15991, dsc 0.84009\n",
      "Batch train [1] loss 0.19871, dsc 0.80129\n",
      "Batch train [1] loss 0.14180, dsc 0.85820\n",
      "Batch train [1] loss 0.21884, dsc 0.78116\n",
      "Batch train [1] loss 0.16785, dsc 0.83215\n",
      "Batch train [1] loss 0.21013, dsc 0.78987\n",
      "Batch train [1] loss 0.15106, dsc 0.84894\n",
      "Batch train [1] loss 0.12530, dsc 0.87470\n",
      "Batch train [1] loss 0.13461, dsc 0.86539\n",
      "Batch train [1] loss 0.14030, dsc 0.85970\n",
      "Batch train [1] loss 0.15927, dsc 0.84073\n",
      "Batch train [1] loss 0.16584, dsc 0.83416\n",
      "Batch train [1] loss 0.15553, dsc 0.84447\n",
      "Batch train [1] loss 0.16313, dsc 0.83687\n",
      "Batch train [1] loss 0.14625, dsc 0.85375\n",
      "Batch train [1] loss 0.16207, dsc 0.83793\n",
      "Batch train [1] loss 0.23195, dsc 0.76805\n",
      "Epoch [43] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 42, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  42, step 0\n",
      "Batch eval [1] loss 0.17217, dsc 0.82783\n",
      "Batch eval [1] loss 0.16143, dsc 0.83857\n",
      "Batch eval [1] loss 0.25825, dsc 0.74175\n",
      "Batch eval [1] loss 0.18488, dsc 0.81512\n",
      "Batch eval [1] loss 0.28025, dsc 0.71975\n",
      "Epoch [43] valid done\n",
      "Epoch [43] T 5052.69s, deltaT 116.15s, loss: train 0.17600, valid 0.21140, dsc: train 0.82400, valid 0.78860\n",
      "DEBUG: Writing to tensorboard before epoch True, 43, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  43, step 0\n",
      "Batch train [1] loss 0.17154, dsc 0.82846\n",
      "Batch train [1] loss 0.16668, dsc 0.83332\n",
      "Batch train [1] loss 0.17668, dsc 0.82332\n",
      "Batch train [1] loss 0.24104, dsc 0.75896\n",
      "Batch train [1] loss 0.15706, dsc 0.84294\n",
      "Batch train [1] loss 0.19660, dsc 0.80340\n",
      "Batch train [1] loss 0.17252, dsc 0.82748\n",
      "Batch train [1] loss 0.20789, dsc 0.79211\n",
      "Batch train [1] loss 0.16500, dsc 0.83500\n",
      "Batch train [1] loss 0.19772, dsc 0.80228\n",
      "Batch train [1] loss 0.16414, dsc 0.83586\n",
      "Batch train [1] loss 0.18671, dsc 0.81329\n",
      "Batch train [1] loss 0.14731, dsc 0.85269\n",
      "Batch train [1] loss 0.16330, dsc 0.83670\n",
      "Batch train [1] loss 0.21316, dsc 0.78684\n",
      "Batch train [1] loss 0.19597, dsc 0.80403\n",
      "Batch train [1] loss 0.20227, dsc 0.79773\n",
      "Batch train [1] loss 0.13765, dsc 0.86235\n",
      "Batch train [1] loss 0.16860, dsc 0.83140\n",
      "Batch train [1] loss 0.21627, dsc 0.78373\n",
      "Batch train [1] loss 0.20228, dsc 0.79772\n",
      "Batch train [1] loss 0.11990, dsc 0.88010\n",
      "Batch train [1] loss 0.15085, dsc 0.84915\n",
      "Batch train [1] loss 0.16465, dsc 0.83535\n",
      "Batch train [1] loss 0.17954, dsc 0.82046\n",
      "Batch train [1] loss 0.14849, dsc 0.85151\n",
      "Batch train [1] loss 0.19431, dsc 0.80569\n",
      "Batch train [1] loss 0.13771, dsc 0.86229\n",
      "Batch train [1] loss 0.14016, dsc 0.85984\n",
      "Batch train [1] loss 0.13725, dsc 0.86275\n",
      "Batch train [1] loss 0.12726, dsc 0.87274\n",
      "Batch train [1] loss 0.12746, dsc 0.87254\n",
      "Batch train [1] loss 0.14862, dsc 0.85138\n",
      "Batch train [1] loss 0.17818, dsc 0.82182\n",
      "Batch train [1] loss 0.15231, dsc 0.84769\n",
      "Batch train [1] loss 0.15208, dsc 0.84792\n",
      "Batch train [1] loss 0.21873, dsc 0.78127\n",
      "Batch train [1] loss 0.21286, dsc 0.78714\n",
      "Batch train [1] loss 0.19598, dsc 0.80402\n",
      "Batch train [1] loss 0.16664, dsc 0.83336\n",
      "Epoch [44] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 43, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  43, step 0\n",
      "Batch eval [1] loss 0.16189, dsc 0.83811\n",
      "Batch eval [1] loss 0.16187, dsc 0.83813\n",
      "Batch eval [1] loss 0.28268, dsc 0.71732\n",
      "Batch eval [1] loss 0.17670, dsc 0.82330\n",
      "Batch eval [1] loss 0.27228, dsc 0.72772\n",
      "Epoch [44] valid done\n",
      "Epoch [44] T 5168.98s, deltaT 116.27s, loss: train 0.17258, valid 0.21108, dsc: train 0.82742, valid 0.78892\n",
      "DEBUG: Writing to tensorboard before epoch True, 44, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  44, step 0\n",
      "Batch train [1] loss 0.15816, dsc 0.84184\n",
      "Batch train [1] loss 0.15039, dsc 0.84961\n",
      "Batch train [1] loss 0.15906, dsc 0.84094\n",
      "Batch train [1] loss 0.15462, dsc 0.84538\n",
      "Batch train [1] loss 0.19781, dsc 0.80219\n",
      "Batch train [1] loss 0.15344, dsc 0.84656\n",
      "Batch train [1] loss 0.21827, dsc 0.78173\n",
      "Batch train [1] loss 0.14369, dsc 0.85631\n",
      "Batch train [1] loss 0.16826, dsc 0.83174\n",
      "Batch train [1] loss 0.14963, dsc 0.85037\n",
      "Batch train [1] loss 0.14760, dsc 0.85240\n",
      "Batch train [1] loss 0.17182, dsc 0.82818\n",
      "Batch train [1] loss 0.18343, dsc 0.81657\n",
      "Batch train [1] loss 0.17228, dsc 0.82772\n",
      "Batch train [1] loss 0.13432, dsc 0.86568\n",
      "Batch train [1] loss 0.17915, dsc 0.82085\n",
      "Batch train [1] loss 0.21197, dsc 0.78803\n",
      "Batch train [1] loss 0.22893, dsc 0.77107\n",
      "Batch train [1] loss 0.13542, dsc 0.86458\n",
      "Batch train [1] loss 0.15619, dsc 0.84381\n",
      "Batch train [1] loss 0.19908, dsc 0.80092\n",
      "Batch train [1] loss 0.19872, dsc 0.80128\n",
      "Batch train [1] loss 0.17858, dsc 0.82142\n",
      "Batch train [1] loss 0.14579, dsc 0.85421\n",
      "Batch train [1] loss 0.14598, dsc 0.85402\n",
      "Batch train [1] loss 0.14936, dsc 0.85064\n",
      "Batch train [1] loss 0.21213, dsc 0.78787\n",
      "Batch train [1] loss 0.20118, dsc 0.79882\n",
      "Batch train [1] loss 0.13950, dsc 0.86050\n",
      "Batch train [1] loss 0.19063, dsc 0.80937\n",
      "Batch train [1] loss 0.17290, dsc 0.82710\n",
      "Batch train [1] loss 0.21154, dsc 0.78846\n",
      "Batch train [1] loss 0.13545, dsc 0.86455\n",
      "Batch train [1] loss 0.13480, dsc 0.86520\n",
      "Batch train [1] loss 0.19944, dsc 0.80056\n",
      "Batch train [1] loss 0.19751, dsc 0.80249\n",
      "Batch train [1] loss 0.20532, dsc 0.79468\n",
      "Batch train [1] loss 0.16561, dsc 0.83439\n",
      "Batch train [1] loss 0.15344, dsc 0.84656\n",
      "Batch train [1] loss 0.17725, dsc 0.82275\n",
      "Epoch [45] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 44, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  44, step 0\n",
      "Batch eval [1] loss 0.17906, dsc 0.82094\n",
      "Batch eval [1] loss 0.14765, dsc 0.85235\n",
      "Batch eval [1] loss 0.27861, dsc 0.72139\n",
      "Batch eval [1] loss 0.18891, dsc 0.81109\n",
      "Batch eval [1] loss 0.27430, dsc 0.72570\n",
      "Epoch [45] valid done\n",
      "Epoch [45] T 5285.30s, deltaT 116.32s, loss: train 0.17222, valid 0.21370, dsc: train 0.82778, valid 0.78630\n",
      "DEBUG: Writing to tensorboard before epoch True, 45, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  45, step 0\n",
      "Batch train [1] loss 0.16588, dsc 0.83412\n",
      "Batch train [1] loss 0.12454, dsc 0.87546\n",
      "Batch train [1] loss 0.18251, dsc 0.81749\n",
      "Batch train [1] loss 0.16988, dsc 0.83012\n",
      "Batch train [1] loss 0.15550, dsc 0.84450\n",
      "Batch train [1] loss 0.15247, dsc 0.84753\n",
      "Batch train [1] loss 0.13690, dsc 0.86310\n",
      "Batch train [1] loss 0.19874, dsc 0.80126\n",
      "Batch train [1] loss 0.14484, dsc 0.85516\n",
      "Batch train [1] loss 0.17756, dsc 0.82244\n",
      "Batch train [1] loss 0.20095, dsc 0.79905\n",
      "Batch train [1] loss 0.16698, dsc 0.83302\n",
      "Batch train [1] loss 0.17090, dsc 0.82910\n",
      "Batch train [1] loss 0.12851, dsc 0.87149\n",
      "Batch train [1] loss 0.19299, dsc 0.80701\n",
      "Batch train [1] loss 0.20462, dsc 0.79538\n",
      "Batch train [1] loss 0.20193, dsc 0.79807\n",
      "Batch train [1] loss 0.16988, dsc 0.83012\n",
      "Batch train [1] loss 0.13732, dsc 0.86268\n",
      "Batch train [1] loss 0.16983, dsc 0.83017\n",
      "Batch train [1] loss 0.18641, dsc 0.81359\n",
      "Batch train [1] loss 0.20552, dsc 0.79448\n",
      "Batch train [1] loss 0.17678, dsc 0.82322\n",
      "Batch train [1] loss 0.18376, dsc 0.81624\n",
      "Batch train [1] loss 0.13559, dsc 0.86441\n",
      "Batch train [1] loss 0.14827, dsc 0.85173\n",
      "Batch train [1] loss 0.14704, dsc 0.85296\n",
      "Batch train [1] loss 0.16037, dsc 0.83963\n",
      "Batch train [1] loss 0.13309, dsc 0.86691\n",
      "Batch train [1] loss 0.28942, dsc 0.71058\n",
      "Batch train [1] loss 0.12851, dsc 0.87149\n",
      "Batch train [1] loss 0.14271, dsc 0.85729\n",
      "Batch train [1] loss 0.15969, dsc 0.84031\n",
      "Batch train [1] loss 0.13674, dsc 0.86326\n",
      "Batch train [1] loss 0.14950, dsc 0.85050\n",
      "Batch train [1] loss 0.14155, dsc 0.85845\n",
      "Batch train [1] loss 0.21744, dsc 0.78256\n",
      "Batch train [1] loss 0.22184, dsc 0.77816\n",
      "Batch train [1] loss 0.20066, dsc 0.79934\n",
      "Batch train [1] loss 0.19963, dsc 0.80037\n",
      "Epoch [46] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 45, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  45, step 0\n",
      "Batch eval [1] loss 0.18858, dsc 0.81142\n",
      "Batch eval [1] loss 0.14298, dsc 0.85702\n",
      "Batch eval [1] loss 0.23638, dsc 0.76362\n",
      "Batch eval [1] loss 0.15689, dsc 0.84311\n",
      "Batch eval [1] loss 0.28081, dsc 0.71919\n",
      "Epoch [46] valid done\n",
      "Epoch [46] T 5401.47s, deltaT 116.16s, loss: train 0.17043, valid 0.20112, dsc: train 0.82957, valid 0.79888\n",
      "DEBUG: Writing to tensorboard before epoch True, 46, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  46, step 0\n",
      "Batch train [1] loss 0.15042, dsc 0.84958\n",
      "Batch train [1] loss 0.18195, dsc 0.81805\n",
      "Batch train [1] loss 0.12757, dsc 0.87243\n",
      "Batch train [1] loss 0.20186, dsc 0.79814\n",
      "Batch train [1] loss 0.22988, dsc 0.77012\n",
      "Batch train [1] loss 0.15316, dsc 0.84684\n",
      "Batch train [1] loss 0.13890, dsc 0.86110\n",
      "Batch train [1] loss 0.15007, dsc 0.84993\n",
      "Batch train [1] loss 0.21382, dsc 0.78618\n",
      "Batch train [1] loss 0.16237, dsc 0.83763\n",
      "Batch train [1] loss 0.14036, dsc 0.85964\n",
      "Batch train [1] loss 0.14013, dsc 0.85987\n",
      "Batch train [1] loss 0.18022, dsc 0.81978\n",
      "Batch train [1] loss 0.11462, dsc 0.88538\n",
      "Batch train [1] loss 0.16769, dsc 0.83231\n",
      "Batch train [1] loss 0.17385, dsc 0.82615\n",
      "Batch train [1] loss 0.15859, dsc 0.84141\n",
      "Batch train [1] loss 0.18850, dsc 0.81150\n",
      "Batch train [1] loss 0.13724, dsc 0.86276\n",
      "Batch train [1] loss 0.16729, dsc 0.83271\n",
      "Batch train [1] loss 0.17113, dsc 0.82887\n",
      "Batch train [1] loss 0.10324, dsc 0.89676\n",
      "Batch train [1] loss 0.20673, dsc 0.79327\n",
      "Batch train [1] loss 0.20995, dsc 0.79005\n",
      "Batch train [1] loss 0.15290, dsc 0.84710\n",
      "Batch train [1] loss 0.13492, dsc 0.86508\n",
      "Batch train [1] loss 0.13785, dsc 0.86215\n",
      "Batch train [1] loss 0.14715, dsc 0.85285\n",
      "Batch train [1] loss 0.19807, dsc 0.80193\n",
      "Batch train [1] loss 0.14851, dsc 0.85149\n",
      "Batch train [1] loss 0.18636, dsc 0.81364\n",
      "Batch train [1] loss 0.20538, dsc 0.79462\n",
      "Batch train [1] loss 0.18622, dsc 0.81378\n",
      "Batch train [1] loss 0.22072, dsc 0.77928\n",
      "Batch train [1] loss 0.15360, dsc 0.84640\n",
      "Batch train [1] loss 0.16687, dsc 0.83313\n",
      "Batch train [1] loss 0.13937, dsc 0.86063\n",
      "Batch train [1] loss 0.14992, dsc 0.85008\n",
      "Batch train [1] loss 0.12226, dsc 0.87774\n",
      "Batch train [1] loss 0.14911, dsc 0.85089\n",
      "Epoch [47] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 46, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  46, step 0\n",
      "Batch eval [1] loss 0.23074, dsc 0.76926\n",
      "Batch eval [1] loss 0.16129, dsc 0.83871\n",
      "Batch eval [1] loss 0.24334, dsc 0.75666\n",
      "Batch eval [1] loss 0.20923, dsc 0.79077\n",
      "Batch eval [1] loss 0.28083, dsc 0.71917\n",
      "Epoch [47] valid done\n",
      "Epoch [47] T 5517.49s, deltaT 116.01s, loss: train 0.16422, valid 0.22509, dsc: train 0.83578, valid 0.77491\n",
      "DEBUG: Writing to tensorboard before epoch True, 47, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  47, step 0\n",
      "Batch train [1] loss 0.16120, dsc 0.83880\n",
      "Batch train [1] loss 0.15551, dsc 0.84449\n",
      "Batch train [1] loss 0.20053, dsc 0.79947\n",
      "Batch train [1] loss 0.13711, dsc 0.86289\n",
      "Batch train [1] loss 0.12527, dsc 0.87473\n",
      "Batch train [1] loss 0.14912, dsc 0.85088\n",
      "Batch train [1] loss 0.14042, dsc 0.85958\n",
      "Batch train [1] loss 0.18111, dsc 0.81889\n",
      "Batch train [1] loss 0.20204, dsc 0.79796\n",
      "Batch train [1] loss 0.16762, dsc 0.83238\n",
      "Batch train [1] loss 0.18272, dsc 0.81728\n",
      "Batch train [1] loss 0.14249, dsc 0.85751\n",
      "Batch train [1] loss 0.15976, dsc 0.84024\n",
      "Batch train [1] loss 0.12806, dsc 0.87194\n",
      "Batch train [1] loss 0.17846, dsc 0.82154\n",
      "Batch train [1] loss 0.18319, dsc 0.81681\n",
      "Batch train [1] loss 0.16358, dsc 0.83642\n",
      "Batch train [1] loss 0.20120, dsc 0.79880\n",
      "Batch train [1] loss 0.13894, dsc 0.86106\n",
      "Batch train [1] loss 0.20601, dsc 0.79399\n",
      "Batch train [1] loss 0.13725, dsc 0.86275\n",
      "Batch train [1] loss 0.15072, dsc 0.84928\n",
      "Batch train [1] loss 0.13868, dsc 0.86132\n",
      "Batch train [1] loss 0.15740, dsc 0.84260\n",
      "Batch train [1] loss 0.14584, dsc 0.85416\n",
      "Batch train [1] loss 0.14203, dsc 0.85797\n",
      "Batch train [1] loss 0.13049, dsc 0.86951\n",
      "Batch train [1] loss 0.20919, dsc 0.79081\n",
      "Batch train [1] loss 0.20847, dsc 0.79153\n",
      "Batch train [1] loss 0.17062, dsc 0.82938\n",
      "Batch train [1] loss 0.18466, dsc 0.81534\n",
      "Batch train [1] loss 0.21726, dsc 0.78274\n",
      "Batch train [1] loss 0.13515, dsc 0.86485\n",
      "Batch train [1] loss 0.14243, dsc 0.85757\n",
      "Batch train [1] loss 0.22963, dsc 0.77037\n",
      "Batch train [1] loss 0.11142, dsc 0.88858\n",
      "Batch train [1] loss 0.18454, dsc 0.81546\n",
      "Batch train [1] loss 0.14400, dsc 0.85600\n",
      "Batch train [1] loss 0.16750, dsc 0.83250\n",
      "Batch train [1] loss 0.17196, dsc 0.82804\n",
      "Epoch [48] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 47, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  47, step 0\n",
      "Batch eval [1] loss 0.20010, dsc 0.79990\n",
      "Batch eval [1] loss 0.16676, dsc 0.83324\n",
      "Batch eval [1] loss 0.30572, dsc 0.69428\n",
      "Batch eval [1] loss 0.18611, dsc 0.81389\n",
      "Batch eval [1] loss 0.25217, dsc 0.74783\n",
      "Epoch [48] valid done\n",
      "Epoch [48] T 5633.69s, deltaT 116.19s, loss: train 0.16459, valid 0.22217, dsc: train 0.83541, valid 0.77783\n",
      "DEBUG: Writing to tensorboard before epoch True, 48, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  48, step 0\n",
      "Batch train [1] loss 0.15781, dsc 0.84219\n",
      "Batch train [1] loss 0.11746, dsc 0.88254\n",
      "Batch train [1] loss 0.15506, dsc 0.84494\n",
      "Batch train [1] loss 0.12233, dsc 0.87767\n",
      "Batch train [1] loss 0.18357, dsc 0.81643\n",
      "Batch train [1] loss 0.14473, dsc 0.85527\n",
      "Batch train [1] loss 0.13083, dsc 0.86917\n",
      "Batch train [1] loss 0.14341, dsc 0.85659\n",
      "Batch train [1] loss 0.15316, dsc 0.84684\n",
      "Batch train [1] loss 0.16178, dsc 0.83822\n",
      "Batch train [1] loss 0.18862, dsc 0.81138\n",
      "Batch train [1] loss 0.16998, dsc 0.83002\n",
      "Batch train [1] loss 0.12760, dsc 0.87240\n",
      "Batch train [1] loss 0.13455, dsc 0.86545\n",
      "Batch train [1] loss 0.15517, dsc 0.84483\n",
      "Batch train [1] loss 0.18031, dsc 0.81969\n",
      "Batch train [1] loss 0.15055, dsc 0.84945\n",
      "Batch train [1] loss 0.10950, dsc 0.89050\n",
      "Batch train [1] loss 0.18586, dsc 0.81414\n",
      "Batch train [1] loss 0.15080, dsc 0.84920\n",
      "Batch train [1] loss 0.14419, dsc 0.85581\n",
      "Batch train [1] loss 0.13826, dsc 0.86174\n",
      "Batch train [1] loss 0.12973, dsc 0.87027\n",
      "Batch train [1] loss 0.19845, dsc 0.80155\n",
      "Batch train [1] loss 0.21269, dsc 0.78731\n",
      "Batch train [1] loss 0.16172, dsc 0.83828\n",
      "Batch train [1] loss 0.19752, dsc 0.80248\n",
      "Batch train [1] loss 0.13970, dsc 0.86030\n",
      "Batch train [1] loss 0.18086, dsc 0.81914\n",
      "Batch train [1] loss 0.16390, dsc 0.83610\n",
      "Batch train [1] loss 0.21810, dsc 0.78190\n",
      "Batch train [1] loss 0.15442, dsc 0.84558\n",
      "Batch train [1] loss 0.13068, dsc 0.86932\n",
      "Batch train [1] loss 0.19687, dsc 0.80313\n",
      "Batch train [1] loss 0.11739, dsc 0.88261\n",
      "Batch train [1] loss 0.12694, dsc 0.87306\n",
      "Batch train [1] loss 0.12353, dsc 0.87647\n",
      "Batch train [1] loss 0.19534, dsc 0.80466\n",
      "Batch train [1] loss 0.14663, dsc 0.85337\n",
      "Batch train [1] loss 0.17882, dsc 0.82118\n",
      "Epoch [49] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 48, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  48, step 0\n",
      "Batch eval [1] loss 0.17940, dsc 0.82060\n",
      "Batch eval [1] loss 0.14144, dsc 0.85856\n",
      "Batch eval [1] loss 0.26027, dsc 0.73973\n",
      "Batch eval [1] loss 0.18869, dsc 0.81131\n",
      "Batch eval [1] loss 0.25706, dsc 0.74294\n",
      "Epoch [49] valid done\n",
      "Epoch [49] T 5749.35s, deltaT 115.65s, loss: train 0.15697, valid 0.20537, dsc: train 0.84303, valid 0.79463\n",
      "DEBUG: Writing to tensorboard before epoch True, 49, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  49, step 0\n",
      "Batch train [1] loss 0.12798, dsc 0.87202\n",
      "Batch train [1] loss 0.12524, dsc 0.87476\n",
      "Batch train [1] loss 0.10790, dsc 0.89210\n",
      "Batch train [1] loss 0.17741, dsc 0.82259\n",
      "Batch train [1] loss 0.13871, dsc 0.86129\n",
      "Batch train [1] loss 0.15824, dsc 0.84176\n",
      "Batch train [1] loss 0.18264, dsc 0.81736\n",
      "Batch train [1] loss 0.15516, dsc 0.84484\n",
      "Batch train [1] loss 0.18299, dsc 0.81701\n",
      "Batch train [1] loss 0.15906, dsc 0.84094\n",
      "Batch train [1] loss 0.13323, dsc 0.86677\n",
      "Batch train [1] loss 0.15410, dsc 0.84590\n",
      "Batch train [1] loss 0.14763, dsc 0.85237\n",
      "Batch train [1] loss 0.10928, dsc 0.89072\n",
      "Batch train [1] loss 0.18503, dsc 0.81497\n",
      "Batch train [1] loss 0.17239, dsc 0.82761\n",
      "Batch train [1] loss 0.13623, dsc 0.86377\n",
      "Batch train [1] loss 0.15518, dsc 0.84482\n",
      "Batch train [1] loss 0.15374, dsc 0.84626\n",
      "Batch train [1] loss 0.12540, dsc 0.87460\n",
      "Batch train [1] loss 0.16088, dsc 0.83912\n",
      "Batch train [1] loss 0.13879, dsc 0.86121\n",
      "Batch train [1] loss 0.14308, dsc 0.85692\n",
      "Batch train [1] loss 0.16977, dsc 0.83023\n",
      "Batch train [1] loss 0.13890, dsc 0.86110\n",
      "Batch train [1] loss 0.17925, dsc 0.82075\n",
      "Batch train [1] loss 0.14965, dsc 0.85035\n",
      "Batch train [1] loss 0.16105, dsc 0.83895\n",
      "Batch train [1] loss 0.13686, dsc 0.86314\n",
      "Batch train [1] loss 0.15153, dsc 0.84847\n",
      "Batch train [1] loss 0.17396, dsc 0.82604\n",
      "Batch train [1] loss 0.13167, dsc 0.86833\n",
      "Batch train [1] loss 0.12565, dsc 0.87435\n",
      "Batch train [1] loss 0.15409, dsc 0.84591\n",
      "Batch train [1] loss 0.18915, dsc 0.81085\n",
      "Batch train [1] loss 0.18306, dsc 0.81694\n",
      "Batch train [1] loss 0.14098, dsc 0.85902\n",
      "Batch train [1] loss 0.19217, dsc 0.80783\n",
      "Batch train [1] loss 0.11966, dsc 0.88034\n",
      "Batch train [1] loss 0.12639, dsc 0.87361\n",
      "Epoch [50] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 49, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  49, step 0\n",
      "Batch eval [1] loss 0.18952, dsc 0.81048\n",
      "Batch eval [1] loss 0.13658, dsc 0.86342\n",
      "Batch eval [1] loss 0.24710, dsc 0.75290\n",
      "Batch eval [1] loss 0.18369, dsc 0.81631\n",
      "Batch eval [1] loss 0.25684, dsc 0.74316\n",
      "Epoch [50] valid done\n",
      "Epoch [50] T 5864.98s, deltaT 115.62s, loss: train 0.15135, valid 0.20274, dsc: train 0.84865, valid 0.79726\n",
      "DEBUG: Writing to tensorboard before epoch True, 50, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  50, step 0\n",
      "Batch train [1] loss 0.12103, dsc 0.87897\n",
      "Batch train [1] loss 0.14439, dsc 0.85561\n",
      "Batch train [1] loss 0.12572, dsc 0.87428\n",
      "Batch train [1] loss 0.17479, dsc 0.82521\n",
      "Batch train [1] loss 0.15458, dsc 0.84542\n",
      "Batch train [1] loss 0.12061, dsc 0.87939\n",
      "Batch train [1] loss 0.11867, dsc 0.88133\n",
      "Batch train [1] loss 0.13913, dsc 0.86087\n",
      "Batch train [1] loss 0.12879, dsc 0.87121\n",
      "Batch train [1] loss 0.14959, dsc 0.85041\n",
      "Batch train [1] loss 0.19385, dsc 0.80615\n",
      "Batch train [1] loss 0.14159, dsc 0.85841\n",
      "Batch train [1] loss 0.16536, dsc 0.83464\n",
      "Batch train [1] loss 0.20406, dsc 0.79594\n",
      "Batch train [1] loss 0.13536, dsc 0.86464\n",
      "Batch train [1] loss 0.11972, dsc 0.88028\n",
      "Batch train [1] loss 0.20146, dsc 0.79854\n",
      "Batch train [1] loss 0.16301, dsc 0.83699\n",
      "Batch train [1] loss 0.11593, dsc 0.88407\n",
      "Batch train [1] loss 0.13373, dsc 0.86627\n",
      "Batch train [1] loss 0.17113, dsc 0.82887\n",
      "Batch train [1] loss 0.12823, dsc 0.87177\n",
      "Batch train [1] loss 0.16498, dsc 0.83502\n",
      "Batch train [1] loss 0.15995, dsc 0.84005\n",
      "Batch train [1] loss 0.12858, dsc 0.87142\n",
      "Batch train [1] loss 0.16852, dsc 0.83148\n",
      "Batch train [1] loss 0.12853, dsc 0.87147\n",
      "Batch train [1] loss 0.14737, dsc 0.85263\n",
      "Batch train [1] loss 0.14068, dsc 0.85932\n",
      "Batch train [1] loss 0.13571, dsc 0.86429\n",
      "Batch train [1] loss 0.17437, dsc 0.82563\n",
      "Batch train [1] loss 0.19023, dsc 0.80977\n",
      "Batch train [1] loss 0.14346, dsc 0.85654\n",
      "Batch train [1] loss 0.11933, dsc 0.88067\n",
      "Batch train [1] loss 0.17806, dsc 0.82194\n",
      "Batch train [1] loss 0.13750, dsc 0.86250\n",
      "Batch train [1] loss 0.12969, dsc 0.87031\n",
      "Batch train [1] loss 0.13776, dsc 0.86224\n",
      "Batch train [1] loss 0.21207, dsc 0.78793\n",
      "Batch train [1] loss 0.14838, dsc 0.85162\n",
      "Epoch [51] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 50, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  50, step 0\n",
      "Batch eval [1] loss 0.18379, dsc 0.81621\n",
      "Batch eval [1] loss 0.14873, dsc 0.85127\n",
      "Batch eval [1] loss 0.25083, dsc 0.74917\n",
      "Batch eval [1] loss 0.18749, dsc 0.81251\n",
      "Batch eval [1] loss 0.25096, dsc 0.74904\n",
      "Epoch [51] valid done\n",
      "Epoch [51] T 5981.37s, deltaT 116.38s, loss: train 0.14990, valid 0.20436, dsc: train 0.85010, valid 0.79564\n",
      "DEBUG: Writing to tensorboard before epoch True, 51, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  51, step 0\n",
      "Batch train [1] loss 0.17249, dsc 0.82751\n",
      "Batch train [1] loss 0.14062, dsc 0.85938\n",
      "Batch train [1] loss 0.13210, dsc 0.86790\n",
      "Batch train [1] loss 0.13635, dsc 0.86365\n",
      "Batch train [1] loss 0.17225, dsc 0.82775\n",
      "Batch train [1] loss 0.12375, dsc 0.87625\n",
      "Batch train [1] loss 0.14549, dsc 0.85451\n",
      "Batch train [1] loss 0.14931, dsc 0.85069\n",
      "Batch train [1] loss 0.13948, dsc 0.86052\n",
      "Batch train [1] loss 0.15487, dsc 0.84513\n",
      "Batch train [1] loss 0.17914, dsc 0.82086\n",
      "Batch train [1] loss 0.14385, dsc 0.85615\n",
      "Batch train [1] loss 0.18106, dsc 0.81894\n",
      "Batch train [1] loss 0.14431, dsc 0.85569\n",
      "Batch train [1] loss 0.12445, dsc 0.87555\n",
      "Batch train [1] loss 0.16145, dsc 0.83855\n",
      "Batch train [1] loss 0.19237, dsc 0.80763\n",
      "Batch train [1] loss 0.17703, dsc 0.82297\n",
      "Batch train [1] loss 0.12781, dsc 0.87219\n",
      "Batch train [1] loss 0.14635, dsc 0.85365\n",
      "Batch train [1] loss 0.13273, dsc 0.86727\n",
      "Batch train [1] loss 0.13284, dsc 0.86716\n",
      "Batch train [1] loss 0.10685, dsc 0.89315\n",
      "Batch train [1] loss 0.18466, dsc 0.81534\n",
      "Batch train [1] loss 0.15325, dsc 0.84675\n",
      "Batch train [1] loss 0.14372, dsc 0.85628\n",
      "Batch train [1] loss 0.18416, dsc 0.81584\n",
      "Batch train [1] loss 0.15231, dsc 0.84769\n",
      "Batch train [1] loss 0.16903, dsc 0.83097\n",
      "Batch train [1] loss 0.11188, dsc 0.88812\n",
      "Batch train [1] loss 0.12133, dsc 0.87867\n",
      "Batch train [1] loss 0.12311, dsc 0.87689\n",
      "Batch train [1] loss 0.13725, dsc 0.86275\n",
      "Batch train [1] loss 0.14497, dsc 0.85503\n",
      "Batch train [1] loss 0.15652, dsc 0.84348\n",
      "Batch train [1] loss 0.14635, dsc 0.85365\n",
      "Batch train [1] loss 0.15982, dsc 0.84018\n",
      "Batch train [1] loss 0.20202, dsc 0.79798\n",
      "Batch train [1] loss 0.11276, dsc 0.88724\n",
      "Batch train [1] loss 0.14173, dsc 0.85827\n",
      "Epoch [52] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 51, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  51, step 0\n",
      "Batch eval [1] loss 0.29102, dsc 0.70898\n",
      "Batch eval [1] loss 0.17503, dsc 0.82497\n",
      "Batch eval [1] loss 0.29826, dsc 0.70174\n",
      "Batch eval [1] loss 0.26547, dsc 0.73453\n",
      "Batch eval [1] loss 0.29635, dsc 0.70365\n",
      "Epoch [52] valid done\n",
      "Epoch [52] T 6099.27s, deltaT 117.90s, loss: train 0.14905, valid 0.26523, dsc: train 0.85095, valid 0.73477\n",
      "DEBUG: Writing to tensorboard before epoch True, 52, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  52, step 0\n",
      "Batch train [1] loss 0.15761, dsc 0.84239\n",
      "Batch train [1] loss 0.13865, dsc 0.86135\n",
      "Batch train [1] loss 0.15200, dsc 0.84800\n",
      "Batch train [1] loss 0.13695, dsc 0.86305\n",
      "Batch train [1] loss 0.17621, dsc 0.82379\n",
      "Batch train [1] loss 0.14731, dsc 0.85269\n",
      "Batch train [1] loss 0.15787, dsc 0.84213\n",
      "Batch train [1] loss 0.11963, dsc 0.88037\n",
      "Batch train [1] loss 0.11826, dsc 0.88174\n",
      "Batch train [1] loss 0.15180, dsc 0.84820\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6bd339837954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mshow_model_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_model_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_model_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterate_model_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterate_model_v3v2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/train_loop.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model_info, iterate_model_fn)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch [%d] train done'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f3da01b338f2>\u001b[0m in \u001b[0;36miterate_model_v3v2\u001b[0;34m(dataloader, model, optimizer, loss_func, device, is_eval)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             item_loss, item_dsc, inputs_len = loss_batch(model, optimizer, loss_func, inputs, labels,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                                          calc_backward=not is_eval)\n\u001b[1;32m     55\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/loss_batch.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, optimizer, loss_func, model_input, true_output, calc_backward)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_backward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "TRAIN_MODELS = True\n",
    "if TRAIN_MODELS:\n",
    "    for OAR_KEY, OAR_VALUE in labels_list:\n",
    "        cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "        log_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_name = f'{log_date}_3d_unet_lowres_model3v2_{OAR_KEY}'\n",
    "\n",
    "        print(f'Training model with dataset label \\'{OAR_KEY}\\', value \\'{OAR_VALUE}\\'')\n",
    "        print(f'folder \\'{model_name}\\'')\n",
    "        cut_model_info = prepare_model(epochs=75,\n",
    "                                       learning_rate=3e-4,\n",
    "                                       in_channels=8,\n",
    "                                       input_data_channels=1,\n",
    "                                       output_label_channels=1,\n",
    "                                       dropout_rate=0.2,\n",
    "                                       train_batch_size=1,\n",
    "                                       model_name=model_name,\n",
    "                                       train_dataset=cut_train_dataset, \n",
    "                                       valid_dataset=cut_valid_dataset, \n",
    "                                       test_dataset=cut_test_dataset,\n",
    "                                       model_class=UNetV3v2)\n",
    "        show_model_info(cut_model_info)\n",
    "        print('\\n\\n')\n",
    "        train_loop(cut_model_info, iterate_model_fn=iterate_model_v3v2)\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # clearing memory\n",
    "        del cut_model_info\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = [tmp_list[5], tmp_list[6], tmp_list[7], tmp_list[10], tmp_list[11], tmp_list[12]]\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_models(oar_key):\n",
    "    possible_models = [folder_name for folder_name in os.listdir('./models') if oar_key in folder_name]    \n",
    "    \n",
    "    return possible_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading models to CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    epoch = 75\n",
    "    possible_models = get_possible_models(f\"model3v2_{OAR_KEY}\")\n",
    "    if len(possible_models) <= 0:\n",
    "        print(f'{OAR_KEY} Model: No avaiable model')\n",
    "        continue\n",
    "\n",
    "    model_name = possible_models[0]\n",
    "    print(f'{OAR_KEY} Model: Loading model {model_name}')\n",
    "\n",
    "    # loading model checkpoint\n",
    "    cut_model_info = load_checkpoint_model_info(model_name, epoch, cut_train_dataset, cut_valid_dataset, cut_test_dataset, model_class=UNetV3v2)\n",
    "\n",
    "    # moving model to cpu/cuda with eval mode\n",
    "    cut_model_info['device'] = 'cpu'\n",
    "    cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "    cut_model_info['model'].eval()\n",
    "    cut_model_info['model'].disable_tensorboard_writing = True\n",
    "    \n",
    "    models[OAR_KEY] = cut_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_DSC_INFO = True\n",
    "if SHOW_DSC_INFO:\n",
    "    info_per_organs_df = {}\n",
    "    models_info = list()\n",
    "    for OAR_KEY, OAR_VALUE in labels_list:\n",
    "        if OAR_KEY not in models:\n",
    "            print(f'{OAR_KEY} Model: No avaiable model')\n",
    "            continue\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[OAR_KEY]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "        cut_model_info['model'].disable_tensorboard_writing = True\n",
    "\n",
    "        # preparing dataset for comparison\n",
    "        cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "\n",
    "        # calculating dsc predictions        \n",
    "        info_df, preds, rescaled_preds = get_threshold_info_df(\n",
    "                                    model=cut_model_info['model'], \n",
    "                                    dataset=cut_full_res_dataset, \n",
    "                                    device=cut_model_info['device'], \n",
    "                                    train_indices=cut_train_dataset.indices, \n",
    "                                    valid_indices=cut_valid_dataset.indices, \n",
    "                                    test_indices=cut_test_dataset.indices,\n",
    "                                    step=0.5)\n",
    "        info_per_organs_df[OAR_KEY] = info_df\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "\n",
    "        # parsing data\n",
    "        best_threshold_col = 'thres_rescaled_dsc_0.50'\n",
    "        train_tmp_df = info_df[info_df['is_train']][best_threshold_col]\n",
    "        valid_tmp_df = info_df[info_df['is_valid']][best_threshold_col]\n",
    "        train_dsc = train_tmp_df.mean()\n",
    "        valid_dsc = valid_tmp_df.mean()\n",
    "        print(f'{OAR_KEY} Model: DSC train {round(train_dsc, 4)} valid {round(valid_dsc, 4)}')\n",
    "\n",
    "        models_info.append({\n",
    "            'oar_key': OAR_KEY,\n",
    "            'model_name': model_name,\n",
    "            # Train\n",
    "            'train_dsc_mean': train_dsc,\n",
    "            'train_dsc_std': train_tmp_df.std(),\n",
    "            'train_dsc_median': train_tmp_df.median(),\n",
    "            'train_dsc_min': train_tmp_df.min(),\n",
    "            'train_dsc_max': train_tmp_df.max(),\n",
    "            # Valid\n",
    "            'valid_dsc_mean': valid_dsc,\n",
    "            'valid_dsc_std': valid_tmp_df.std(),\n",
    "            'valid_dsc_median': valid_tmp_df.median(),\n",
    "            'valid_dsc_min': valid_tmp_df.min(),\n",
    "            'valid_dsc_max': valid_tmp_df.max(),\n",
    "            # Both\n",
    "            'train_valid_mean_delta': train_dsc - valid_dsc\n",
    "        })\n",
    "\n",
    "    models_info_df = pd.DataFrame(models_info)\n",
    "    \n",
    "    tmp_df = models_info_df[['oar_key', 'train_dsc_mean', 'train_dsc_std', 'valid_dsc_mean', 'valid_dsc_std']].copy()\n",
    "    tmp_df['train_dsc_mean'] = (tmp_df['train_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_mean'] = (tmp_df['valid_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['train_dsc_std'] = (tmp_df['train_dsc_std'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_std'] = (tmp_df['valid_dsc_std'] * 100).round(2)\n",
    "    \n",
    "    display(tmp_df.mean().round(2))\n",
    "    display(tmp_df.round(2))\n",
    "    display(tmp_df.sort_values(by=['train_dsc_std']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_dsc_mean']).drop(columns=['model_name']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_valid_mean_delta']).drop(columns=['model_name']).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_DSC_INFO:\n",
    "    tmp_column = 'is_train' \n",
    "    \n",
    "    print('OARS_LABELS.PAROTID_GLAND_R')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PAROTID_GLAND_R]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.PAROTID_GLAND_L')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PAROTID_GLAND_L]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.OPT_NERVE_L')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.OPT_NERVE_L]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.PITUITARY')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PITUITARY]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions merging and checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_labels_dict = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels_dict['SPINAL_CORD']\n",
    "\n",
    "cut_full_res_dataset.set_output_label(filter_labels_dict)\n",
    "preview_dataset(cut_full_res_dataset, preview_index=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSE_CUT_DATASET = True\n",
    "if PARSE_CUT_DATASET:\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    prediction_threshold = 0.5\n",
    "    output_label_items = list(cut_full_res_dataset.output_label.items())[:]\n",
    "    cut_dataset_predictions = defaultdict(lambda: defaultdict(lambda: np.zeros(cut_full_res_dataset[0][0][0].shape)))\n",
    "    \n",
    "    # for each label\n",
    "    for label_index, val in enumerate(output_label_items[:]):\n",
    "        OAR_KEY, OAR_VALUE = val\n",
    "        # loading model\n",
    "        if OAR_KEY not in models:\n",
    "            print(f'{label_index+1}/{len(output_label_items)}: {OAR_KEY} Model: No avaiable model')\n",
    "            continue\n",
    "        print(f'{label_index+1}/{len(output_label_items)}: {OAR_KEY} Model: got model {datetime.datetime.now()}')\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[OAR_KEY]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "\n",
    "        # for label in whole dataset\n",
    "        for index in range(len(cut_full_res_dataset)):\n",
    "            prediction, rescaled_pred = get_rescaled_pred(cut_model_info['model'], cut_full_res_dataset, \n",
    "                                                          cut_model_info['device'], index, use_only_one_dimension=False)\n",
    "    \n",
    "            cut_dataset_predictions[index][OAR_VALUE] = prediction[0]\n",
    "            # extended_cut_full_res_dataset.data_list[index][label_index + 1] = prediction\n",
    "            # extended_cut_full_res_dataset.data_list[index][label_index + 1] = ((rescaled_pred > prediction_threshold) * 1).astype(np.int8)\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARSE_CUT_DATASET:\n",
    "    def custom_preview_dataset(dataset, predictions, preview_index=0, show_hist=False, use_transform=False):\n",
    "        data, label = dataset.get_raw_item_with_label_filter(preview_index)  # equivalent dataset[preview_index]\n",
    "        if use_transform:\n",
    "            transform = get_dataset_transform()\n",
    "            data, label = transform_input(data, label, transform)\n",
    "\n",
    "        prediction = predictions[preview_index]\n",
    "        max_channels = label.shape[0]\n",
    "        max_slices = label.shape[1]\n",
    "\n",
    "        print(f'data max {data.max()}, min {data.min()}')\n",
    "        print(f'label max {label.max()}, min {label.min()}')\n",
    "\n",
    "        def f(slice_index, label_channel):\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(data[0, slice_index], cmap=\"gray\")\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(prediction[label_channel+1][slice_index])\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(label[label_channel, slice_index])\n",
    "            plt.show()\n",
    "\n",
    "            if show_hist:\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.hist(data.flatten(), 128)\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.hist(label.flatten(), 128)\n",
    "                plt.show()\n",
    "\n",
    "        sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "        labelChannelSlider = widgets.IntSlider(min=0, max=max_channels - 1, step=1, value=(max_channels - 1) / 2)\n",
    "        ui = widgets.VBox([widgets.HBox([sliceSlider, labelChannelSlider])])\n",
    "        out = widgets.interactive_output(f, {'slice_index': sliceSlider, 'label_channel': labelChannelSlider})\n",
    "        # noinspection PyTypeChecker\n",
    "        display(ui, out)\n",
    "    \n",
    "    custom_preview_dataset(cut_full_res_dataset, cut_dataset_predictions, preview_index=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: refactor\n",
    "\n",
    "MERGE_PREDICTIONS = False\n",
    "if MERGE_PREDICTIONS:\n",
    "    merged_predictions = [None] * len(extended_cut_full_res_dataset)\n",
    "    for index in range(len(extended_cut_full_res_dataset)):\n",
    "        # print(f\"{index+1}/{len(extended_cut_full_res_dataset)}: Merging predictions to single label\")\n",
    "        data, label = extended_cut_full_res_dataset.get_raw_item_with_label_filter(index)\n",
    "\n",
    "        new_data = np.zeros(data[0].shape, dtype=np.int16)\n",
    "        for i in range(1, 22):\n",
    "            new_data += data[i]\n",
    "\n",
    "        merged_predictions[index] = new_data\n",
    "    print('Merging done')\n",
    "\n",
    "    # checking how many masks are overlapping\n",
    "    for i, tmp_merged in enumerate(merged_predictions):\n",
    "        display(f'scan id {i}: {np.where(tmp_merged == 1)[0].shape[0]}, {np.where(tmp_merged == 2)[0].shape[0]}, {np.where(tmp_merged == 3)[0].shape[0]}, {np.where(tmp_merged == 4)[0].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: refactor\n",
    "\n",
    "from src.losses import calc_dscm\n",
    "\n",
    "def custom_preview_dataset2(dataset, preview_index=0, use_transform=False):\n",
    "    data, label = dataset.get_raw_item_with_label_filter(preview_index)\n",
    "    if use_transform:\n",
    "        transform = get_dataset_transform()\n",
    "        data, label = transform_input(data, label, transform)\n",
    "        \n",
    "    cut_data, cut_label = cut_full_res_dataset.get_raw_item_with_label_filter(preview_index)\n",
    "    max_channels = label.shape[0]\n",
    "    max_slices = label.shape[1]\n",
    "    \n",
    "    print(f'data max {data.max()}, min {data.min()}')\n",
    "    print(f'label max {label.max()}, min {label.min()}')\n",
    "    print(f'{data.shape}, {cut_data.shape}, {label.shape}, {cut_label.shape}')\n",
    "    print(f'{data.dtype}, {cut_data.dtype}, {label.dtype}, {cut_label.dtype}')\n",
    "    tmp_merged = merged_predictions[preview_index]\n",
    "    print(f'{np.where(tmp_merged == 1)[0].shape},{np.where(tmp_merged == 2)[0].shape},{np.where(tmp_merged == 3)[0].shape},{np.where(tmp_merged == 4)[0].shape}')\n",
    "\n",
    "    def f(slice_index, label_channel):\n",
    "        print(f'{OARS_LABELS.OARS_LABELS_R_DICT[label_channel+1]}')\n",
    "        tmp_tensor_label = torch.tensor(label[label_channel])\n",
    "        tmp_tensor_prediciton = torch.tensor(data[label_channel+1])\n",
    "        tmp_dsc = calc_dsc(tmp_tensor_label, tmp_tensor_prediciton)\n",
    "        print(f'dsc {tmp_dsc}')\n",
    "\n",
    "        plt.figure(figsize=(30, 20))\n",
    "\n",
    "        plt.subplot(2, 3, 1).title.set_text('data')\n",
    "        plt.imshow(cut_data[0, slice_index], cmap=\"gray\")\n",
    "        plt.subplot(2, 3, 2).title.set_text('label')\n",
    "        plt.imshow(label[label_channel, slice_index])\n",
    "        plt.subplot(2, 3, 3).title.set_text('prediciton')\n",
    "        plt.imshow(data[label_channel+1, slice_index])\n",
    "        # print(data.shape, np.sum(data[label_channel+1]), np.unique(data[1])[-1])\n",
    "        print(f'slices with values > 0', (np.where(data[label_channel+1] > 0))[0])\n",
    "        \n",
    "        plt.subplot(2, 3, 4).title.set_text('merged prediction labels')\n",
    "        plt.imshow(tmp_merged[slice_index], vmin=0, vmax=np.unique(tmp_merged)[-1])\n",
    "        plt.subplot(2, 3, 5).title.set_text('merged labels ')\n",
    "        plt.imshow(np.sum(label, axis=0)[slice_index])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "    labelChannelSlider = widgets.IntSlider(min=0, max=max_channels - 1, step=1, value=(max_channels - 1) / 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider, labelChannelSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider, 'label_channel': labelChannelSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)\n",
    "\n",
    "custom_preview_dataset2(extended_cut_full_res_dataset, preview_index=35, use_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
