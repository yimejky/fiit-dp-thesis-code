{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/dp_tomastik/code')\n",
    "    !bash \"/content/drive/My Drive/dp_tomastik/code/scripts/install_libs.sh\"\n",
    "    \n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "from torchio import RandomAffine, Compose, ZNormalization\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from src.helpers import preview_3d_image\n",
    "from src.helpers import show_cuda_usage, preview_model_dataset_pred, preview_dataset\n",
    "from src.helpers import get_threshold_info_df, get_rescaled_preds\n",
    "from src.helpers import compare_prediction_with_ground_true, compare_one_prediction_with_ground_true\n",
    "from src.helpers import get_img_outliers_pixels, get_raw_with_prediction\n",
    "from src.helpers import get_rescaled_pred\n",
    "from src.helpers import get_transformed_label_np, create_regis_trans_list, trans_list\n",
    "\n",
    "from src.dataset import HaNOarsDataset, transform_input_with_registration, get_norm_transform\n",
    "from src.dataset import get_full_res_cut, get_cut_lists, OARS_LABELS, get_dataset, get_dataset_info, get_dataset_transform\n",
    "from src.dataset import split_dataset, copy_split_dataset\n",
    "\n",
    "from src.model_and_training import prepare_model, train_loop, show_model_info, load_checkpoint_model_info\n",
    "from src.model_and_training import iterate_model_v3v2\n",
    "from src.model_and_training.getters.get_device import get_device\n",
    "from src.model_and_training.architectures.unet_architecture_v3v2 import UNetV3v2\n",
    "\n",
    "from src.consts import DATASET_MAX_BOUNDING_BOX, DESIRE_BOUNDING_BOX_SIZE\n",
    "  \n",
    "torch.manual_seed(20)\n",
    "logging.basicConfig(filename='logs/model3v2_all_organs_jupyter.log', level=logging.DEBUG)\n",
    "\n",
    "print('Dataset biggest bounding box wihtout spinal cord', DATASET_MAX_BOUNDING_BOX)\n",
    "print('Cut target size', DESIRE_BOUNDING_BOX_SIZE)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'Tesla K80')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training all organs models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing dataset input example\n",
    "# data_path = f'./data/HaN_OAR_cut_left_parotid_reg'\n",
    "# cut_full_res_dataset = HaNOarsDataset(data_path, size=50, load_images=False)\n",
    "# cut_full_res_dataset.load_from_file(data_path)\n",
    "# cut_full_res_dataset.set_output_label(OARS_LABELS.PAROTID_GLAND_R)\n",
    "                                     \n",
    "# preview_3d_image(cut_full_res_dataset[0][0][0], figsize=(4,4))\n",
    "# preview_3d_image(cut_full_res_dataset[0][0][1], figsize=(4,4))\n",
    "# preview_3d_image(cut_full_res_dataset[0][1], figsize=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_parotid, PAROTID_GLAND_R, 13\n",
      "all_maps, PITUITARY, 11\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = list()\n",
    "\n",
    "# creating registration dataset and organ segmentation pairs\n",
    "# dataset use inverted labeling of left and right\n",
    "labels_list.append(('left_parotid', *tmp_list[12]))\n",
    "# labels_list.append(('right_parotid', *tmp_list[11]))\n",
    "\n",
    "# labels_list.append(('brainstem', *tmp_list[10]))\n",
    "# labels_list.append(('parotids', *tmp_list[10]))\n",
    "labels_list.append(('all_maps', *tmp_list[10]))\n",
    "\n",
    "for DATASET_REG_NAME, OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{DATASET_REG_NAME}, {OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 72, 192, 168)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_full_res_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e457b56b7af42b1a8b848d33ec4fc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2546c07ae4764b51b0da378280e9c6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7671f81ca7fe446090976e6552614853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec69476ba40e4557bd465c64b50e81d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input tensor must be 4D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9b8ea752af37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpreview_3d_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreview_3d_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtmp_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_input_with_registration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dataset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/dataset/transform_input.py\u001b[0m in \u001b[0;36mtransform_input_with_registration\u001b[0;34m(item_data, item_label, transform)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_input_with_registration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# parsing to subject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0msubject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_torchio_registration_subject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/dataset/transform_input.py\u001b[0m in \u001b[0;36mget_torchio_registration_subject\u001b[0;34m(item_data, item_label)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# print(f\"{t1_input.shape}\", {t2_input.shape})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScalarImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt1_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt2_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchio/data/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Type of ScalarImage is always torchio.INTENSITY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mINTENSITY\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchio/data/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, type, tensor, affine, check_nans, channels_last, reader, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchio/data/image.py\u001b[0m in \u001b[0;36m_parse_tensor\u001b[0;34m(self, tensor, none_ok)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input tensor must be 4D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input tensor must be 4D"
     ]
    }
   ],
   "source": [
    "index = 6\n",
    "preview_3d_image(cut_train_dataset[index][0][0], figsize=(4,4))\n",
    "preview_3d_image(cut_train_dataset[index][0][1], figsize=(4,4))\n",
    "tmp_inputs, tmp_labels = transform_input_with_registration(cut_train_dataset[index][0][0], cut_train_dataset[index][0][1], get_dataset_transform())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with dataset label 'PAROTID_GLAND_R', value '13'\n",
      "folder '20210412-222407_3d_unet_lowres_model3v2__cloud-PAROTID_GLAND_R-left_parotid_reg'\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yimejky/fiit-dp-thesis-code/src/model_and_training/architectures/unet_architecture_v3v2.py:301: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  img_np = layer_output.data[0].detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Model number of params: 1221609, trainable 1221609\n",
      "\n",
      "\n",
      "\n",
      "Running training loop\n",
      "DEBUG: Writing to tensorboard before epoch True, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  0, step 0\n",
      "Batch train [2] loss 0.99887, dsc 0.00113\n",
      "Batch train [2] loss 0.99072, dsc 0.00928\n",
      "Batch train [2] loss 0.99048, dsc 0.00952\n",
      "Batch train [2] loss 0.99726, dsc 0.00274\n",
      "Batch train [2] loss 0.99832, dsc 0.00168\n",
      "Batch train [2] loss 0.99805, dsc 0.00195\n",
      "Batch train [2] loss 0.99862, dsc 0.00138\n",
      "Batch train [2] loss 0.98926, dsc 0.01074\n",
      "Batch train [2] loss 0.98809, dsc 0.01191\n",
      "Batch train [2] loss 0.99842, dsc 0.00158\n",
      "Batch train [2] loss 0.99926, dsc 0.00074\n",
      "Batch train [2] loss 0.99775, dsc 0.00225\n",
      "Batch train [2] loss 0.99508, dsc 0.00492\n",
      "Batch train [2] loss 0.99214, dsc 0.00786\n",
      "Batch train [2] loss 0.98918, dsc 0.01082\n",
      "Batch train [2] loss 0.99784, dsc 0.00216\n",
      "Batch train [2] loss 0.99520, dsc 0.00480\n",
      "Batch train [2] loss 0.98830, dsc 0.01170\n",
      "Batch train [2] loss 0.99469, dsc 0.00531\n",
      "Batch train [2] loss 0.99247, dsc 0.00753\n",
      "Epoch [1] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Batch eval [1] loss 0.99024, dsc 0.00976\n",
      "Batch eval [1] loss 0.99306, dsc 0.00694\n",
      "Batch eval [1] loss 0.98939, dsc 0.01061\n",
      "Batch eval [1] loss 0.99325, dsc 0.00675\n",
      "Batch eval [1] loss 0.99474, dsc 0.00526\n",
      "Epoch [1] valid done\n",
      "Epoch [1] T 371.43s, deltaT 371.43s, loss: train 0.99450, valid 0.99214, dsc: train 0.00550, valid 0.00786\n",
      "DEBUG: Writing to tensorboard before epoch True, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  1, step 0\n",
      "Batch train [2] loss 0.99621, dsc 0.00379\n",
      "Batch train [2] loss 0.98485, dsc 0.01515\n",
      "Batch train [2] loss 0.98788, dsc 0.01212\n",
      "Batch train [2] loss 0.99167, dsc 0.00833\n",
      "Batch train [2] loss 0.99100, dsc 0.00900\n",
      "Batch train [2] loss 0.99942, dsc 0.00058\n",
      "Batch train [2] loss 0.98649, dsc 0.01351\n",
      "Batch train [2] loss 0.98405, dsc 0.01595\n",
      "Batch train [2] loss 0.99178, dsc 0.00822\n",
      "Batch train [2] loss 0.99080, dsc 0.00920\n",
      "Batch train [2] loss 0.98202, dsc 0.01798\n",
      "Batch train [2] loss 0.98847, dsc 0.01153\n",
      "Batch train [2] loss 0.98527, dsc 0.01473\n",
      "Batch train [2] loss 0.99302, dsc 0.00698\n",
      "Batch train [2] loss 0.99534, dsc 0.00466\n",
      "Batch train [2] loss 0.97828, dsc 0.02172\n",
      "Batch train [2] loss 0.98254, dsc 0.01746\n",
      "Batch train [2] loss 0.98669, dsc 0.01331\n",
      "Batch train [2] loss 0.97430, dsc 0.02570\n",
      "Batch train [2] loss 0.99641, dsc 0.00359\n",
      "Epoch [2] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  1, step 0\n",
      "Batch eval [1] loss 0.98726, dsc 0.01274\n",
      "Batch eval [1] loss 0.99124, dsc 0.00876\n",
      "Batch eval [1] loss 0.98721, dsc 0.01279\n",
      "Batch eval [1] loss 0.99177, dsc 0.00823\n",
      "Batch eval [1] loss 0.99321, dsc 0.00679\n",
      "Epoch [2] valid done\n",
      "Epoch [2] T 745.37s, deltaT 373.94s, loss: train 0.98832, valid 0.99014, dsc: train 0.01168, valid 0.00986\n",
      "DEBUG: Writing to tensorboard before epoch True, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  2, step 0\n",
      "Batch train [2] loss 0.99183, dsc 0.00817\n",
      "Batch train [2] loss 0.99784, dsc 0.00216\n",
      "Batch train [2] loss 0.99217, dsc 0.00783\n",
      "Batch train [2] loss 0.98989, dsc 0.01010\n",
      "Batch train [2] loss 0.98577, dsc 0.01423\n",
      "Batch train [2] loss 0.99845, dsc 0.00155\n",
      "Batch train [2] loss 0.99349, dsc 0.00651\n",
      "Batch train [2] loss 0.99949, dsc 0.00051\n",
      "Batch train [2] loss 0.98430, dsc 0.01570\n",
      "Batch train [2] loss 0.99721, dsc 0.00279\n",
      "Batch train [2] loss 0.99887, dsc 0.00113\n",
      "Batch train [2] loss 0.99481, dsc 0.00519\n",
      "Batch train [2] loss 0.99430, dsc 0.00570\n",
      "Batch train [2] loss 0.99104, dsc 0.00896\n",
      "Batch train [2] loss 0.98500, dsc 0.01500\n",
      "Batch train [2] loss 0.99778, dsc 0.00222\n",
      "Batch train [2] loss 0.99756, dsc 0.00244\n",
      "Batch train [2] loss 0.99790, dsc 0.00210\n",
      "Batch train [2] loss 0.99909, dsc 0.00091\n",
      "Batch train [2] loss 0.99032, dsc 0.00968\n",
      "Epoch [3] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  2, step 0\n",
      "Batch eval [1] loss 0.98740, dsc 0.01260\n",
      "Batch eval [1] loss 0.99136, dsc 0.00864\n",
      "Batch eval [1] loss 0.98900, dsc 0.01100\n",
      "Batch eval [1] loss 0.99213, dsc 0.00787\n",
      "Batch eval [1] loss 0.99256, dsc 0.00744\n",
      "Epoch [3] valid done\n",
      "Epoch [3] T 1119.00s, deltaT 373.63s, loss: train 0.99386, valid 0.99049, dsc: train 0.00614, valid 0.00951\n",
      "DEBUG: Writing to tensorboard before epoch True, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  3, step 0\n",
      "Batch train [2] loss 0.96141, dsc 0.03859\n",
      "Batch train [2] loss 0.98978, dsc 0.01022\n",
      "Batch train [2] loss 0.99059, dsc 0.00941\n",
      "Batch train [2] loss 0.98953, dsc 0.01047\n",
      "Batch train [2] loss 0.99870, dsc 0.00130\n",
      "Batch train [2] loss 0.99705, dsc 0.00295\n",
      "Batch train [2] loss 0.99691, dsc 0.00309\n",
      "Batch train [2] loss 0.99819, dsc 0.00181\n",
      "Batch train [2] loss 0.99084, dsc 0.00916\n",
      "Batch train [2] loss 0.99523, dsc 0.00477\n",
      "Batch train [2] loss 0.99712, dsc 0.00288\n",
      "Batch train [2] loss 0.99746, dsc 0.00254\n",
      "Batch train [2] loss 0.98486, dsc 0.01514\n",
      "Batch train [2] loss 0.98625, dsc 0.01375\n",
      "Batch train [2] loss 0.99520, dsc 0.00480\n",
      "Batch train [2] loss 0.98763, dsc 0.01238\n",
      "Batch train [2] loss 0.99638, dsc 0.00362\n",
      "Batch train [2] loss 0.99786, dsc 0.00214\n",
      "Batch train [2] loss 0.97865, dsc 0.02135\n",
      "Batch train [2] loss 0.99676, dsc 0.00324\n",
      "Epoch [4] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  3, step 0\n",
      "Batch eval [1] loss 0.98392, dsc 0.01608\n",
      "Batch eval [1] loss 0.98819, dsc 0.01181\n",
      "Batch eval [1] loss 0.98657, dsc 0.01343\n",
      "Batch eval [1] loss 0.98877, dsc 0.01123\n",
      "Batch eval [1] loss 0.99110, dsc 0.00890\n",
      "Epoch [4] valid done\n",
      "Epoch [4] T 1492.16s, deltaT 373.17s, loss: train 0.99132, valid 0.98771, dsc: train 0.00868, valid 0.01229\n",
      "DEBUG: Writing to tensorboard before epoch True, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  4, step 0\n",
      "Batch train [2] loss 0.99677, dsc 0.00323\n",
      "Batch train [2] loss 0.99809, dsc 0.00191\n",
      "Batch train [2] loss 0.98393, dsc 0.01607\n",
      "Batch train [2] loss 0.99534, dsc 0.00466\n",
      "Batch train [2] loss 0.99760, dsc 0.00240\n",
      "Batch train [2] loss 0.99654, dsc 0.00346\n",
      "Batch train [2] loss 0.99349, dsc 0.00651\n",
      "Batch train [2] loss 0.99831, dsc 0.00169\n",
      "Batch train [2] loss 0.97784, dsc 0.02216\n",
      "Batch train [2] loss 0.99824, dsc 0.00176\n",
      "Batch train [2] loss 0.99239, dsc 0.00761\n",
      "Batch train [2] loss 0.99319, dsc 0.00681\n",
      "Batch train [2] loss 0.99378, dsc 0.00622\n",
      "Batch train [2] loss 0.99615, dsc 0.00385\n",
      "Batch train [2] loss 0.99730, dsc 0.00270\n",
      "Batch train [2] loss 0.99936, dsc 0.00064\n",
      "Batch train [2] loss 0.99517, dsc 0.00483\n",
      "Batch train [2] loss 0.99984, dsc 0.00016\n",
      "Batch train [2] loss 0.99210, dsc 0.00790\n",
      "Batch train [2] loss 0.99525, dsc 0.00475\n",
      "Epoch [5] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  4, step 0\n",
      "Batch eval [1] loss 0.97935, dsc 0.02065\n",
      "Batch eval [1] loss 0.98518, dsc 0.01482\n",
      "Batch eval [1] loss 0.97904, dsc 0.02096\n",
      "Batch eval [1] loss 0.98565, dsc 0.01435\n",
      "Batch eval [1] loss 0.98861, dsc 0.01139\n",
      "Epoch [5] valid done\n",
      "Epoch [5] T 1864.40s, deltaT 372.24s, loss: train 0.99453, valid 0.98356, dsc: train 0.00547, valid 0.01644\n",
      "DEBUG: Writing to tensorboard before epoch True, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  5, step 0\n",
      "Batch train [2] loss 0.98329, dsc 0.01671\n",
      "Batch train [2] loss 0.99219, dsc 0.00781\n",
      "Batch train [2] loss 0.97425, dsc 0.02575\n",
      "Batch train [2] loss 0.99503, dsc 0.00497\n",
      "Batch train [2] loss 0.99467, dsc 0.00533\n",
      "Batch train [2] loss 0.98593, dsc 0.01407\n",
      "Batch train [2] loss 0.98189, dsc 0.01811\n",
      "Batch train [2] loss 0.99683, dsc 0.00317\n",
      "Batch train [2] loss 0.99422, dsc 0.00578\n",
      "Batch train [2] loss 0.99870, dsc 0.00130\n",
      "Batch train [2] loss 0.98514, dsc 0.01486\n",
      "Batch train [2] loss 0.99423, dsc 0.00577\n",
      "Batch train [2] loss 0.97776, dsc 0.02224\n",
      "Batch train [2] loss 0.98539, dsc 0.01461\n",
      "Batch train [2] loss 0.99183, dsc 0.00817\n",
      "Batch train [2] loss 0.97371, dsc 0.02629\n",
      "Batch train [2] loss 0.99993, dsc 0.00007\n",
      "Batch train [2] loss 0.99833, dsc 0.00167\n",
      "Batch train [2] loss 0.99121, dsc 0.00879\n",
      "Batch train [2] loss 0.99499, dsc 0.00501\n",
      "Epoch [6] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  5, step 0\n",
      "Batch eval [1] loss 0.97942, dsc 0.02058\n",
      "Batch eval [1] loss 0.98502, dsc 0.01498\n",
      "Batch eval [1] loss 0.97750, dsc 0.02250\n",
      "Batch eval [1] loss 0.98577, dsc 0.01423\n",
      "Batch eval [1] loss 0.98883, dsc 0.01117\n",
      "Epoch [6] valid done\n",
      "Epoch [6] T 2237.42s, deltaT 373.02s, loss: train 0.98948, valid 0.98331, dsc: train 0.01052, valid 0.01669\n",
      "DEBUG: Writing to tensorboard before epoch True, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  6, step 0\n",
      "Batch train [2] loss 0.98684, dsc 0.01316\n",
      "Batch train [2] loss 0.98021, dsc 0.01979\n",
      "Batch train [2] loss 0.99859, dsc 0.00141\n",
      "Batch train [2] loss 0.99377, dsc 0.00623\n",
      "Batch train [2] loss 0.99770, dsc 0.00230\n",
      "Batch train [2] loss 0.99715, dsc 0.00285\n",
      "Batch train [2] loss 0.99564, dsc 0.00436\n",
      "Batch train [2] loss 0.99616, dsc 0.00384\n",
      "Batch train [2] loss 0.99138, dsc 0.00862\n",
      "Batch train [2] loss 0.98972, dsc 0.01028\n",
      "Batch train [2] loss 0.99175, dsc 0.00825\n",
      "Batch train [2] loss 0.99516, dsc 0.00484\n",
      "Batch train [2] loss 0.98101, dsc 0.01899\n",
      "Batch train [2] loss 0.99730, dsc 0.00270\n",
      "Batch train [2] loss 0.98902, dsc 0.01098\n",
      "Batch train [2] loss 0.99242, dsc 0.00758\n",
      "Batch train [2] loss 0.98414, dsc 0.01586\n",
      "Batch train [2] loss 0.99808, dsc 0.00192\n",
      "Batch train [2] loss 0.97833, dsc 0.02167\n",
      "Batch train [2] loss 0.99991, dsc 0.00009\n",
      "Epoch [7] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  6, step 0\n",
      "Batch eval [1] loss 0.97839, dsc 0.02161\n",
      "Batch eval [1] loss 0.98447, dsc 0.01553\n",
      "Batch eval [1] loss 0.97703, dsc 0.02297\n",
      "Batch eval [1] loss 0.98478, dsc 0.01522\n",
      "Batch eval [1] loss 0.98812, dsc 0.01188\n",
      "Epoch [7] valid done\n",
      "Epoch [7] T 2609.09s, deltaT 371.67s, loss: train 0.99171, valid 0.98256, dsc: train 0.00829, valid 0.01744\n",
      "DEBUG: Writing to tensorboard before epoch True, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  7, step 0\n",
      "Batch train [2] loss 0.99629, dsc 0.00371\n",
      "Batch train [2] loss 0.97231, dsc 0.02769\n",
      "Batch train [2] loss 0.99028, dsc 0.00972\n",
      "Batch train [2] loss 0.98948, dsc 0.01052\n",
      "Batch train [2] loss 0.99769, dsc 0.00231\n",
      "Batch train [2] loss 0.99099, dsc 0.00901\n",
      "Batch train [2] loss 0.99429, dsc 0.00571\n",
      "Batch train [2] loss 0.97241, dsc 0.02759\n",
      "Batch train [2] loss 0.98635, dsc 0.01365\n",
      "Batch train [2] loss 0.97563, dsc 0.02437\n",
      "Batch train [2] loss 0.99683, dsc 0.00317\n",
      "Batch train [2] loss 0.99150, dsc 0.00850\n",
      "Batch train [2] loss 0.99594, dsc 0.00406\n",
      "Batch train [2] loss 0.99841, dsc 0.00159\n",
      "Batch train [2] loss 0.98813, dsc 0.01187\n",
      "Batch train [2] loss 0.98926, dsc 0.01074\n",
      "Batch train [2] loss 0.99498, dsc 0.00502\n",
      "Batch train [2] loss 0.99225, dsc 0.00775\n",
      "Batch train [2] loss 0.98108, dsc 0.01892\n",
      "Batch train [2] loss 0.98112, dsc 0.01888\n",
      "Epoch [8] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  7, step 0\n",
      "Batch eval [1] loss 0.97845, dsc 0.02155\n",
      "Batch eval [1] loss 0.98386, dsc 0.01614\n",
      "Batch eval [1] loss 0.97731, dsc 0.02269\n",
      "Batch eval [1] loss 0.98487, dsc 0.01513\n",
      "Batch eval [1] loss 0.98791, dsc 0.01209\n",
      "Epoch [8] valid done\n",
      "Epoch [8] T 2981.01s, deltaT 371.92s, loss: train 0.98876, valid 0.98248, dsc: train 0.01124, valid 0.01752\n",
      "DEBUG: Writing to tensorboard before epoch True, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  8, step 0\n",
      "Batch train [2] loss 0.99580, dsc 0.00420\n",
      "Batch train [2] loss 0.99336, dsc 0.00664\n",
      "Batch train [2] loss 0.98845, dsc 0.01155\n",
      "Batch train [2] loss 0.99903, dsc 0.00097\n",
      "Batch train [2] loss 0.99030, dsc 0.00970\n",
      "Batch train [2] loss 0.99268, dsc 0.00732\n",
      "Batch train [2] loss 0.98908, dsc 0.01092\n",
      "Batch train [2] loss 0.99826, dsc 0.00174\n",
      "Batch train [2] loss 0.99454, dsc 0.00546\n",
      "Batch train [2] loss 0.99296, dsc 0.00704\n",
      "Batch train [2] loss 0.99344, dsc 0.00656\n",
      "Batch train [2] loss 0.99854, dsc 0.00146\n",
      "Batch train [2] loss 0.99598, dsc 0.00402\n",
      "Batch train [2] loss 0.98343, dsc 0.01657\n",
      "Batch train [2] loss 0.99983, dsc 0.00017\n",
      "Batch train [2] loss 0.99231, dsc 0.00769\n",
      "Batch train [2] loss 0.99695, dsc 0.00305\n",
      "Batch train [2] loss 0.99106, dsc 0.00894\n",
      "Batch train [2] loss 0.99228, dsc 0.00772\n",
      "Batch train [2] loss 0.98992, dsc 0.01008\n",
      "Epoch [9] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  8, step 0\n",
      "Batch eval [1] loss 0.97761, dsc 0.02239\n",
      "Batch eval [1] loss 0.98326, dsc 0.01674\n",
      "Batch eval [1] loss 0.97637, dsc 0.02363\n",
      "Batch eval [1] loss 0.98434, dsc 0.01566\n",
      "Batch eval [1] loss 0.98760, dsc 0.01240\n",
      "Epoch [9] valid done\n",
      "Epoch [9] T 3353.62s, deltaT 372.61s, loss: train 0.99341, valid 0.98184, dsc: train 0.00659, valid 0.01816\n",
      "DEBUG: Writing to tensorboard before epoch True, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  9, step 0\n",
      "Batch train [2] loss 0.99726, dsc 0.00274\n",
      "Batch train [2] loss 0.98416, dsc 0.01584\n",
      "Batch train [2] loss 0.98928, dsc 0.01072\n",
      "Batch train [2] loss 0.99621, dsc 0.00379\n",
      "Batch train [2] loss 0.99491, dsc 0.00509\n",
      "Batch train [2] loss 0.99938, dsc 0.00062\n",
      "Batch train [2] loss 0.99935, dsc 0.00065\n",
      "Batch train [2] loss 0.99516, dsc 0.00484\n",
      "Batch train [2] loss 0.99943, dsc 0.00057\n",
      "Batch train [2] loss 0.99018, dsc 0.00982\n",
      "Batch train [2] loss 0.99909, dsc 0.00091\n",
      "Batch train [2] loss 0.99320, dsc 0.00680\n",
      "Batch train [2] loss 0.97997, dsc 0.02003\n",
      "Batch train [2] loss 0.98462, dsc 0.01538\n",
      "Batch train [2] loss 0.99257, dsc 0.00743\n",
      "Batch train [2] loss 0.98399, dsc 0.01601\n",
      "Batch train [2] loss 0.99309, dsc 0.00691\n",
      "Batch train [2] loss 0.98699, dsc 0.01301\n",
      "Batch train [2] loss 0.98973, dsc 0.01027\n",
      "Batch train [2] loss 0.98668, dsc 0.01332\n",
      "Epoch [10] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  9, step 0\n",
      "Batch eval [1] loss 0.97869, dsc 0.02131\n",
      "Batch eval [1] loss 0.98380, dsc 0.01620\n",
      "Batch eval [1] loss 0.97855, dsc 0.02145\n",
      "Batch eval [1] loss 0.98604, dsc 0.01396\n",
      "Batch eval [1] loss 0.98874, dsc 0.01126\n",
      "Epoch [10] valid done\n",
      "Epoch [10] T 3725.30s, deltaT 371.68s, loss: train 0.99176, valid 0.98316, dsc: train 0.00824, valid 0.01684\n",
      "DEBUG: Writing to tensorboard before epoch True, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  10, step 0\n",
      "Batch train [2] loss 0.97864, dsc 0.02136\n",
      "Batch train [2] loss 0.98475, dsc 0.01525\n",
      "Batch train [2] loss 0.99332, dsc 0.00668\n",
      "Batch train [2] loss 0.99179, dsc 0.00821\n",
      "Batch train [2] loss 0.98724, dsc 0.01276\n",
      "Batch train [2] loss 0.99309, dsc 0.00691\n",
      "Batch train [2] loss 0.99960, dsc 0.00040\n",
      "Batch train [2] loss 0.98624, dsc 0.01376\n",
      "Batch train [2] loss 0.99438, dsc 0.00562\n",
      "Batch train [2] loss 0.99803, dsc 0.00197\n",
      "Batch train [2] loss 0.99032, dsc 0.00968\n",
      "Batch train [2] loss 0.99481, dsc 0.00519\n",
      "Batch train [2] loss 0.97076, dsc 0.02924\n",
      "Batch train [2] loss 0.99713, dsc 0.00287\n",
      "Batch train [2] loss 0.98397, dsc 0.01603\n",
      "Batch train [2] loss 0.99825, dsc 0.00175\n",
      "Batch train [2] loss 0.97614, dsc 0.02386\n",
      "Batch train [2] loss 0.99202, dsc 0.00798\n",
      "Batch train [2] loss 0.98282, dsc 0.01718\n",
      "Batch train [2] loss 0.99033, dsc 0.00967\n",
      "Epoch [11] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  10, step 0\n",
      "Batch eval [1] loss 0.97931, dsc 0.02069\n",
      "Batch eval [1] loss 0.98416, dsc 0.01584\n",
      "Batch eval [1] loss 0.97911, dsc 0.02089\n",
      "Batch eval [1] loss 0.98706, dsc 0.01294\n",
      "Batch eval [1] loss 0.98955, dsc 0.01045\n",
      "Epoch [11] valid done\n",
      "Epoch [11] T 4098.22s, deltaT 372.92s, loss: train 0.98918, valid 0.98384, dsc: train 0.01082, valid 0.01616\n",
      "DEBUG: Writing to tensorboard before epoch True, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  11, step 0\n",
      "Batch train [2] loss 0.99332, dsc 0.00668\n",
      "Batch train [2] loss 0.99442, dsc 0.00558\n",
      "Batch train [2] loss 0.99210, dsc 0.00790\n",
      "Batch train [2] loss 0.98653, dsc 0.01347\n",
      "Batch train [2] loss 0.99045, dsc 0.00955\n",
      "Batch train [2] loss 0.99265, dsc 0.00735\n",
      "Batch train [2] loss 0.99534, dsc 0.00466\n",
      "Batch train [2] loss 0.97831, dsc 0.02169\n",
      "Batch train [2] loss 0.98620, dsc 0.01380\n",
      "Batch train [2] loss 0.98967, dsc 0.01033\n",
      "Batch train [2] loss 0.97892, dsc 0.02108\n",
      "Batch train [2] loss 0.99470, dsc 0.00530\n",
      "Batch train [2] loss 0.99439, dsc 0.00561\n",
      "Batch train [2] loss 0.97796, dsc 0.02204\n",
      "Batch train [2] loss 0.99675, dsc 0.00325\n",
      "Batch train [2] loss 0.98019, dsc 0.01981\n",
      "Batch train [2] loss 0.99862, dsc 0.00138\n",
      "Batch train [2] loss 0.99766, dsc 0.00234\n",
      "Batch train [2] loss 0.99383, dsc 0.00617\n",
      "Batch train [2] loss 0.97134, dsc 0.02866\n",
      "Epoch [12] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  11, step 0\n",
      "Batch eval [1] loss 0.97801, dsc 0.02199\n",
      "Batch eval [1] loss 0.98330, dsc 0.01670\n",
      "Batch eval [1] loss 0.97996, dsc 0.02004\n",
      "Batch eval [1] loss 0.98596, dsc 0.01404\n",
      "Batch eval [1] loss 0.98887, dsc 0.01113\n",
      "Epoch [12] valid done\n",
      "Epoch [12] T 4470.83s, deltaT 372.61s, loss: train 0.98917, valid 0.98322, dsc: train 0.01083, valid 0.01678\n",
      "DEBUG: Writing to tensorboard before epoch True, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  12, step 0\n",
      "Batch train [2] loss 0.99718, dsc 0.00282\n",
      "Batch train [2] loss 0.99733, dsc 0.00267\n",
      "Batch train [2] loss 0.99689, dsc 0.00311\n",
      "Batch train [2] loss 0.99491, dsc 0.00509\n",
      "Batch train [2] loss 0.99882, dsc 0.00118\n",
      "Batch train [2] loss 0.98979, dsc 0.01021\n",
      "Batch train [2] loss 0.98810, dsc 0.01190\n",
      "Batch train [2] loss 0.97866, dsc 0.02134\n",
      "Batch train [2] loss 0.99897, dsc 0.00103\n",
      "Batch train [2] loss 0.97580, dsc 0.02420\n",
      "Batch train [2] loss 0.97319, dsc 0.02681\n",
      "Batch train [2] loss 0.98180, dsc 0.01820\n",
      "Batch train [2] loss 0.99434, dsc 0.00566\n",
      "Batch train [2] loss 0.99195, dsc 0.00805\n",
      "Batch train [2] loss 0.98745, dsc 0.01255\n",
      "Batch train [2] loss 0.99921, dsc 0.00079\n",
      "Batch train [2] loss 0.99201, dsc 0.00799\n",
      "Batch train [2] loss 0.98867, dsc 0.01133\n",
      "Batch train [2] loss 0.99822, dsc 0.00178\n",
      "Batch train [2] loss 0.99807, dsc 0.00193\n",
      "Epoch [13] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  12, step 0\n",
      "Batch eval [1] loss 0.97914, dsc 0.02086\n",
      "Batch eval [1] loss 0.98338, dsc 0.01662\n",
      "Batch eval [1] loss 0.97976, dsc 0.02024\n",
      "Batch eval [1] loss 0.98610, dsc 0.01390\n",
      "Batch eval [1] loss 0.98828, dsc 0.01172\n",
      "Epoch [13] valid done\n",
      "Epoch [13] T 4842.79s, deltaT 371.96s, loss: train 0.99107, valid 0.98333, dsc: train 0.00893, valid 0.01667\n",
      "DEBUG: Writing to tensorboard before epoch True, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  13, step 0\n",
      "Batch train [2] loss 0.96679, dsc 0.03321\n",
      "Batch train [2] loss 0.99173, dsc 0.00827\n",
      "Batch train [2] loss 0.99137, dsc 0.00863\n",
      "Batch train [2] loss 0.96470, dsc 0.03530\n",
      "Batch train [2] loss 0.99568, dsc 0.00432\n",
      "Batch train [2] loss 0.99538, dsc 0.00462\n",
      "Batch train [2] loss 0.99852, dsc 0.00148\n",
      "Batch train [2] loss 0.98647, dsc 0.01353\n",
      "Batch train [2] loss 0.98548, dsc 0.01452\n",
      "Batch train [2] loss 0.98840, dsc 0.01160\n",
      "Batch train [2] loss 0.99520, dsc 0.00480\n",
      "Batch train [2] loss 0.96410, dsc 0.03590\n",
      "Batch train [2] loss 0.98085, dsc 0.01915\n",
      "Batch train [2] loss 0.96888, dsc 0.03112\n",
      "Batch train [2] loss 0.98330, dsc 0.01670\n",
      "Batch train [2] loss 0.98556, dsc 0.01444\n",
      "Batch train [2] loss 0.97360, dsc 0.02640\n",
      "Batch train [2] loss 0.99244, dsc 0.00756\n",
      "Batch train [2] loss 0.99214, dsc 0.00786\n",
      "Batch train [2] loss 0.99423, dsc 0.00577\n",
      "Epoch [14] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  13, step 0\n",
      "Batch eval [1] loss 0.97514, dsc 0.02486\n",
      "Batch eval [1] loss 0.98117, dsc 0.01883\n",
      "Batch eval [1] loss 0.97330, dsc 0.02670\n",
      "Batch eval [1] loss 0.98239, dsc 0.01761\n",
      "Batch eval [1] loss 0.98594, dsc 0.01406\n",
      "Epoch [14] valid done\n",
      "Epoch [14] T 5216.11s, deltaT 373.32s, loss: train 0.98474, valid 0.97959, dsc: train 0.01526, valid 0.02041\n",
      "DEBUG: Writing to tensorboard before epoch True, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  14, step 0\n",
      "Batch train [2] loss 0.99112, dsc 0.00888\n",
      "Batch train [2] loss 0.98215, dsc 0.01785\n",
      "Batch train [2] loss 0.99154, dsc 0.00846\n",
      "Batch train [2] loss 0.99621, dsc 0.00379\n",
      "Batch train [2] loss 0.99412, dsc 0.00588\n",
      "Batch train [2] loss 0.95937, dsc 0.04063\n",
      "Batch train [2] loss 0.98963, dsc 0.01037\n",
      "Batch train [2] loss 0.99645, dsc 0.00355\n",
      "Batch train [2] loss 0.99751, dsc 0.00249\n",
      "Batch train [2] loss 0.99622, dsc 0.00378\n",
      "Batch train [2] loss 0.98408, dsc 0.01592\n",
      "Batch train [2] loss 0.99544, dsc 0.00456\n",
      "Batch train [2] loss 0.99235, dsc 0.00765\n",
      "Batch train [2] loss 0.98319, dsc 0.01681\n",
      "Batch train [2] loss 0.98728, dsc 0.01272\n",
      "Batch train [2] loss 0.99333, dsc 0.00667\n",
      "Batch train [2] loss 0.97091, dsc 0.02909\n",
      "Batch train [2] loss 0.99615, dsc 0.00385\n",
      "Batch train [2] loss 0.96723, dsc 0.03277\n",
      "Batch train [2] loss 0.99530, dsc 0.00470\n",
      "Epoch [15] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  14, step 0\n",
      "Batch eval [1] loss 0.97650, dsc 0.02350\n",
      "Batch eval [1] loss 0.98228, dsc 0.01772\n",
      "Batch eval [1] loss 0.97710, dsc 0.02290\n",
      "Batch eval [1] loss 0.98303, dsc 0.01697\n",
      "Batch eval [1] loss 0.98726, dsc 0.01274\n",
      "Epoch [15] valid done\n",
      "Epoch [15] T 5588.90s, deltaT 372.79s, loss: train 0.98798, valid 0.98123, dsc: train 0.01202, valid 0.01877\n",
      "DEBUG: Writing to tensorboard before epoch True, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  15, step 0\n",
      "Batch train [2] loss 0.98969, dsc 0.01031\n",
      "Batch train [2] loss 0.99937, dsc 0.00063\n",
      "Batch train [2] loss 0.99759, dsc 0.00241\n",
      "Batch train [2] loss 0.99583, dsc 0.00417\n",
      "Batch train [2] loss 0.99314, dsc 0.00686\n",
      "Batch train [2] loss 0.99358, dsc 0.00642\n",
      "Batch train [2] loss 0.97454, dsc 0.02546\n",
      "Batch train [2] loss 0.98032, dsc 0.01968\n",
      "Batch train [2] loss 0.98221, dsc 0.01779\n",
      "Batch train [2] loss 0.98683, dsc 0.01317\n",
      "Batch train [2] loss 0.99215, dsc 0.00785\n",
      "Batch train [2] loss 0.99814, dsc 0.00186\n",
      "Batch train [2] loss 0.99230, dsc 0.00770\n",
      "Batch train [2] loss 0.99317, dsc 0.00683\n",
      "Batch train [2] loss 0.98362, dsc 0.01638\n",
      "Batch train [2] loss 0.97930, dsc 0.02070\n",
      "Batch train [2] loss 0.99975, dsc 0.00025\n",
      "Batch train [2] loss 0.98317, dsc 0.01683\n",
      "Batch train [2] loss 0.98787, dsc 0.01213\n",
      "Batch train [2] loss 0.99027, dsc 0.00973\n",
      "Epoch [16] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  15, step 0\n",
      "Batch eval [1] loss 0.97957, dsc 0.02043\n",
      "Batch eval [1] loss 0.98330, dsc 0.01670\n",
      "Batch eval [1] loss 0.97853, dsc 0.02147\n",
      "Batch eval [1] loss 0.98501, dsc 0.01499\n",
      "Batch eval [1] loss 0.98789, dsc 0.01211\n",
      "Epoch [16] valid done\n",
      "Epoch [16] T 5962.18s, deltaT 373.27s, loss: train 0.98964, valid 0.98286, dsc: train 0.01036, valid 0.01714\n",
      "DEBUG: Writing to tensorboard before epoch True, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  16, step 0\n",
      "Batch train [2] loss 0.99726, dsc 0.00274\n",
      "Batch train [2] loss 0.99054, dsc 0.00946\n",
      "Batch train [2] loss 0.99878, dsc 0.00122\n",
      "Batch train [2] loss 0.97067, dsc 0.02933\n",
      "Batch train [2] loss 0.98810, dsc 0.01190\n",
      "Batch train [2] loss 0.99521, dsc 0.00479\n",
      "Batch train [2] loss 0.98207, dsc 0.01793\n",
      "Batch train [2] loss 0.99162, dsc 0.00838\n",
      "Batch train [2] loss 0.98883, dsc 0.01117\n",
      "Batch train [2] loss 0.98830, dsc 0.01170\n",
      "Batch train [2] loss 0.99107, dsc 0.00893\n",
      "Batch train [2] loss 0.99210, dsc 0.00790\n",
      "Batch train [2] loss 0.97596, dsc 0.02404\n",
      "Batch train [2] loss 0.99057, dsc 0.00943\n",
      "Batch train [2] loss 0.99110, dsc 0.00890\n",
      "Batch train [2] loss 0.99931, dsc 0.00069\n",
      "Batch train [2] loss 0.98080, dsc 0.01920\n",
      "Batch train [2] loss 0.99446, dsc 0.00554\n",
      "Batch train [2] loss 0.98704, dsc 0.01296\n",
      "Batch train [2] loss 0.99106, dsc 0.00894\n",
      "Epoch [17] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  16, step 0\n",
      "Batch eval [1] loss 0.97677, dsc 0.02323\n",
      "Batch eval [1] loss 0.98270, dsc 0.01730\n",
      "Batch eval [1] loss 0.97589, dsc 0.02411\n",
      "Batch eval [1] loss 0.98335, dsc 0.01665\n",
      "Batch eval [1] loss 0.98790, dsc 0.01210\n",
      "Epoch [17] valid done\n",
      "Epoch [17] T 6336.07s, deltaT 373.89s, loss: train 0.98924, valid 0.98132, dsc: train 0.01076, valid 0.01868\n",
      "DEBUG: Writing to tensorboard before epoch True, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  17, step 0\n",
      "Batch train [2] loss 0.97334, dsc 0.02666\n",
      "Batch train [2] loss 0.99830, dsc 0.00170\n",
      "Batch train [2] loss 0.99483, dsc 0.00517\n",
      "Batch train [2] loss 0.99826, dsc 0.00174\n",
      "Batch train [2] loss 0.96671, dsc 0.03329\n",
      "Batch train [2] loss 0.99362, dsc 0.00638\n",
      "Batch train [2] loss 0.97900, dsc 0.02100\n",
      "Batch train [2] loss 0.98729, dsc 0.01271\n",
      "Batch train [2] loss 0.99930, dsc 0.00070\n",
      "Batch train [2] loss 0.96170, dsc 0.03830\n",
      "Batch train [2] loss 0.99987, dsc 0.00013\n",
      "Batch train [2] loss 0.99072, dsc 0.00928\n",
      "Batch train [2] loss 0.99258, dsc 0.00742\n",
      "Batch train [2] loss 0.99588, dsc 0.00412\n",
      "Batch train [2] loss 0.95819, dsc 0.04181\n",
      "Batch train [2] loss 0.95640, dsc 0.04360\n",
      "Batch train [2] loss 0.98773, dsc 0.01227\n",
      "Batch train [2] loss 0.97465, dsc 0.02535\n",
      "Batch train [2] loss 0.96693, dsc 0.03307\n",
      "Batch train [2] loss 0.97224, dsc 0.02776\n",
      "Epoch [18] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  17, step 0\n",
      "Batch eval [1] loss 0.97694, dsc 0.02306\n",
      "Batch eval [1] loss 0.98268, dsc 0.01732\n",
      "Batch eval [1] loss 0.97948, dsc 0.02052\n",
      "Batch eval [1] loss 0.98370, dsc 0.01630\n",
      "Batch eval [1] loss 0.98801, dsc 0.01199\n",
      "Epoch [18] valid done\n",
      "Epoch [18] T 6709.93s, deltaT 373.86s, loss: train 0.98238, valid 0.98216, dsc: train 0.01762, valid 0.01784\n",
      "DEBUG: Writing to tensorboard before epoch True, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  18, step 0\n",
      "Batch train [2] loss 0.99525, dsc 0.00475\n",
      "Batch train [2] loss 0.97913, dsc 0.02087\n",
      "Batch train [2] loss 0.95707, dsc 0.04293\n",
      "Batch train [2] loss 0.96873, dsc 0.03127\n",
      "Batch train [2] loss 0.99826, dsc 0.00174\n",
      "Batch train [2] loss 0.99723, dsc 0.00277\n",
      "Batch train [2] loss 0.97393, dsc 0.02607\n",
      "Batch train [2] loss 0.99593, dsc 0.00407\n",
      "Batch train [2] loss 0.99852, dsc 0.00148\n",
      "Batch train [2] loss 0.99388, dsc 0.00612\n",
      "Batch train [2] loss 0.99826, dsc 0.00174\n",
      "Batch train [2] loss 0.99055, dsc 0.00945\n",
      "Batch train [2] loss 0.99530, dsc 0.00470\n",
      "Batch train [2] loss 0.99493, dsc 0.00507\n",
      "Batch train [2] loss 0.95959, dsc 0.04041\n",
      "Batch train [2] loss 0.99991, dsc 0.00009\n",
      "Batch train [2] loss 0.98433, dsc 0.01567\n",
      "Batch train [2] loss 0.99579, dsc 0.00421\n",
      "Batch train [2] loss 0.98994, dsc 0.01006\n",
      "Batch train [2] loss 0.98253, dsc 0.01747\n",
      "Epoch [19] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  18, step 0\n",
      "Batch eval [1] loss 0.97777, dsc 0.02223\n",
      "Batch eval [1] loss 0.98471, dsc 0.01529\n",
      "Batch eval [1] loss 0.98045, dsc 0.01955\n",
      "Batch eval [1] loss 0.98490, dsc 0.01510\n",
      "Batch eval [1] loss 0.99026, dsc 0.00974\n",
      "Epoch [19] valid done\n",
      "Epoch [19] T 7082.05s, deltaT 372.12s, loss: train 0.98745, valid 0.98362, dsc: train 0.01255, valid 0.01638\n",
      "DEBUG: Writing to tensorboard before epoch True, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  19, step 0\n",
      "Batch train [2] loss 0.97313, dsc 0.02687\n",
      "Batch train [2] loss 0.98903, dsc 0.01097\n",
      "Batch train [2] loss 0.98877, dsc 0.01123\n",
      "Batch train [2] loss 0.98763, dsc 0.01237\n",
      "Batch train [2] loss 0.99280, dsc 0.00720\n",
      "Batch train [2] loss 0.99495, dsc 0.00505\n",
      "Batch train [2] loss 0.97102, dsc 0.02898\n",
      "Batch train [2] loss 0.98847, dsc 0.01153\n",
      "Batch train [2] loss 0.96993, dsc 0.03007\n",
      "Batch train [2] loss 0.97311, dsc 0.02689\n",
      "Batch train [2] loss 0.99436, dsc 0.00564\n",
      "Batch train [2] loss 0.99075, dsc 0.00925\n",
      "Batch train [2] loss 0.99864, dsc 0.00136\n",
      "Batch train [2] loss 0.99916, dsc 0.00084\n",
      "Batch train [2] loss 0.98990, dsc 0.01010\n",
      "Batch train [2] loss 0.97803, dsc 0.02197\n",
      "Batch train [2] loss 0.99189, dsc 0.00811\n",
      "Batch train [2] loss 0.99891, dsc 0.00109\n",
      "Batch train [2] loss 0.98434, dsc 0.01566\n",
      "Batch train [2] loss 0.98780, dsc 0.01220\n",
      "Epoch [20] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  19, step 0\n",
      "Batch eval [1] loss 0.97633, dsc 0.02367\n",
      "Batch eval [1] loss 0.98203, dsc 0.01797\n",
      "Batch eval [1] loss 0.98120, dsc 0.01880\n",
      "Batch eval [1] loss 0.98267, dsc 0.01733\n",
      "Batch eval [1] loss 0.98678, dsc 0.01322\n",
      "Epoch [20] valid done\n",
      "Epoch [20] T 7454.16s, deltaT 372.11s, loss: train 0.98713, valid 0.98180, dsc: train 0.01287, valid 0.01820\n",
      "DEBUG: Writing to tensorboard before epoch True, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  20, step 0\n",
      "Batch train [2] loss 0.99399, dsc 0.00601\n",
      "Batch train [2] loss 0.97842, dsc 0.02158\n",
      "Batch train [2] loss 0.98042, dsc 0.01958\n",
      "Batch train [2] loss 0.99544, dsc 0.00456\n",
      "Batch train [2] loss 0.97804, dsc 0.02196\n",
      "Batch train [2] loss 0.99444, dsc 0.00556\n",
      "Batch train [2] loss 0.99624, dsc 0.00376\n",
      "Batch train [2] loss 0.97777, dsc 0.02223\n",
      "Batch train [2] loss 0.98292, dsc 0.01708\n",
      "Batch train [2] loss 0.99456, dsc 0.00544\n",
      "Batch train [2] loss 0.99483, dsc 0.00517\n",
      "Batch train [2] loss 0.96417, dsc 0.03583\n",
      "Batch train [2] loss 0.99563, dsc 0.00437\n",
      "Batch train [2] loss 0.98910, dsc 0.01090\n",
      "Batch train [2] loss 0.99192, dsc 0.00808\n",
      "Batch train [2] loss 0.99473, dsc 0.00527\n",
      "Batch train [2] loss 0.98693, dsc 0.01307\n",
      "Batch train [2] loss 0.99255, dsc 0.00745\n",
      "Batch train [2] loss 0.98827, dsc 0.01173\n",
      "Batch train [2] loss 0.97935, dsc 0.02065\n",
      "Epoch [21] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  20, step 0\n",
      "Batch eval [1] loss 0.97452, dsc 0.02548\n",
      "Batch eval [1] loss 0.98101, dsc 0.01899\n",
      "Batch eval [1] loss 0.97379, dsc 0.02621\n",
      "Batch eval [1] loss 0.98217, dsc 0.01783\n",
      "Batch eval [1] loss 0.98613, dsc 0.01387\n",
      "Epoch [21] valid done\n",
      "Epoch [21] T 7826.05s, deltaT 371.90s, loss: train 0.98749, valid 0.97952, dsc: train 0.01251, valid 0.02048\n",
      "DEBUG: Writing to tensorboard before epoch True, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  21, step 0\n",
      "Batch train [2] loss 0.96231, dsc 0.03769\n",
      "Batch train [2] loss 0.98455, dsc 0.01545\n",
      "Batch train [2] loss 0.96588, dsc 0.03412\n",
      "Batch train [2] loss 0.99397, dsc 0.00603\n",
      "Batch train [2] loss 0.99247, dsc 0.00753\n",
      "Batch train [2] loss 0.98292, dsc 0.01708\n",
      "Batch train [2] loss 0.98174, dsc 0.01826\n",
      "Batch train [2] loss 0.99439, dsc 0.00561\n",
      "Batch train [2] loss 0.97729, dsc 0.02271\n",
      "Batch train [2] loss 0.99659, dsc 0.00341\n",
      "Batch train [2] loss 0.97924, dsc 0.02076\n",
      "Batch train [2] loss 0.99608, dsc 0.00392\n",
      "Batch train [2] loss 0.99476, dsc 0.00524\n",
      "Batch train [2] loss 0.99972, dsc 0.00028\n",
      "Batch train [2] loss 0.99127, dsc 0.00873\n",
      "Batch train [2] loss 0.98696, dsc 0.01304\n",
      "Batch train [2] loss 0.98905, dsc 0.01095\n",
      "Batch train [2] loss 0.99715, dsc 0.00285\n",
      "Batch train [2] loss 0.99858, dsc 0.00142\n",
      "Batch train [2] loss 0.98696, dsc 0.01304\n",
      "Epoch [22] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  21, step 0\n",
      "Batch eval [1] loss 0.97527, dsc 0.02473\n",
      "Batch eval [1] loss 0.98142, dsc 0.01858\n",
      "Batch eval [1] loss 0.97249, dsc 0.02751\n",
      "Batch eval [1] loss 0.98189, dsc 0.01811\n",
      "Batch eval [1] loss 0.98587, dsc 0.01413\n",
      "Epoch [22] valid done\n",
      "Epoch [22] T 8198.59s, deltaT 372.53s, loss: train 0.98759, valid 0.97939, dsc: train 0.01241, valid 0.02061\n",
      "DEBUG: Writing to tensorboard before epoch True, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  22, step 0\n",
      "Batch train [2] loss 0.98572, dsc 0.01428\n",
      "Batch train [2] loss 0.99308, dsc 0.00692\n",
      "Batch train [2] loss 0.99854, dsc 0.00146\n",
      "Batch train [2] loss 0.98742, dsc 0.01258\n",
      "Batch train [2] loss 0.99100, dsc 0.00900\n",
      "Batch train [2] loss 0.99313, dsc 0.00687\n",
      "Batch train [2] loss 0.99693, dsc 0.00307\n",
      "Batch train [2] loss 0.99705, dsc 0.00295\n",
      "Batch train [2] loss 0.97793, dsc 0.02207\n",
      "Batch train [2] loss 0.96907, dsc 0.03093\n",
      "Batch train [2] loss 0.97277, dsc 0.02723\n",
      "Batch train [2] loss 0.98162, dsc 0.01838\n",
      "Batch train [2] loss 0.97614, dsc 0.02386\n",
      "Batch train [2] loss 0.98337, dsc 0.01663\n",
      "Batch train [2] loss 0.96443, dsc 0.03557\n",
      "Batch train [2] loss 0.98142, dsc 0.01858\n",
      "Batch train [2] loss 0.97412, dsc 0.02588\n",
      "Batch train [2] loss 0.99450, dsc 0.00550\n",
      "Batch train [2] loss 0.99844, dsc 0.00156\n",
      "Batch train [2] loss 0.96537, dsc 0.03463\n",
      "Epoch [23] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  22, step 0\n",
      "Batch eval [1] loss 0.97527, dsc 0.02473\n",
      "Batch eval [1] loss 0.98064, dsc 0.01936\n",
      "Batch eval [1] loss 0.97343, dsc 0.02657\n",
      "Batch eval [1] loss 0.98231, dsc 0.01769\n",
      "Batch eval [1] loss 0.98614, dsc 0.01386\n",
      "Epoch [23] valid done\n",
      "Epoch [23] T 8569.91s, deltaT 371.32s, loss: train 0.98410, valid 0.97956, dsc: train 0.01590, valid 0.02044\n",
      "DEBUG: Writing to tensorboard before epoch True, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  23, step 0\n",
      "Batch train [2] loss 0.99106, dsc 0.00894\n",
      "Batch train [2] loss 0.98617, dsc 0.01383\n",
      "Batch train [2] loss 0.95316, dsc 0.04684\n",
      "Batch train [2] loss 0.99296, dsc 0.00704\n",
      "Batch train [2] loss 0.99109, dsc 0.00891\n",
      "Batch train [2] loss 0.98707, dsc 0.01293\n",
      "Batch train [2] loss 0.99282, dsc 0.00718\n",
      "Batch train [2] loss 0.99995, dsc 0.00005\n",
      "Batch train [2] loss 0.98158, dsc 0.01842\n",
      "Batch train [2] loss 0.98686, dsc 0.01314\n",
      "Batch train [2] loss 0.98338, dsc 0.01662\n",
      "Batch train [2] loss 0.97085, dsc 0.02915\n",
      "Batch train [2] loss 0.98070, dsc 0.01930\n",
      "Batch train [2] loss 0.96840, dsc 0.03160\n",
      "Batch train [2] loss 0.98234, dsc 0.01766\n",
      "Batch train [2] loss 0.99354, dsc 0.00646\n",
      "Batch train [2] loss 0.94243, dsc 0.05757\n",
      "Batch train [2] loss 0.93657, dsc 0.06343\n",
      "Batch train [2] loss 0.94454, dsc 0.05546\n",
      "Batch train [2] loss 0.98287, dsc 0.01713\n",
      "Epoch [24] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  23, step 0\n",
      "Batch eval [1] loss 0.98726, dsc 0.01274\n",
      "Batch eval [1] loss 0.98990, dsc 0.01010\n",
      "Batch eval [1] loss 0.98512, dsc 0.01488\n",
      "Batch eval [1] loss 0.99039, dsc 0.00961\n",
      "Batch eval [1] loss 0.99346, dsc 0.00654\n",
      "Epoch [24] valid done\n",
      "Epoch [24] T 8942.12s, deltaT 372.21s, loss: train 0.97742, valid 0.98923, dsc: train 0.02258, valid 0.01077\n",
      "DEBUG: Writing to tensorboard before epoch True, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  24, step 0\n",
      "Batch train [2] loss 0.97021, dsc 0.02979\n",
      "Batch train [2] loss 0.98365, dsc 0.01635\n",
      "Batch train [2] loss 0.99868, dsc 0.00132\n",
      "Batch train [2] loss 0.96477, dsc 0.03523\n",
      "Batch train [2] loss 0.99987, dsc 0.00013\n",
      "Batch train [2] loss 0.99801, dsc 0.00199\n",
      "Batch train [2] loss 0.94931, dsc 0.05069\n",
      "Batch train [2] loss 0.98482, dsc 0.01518\n",
      "Batch train [2] loss 0.99328, dsc 0.00672\n",
      "Batch train [2] loss 0.97299, dsc 0.02701\n",
      "Batch train [2] loss 0.99323, dsc 0.00677\n",
      "Batch train [2] loss 0.99614, dsc 0.00386\n",
      "Batch train [2] loss 0.96928, dsc 0.03072\n",
      "Batch train [2] loss 0.99366, dsc 0.00634\n",
      "Batch train [2] loss 0.99016, dsc 0.00984\n",
      "Batch train [2] loss 0.98463, dsc 0.01537\n",
      "Batch train [2] loss 0.98707, dsc 0.01293\n",
      "Batch train [2] loss 0.98829, dsc 0.01171\n",
      "Batch train [2] loss 0.99212, dsc 0.00788\n",
      "Batch train [2] loss 0.99239, dsc 0.00761\n",
      "Epoch [25] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  24, step 0\n",
      "Batch eval [1] loss 0.96546, dsc 0.03454\n",
      "Batch eval [1] loss 0.97694, dsc 0.02306\n",
      "Batch eval [1] loss 0.97912, dsc 0.02088\n",
      "Batch eval [1] loss 0.97541, dsc 0.02459\n",
      "Batch eval [1] loss 0.98164, dsc 0.01836\n",
      "Epoch [25] valid done\n",
      "Epoch [25] T 9315.04s, deltaT 372.92s, loss: train 0.98513, valid 0.97571, dsc: train 0.01487, valid 0.02429\n",
      "DEBUG: Writing to tensorboard before epoch True, 25, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  25, step 0\n",
      "Batch train [2] loss 0.96158, dsc 0.03842\n",
      "Batch train [2] loss 0.99812, dsc 0.00188\n",
      "Batch train [2] loss 0.99952, dsc 0.00048\n",
      "Batch train [2] loss 0.98227, dsc 0.01773\n",
      "Batch train [2] loss 0.98748, dsc 0.01252\n",
      "Batch train [2] loss 0.99265, dsc 0.00735\n",
      "Batch train [2] loss 0.99635, dsc 0.00365\n",
      "Batch train [2] loss 0.98203, dsc 0.01797\n",
      "Batch train [2] loss 0.98548, dsc 0.01452\n",
      "Batch train [2] loss 0.97964, dsc 0.02036\n",
      "Batch train [2] loss 0.98583, dsc 0.01417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd5b9e6ab2e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mshow_model_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_model_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_model_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterate_model_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterate_model_v3v2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/train_loop.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model_info, iterate_model_fn)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# training dsc and loss are calculated during training per batch, that means it is approximation!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch [%d] train done'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/iterate_model_v3v2.py\u001b[0m in \u001b[0;36miterate_model_v3v2\u001b[0;34m(dataloader, model, optimizer, loss_func, device, is_eval)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             item_loss, item_dsc, inputs_len = loss_batch(model, optimizer, loss_func, inputs, labels,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                                          calc_backward=not is_eval)\n\u001b[1;32m     55\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/loss_batch.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, optimizer, loss_func, model_input, true_output, calc_backward)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_backward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAIN_MODELS = True\n",
    "if TRAIN_MODELS:\n",
    "    for DATASET_REG_NAME, OAR_KEY, OAR_VALUE in labels_list:\n",
    "        # loading dataset\n",
    "        data_path = f'./data/HaN_OAR_cut_{DATASET_REG_NAME}_reg'\n",
    "        cut_full_res_dataset = HaNOarsDataset(data_path, size=50, load_images=False)\n",
    "        cut_full_res_dataset.load_from_file(data_path)\n",
    "        cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "        \n",
    "        cut_full_res_dataset_obj = split_dataset(cut_full_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "        cut_train_dataset, cut_valid_dataset, cut_test_dataset = itemgetter(*['train_dataset', 'valid_dataset', 'test_dataset'])(cut_full_res_dataset_obj)\n",
    "        \n",
    "        # preparing model name\n",
    "        log_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_name = f'{log_date}_3d_unet_lowres_model3v2__cloud-{OAR_KEY}-{DATASET_REG_NAME}_reg'\n",
    "\n",
    "        print(f'Training model with dataset label \\'{OAR_KEY}\\', value \\'{OAR_VALUE}\\'')\n",
    "        print(f'folder \\'{model_name}\\'')\n",
    "        cut_model_info = prepare_model(epochs=75,\n",
    "                                       learning_rate=3e-4,\n",
    "                                       in_channels=8,\n",
    "                                       input_data_channels=1,\n",
    "                                       output_label_channels=1,\n",
    "                                       dropout_rate=0.2,\n",
    "                                       train_batch_size=2,\n",
    "                                       model_name=model_name,\n",
    "                                       train_dataset=cut_train_dataset, \n",
    "                                       valid_dataset=cut_valid_dataset, \n",
    "                                       test_dataset=cut_test_dataset,\n",
    "                                       model_class=UNetV3v2)\n",
    "        show_model_info(cut_model_info)\n",
    "        print('\\n\\n')\n",
    "        train_loop(cut_model_info, iterate_model_fn=iterate_model_v3v2)\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # clearing memory\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = list()\n",
    "\n",
    "# creating registration dataset and organ segmentation pairs\n",
    "# dataset use inverted labeling of left and right\n",
    "labels_list.append(('left_parotid', *tmp_list[12]))\n",
    "labels_list.append(('right_parotid', *tmp_list[11]))\n",
    "\n",
    "labels_list.append(('brainstem', *tmp_list[10]))\n",
    "labels_list.append(('parotids', *tmp_list[10]))\n",
    "labels_list.append(('all_maps', *tmp_list[10]))\n",
    "\n",
    "for DATASET_REG_NAME, OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{DATASET_REG_NAME}, {OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_models(oar_key):\n",
    "    possible_models = [folder_name for folder_name in os.listdir('./models') if oar_key in folder_name]    \n",
    "    \n",
    "    return possible_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading models to CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "for DATASET_REG_NAME, OAR_KEY, OAR_VALUE in labels_list:\n",
    "    model_reg_name = f'{OAR_KEY}-{DATASET_REG_NAME}'\n",
    "    \n",
    "    # dataset loading\n",
    "    data_path = f'./data/HaN_OAR_cut_{DATASET_REG_NAME}_reg'\n",
    "    cut_full_res_dataset = HaNOarsDataset(data_path, size=50, load_images=False)\n",
    "    cut_full_res_dataset.load_from_file(data_path)\n",
    "    cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "    cut_full_res_dataset_obj = split_dataset(cut_full_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "    cut_train_dataset, cut_valid_dataset, cut_test_dataset = itemgetter(*['train_dataset', 'valid_dataset', 'test_dataset'])(cut_full_res_dataset_obj)\n",
    "    \n",
    "    epoch = 1\n",
    "    possible_models = get_possible_models(f\"model3v2__cloud-{OAR_KEY}-{DATASET_REG_NAME}_reg\")\n",
    "    if len(possible_models) <= 0:\n",
    "        print(f'{OAR_KEY} Model: No avaiable model')\n",
    "        continue\n",
    "\n",
    "    model_name = possible_models[0]\n",
    "    print(f'{model_reg_name} Model: Loading model {model_name}')\n",
    "\n",
    "    # loading model checkpoint\n",
    "    cut_model_info = load_checkpoint_model_info(model_name, epoch, cut_train_dataset, cut_valid_dataset, cut_test_dataset, model_class=UNetV3v2)\n",
    "\n",
    "    # moving model to cpu/cuda with eval mode\n",
    "    cut_model_info['device'] = 'cpu'\n",
    "    cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "    cut_model_info['model'].eval()\n",
    "    cut_model_info['model'].disable_tensorboard_writing = True\n",
    "    \n",
    "    models[model_reg_name] = cut_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Eval vs Train Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing iteration function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_full_res_dataset.set_output_label(OARS_LABELS.PITUITARY)\n",
    "cut_model_info = models[list(models.keys())[0]]\n",
    "cut_model_info['device'] = get_device()\n",
    "cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "cut_model_info['model'].disable_tensorboard_writing = True\n",
    "    \n",
    "model, model_name, optimizer, criterion = itemgetter('model', 'model_name', 'optimizer', 'criterion')(cut_model_info)\n",
    "epochs, device, tensorboard_writer = itemgetter('epochs', 'device', 'tensorboard_writer')(cut_model_info)\n",
    "train_dataloader, valid_dataloader, test_dataloader = itemgetter('train_dataloader',\n",
    "                                                                 'valid_dataloader',\n",
    "                                                                 'test_dataloader')(cut_model_info)\n",
    "model.actual_epoch = 100\n",
    "\n",
    "valid_loss, valid_dsc = iterate_model_v3v2(valid_dataloader, model, optimizer, criterion, device, is_eval=True)\n",
    "print(valid_loss, valid_dsc)\n",
    "\n",
    "cut_model_info['model'].disable_tensorboard_writing = True\n",
    "cut_model_info['device'] = 'cpu'\n",
    "cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_DSC_INFO = True\n",
    "if SHOW_DSC_INFO:\n",
    "    info_per_organs_df = {}\n",
    "    models_info = list()\n",
    "    for DATASET_REG_NAME, OAR_KEY, OAR_VALUE in labels_list:\n",
    "        model_name = f'{OAR_KEY}-{DATASET_REG_NAME}'\n",
    "        \n",
    "        if model_name not in models:\n",
    "            print(f'{model_name} Model: No avaiable model')\n",
    "            continue\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[model_name]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "        cut_model_info['model'].disable_tensorboard_writing = True\n",
    "\n",
    "        # preparing dataset for comparison\n",
    "        # dataset loading\n",
    "        data_path = f'./data/HaN_OAR_cut_{DATASET_REG_NAME}_reg'\n",
    "        cut_full_res_dataset = HaNOarsDataset(data_path, size=50, load_images=False)\n",
    "        cut_full_res_dataset.load_from_file(data_path)\n",
    "        cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "        cut_full_res_dataset_obj = split_dataset(cut_full_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "        cut_train_dataset, cut_valid_dataset, cut_test_dataset = itemgetter(*['train_dataset', 'valid_dataset', 'test_dataset'])(cut_full_res_dataset_obj)\n",
    "    \n",
    "\n",
    "        # calculating dsc predictions        \n",
    "        info_df, preds, rescaled_preds = get_threshold_info_df(\n",
    "                                    model=cut_model_info['model'], \n",
    "                                    dataset=cut_full_res_dataset, \n",
    "                                    device=cut_model_info['device'], \n",
    "                                    train_indices=cut_train_dataset.indices, \n",
    "                                    valid_indices=cut_valid_dataset.indices, \n",
    "                                    test_indices=cut_test_dataset.indices,\n",
    "                                    step=0.5,\n",
    "                                    transform_input_fn=transform_input_with_registration)\n",
    "        info_per_organs_df[model_name] = info_df\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "\n",
    "        # parsing data\n",
    "        best_threshold_col = 'thres_rescaled_dsc_0.50'\n",
    "        train_tmp_df = info_df[info_df['is_train']][best_threshold_col]\n",
    "        valid_tmp_df = info_df[info_df['is_valid']][best_threshold_col]\n",
    "        train_dsc = train_tmp_df.mean()\n",
    "        valid_dsc = valid_tmp_df.mean()\n",
    "        print(f'{model_name} Model: DSC train {round(train_dsc, 4)} valid {round(valid_dsc, 4)}')\n",
    "\n",
    "        models_info.append({\n",
    "            'oar_key': OAR_KEY,\n",
    "            'model_name': model_name,\n",
    "            # Train\n",
    "            'train_dsc_mean': train_dsc,\n",
    "            'train_dsc_std': train_tmp_df.std(),\n",
    "            'train_dsc_median': train_tmp_df.median(),\n",
    "            'train_dsc_min': train_tmp_df.min(),\n",
    "            'train_dsc_max': train_tmp_df.max(),\n",
    "            # Valid\n",
    "            'valid_dsc_mean': valid_dsc,\n",
    "            'valid_dsc_std': valid_tmp_df.std(),\n",
    "            'valid_dsc_median': valid_tmp_df.median(),\n",
    "            'valid_dsc_min': valid_tmp_df.min(),\n",
    "            'valid_dsc_max': valid_tmp_df.max(),\n",
    "            # Both\n",
    "            'train_valid_mean_delta': train_dsc - valid_dsc\n",
    "        })\n",
    "\n",
    "    models_info_df = pd.DataFrame(models_info)\n",
    "    \n",
    "    tmp_df = models_info_df[['oar_key', 'train_dsc_mean', 'train_dsc_std', 'valid_dsc_mean', 'valid_dsc_std']].copy()\n",
    "    tmp_df['train_dsc_mean'] = (tmp_df['train_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_mean'] = (tmp_df['valid_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['train_dsc_std'] = (tmp_df['train_dsc_std'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_std'] = (tmp_df['valid_dsc_std'] * 100).round(2)\n",
    "    \n",
    "    display(tmp_df.mean().round(2))\n",
    "    display(tmp_df.round(2))\n",
    "    display(tmp_df.sort_values(by=['train_dsc_std']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_dsc_mean']).drop(columns=['model_name']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_valid_mean_delta']).drop(columns=['model_name']).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_DSC_INFO:\n",
    "    tmp_column = 'is_train'\n",
    "    \n",
    "    try:\n",
    "        print('OARS_LABELS.PAROTID_GLAND_R')\n",
    "        tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PAROTID_GLAND_R]]\n",
    "        display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:   \n",
    "        print('OARS_LABELS.PAROTID_GLAND_L')\n",
    "        tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PAROTID_GLAND_L]]\n",
    "        display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try: \n",
    "        print('OARS_LABELS.OPT_NERVE_L')\n",
    "        tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.OPT_NERVE_L]]\n",
    "        display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try: \n",
    "        print('OARS_LABELS.PITUITARY')\n",
    "        tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PITUITARY]]\n",
    "        display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions merging and checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_labels_dict = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels_dict['SPINAL_CORD']\n",
    "\n",
    "cut_full_res_dataset.set_output_label(filter_labels_dict)\n",
    "preview_dataset(cut_full_res_dataset, preview_index=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSE_CUT_DATASET = True\n",
    "if PARSE_CUT_DATASET:\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    prediction_threshold = 0.5\n",
    "    cut_dataset_predictions = defaultdict(lambda: defaultdict(lambda: np.zeros(cut_full_res_dataset[0][0][0].shape)))\n",
    "    \n",
    "    # for each label\n",
    "    for label_index, val in enumerate(labels_list[:]):\n",
    "        DATASET_REG_NAME, OAR_KEY, OAR_VALUE = val\n",
    "        model_name = f'{OAR_KEY}-{DATASET_REG_NAME}'\n",
    "        \n",
    "        # loading model\n",
    "        if model_name not in models:\n",
    "            print(f'{label_index+1}/{len(labels_list)}: {model_name} Model: No avaiable model')\n",
    "            continue\n",
    "        print(f'{label_index+1}/{len(labels_list)}: {model_name} Model: got model {datetime.datetime.now()}')\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[model_name]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "        cut_model_info['model'].disable_tensorboard_writing = True\n",
    "\n",
    "        # for label in whole dataset\n",
    "        for index in range(len(cut_full_res_dataset)):\n",
    "            prediction, rescaled_pred = get_rescaled_pred(cut_model_info['model'], cut_full_res_dataset, \n",
    "                                                          cut_model_info['device'], index, use_only_one_dimension=False)\n",
    "    \n",
    "            cut_dataset_predictions[index][OAR_VALUE] = prediction[0]\n",
    "            # extended_cut_full_res_dataset.data_list[index][label_index + 1] = prediction\n",
    "            # extended_cut_full_res_dataset.data_list[index][label_index + 1] = ((rescaled_pred > prediction_threshold) * 1).astype(np.int8)\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_labels_dict = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels_dict['SPINAL_CORD']\n",
    "\n",
    "cut_full_res_dataset.set_output_label(filter_labels_dict)\n",
    "preview_dataset(cut_full_res_dataset, preview_index=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARSE_CUT_DATASET:\n",
    "    def custom_preview_dataset(dataset, predictions, preview_index=0, show_hist=False, use_transform=False):\n",
    "        data, label = dataset.get_raw_item_with_label_filter(preview_index)  # equivalent dataset[preview_index]\n",
    "        if use_transform:\n",
    "            transform = get_dataset_transform()\n",
    "            data, label = transform_input(data, label, transform)\n",
    "\n",
    "        prediction = predictions[preview_index]\n",
    "        max_channels = label.shape[0]\n",
    "        max_slices = label.shape[1]\n",
    "\n",
    "        print(f'data max {data.max()}, min {data.min()}')\n",
    "        print(f'label max {label.max()}, min {label.min()}')\n",
    "        print(f'data {data.shape}, label {label.shape}')\n",
    "\n",
    "        def f(slice_index, label_channel):\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(data[0, slice_index], cmap=\"gray\")\n",
    "            plt.title('data')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(prediction[label_channel+1][slice_index])\n",
    "            plt.title(f'prediction {label_channel}')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(label[label_channel, slice_index])\n",
    "            plt.title(f'label {label_channel}')\n",
    "            plt.show()\n",
    "\n",
    "            if show_hist:\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.hist(data.flatten(), 128)\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.hist(label.flatten(), 128)\n",
    "                plt.show()\n",
    "\n",
    "        sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "        labelChannelSlider = widgets.IntSlider(min=0, max=max_channels - 1, step=1, value=(max_channels - 1) / 2)\n",
    "        ui = widgets.VBox([widgets.HBox([sliceSlider, labelChannelSlider])])\n",
    "        out = widgets.interactive_output(f, {'slice_index': sliceSlider, 'label_channel': labelChannelSlider})\n",
    "        # noinspection PyTypeChecker\n",
    "        display(ui, out)\n",
    "    \n",
    "    index = cut_valid_dataset.indices[3]\n",
    "    index = 35\n",
    "    custom_preview_dataset(cut_full_res_dataset, cut_dataset_predictions, preview_index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
