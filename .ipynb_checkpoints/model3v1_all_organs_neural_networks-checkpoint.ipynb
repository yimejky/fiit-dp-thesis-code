{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n",
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/dp_tomastik/code')\n",
    "    !bash \"/content/drive/My Drive/dp_tomastik/code/scripts/install_libs.sh\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "from torchio import RandomAffine, Compose, ZNormalization\n",
    "\n",
    "import src.dataset.oars_labels_consts as OARS_LABELS\n",
    "from src.consts import DATASET_MAX_BOUNDING_BOX, DESIRE_BOUNDING_BOX_SIZE\n",
    "from src.helpers.threshold_calc_helpers import get_threshold_info_df\n",
    "from src.helpers.show_model_dataset_pred_preview import show_model_dataset_pred_preview\n",
    "from src.dataset.get_cut_lists import get_cut_lists\n",
    "from src.dataset.get_full_res_cut import get_full_res_cut\n",
    "from src.dataset.get_dataset import get_dataset\n",
    "from src.dataset.get_dataset_info import get_dataset_info\n",
    "from src.dataset.preview_dataset import preview_dataset\n",
    "from src.dataset.get_dataset_transform import get_dataset_transform\n",
    "from src.model_and_training.prepare_model import prepare_model\n",
    "from src.model_and_training.train_loop import train_loop\n",
    "from src.model_and_training.show_model_info import show_model_info\n",
    "from src.model_and_training.load_checkpoint_model_info import load_checkpoint_model_info\n",
    "from src.helpers.show_cuda_usage import show_cuda_usage\n",
    "from src.helpers.get_rescaled_pred import get_rescaled_preds\n",
    "from src.dataset.split_dataset import split_dataset, copy_split_dataset\n",
    "from src.helpers.compare_prediction_with_ground_true import compare_prediction_with_ground_true, compare_one_prediction_with_ground_true\n",
    "from src.helpers.get_img_outliers_pixels import get_img_outliers_pixels\n",
    "from src.helpers.get_raw_with_prediction import get_raw_with_prediction\n",
    "from src.model_and_training.getters.get_device import get_device\n",
    "from src.model_and_training.unet_architecture_v3v1 import UNetV3v1\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "torch.manual_seed(20)\n",
    "logging.basicConfig(filename='logs/all_organs_jupyter.log', level=logging.DEBUG)\n",
    "\n",
    "print('Dataset biggest bounding box wihtout spinal cord', DATASET_MAX_BOUNDING_BOX)\n",
    "print('Cut target size', DESIRE_BOUNDING_BOX_SIZE)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_models(oar_key):\n",
    "    possible_models = [folder_name for folder_name in os.listdir('./models') if oar_key in folder_name]    \n",
    "    \n",
    "    return possible_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading precourse neural network with datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 16x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "dilatating 1x dataset\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n",
      "CUDA using 1x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolas/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'src.losses.dice_loss.DiceLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model number of params: 298881, trainable 298881\n",
      "get_cut_lists: Cutting index 0\n",
      "get_full_res_cut: Removing 10/1335 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1223526 1223526\n",
      "get_cut_lists: Cutting index 1\n",
      "get_full_res_cut: Removing 0/1416 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1326052 1326052\n",
      "get_cut_lists: Cutting index 2\n",
      "get_full_res_cut: Removing 0/1873 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 20   0 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1890464 1890464\n",
      "get_cut_lists: Cutting index 3\n",
      "get_full_res_cut: Removing 0/1545 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [17 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1560217 1560217\n",
      "get_cut_lists: Cutting index 4\n",
      "get_full_res_cut: Removing 9/1510 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 48 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1451227 1451227\n",
      "get_cut_lists: Cutting index 5\n",
      "get_full_res_cut: Removing 0/1390 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1262651 1262651\n",
      "get_cut_lists: Cutting index 6\n",
      "get_full_res_cut: Removing 0/1451 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1566938 1566938\n",
      "get_cut_lists: Cutting index 7\n",
      "get_full_res_cut: Removing 0/958 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [29 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 869847 869847\n",
      "get_cut_lists: Cutting index 8\n",
      "get_full_res_cut: Removing 0/1489 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1397249 1397249\n",
      "get_cut_lists: Cutting index 9\n",
      "get_full_res_cut: Removing 0/1465 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1350330 1350330\n",
      "get_cut_lists: Cutting index 10\n",
      "get_full_res_cut: Removing 0/1650 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20  0 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1635868 1635868\n",
      "get_cut_lists: Cutting index 11\n",
      "get_full_res_cut: Removing 16/1371 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1283062 1283062\n",
      "get_cut_lists: Cutting index 12\n",
      "get_full_res_cut: Removing 0/1594 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1518406 1518406\n",
      "get_cut_lists: Cutting index 13\n",
      "get_full_res_cut: Removing 0/1482 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1504194 1504194\n",
      "get_cut_lists: Cutting index 14\n",
      "get_full_res_cut: Removing 0/1191 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1084254 1084254\n",
      "get_cut_lists: Cutting index 15\n",
      "get_full_res_cut: Removing 0/1267 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1221257 1221257\n",
      "get_cut_lists: Cutting index 16\n",
      "get_full_res_cut: Removing 2/1009 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 64 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 945639 945639\n",
      "get_cut_lists: Cutting index 17\n",
      "get_full_res_cut: Removing 0/1498 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1469035 1469035\n",
      "get_cut_lists: Cutting index 18\n",
      "get_full_res_cut: Removing 7/1371 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1322571 1322571\n",
      "get_cut_lists: Cutting index 19\n",
      "get_full_res_cut: Removing 0/1608 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [17 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1593516 1593516\n",
      "get_cut_lists: Cutting index 20\n",
      "get_full_res_cut: Removing 0/1359 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1390348 1390348\n",
      "get_cut_lists: Cutting index 21\n",
      "get_full_res_cut: Removing 0/1536 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 22  16 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1463017 1463017\n",
      "get_cut_lists: Cutting index 22\n",
      "get_full_res_cut: Removing 0/1231 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [26 32 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1162215 1162215\n",
      "get_cut_lists: Cutting index 23\n",
      "get_full_res_cut: Removing 0/1154 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1029805 1029805\n",
      "get_cut_lists: Cutting index 24\n",
      "get_full_res_cut: Removing 0/1669 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 29 -16   8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1689537 1689537\n",
      "get_cut_lists: Cutting index 25\n",
      "get_full_res_cut: Removing 0/1267 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1141739 1141739\n",
      "get_cut_lists: Cutting index 26\n",
      "get_full_res_cut: Removing 9/1289 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [18 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1167835 1167835\n",
      "get_cut_lists: Cutting index 27\n",
      "get_full_res_cut: Removing 15/1780 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23  0  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1783264 1783264\n",
      "get_cut_lists: Cutting index 28\n",
      "get_full_res_cut: Removing 25/1916 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 22  16 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1944758 1944758\n",
      "get_cut_lists: Cutting index 29\n",
      "get_full_res_cut: Removing 0/1369 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1583396 1583396\n",
      "get_cut_lists: Cutting index 30\n",
      "get_full_res_cut: Removing 11/1390 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1248609 1248609\n",
      "get_cut_lists: Cutting index 31\n",
      "get_full_res_cut: Removing 0/1087 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 947124 947124\n",
      "get_cut_lists: Cutting index 32\n",
      "get_full_res_cut: Removing 39/1798 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [16 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1648187 1648187\n",
      "get_cut_lists: Cutting index 33\n",
      "get_full_res_cut: Removing 0/1327 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1214697 1214697\n",
      "get_cut_lists: Cutting index 34\n",
      "get_full_res_cut: Removing 0/1528 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1445951 1445951\n",
      "get_cut_lists: Cutting index 35\n",
      "get_full_res_cut: Removing 0/1981 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 14  32 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1963068 1963068\n",
      "get_cut_lists: Cutting index 36\n",
      "get_full_res_cut: Removing 0/1403 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [26 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1241941 1241941\n",
      "get_cut_lists: Cutting index 37\n",
      "get_full_res_cut: Removing 0/1417 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 32 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1298886 1298886\n",
      "get_cut_lists: Cutting index 38\n",
      "get_full_res_cut: Removing 0/1567 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1731533 1731533\n",
      "get_cut_lists: Cutting index 39\n",
      "get_full_res_cut: Removing 15/1286 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1067335 1067335\n",
      "get_cut_lists: Cutting index 40\n",
      "get_full_res_cut: Removing 0/1328 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1311715 1311715\n",
      "get_cut_lists: Cutting index 41\n",
      "get_full_res_cut: Removing 0/1559 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [18 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1411792 1411792\n",
      "get_cut_lists: Cutting index 42\n",
      "get_full_res_cut: Removing 10/1102 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 951804 951804\n",
      "get_cut_lists: Cutting index 43\n",
      "get_full_res_cut: Removing 0/1143 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [32 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1024831 1024831\n",
      "get_cut_lists: Cutting index 44\n",
      "get_full_res_cut: Removing 0/1734 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [13 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1763923 1763923\n",
      "get_cut_lists: Cutting index 45\n",
      "get_full_res_cut: Removing 0/1156 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 16 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1115633 1115633\n",
      "get_cut_lists: Cutting index 46\n",
      "get_full_res_cut: Removing 0/1657 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1670156 1670156\n",
      "get_cut_lists: Cutting index 47\n",
      "get_full_res_cut: Removing 0/1436 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1413179 1413179\n",
      "get_cut_lists: Cutting index 48\n",
      "get_full_res_cut: Removing 0/1002 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [28 64 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 781269 781269\n",
      "get_cut_lists: Cutting index 49\n",
      "get_full_res_cut: Removing 0/1705 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1756965 1756965\n"
     ]
    }
   ],
   "source": [
    "datasets_params = ['train_dataset', 'valid_dataset', 'test_dataset']\n",
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "\n",
    "# low res\n",
    "low_res_dataset = get_dataset(dataset_size=50, shrink_factor=16, filter_labels=filter_labels, unify_labels=True)\n",
    "low_res_dataset.dilatate_labels(repeat=1)\n",
    "low_res_dataset.to_numpy()\n",
    "low_res_split_dataset_obj = split_dataset(low_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset = itemgetter(*datasets_params)(low_res_split_dataset_obj)\n",
    "\n",
    "# full res\n",
    "full_res_dataset = get_dataset(dataset_size=50, shrink_factor=1, filter_labels=filter_labels, unify_labels=False)\n",
    "full_res_dataset.to_numpy()\n",
    "full_res_split_dataset_obj = copy_split_dataset(full_res_dataset, low_res_split_dataset_obj)\n",
    "\n",
    "# low res model - precourse model\n",
    "epoch = 500\n",
    "log_date = datetime.datetime(year=2020, month=10, day=27, hour=11, minute=45, second=30).strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f'{log_date}_3d_unet_PRECOURSE'\n",
    "\n",
    "low_res_model_info = load_checkpoint_model_info(model_name, epoch, train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset)\n",
    "show_model_info(low_res_model_info)\n",
    "\n",
    "# moving low res to gpu\n",
    "low_res_model_info['device'] = get_device()\n",
    "# low_res_model_info['device'] = 'cpu'\n",
    "low_res_model_info['model'] = low_res_model_info['model'].to(low_res_model_info['device'])\n",
    "low_res_model_info['model'].eval()\n",
    "\n",
    "# cut res\n",
    "cut_full_res_dataset = full_res_dataset.copy(copy_lists=False)\n",
    "cut_full_res_dataset = get_cut_lists(low_res_model_info['model'],\n",
    "                                     low_res_model_info['device'],\n",
    "                                     low_res_dataset, \n",
    "                                     full_res_dataset, \n",
    "                                     cut_full_res_dataset, \n",
    "                                     low_res_mask_threshold=0.5)\n",
    "cut_full_res_dataset.set_output_label(None)\n",
    "cut_split_dataset_obj = copy_split_dataset(cut_full_res_dataset, low_res_split_dataset_obj)\n",
    "cut_train_dataset, cut_valid_dataset, cut_test_dataset = itemgetter(*datasets_params)(cut_split_dataset_obj)\n",
    "\n",
    "# moving low res model to cpu\n",
    "low_res_model_info['device'] = 'cpu'\n",
    "low_res_model_info['model'] = low_res_model_info['model'].to(low_res_model_info['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(low_res_dataset, low_res_split_dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071, min -1024\n",
      "label max 22, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89e6ccd553a4cc2b0ecfbd4c716cec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=0, max=0))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218185a4ecf14289bd0e813af421d90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(cut_full_res_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training all organs models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking list used for training single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset label 'BRAIN_STEM', \t value '1'\n",
      "dataset label 'EYE_L', \t value '2'\n",
      "dataset label 'EYE_R', \t value '3'\n",
      "dataset label 'LENS_L', \t value '4'\n",
      "dataset label 'LENS_R', \t value '5'\n",
      "dataset label 'OPT_NERVE_L', \t value '6'\n",
      "dataset label 'OPT_NERVE_R', \t value '7'\n",
      "dataset label 'OPT_CHIASMA', \t value '8'\n",
      "dataset label 'TEMPORAL_LOBES_L', \t value '9'\n",
      "dataset label 'TEMPORAL_LOBES_R', \t value '10'\n",
      "dataset label 'PITUITARY', \t value '11'\n",
      "dataset label 'PAROTID_GLAND_L', \t value '12'\n",
      "dataset label 'PAROTID_GLAND_R', \t value '13'\n",
      "dataset label 'INNER_EAR_L', \t value '14'\n",
      "dataset label 'INNER_EAR_R', \t value '15'\n",
      "dataset label 'MID_EAR_L', \t value '16'\n",
      "dataset label 'MID_EAR_R', \t value '17'\n",
      "dataset label 'T_M_JOINT_L', \t value '18'\n",
      "dataset label 'T_M_JOINT_R', \t value '19'\n",
      "dataset label 'MANDIBLE_L', \t value '21'\n",
      "dataset label 'MANDIBLE_R', \t value '22'\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "for OAR_KEY, OAR_VALUE in list(filter_labels.items())[:]:\n",
    "    cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "    print(f'dataset label \\'{OAR_KEY}\\', \\t value \\'{OAR_VALUE}\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT_NERVE_L, 6\n",
      "OPT_NERVE_R, 7\n",
      "OPT_CHIASMA, 8\n",
      "PAROTID_GLAND_L, 12\n",
      "PAROTID_GLAND_R, 13\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = [tmp_list[5], tmp_list[6], tmp_list[7], tmp_list[11], tmp_list[12]]\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_MODELS = False\n",
    "if TRAIN_MODELS:\n",
    "    for OAR_KEY, OAR_VALUE in labels_list:\n",
    "        cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "        log_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_name = f'{log_date}_3d_unet_lowres_model3v1_{OAR_KEY}'\n",
    "\n",
    "        print(f'Training model with dataset label \\'{OAR_KEY}\\', value \\'{OAR_VALUE}\\'')\n",
    "        print(f'folder \\'{model_name}\\'')\n",
    "        cut_model_info = prepare_model(epochs=75,\n",
    "                                       learning_rate=3e-4,\n",
    "                                       in_channels=8,\n",
    "                                       input_data_channels=1,\n",
    "                                       output_label_channels=1,\n",
    "                                       dropout_rate=0.2,\n",
    "                                       train_batch_size=1,\n",
    "                                       model_name=model_name,\n",
    "                                       train_dataset=cut_train_dataset, \n",
    "                                       valid_dataset=cut_valid_dataset, \n",
    "                                       test_dataset=cut_test_dataset,\n",
    "                                       model_class=UNetV3v1)\n",
    "        show_model_info(cut_model_info)\n",
    "        print('\\n\\n')\n",
    "        train_loop(cut_model_info)\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # clearing memory\n",
    "        del cut_model_info\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT_NERVE_L, 6\n",
      "OPT_NERVE_R, 7\n",
      "OPT_CHIASMA, 8\n",
      "PITUITARY, 11\n",
      "PAROTID_GLAND_L, 12\n",
      "PAROTID_GLAND_R, 13\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = [tmp_list[5], tmp_list[6], tmp_list[7], tmp_list[10], tmp_list[11], tmp_list[12]]\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_models(oar_key):\n",
    "    possible_models = [folder_name for folder_name in os.listdir('./models') if oar_key in folder_name]    \n",
    "    \n",
    "    return possible_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading models to CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT_NERVE_L Model: Loading model 20210309-012048_3d_unet_lowres_model3v1_OPT_NERVE_L\n",
      "OPT_NERVE_R Model: Loading model 20210309-034637_3d_unet_lowres_model3v1_OPT_NERVE_R\n",
      "OPT_CHIASMA Model: Loading model 20210309-061213_3d_unet_lowres_model3v1_OPT_CHIASMA\n",
      "PITUITARY Model: Loading model 20210308-182550_3d_unet_lowres_model3v1_PITUITARY\n",
      "PAROTID_GLAND_L Model: Loading model 20210309-083743_3d_unet_lowres_model3v1_PAROTID_GLAND_L\n",
      "PAROTID_GLAND_R Model: Loading model 20210309-110322_3d_unet_lowres_model3v1_PAROTID_GLAND_R\n"
     ]
    }
   ],
   "source": [
    "models = dict()\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    epoch = 74\n",
    "    possible_models = get_possible_models(f\"model3v1_{OAR_KEY}\")\n",
    "    if len(possible_models) <= 0:\n",
    "        print(f'{OAR_KEY} Model: No avaiable model')\n",
    "        continue\n",
    "\n",
    "    model_name = possible_models[0]\n",
    "    print(f'{OAR_KEY} Model: Loading model {model_name}')\n",
    "\n",
    "    # loading model checkpoint\n",
    "    cut_model_info = load_checkpoint_model_info(model_name, epoch, cut_train_dataset, cut_valid_dataset, cut_test_dataset, model_class=UNetV3v1)\n",
    "\n",
    "    # moving model to cpu/cuda with eval mode\n",
    "    cut_model_info['device'] = 'cpu'\n",
    "    cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "    cut_model_info['model'].eval()\n",
    "    cut_model_info['model'].disable_tensorboard_writing = True\n",
    "    \n",
    "    models[OAR_KEY] = cut_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_DSC_INFO = False\n",
    "if SHOW_DSC_INFO:\n",
    "    info_per_organs_df = {}\n",
    "    models_info = list()\n",
    "    for OAR_KEY, OAR_VALUE in labels_list:\n",
    "        if OAR_KEY not in models:\n",
    "            print(f'{OAR_KEY} Model: No avaiable model')\n",
    "            continue\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[OAR_KEY]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "        cut_model_info['model'].disable_tensorboard_writing = True\n",
    "\n",
    "        # preparing dataset for comparison\n",
    "        cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "\n",
    "        # calculating dsc predictions        \n",
    "        info_df, preds, rescaled_preds = get_threshold_info_df(model=cut_model_info['model'], \n",
    "                                    dataset=cut_full_res_dataset, \n",
    "                                    device=cut_model_info['device'], \n",
    "                                    train_indices=cut_train_dataset.indices, \n",
    "                                    valid_indices=cut_valid_dataset.indices, \n",
    "                                    test_indices=cut_test_dataset.indices,\n",
    "                                    step=0.5)\n",
    "        info_per_organs_df[OAR_KEY] = info_df\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "\n",
    "        # parsing data\n",
    "        best_threshold_col = 'thres_rescaled_dsc_0.50'\n",
    "        train_tmp_df = info_df[info_df['is_train']][best_threshold_col]\n",
    "        valid_tmp_df = info_df[info_df['is_valid']][best_threshold_col]\n",
    "        train_dsc = train_tmp_df.mean()\n",
    "        valid_dsc = valid_tmp_df.mean()\n",
    "        print(f'{OAR_KEY} Model: DSC train {round(train_dsc, 4)} valid {round(valid_dsc, 4)}')\n",
    "\n",
    "        models_info.append({\n",
    "            'oar_key': OAR_KEY,\n",
    "            'model_name': model_name,\n",
    "            # Train\n",
    "            'train_dsc_mean': train_dsc,\n",
    "            'train_dsc_std': train_tmp_df.std(),\n",
    "            'train_dsc_median': train_tmp_df.median(),\n",
    "            'train_dsc_min': train_tmp_df.min(),\n",
    "            'train_dsc_max': train_tmp_df.max(),\n",
    "            # Valid\n",
    "            'valid_dsc_mean': valid_dsc,\n",
    "            'valid_dsc_std': valid_tmp_df.std(),\n",
    "            'valid_dsc_median': valid_tmp_df.median(),\n",
    "            'valid_dsc_min': valid_tmp_df.min(),\n",
    "            'valid_dsc_max': valid_tmp_df.max(),\n",
    "            # Both\n",
    "            'train_valid_mean_delta': train_dsc - valid_dsc\n",
    "        })\n",
    "\n",
    "    models_info_df = pd.DataFrame(models_info)\n",
    "    \n",
    "    tmp_df = models_info_df[['oar_key', 'train_dsc_mean', 'train_dsc_std', 'valid_dsc_mean', 'valid_dsc_std']].copy()\n",
    "    tmp_df['train_dsc_mean'] = (tmp_df['train_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_mean'] = (tmp_df['valid_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['train_dsc_std'] = (tmp_df['train_dsc_std'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_std'] = (tmp_df['valid_dsc_std'] * 100).round(2)\n",
    "    \n",
    "    display(tmp_df.mean().round(2))\n",
    "    display(tmp_df.round(2))\n",
    "    display(tmp_df.sort_values(by=['train_dsc_std']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_dsc_mean']).drop(columns=['model_name']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_valid_mean_delta']).drop(columns=['model_name']).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_DSC_INFO:\n",
    "    tmp_column = 'is_train' \n",
    "    \n",
    "    print('OARS_LABELS.PAROTID_GLAND_L')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PAROTID_GLAND_L]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.OPT_NERVE_L')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.OPT_NERVE_L]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.PITUITARY')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PITUITARY]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions merging and checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preview_dataset(dataset, preview_index=0, show_hist=False, use_transform=False):\n",
    "    if use_transform:\n",
    "        data, label = dataset[preview_index]\n",
    "    else:\n",
    "        data, label = dataset.get_raw_item_with_label_filter(preview_index)\n",
    "    max_channels = label.shape[0]\n",
    "    max_slices = label.shape[1]\n",
    "\n",
    "    print(f'data max {data.max()}, min {data.min()}')\n",
    "    print(f'label max {label.max()}, min {label.min()}')\n",
    "\n",
    "    def f(slice_index, label_channel):\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(data[0, slice_index], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(data[label_channel+1, slice_index])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(label[label_channel, slice_index])\n",
    "        plt.show()\n",
    "\n",
    "        if show_hist:\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.hist(data.flatten(), 128)\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.hist(label.flatten(), 128)\n",
    "            plt.show()\n",
    "\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "    labelChannelSlider = widgets.IntSlider(min=0, max=max_channels - 1, step=1, value=(max_channels - 1) / 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider, labelChannelSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider, 'label_channel': labelChannelSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071, min -1024\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db7115ac30d48ee861a504e826fa6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=10, max=20))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b764ce24cad04293b52c77864e7a25b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_labels_dict = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels_dict['SPINAL_CORD']\n",
    "\n",
    "cut_full_res_dataset.set_output_label(filter_labels_dict)\n",
    "preview_dataset(cut_full_res_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/21: BRAIN_STEM Model: No avaiable model\n",
      "2/21: EYE_L Model: No avaiable model\n",
      "3/21: EYE_R Model: No avaiable model\n",
      "4/21: LENS_L Model: No avaiable model\n",
      "5/21: LENS_R Model: No avaiable model\n",
      "6/21: OPT_NERVE_L Model: got model 2021-03-15 16:06:59.917339\n",
      "7/21: OPT_NERVE_R Model: got model 2021-03-15 16:07:19.936131\n",
      "8/21: OPT_CHIASMA Model: got model 2021-03-15 16:07:39.733704\n",
      "9/21: TEMPORAL_LOBES_L Model: No avaiable model\n",
      "10/21: TEMPORAL_LOBES_R Model: No avaiable model\n",
      "11/21: PITUITARY Model: got model 2021-03-15 16:07:59.351204\n",
      "12/21: PAROTID_GLAND_L Model: got model 2021-03-15 16:08:19.769163\n",
      "13/21: PAROTID_GLAND_R Model: got model 2021-03-15 16:08:39.509099\n",
      "14/21: INNER_EAR_L Model: No avaiable model\n",
      "15/21: INNER_EAR_R Model: No avaiable model\n",
      "16/21: MID_EAR_L Model: No avaiable model\n",
      "17/21: MID_EAR_R Model: No avaiable model\n",
      "18/21: T_M_JOINT_L Model: No avaiable model\n",
      "19/21: T_M_JOINT_R Model: No avaiable model\n",
      "20/21: MANDIBLE_L Model: No avaiable model\n",
      "21/21: MANDIBLE_R Model: No avaiable model\n",
      "data max 3071, min -1024\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d481cf384440348d774c7eb8b1eeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=10, max=20))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e3d4ddbe904c5f8135e196bc89d6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.dataset.get_norm_transform import get_norm_transform\n",
    "from src.dataset.transform_input import transform_input\n",
    "from src.helpers.get_rescaled_pred import get_rescaled_pred\n",
    "\n",
    "PARSE_CUT_DATASET = True\n",
    "if PARSE_CUT_DATASET:\n",
    "    extended_cut_full_res_dataset = cut_full_res_dataset.copy()\n",
    "    \n",
    "    # preparing cut dataset\n",
    "    for index in range(len(extended_cut_full_res_dataset)):\n",
    "        tmp_label = extended_cut_full_res_dataset.label_list[index]\n",
    "        new_data_channels = len(extended_cut_full_res_dataset.output_label) + 1\n",
    "        new_data_shape = (new_data_channels, *tmp_label[0].shape)\n",
    "        new_data = np.zeros(new_data_shape, dtype=np.int16)\n",
    "        new_data[0] = extended_cut_full_res_dataset.data_list[index][0]\n",
    "\n",
    "        extended_cut_full_res_dataset.data_list[index] = new_data\n",
    "\n",
    "    prediction_threshold = 0.5\n",
    "    output_label_items = list(extended_cut_full_res_dataset.output_label.items())[:]\n",
    "    # for each label\n",
    "    for label_index, val in enumerate(output_label_items[:]):\n",
    "        OAR_KEY, OAR_VALUE = val\n",
    "        # loading model\n",
    "        if OAR_KEY not in models:\n",
    "            print(f'{label_index+1}/{len(output_label_items)}: {OAR_KEY} Model: No avaiable model')\n",
    "            continue\n",
    "        print(f'{label_index+1}/{len(output_label_items)}: {OAR_KEY} Model: got model {datetime.datetime.now()}')\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[OAR_KEY]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "\n",
    "        # for label in whole dataset\n",
    "        for index in range(len(extended_cut_full_res_dataset)):\n",
    "            prediction, rescaled_pred = get_rescaled_pred(cut_model_info['model'], \n",
    "                                                          cut_full_res_dataset, \n",
    "                                                          cut_model_info['device'], \n",
    "                                                          index,\n",
    "                                                          use_only_one_dimension=True)\n",
    "            \n",
    "            extended_cut_full_res_dataset.data_list[index][label_index + 1] = ((rescaled_pred > prediction_threshold) * 1).astype(np.int8)\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        \n",
    "    custom_preview_dataset(extended_cut_full_res_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0, 13120, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1, 14534, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2, 6077, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'3, 11339, 3, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'4, 20124, 12, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'5, 15714, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'6, 20554, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'7, 7725, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'8, 16483, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'9, 11301, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'10, 21334, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'11, 17808, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'12, 19614, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'13, 15096, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'14, 14050, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'15, 11787, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'16, 7616, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'17, 20557, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'18, 18881, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'19, 10633, 17, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'20, 15394, 20, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'21, 19341, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'22, 7701, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'23, 9684, 3, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'24, 12251, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'25, 17332, 10, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'26, 13218, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'27, 14729, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'28, 7625, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'29, 14825, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'30, 9987, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'31, 8540, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'32, 16243, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'33, 11370, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'34, 15393, 23, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'35, 20892, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'36, 17766, 13, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'37, 9148, 10, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'38, 20507, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'39, 8702, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'40, 13085, 41, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'41, 13142, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'42, 9131, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'43, 7946, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'44, 24287, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'45, 7299, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'46, 13661, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'47, 9608, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'48, 7284, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'49, 7523, 0, 0, 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MERGE_PREDICTIONS = True\n",
    "if MERGE_PREDICTIONS:\n",
    "    merged_predictions = [None] * len(extended_cut_full_res_dataset)\n",
    "    for index in range(len(extended_cut_full_res_dataset)):\n",
    "        # print(f\"{index+1}/{len(extended_cut_full_res_dataset)}: Merging predictions to single label\")\n",
    "        data, label = extended_cut_full_res_dataset.get_raw_item_with_label_filter(index)\n",
    "\n",
    "        new_data = np.zeros(data[0].shape, dtype=np.int16)\n",
    "        for i in range(1, 22):\n",
    "            new_data += data[i]\n",
    "\n",
    "        merged_predictions[index] = new_data\n",
    "    print('Merging done')\n",
    "\n",
    "    # checking how many masks are overlapping\n",
    "    for i, tmp_merged in enumerate(merged_predictions):\n",
    "        display(f'{i}, {np.where(tmp_merged == 1)[0].shape[0]}, {np.where(tmp_merged == 2)[0].shape[0]}, {np.where(tmp_merged == 3)[0].shape[0]}, {np.where(tmp_merged == 4)[0].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071, min -1024\n",
      "label max 1, min 0\n",
      "(22, 72, 192, 168), (1, 72, 192, 168), (21, 72, 192, 168), (21, 72, 192, 168)\n",
      "int16, int16, int8, int8\n",
      "(13120,),(0,),(0,),(0,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0481f03d35124956a4798ecc52c07a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=10, max=20))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effe2cb0cd7746acacbfdbf4b56f78eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.helpers.calc_dsc import calc_dsc\n",
    "\n",
    "def custom_preview_dataset2(dataset, preview_index=0, show_hist=False, use_transform=False):\n",
    "    if use_transform:\n",
    "        data, label = dataset[preview_index]\n",
    "    else:\n",
    "        data, label = dataset.get_raw_item_with_label_filter(preview_index)\n",
    "        \n",
    "    cut_data, cut_label = cut_full_res_dataset.get_raw_item_with_label_filter(preview_index)\n",
    "    max_channels = label.shape[0]\n",
    "    max_slices = label.shape[1]\n",
    "    \n",
    "    print(f'data max {data.max()}, min {data.min()}')\n",
    "    print(f'label max {label.max()}, min {label.min()}')\n",
    "    print(f'{data.shape}, {cut_data.shape}, {label.shape}, {cut_label.shape}')\n",
    "    print(f'{data.dtype}, {cut_data.dtype}, {label.dtype}, {cut_label.dtype}')\n",
    "    tmp_merged = merged_predictions[preview_index]\n",
    "    print(f'{np.where(tmp_merged == 1)[0].shape},{np.where(tmp_merged == 2)[0].shape},{np.where(tmp_merged == 3)[0].shape},{np.where(tmp_merged == 4)[0].shape}')\n",
    "\n",
    "    def f(slice_index, label_channel):\n",
    "        print(f'{OARS_LABELS.OARS_LABELS_R_DICT[label_channel+1]}')\n",
    "        tmp_tensor_label = torch.tensor(label[label_channel])\n",
    "        tmp_tensor_prediciton = torch.tensor(data[label_channel+1])\n",
    "        tmp_dsc = calc_dsc(tmp_tensor_label, tmp_tensor_prediciton)\n",
    "        print(f'dsc {tmp_dsc}')\n",
    "\n",
    "        plt.figure(figsize=(30, 20))\n",
    "\n",
    "        plt.subplot(2, 3, 1).title.set_text('data')\n",
    "        plt.imshow(cut_data[0, slice_index], cmap=\"gray\")\n",
    "        plt.subplot(2, 3, 2).title.set_text('label')\n",
    "        plt.imshow(label[label_channel, slice_index])\n",
    "        plt.subplot(2, 3, 3).title.set_text('prediciton')\n",
    "        plt.imshow(data[label_channel+1, slice_index])\n",
    "        # print(data.shape, np.sum(data[label_channel+1]), np.unique(data[1])[-1])\n",
    "        print(f'slices with values > 0', (np.where(data[label_channel+1] > 0))[0])\n",
    "        \n",
    "        plt.subplot(2, 3, 4).title.set_text('merged prediction labels')\n",
    "        plt.imshow(tmp_merged[slice_index], vmin=0, vmax=np.unique(tmp_merged)[-1])\n",
    "        plt.subplot(2, 3, 5).title.set_text('merged labels ')\n",
    "        plt.imshow(np.sum(label, axis=0)[slice_index])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "    labelChannelSlider = widgets.IntSlider(min=0, max=max_channels - 1, step=1, value=(max_channels - 1) / 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider, labelChannelSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider, 'label_channel': labelChannelSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)\n",
    "\n",
    "custom_preview_dataset2(extended_cut_full_res_dataset, preview_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
