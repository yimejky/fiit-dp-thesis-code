{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n",
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/dp_tomastik/code')\n",
    "    !bash \"/content/drive/My Drive/dp_tomastik/code/scripts/install_libs.sh\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "from torchio import RandomAffine, Compose, ZNormalization\n",
    "\n",
    "import src.dataset.oars_labels_consts as OARS_LABELS\n",
    "from src.consts import DATASET_MAX_BOUNDING_BOX, DESIRE_BOUNDING_BOX_SIZE\n",
    "from src.helpers.threshold_calc_helpers import get_threshold_info_df\n",
    "from src.helpers.show_model_dataset_pred_preview import show_model_dataset_pred_preview\n",
    "from src.dataset.get_cut_lists import get_cut_lists\n",
    "from src.dataset.get_full_res_cut import get_full_res_cut\n",
    "from src.dataset.get_dataset import get_dataset\n",
    "from src.dataset.get_dataset_info import get_dataset_info\n",
    "from src.dataset.preview_dataset import preview_dataset\n",
    "from src.dataset.get_dataset_transform import get_dataset_transform\n",
    "from src.model_and_training.prepare_model import prepare_model\n",
    "from src.model_and_training.train_loop import train_loop\n",
    "from src.model_and_training.show_model_info import show_model_info\n",
    "from src.model_and_training.load_checkpoint_model_info import load_checkpoint_model_info\n",
    "from src.helpers.show_cuda_usage import show_cuda_usage\n",
    "from src.helpers.get_rescaled_pred import get_rescaled_preds\n",
    "from src.dataset.split_dataset import split_dataset, copy_split_dataset\n",
    "from src.helpers.compare_prediction_with_ground_true import compare_prediction_with_ground_true, compare_one_prediction_with_ground_true\n",
    "from src.helpers.get_img_outliers_pixels import get_img_outliers_pixels\n",
    "from src.helpers.get_raw_with_prediction import get_raw_with_prediction\n",
    "from src.model_and_training.getters.get_device import get_device\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "torch.manual_seed(20)\n",
    "logging.basicConfig(filename='logs/pdd_data_check.log', level=logging.DEBUG)\n",
    "\n",
    "print('Dataset biggest bounding box wihtout spinal cord', DATASET_MAX_BOUNDING_BOX)\n",
    "print('Cut target size', DESIRE_BOUNDING_BOX_SIZE)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_REGISTRATION=False\n",
    "TRANSFORM_REGISTRATION=False\n",
    "DISPLAY_REGISTRATION=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_3d_image(img):\n",
    "    if type(img) is sitk.SimpleITK.Image:\n",
    "        img = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    max_slices = img.shape[0]\n",
    "    def f(slice_index):    \n",
    "        plt.figure(figsize=(16, 16))\n",
    "        plt.imshow(img[slice_index])\n",
    "        plt.show()\n",
    "        print(f\"debug: {img.min()}, {img.max()}\")\n",
    "        print(f\"debug: unique {np.unique(img[slice_index])}\")\n",
    "\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import SimpleITK as sitk\n",
    "import nrrd\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "LOAD_PDDCA = False\n",
    "if LOAD_PDDCA:\n",
    "    # PDDCA\n",
    "    d =\"./data/PDDCA-1.4.1\"\n",
    "    pddca_dir_items = sorted([o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))])\n",
    "\n",
    "    ignore_items = ['0522c0014', '0522c0077', '0522c0079', '0522c0147', '0522c0159', '0522c0161', '0522c0190', '0522c0226', \n",
    "                    '0522c0329', '0522c0330', '0522c0427', '0522c0433', '0522c0441', '0522c0455', '0522c0457', '0522c0479']\n",
    "    print(f'Loading {len(pddca_dir_items) - len(ignore_items)} items')\n",
    "\n",
    "    pddca_items = list() \n",
    "    for item_id in pddca_dir_items:\n",
    "        if item_id in ignore_items:\n",
    "            # print(f\"pddca {item_id}: ignoring\")\n",
    "            continue\n",
    "\n",
    "        # parsing data\n",
    "        data_filepath = Path.joinpath(Path(d), f'./{item_id}/img.nrrd')\n",
    "        pddca_data, header = nrrd.read(data_filepath)\n",
    "        pddca_data = pddca_data.astype(np.int16)\n",
    "        pddca_data = np.transpose(pddca_data, axes=[2, 0, 1]).swapaxes(-2,-1)[...,::-1]\n",
    "\n",
    "        # parsing labels\n",
    "        oar_labels = [\"BrainStem\", \"Chiasm\", \"Mandible\", \"OpticNerve_L\", \"OpticNerve_R\", \"Parotid_L\", \"Parotid_R\", \"Submandibular_L\", \"Submandibular_R\"]\n",
    "        pddca_label = np.zeros(pddca_data.shape, dtype=np.int8)\n",
    "\n",
    "        for OAR_INDEX, OAR_KEY in enumerate(oar_labels):\n",
    "            label_filepath = Path.joinpath(Path(d), f'./{item_id}/structures/{OAR_KEY}.nrrd')\n",
    "            oar_pddca_label, header = nrrd.read(label_filepath)\n",
    "            oar_pddca_label = oar_pddca_label.astype(np.int8)\n",
    "            oar_pddca_label = np.transpose(oar_pddca_label, axes=[2, 0, 1]).swapaxes(-2,-1)[...,::-1]\n",
    "            pddca_label += oar_pddca_label*(OAR_INDEX+1)\n",
    "\n",
    "        # appending\n",
    "        pddca_items.append((pddca_data, pddca_label))\n",
    "        print(f\"pddca {item_id}: {pddca_data.max()}, {pddca_data.min()}, {pddca_label.max()}, {pddca_label.min()}, {pddca_data.dtype}, {pddca_label.dtype}, {pddca_data.shape}, {pddca_label.shape}\")\n",
    "\n",
    "    print('Done loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PDDCA = False\n",
    "if LOAD_PDDCA:\n",
    "    item_index = 1\n",
    "    pddca_data, pddca_label = pddca_items[item_index]\n",
    "\n",
    "    max_slices = pddca_data.shape[0]\n",
    "    def f(slice_index):    \n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(pddca_data[slice_index], cmap=\"gray\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(pddca_label[slice_index])\n",
    "        plt.subplot(2, 2, 3)\n",
    "\n",
    "        tmp_combine = np.stack((pddca_data[slice_index],) * 3, axis=-1)\n",
    "        tmp_combine -= tmp_combine.min()\n",
    "        tmp_combine = tmp_combine / tmp_combine.max()    \n",
    "        tmp = (pddca_label[slice_index] > 1) * 1\n",
    "        tmp_cond = tmp > 0\n",
    "        tmp_combine[tmp_cond, 0] = tmp[tmp_cond]\n",
    "\n",
    "        plt.imshow(tmp_combine)\n",
    "        plt.show()\n",
    "        print(f\"debug: {pddca_data.min()}, {pddca_data.max()}\")\n",
    "        print(f\"debug: {tmp_combine.min()}, {tmp_combine.max()}\")\n",
    "        print(f\"debug: unique {np.unique(pddca_label[slice_index])}\")\n",
    "\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRUCT SEG 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 1x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.dataset.han_oars_dataset.HaNOarsDataset at 0x7feb6ee74850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "\n",
    "full_res_dataset = get_dataset(dataset_size=50, shrink_factor=1, filter_labels=filter_labels, unify_labels=False)\n",
    "full_res_dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_registration_transform_sitk(fixed, moving, show=True):\n",
    "    \"\"\"https://simpleitk.readthedocs.io/en/master/link_ImageRegistrationMethod3_docs.html\"\"\"\n",
    "    def command_iteration(method):\n",
    "        if (method.GetOptimizerIteration() == 0):\n",
    "            print(\"Estimated Scales: \", method.GetOptimizerScales())\n",
    "        print(\"{0:3} = {1:7.5f} : {2}\".format(method.GetOptimizerIteration(),\n",
    "                                              method.GetMetricValue(),\n",
    "                                              method.GetOptimizerPosition()))\n",
    "\n",
    "    R = sitk.ImageRegistrationMethod()\n",
    "    R.SetMetricAsCorrelation()\n",
    "    R.SetOptimizerAsRegularStepGradientDescent(learningRate=2.0,\n",
    "                                               minStep=1e-4,\n",
    "                                               numberOfIterations=500,\n",
    "                                               gradientMagnitudeTolerance=1e-6)\n",
    "    R.SetOptimizerScalesFromIndexShift()\n",
    "    tx = sitk.CenteredTransformInitializer(fixed, moving, sitk.Similarity3DTransform())\n",
    "    R.SetInitialTransform(tx)\n",
    "    R.SetInterpolator(sitk.sitkLinear)\n",
    "    R.AddCommand(sitk.sitkIterationEvent, lambda: command_iteration(R))\n",
    "\n",
    "    output_transform = R.Execute(fixed, moving)\n",
    "\n",
    "    print(\"-------\")\n",
    "    print(output_transform)\n",
    "    print(\"Optimizer stop condition: {0}\".format(R.GetOptimizerStopConditionDescription()))\n",
    "    print(\" Iteration: {0}\".format(R.GetOptimizerIteration()))\n",
    "    print(\" Metric value: {0}\".format(R.GetMetricValue()))\n",
    "\n",
    "    if show:\n",
    "        resampler = sitk.ResampleImageFilter()\n",
    "        resampler.SetReferenceImage(fixed)\n",
    "        resampler.SetInterpolator(sitk.sitkLinear)\n",
    "        resampler.SetDefaultPixelValue(1)\n",
    "        resampler.SetTransform(output_transform)\n",
    "\n",
    "        out = resampler.Execute(moving)\n",
    "\n",
    "        simg1 = sitk.Cast(sitk.RescaleIntensity(fixed), sitk.sitkUInt8)\n",
    "        simg2 = sitk.Cast(sitk.RescaleIntensity(out), sitk.sitkUInt8)\n",
    "        cimg = sitk.Compose(simg1, simg2, simg1 // 2. + simg2 // 2.)\n",
    "        preview_3d_image(cimg)\n",
    "\n",
    "    return output_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_REGISTRATION:\n",
    "    fixed_data, fixed_label = pddca_items[0]\n",
    "    moving_data, moving_label = full_res_dataset.get_raw_item_with_label_filter(0)\n",
    "\n",
    "    fixed_data = fixed_data.astype(np.float32)\n",
    "    moving_data = moving_data.astype(np.float32)[0]\n",
    "    print(fixed_data.dtype, moving_data.dtype, fixed_data.shape, moving_data.shape)\n",
    "\n",
    "    fixed_sitk = sitk.GetImageFromArray(fixed_data)\n",
    "    moving_sitk = sitk.GetImageFromArray(moving_data)\n",
    "\n",
    "    output_transform = get_registration_transform_sitk(fixed_sitk, moving_sitk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRANSFORM_REGISTRATION:\n",
    "    def transform(image, transform):\n",
    "        ref_image = image\n",
    "        interpolator = sitk.sitkNearestNeighbor\n",
    "        default_value = 0\n",
    "        return sitk.Resample(image, ref_image, transform, interpolator, default_value)\n",
    "\n",
    "    fixed_label_sitk = sitk.GetImageFromArray(fixed_label)\n",
    "    trans_fixed_label = transform(fixed_label_sitk, output_transform.GetInverse())\n",
    "    trans_fixed_label_np = sitk.GetArrayFromImage(trans_fixed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY_REGISTRATION:\n",
    "    max_slices = trans_fixed_label_np.shape[0]\n",
    "\n",
    "    def f(slice_index):\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.subplot(2, 2, 1).title.set_text(\"Transformed label from atlas\")\n",
    "        plt.imshow(trans_fixed_label_np[slice_index])\n",
    "        plt.subplot(2, 2, 2).title.set_text(\"Dataset label\")\n",
    "        plt.imshow(moving_label[0, slice_index])\n",
    "        plt.show()\n",
    "\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 120, 219), (136, 120, 219), (136, 120, 219), (136, 120, 219))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_ri = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/RI.mhd'))\n",
    "atlas_brainstem_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/brain_stem_map.mhd'))\n",
    "atlas_left_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/left_parotid_map.mhd'))\n",
    "atlas_right_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/right_parotid_map.mhd'))\n",
    "\n",
    "atlas_ri.shape, atlas_brainstem_map.shape, atlas_left_parotid_map.shape, atlas_right_parotid_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9587d0cab26a40158eb3c77e05d026f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=67, max=135),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e631adbc6052431592c7fc4fa2189fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_slices = atlas_ri.shape[0]\n",
    "def f(slice_index):\n",
    "    plt.figure(figsize=(30, 16))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(atlas_ri[slice_index], cmap=\"gray\")\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(atlas_brainstem_map[slice_index], cmap=\"gray\")\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(atlas_left_parotid_map[slice_index], cmap=\"gray\")\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(atlas_right_parotid_map[slice_index], cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "ui = widgets.VBox([widgets.HBox([sliceSlider])])\n",
    "out = widgets.interactive_output(f, {'slice_index': sliceSlider})\n",
    "# noinspection PyTypeChecker\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: register atlas to NN input, think about speeding up because of data augmentation\n",
    "## TODO: implement architecture CRNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 120, 219), [72, 192, 168])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_ri.shape, DESIRE_BOUNDING_BOX_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNetV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 8x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n",
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "# filter_labels = [OARS_LABELS.EYE_L, OARS_LABELS.EYE_R, OARS_LABELS.LENS_L, OARS_LABELS.LENS_R]\n",
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "dataset = get_dataset(shrink_factor=8, filter_labels=filter_labels)\n",
    "\n",
    "dataset.to_numpy()\n",
    "split_dataset_obj = split_dataset(dataset)\n",
    "\n",
    "get_dataset_info(dataset, split_dataset_obj)\n",
    "train_dataset, valid_dataset, test_dataset = itemgetter('train_dataset', 'valid_dataset', 'test_dataset')(split_dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071, min -1024\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5c585077674eee82992a8ab4fbe6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=79, max=159), IntSlider(value=0, max=0))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fd5ff39b4d4f3ba23999707777657d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(dataset, preview_index=2, show_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with dataset MODEL3\n",
      "folder '20210223-162431_3d_unet_model3'\n",
      "DEBUG EPOCH AND STEP 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolas/fiit-dp-thesis-code/src/model_and_training/unet_architecture_v3.py:221: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tmp = ap3.data[0].detach().cpu().numpy()\n",
      "/home/nikolas/fiit-dp-thesis-code/src/model_and_training/unet_architecture_v3.py:227: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tmp = h.data[0].detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG EPOCH AND STEP 0 0\n",
      "DEBUG EPOCH AND STEP 0 0\n",
      "Model number of params: 1193964, trainable 1193964\n",
      "\n",
      "\n",
      "\n",
      "Running training loop\n",
      "DEBUG EPOCH AND STEP 0 0\n",
      "Batch train [1] loss 0.99687, dsc 0.00313\n",
      "DEBUG EPOCH AND STEP 0 1\n",
      "Batch train [2] loss 0.99431, dsc 0.00569\n",
      "DEBUG EPOCH AND STEP 0 2\n",
      "Batch train [3] loss 0.98713, dsc 0.01287\n",
      "DEBUG EPOCH AND STEP 0 3\n",
      "Batch train [4] loss 0.97470, dsc 0.02530\n",
      "DEBUG EPOCH AND STEP 0 4\n",
      "Batch train [5] loss 0.97967, dsc 0.02033\n",
      "DEBUG EPOCH AND STEP 0 5\n",
      "Batch train [6] loss 0.97428, dsc 0.02572\n",
      "DEBUG EPOCH AND STEP 0 6\n",
      "Batch train [7] loss 0.96444, dsc 0.03556\n",
      "DEBUG EPOCH AND STEP 0 7\n",
      "Batch train [8] loss 0.95290, dsc 0.04710\n",
      "DEBUG EPOCH AND STEP 0 8\n",
      "Batch train [9] loss 0.95929, dsc 0.04071\n",
      "DEBUG EPOCH AND STEP 0 9\n",
      "Batch train [10] loss 0.94880, dsc 0.05120\n",
      "DEBUG EPOCH AND STEP 0 10\n",
      "Batch train [11] loss 0.94185, dsc 0.05815\n",
      "DEBUG EPOCH AND STEP 0 11\n",
      "Batch train [12] loss 0.92508, dsc 0.07492\n",
      "DEBUG EPOCH AND STEP 0 12\n",
      "Batch train [13] loss 0.99541, dsc 0.00459\n",
      "DEBUG EPOCH AND STEP 0 13\n",
      "Batch train [14] loss 0.93678, dsc 0.06322\n",
      "DEBUG EPOCH AND STEP 0 14\n",
      "Batch train [15] loss 0.92115, dsc 0.07885\n",
      "DEBUG EPOCH AND STEP 0 15\n",
      "Batch train [16] loss 0.92524, dsc 0.07476\n",
      "DEBUG EPOCH AND STEP 0 16\n",
      "Batch train [17] loss 0.89357, dsc 0.10643\n",
      "DEBUG EPOCH AND STEP 0 17\n",
      "Batch train [18] loss 0.90863, dsc 0.09137\n",
      "DEBUG EPOCH AND STEP 0 18\n",
      "Batch train [19] loss 0.84124, dsc 0.15876\n",
      "DEBUG EPOCH AND STEP 0 19\n",
      "Batch train [20] loss 0.93223, dsc 0.06777\n",
      "DEBUG EPOCH AND STEP 0 20\n",
      "Batch train [21] loss 0.86349, dsc 0.13651\n",
      "DEBUG EPOCH AND STEP 0 21\n",
      "Batch train [22] loss 0.86180, dsc 0.13820\n",
      "DEBUG EPOCH AND STEP 0 22\n",
      "Batch train [23] loss 0.87964, dsc 0.12036\n",
      "DEBUG EPOCH AND STEP 0 23\n",
      "Batch train [24] loss 0.86414, dsc 0.13586\n",
      "DEBUG EPOCH AND STEP 0 24\n",
      "Batch train [25] loss 0.82150, dsc 0.17850\n",
      "DEBUG EPOCH AND STEP 0 25\n",
      "Batch train [26] loss 0.90312, dsc 0.09688\n",
      "DEBUG EPOCH AND STEP 0 26\n",
      "Batch train [27] loss 0.86889, dsc 0.13111\n",
      "DEBUG EPOCH AND STEP 0 27\n",
      "Batch train [28] loss 0.87829, dsc 0.12171\n",
      "DEBUG EPOCH AND STEP 0 28\n",
      "Batch train [29] loss 0.82235, dsc 0.17765\n",
      "DEBUG EPOCH AND STEP 0 29\n",
      "Batch train [30] loss 0.83310, dsc 0.16690\n",
      "DEBUG EPOCH AND STEP 0 30\n",
      "Batch train [31] loss 0.79710, dsc 0.20290\n",
      "DEBUG EPOCH AND STEP 0 31\n",
      "Batch train [32] loss 0.78744, dsc 0.21256\n",
      "DEBUG EPOCH AND STEP 0 32\n",
      "Batch train [33] loss 0.80318, dsc 0.19682\n",
      "DEBUG EPOCH AND STEP 0 33\n",
      "Batch train [34] loss 0.80484, dsc 0.19516\n",
      "DEBUG EPOCH AND STEP 0 34\n",
      "Batch train [35] loss 0.78900, dsc 0.21100\n",
      "DEBUG EPOCH AND STEP 0 35\n",
      "Batch train [36] loss 0.78487, dsc 0.21513\n",
      "DEBUG EPOCH AND STEP 0 36\n",
      "Batch train [37] loss 0.82920, dsc 0.17080\n",
      "DEBUG EPOCH AND STEP 0 37\n",
      "Batch train [38] loss 0.84908, dsc 0.15092\n",
      "DEBUG EPOCH AND STEP 0 38\n",
      "Batch train [39] loss 0.79330, dsc 0.20670\n",
      "DEBUG EPOCH AND STEP 0 39\n",
      "Batch train [40] loss 0.74454, dsc 0.25546\n",
      "Epoch [1] train done\n",
      "DEBUG EPOCH AND STEP 0 0\n",
      "Batch eval [1] loss 0.88362, dsc 0.11638\n",
      "DEBUG EPOCH AND STEP 0 1\n",
      "Batch eval [2] loss 0.88797, dsc 0.11203\n",
      "DEBUG EPOCH AND STEP 0 2\n",
      "Batch eval [3] loss 0.88206, dsc 0.11794\n",
      "DEBUG EPOCH AND STEP 0 3\n",
      "Batch eval [4] loss 0.89708, dsc 0.10292\n",
      "DEBUG EPOCH AND STEP 0 4\n",
      "Batch eval [5] loss 0.88162, dsc 0.11838\n",
      "Epoch [1] valid done\n",
      "Epoch [1] T 44.68s, deltaT 44.68s, loss: train 0.88831, valid 0.88647, dsc: train 0.11169, valid 0.11353\n",
      "DEBUG EPOCH AND STEP 1 0\n",
      "Batch train [1] loss 0.75271, dsc 0.24729\n",
      "DEBUG EPOCH AND STEP 1 1\n",
      "Batch train [2] loss 0.68924, dsc 0.31076\n",
      "DEBUG EPOCH AND STEP 1 2\n",
      "Batch train [3] loss 0.65200, dsc 0.34800\n",
      "DEBUG EPOCH AND STEP 1 3\n",
      "Batch train [4] loss 0.64319, dsc 0.35681\n",
      "DEBUG EPOCH AND STEP 1 4\n",
      "Batch train [5] loss 0.70647, dsc 0.29353\n",
      "DEBUG EPOCH AND STEP 1 5\n",
      "Batch train [6] loss 0.58807, dsc 0.41193\n",
      "DEBUG EPOCH AND STEP 1 6\n",
      "Batch train [7] loss 0.59497, dsc 0.40503\n",
      "DEBUG EPOCH AND STEP 1 7\n",
      "Batch train [8] loss 0.62213, dsc 0.37787\n",
      "DEBUG EPOCH AND STEP 1 8\n",
      "Batch train [9] loss 0.60055, dsc 0.39945\n",
      "DEBUG EPOCH AND STEP 1 9\n",
      "Batch train [10] loss 0.60663, dsc 0.39337\n",
      "DEBUG EPOCH AND STEP 1 10\n",
      "Batch train [11] loss 0.59863, dsc 0.40137\n",
      "DEBUG EPOCH AND STEP 1 11\n",
      "Batch train [12] loss 0.58991, dsc 0.41009\n",
      "DEBUG EPOCH AND STEP 1 12\n",
      "Batch train [13] loss 0.58853, dsc 0.41147\n",
      "DEBUG EPOCH AND STEP 1 13\n",
      "Batch train [14] loss 0.59050, dsc 0.40950\n",
      "DEBUG EPOCH AND STEP 1 14\n",
      "Batch train [15] loss 0.60502, dsc 0.39498\n",
      "DEBUG EPOCH AND STEP 1 15\n",
      "Batch train [16] loss 0.54684, dsc 0.45316\n",
      "DEBUG EPOCH AND STEP 1 16\n",
      "Batch train [17] loss 0.61727, dsc 0.38273\n",
      "DEBUG EPOCH AND STEP 1 17\n",
      "Batch train [18] loss 0.58284, dsc 0.41716\n",
      "DEBUG EPOCH AND STEP 1 18\n",
      "Batch train [19] loss 0.57961, dsc 0.42039\n",
      "DEBUG EPOCH AND STEP 1 19\n",
      "Batch train [20] loss 0.66073, dsc 0.33927\n",
      "DEBUG EPOCH AND STEP 1 20\n",
      "Batch train [21] loss 0.58575, dsc 0.41425\n",
      "DEBUG EPOCH AND STEP 1 21\n",
      "Batch train [22] loss 0.56547, dsc 0.43453\n",
      "DEBUG EPOCH AND STEP 1 22\n",
      "Batch train [23] loss 0.57735, dsc 0.42265\n",
      "DEBUG EPOCH AND STEP 1 23\n",
      "Batch train [24] loss 0.50922, dsc 0.49078\n",
      "DEBUG EPOCH AND STEP 1 24\n",
      "Batch train [25] loss 0.58227, dsc 0.41773\n",
      "DEBUG EPOCH AND STEP 1 25\n",
      "Batch train [26] loss 0.56388, dsc 0.43612\n",
      "DEBUG EPOCH AND STEP 1 26\n",
      "Batch train [27] loss 0.63348, dsc 0.36652\n",
      "DEBUG EPOCH AND STEP 1 27\n",
      "Batch train [28] loss 0.53036, dsc 0.46964\n",
      "DEBUG EPOCH AND STEP 1 28\n",
      "Batch train [29] loss 0.61192, dsc 0.38808\n",
      "DEBUG EPOCH AND STEP 1 29\n",
      "Batch train [30] loss 0.54774, dsc 0.45226\n",
      "DEBUG EPOCH AND STEP 1 30\n",
      "Batch train [31] loss 0.55447, dsc 0.44553\n",
      "DEBUG EPOCH AND STEP 1 31\n",
      "Batch train [32] loss 0.55382, dsc 0.44618\n",
      "DEBUG EPOCH AND STEP 1 32\n",
      "Batch train [33] loss 0.56272, dsc 0.43728\n",
      "DEBUG EPOCH AND STEP 1 33\n",
      "Batch train [34] loss 0.57889, dsc 0.42111\n",
      "DEBUG EPOCH AND STEP 1 34\n",
      "Batch train [35] loss 0.55391, dsc 0.44609\n",
      "DEBUG EPOCH AND STEP 1 35\n",
      "Batch train [36] loss 0.52089, dsc 0.47911\n",
      "DEBUG EPOCH AND STEP 1 36\n",
      "Batch train [37] loss 0.60251, dsc 0.39749\n",
      "DEBUG EPOCH AND STEP 1 37\n",
      "Batch train [38] loss 0.53839, dsc 0.46161\n",
      "DEBUG EPOCH AND STEP 1 38\n",
      "Batch train [39] loss 0.54121, dsc 0.45879\n",
      "DEBUG EPOCH AND STEP 1 39\n",
      "Batch train [40] loss 0.53429, dsc 0.46571\n",
      "Epoch [2] train done\n",
      "DEBUG EPOCH AND STEP 1 0\n",
      "Batch eval [1] loss 0.61958, dsc 0.38042\n",
      "DEBUG EPOCH AND STEP 1 1\n",
      "Batch eval [2] loss 0.60871, dsc 0.39129\n",
      "DEBUG EPOCH AND STEP 1 2\n",
      "Batch eval [3] loss 0.61432, dsc 0.38568\n",
      "DEBUG EPOCH AND STEP 1 3\n",
      "Batch eval [4] loss 0.58297, dsc 0.41703\n",
      "DEBUG EPOCH AND STEP 1 4\n",
      "Batch eval [5] loss 0.55577, dsc 0.44423\n",
      "Epoch [2] valid done\n",
      "Epoch [2] T 89.21s, deltaT 44.53s, loss: train 0.59161, valid 0.59627, dsc: train 0.40839, valid 0.40373\n",
      "DEBUG EPOCH AND STEP 2 0\n",
      "Batch train [1] loss 0.52579, dsc 0.47421\n",
      "DEBUG EPOCH AND STEP 2 1\n",
      "Batch train [2] loss 0.58157, dsc 0.41843\n",
      "DEBUG EPOCH AND STEP 2 2\n",
      "Batch train [3] loss 0.53056, dsc 0.46944\n",
      "DEBUG EPOCH AND STEP 2 3\n",
      "Batch train [4] loss 0.54340, dsc 0.45660\n",
      "DEBUG EPOCH AND STEP 2 4\n",
      "Batch train [5] loss 0.51186, dsc 0.48814\n",
      "DEBUG EPOCH AND STEP 2 5\n",
      "Batch train [6] loss 0.62116, dsc 0.37884\n",
      "DEBUG EPOCH AND STEP 2 6\n",
      "Batch train [7] loss 0.59631, dsc 0.40369\n",
      "DEBUG EPOCH AND STEP 2 7\n",
      "Batch train [8] loss 0.62841, dsc 0.37159\n",
      "DEBUG EPOCH AND STEP 2 8\n",
      "Batch train [9] loss 0.51723, dsc 0.48277\n",
      "DEBUG EPOCH AND STEP 2 9\n",
      "Batch train [10] loss 0.51951, dsc 0.48049\n",
      "DEBUG EPOCH AND STEP 2 10\n",
      "Batch train [11] loss 0.52192, dsc 0.47808\n",
      "DEBUG EPOCH AND STEP 2 11\n",
      "Batch train [12] loss 0.60695, dsc 0.39305\n",
      "DEBUG EPOCH AND STEP 2 12\n",
      "Batch train [13] loss 0.53565, dsc 0.46435\n",
      "DEBUG EPOCH AND STEP 2 13\n",
      "Batch train [14] loss 0.55239, dsc 0.44761\n",
      "DEBUG EPOCH AND STEP 2 14\n",
      "Batch train [15] loss 0.51696, dsc 0.48304\n",
      "DEBUG EPOCH AND STEP 2 15\n",
      "Batch train [16] loss 0.64363, dsc 0.35637\n",
      "DEBUG EPOCH AND STEP 2 16\n",
      "Batch train [17] loss 0.65006, dsc 0.34994\n",
      "DEBUG EPOCH AND STEP 2 17\n",
      "Batch train [18] loss 0.54534, dsc 0.45466\n",
      "DEBUG EPOCH AND STEP 2 18\n",
      "Batch train [19] loss 0.55924, dsc 0.44076\n",
      "DEBUG EPOCH AND STEP 2 19\n",
      "Batch train [20] loss 0.50257, dsc 0.49743\n",
      "DEBUG EPOCH AND STEP 2 20\n",
      "Batch train [21] loss 0.55829, dsc 0.44171\n",
      "DEBUG EPOCH AND STEP 2 21\n",
      "Batch train [22] loss 0.50468, dsc 0.49532\n",
      "DEBUG EPOCH AND STEP 2 22\n",
      "Batch train [23] loss 0.56709, dsc 0.43291\n",
      "DEBUG EPOCH AND STEP 2 23\n",
      "Batch train [24] loss 0.52142, dsc 0.47858\n",
      "DEBUG EPOCH AND STEP 2 24\n",
      "Batch train [25] loss 0.52479, dsc 0.47521\n",
      "DEBUG EPOCH AND STEP 2 25\n",
      "Batch train [26] loss 0.49420, dsc 0.50580\n",
      "DEBUG EPOCH AND STEP 2 26\n",
      "Batch train [27] loss 0.56129, dsc 0.43871\n",
      "DEBUG EPOCH AND STEP 2 27\n",
      "Batch train [28] loss 0.49132, dsc 0.50868\n",
      "DEBUG EPOCH AND STEP 2 28\n",
      "Batch train [29] loss 0.53280, dsc 0.46720\n",
      "DEBUG EPOCH AND STEP 2 29\n",
      "Batch train [30] loss 0.53160, dsc 0.46840\n",
      "DEBUG EPOCH AND STEP 2 30\n",
      "Batch train [31] loss 0.61440, dsc 0.38560\n",
      "DEBUG EPOCH AND STEP 2 31\n",
      "Batch train [32] loss 0.60794, dsc 0.39206\n",
      "DEBUG EPOCH AND STEP 2 32\n",
      "Batch train [33] loss 0.52827, dsc 0.47173\n",
      "DEBUG EPOCH AND STEP 2 33\n",
      "Batch train [34] loss 0.52433, dsc 0.47567\n",
      "DEBUG EPOCH AND STEP 2 34\n",
      "Batch train [35] loss 0.50750, dsc 0.49250\n",
      "DEBUG EPOCH AND STEP 2 35\n",
      "Batch train [36] loss 0.56695, dsc 0.43305\n",
      "DEBUG EPOCH AND STEP 2 36\n",
      "Batch train [37] loss 0.59277, dsc 0.40723\n",
      "DEBUG EPOCH AND STEP 2 37\n",
      "Batch train [38] loss 0.55343, dsc 0.44657\n",
      "DEBUG EPOCH AND STEP 2 38\n",
      "Batch train [39] loss 0.50877, dsc 0.49123\n",
      "DEBUG EPOCH AND STEP 2 39\n",
      "Batch train [40] loss 0.57979, dsc 0.42021\n",
      "Epoch [3] train done\n",
      "DEBUG EPOCH AND STEP 2 0\n",
      "Batch eval [1] loss 0.58511, dsc 0.41489\n",
      "DEBUG EPOCH AND STEP 2 1\n",
      "Batch eval [2] loss 0.55162, dsc 0.44838\n",
      "DEBUG EPOCH AND STEP 2 2\n",
      "Batch eval [3] loss 0.54580, dsc 0.45420\n",
      "DEBUG EPOCH AND STEP 2 3\n",
      "Batch eval [4] loss 0.55926, dsc 0.44074\n",
      "DEBUG EPOCH AND STEP 2 4\n",
      "Batch eval [5] loss 0.51721, dsc 0.48279\n",
      "Epoch [3] valid done\n",
      "Epoch [3] T 133.43s, deltaT 44.22s, loss: train 0.55205, valid 0.55180, dsc: train 0.44795, valid 0.44820\n",
      "DEBUG EPOCH AND STEP 3 0\n",
      "Batch train [1] loss 0.58025, dsc 0.41975\n",
      "DEBUG EPOCH AND STEP 3 1\n",
      "Batch train [2] loss 0.52733, dsc 0.47267\n",
      "DEBUG EPOCH AND STEP 3 2\n",
      "Batch train [3] loss 0.52159, dsc 0.47841\n",
      "DEBUG EPOCH AND STEP 3 3\n",
      "Batch train [4] loss 0.51109, dsc 0.48891\n",
      "DEBUG EPOCH AND STEP 3 4\n",
      "Batch train [5] loss 0.50430, dsc 0.49570\n",
      "DEBUG EPOCH AND STEP 3 5\n",
      "Batch train [6] loss 0.50198, dsc 0.49802\n",
      "DEBUG EPOCH AND STEP 3 6\n",
      "Batch train [7] loss 0.53811, dsc 0.46189\n",
      "DEBUG EPOCH AND STEP 3 7\n",
      "Batch train [8] loss 0.50976, dsc 0.49024\n",
      "DEBUG EPOCH AND STEP 3 8\n",
      "Batch train [9] loss 0.51704, dsc 0.48296\n",
      "DEBUG EPOCH AND STEP 3 9\n",
      "Batch train [10] loss 0.48135, dsc 0.51865\n",
      "DEBUG EPOCH AND STEP 3 10\n",
      "Batch train [11] loss 0.50703, dsc 0.49297\n",
      "DEBUG EPOCH AND STEP 3 11\n",
      "Batch train [12] loss 0.55581, dsc 0.44419\n",
      "DEBUG EPOCH AND STEP 3 12\n",
      "Batch train [13] loss 0.52544, dsc 0.47456\n",
      "DEBUG EPOCH AND STEP 3 13\n",
      "Batch train [14] loss 0.55350, dsc 0.44650\n",
      "DEBUG EPOCH AND STEP 3 14\n",
      "Batch train [15] loss 0.46411, dsc 0.53589\n",
      "DEBUG EPOCH AND STEP 3 15\n",
      "Batch train [16] loss 0.52874, dsc 0.47126\n",
      "DEBUG EPOCH AND STEP 3 16\n",
      "Batch train [17] loss 0.51846, dsc 0.48154\n",
      "DEBUG EPOCH AND STEP 3 17\n",
      "Batch train [18] loss 0.58306, dsc 0.41694\n",
      "DEBUG EPOCH AND STEP 3 18\n",
      "Batch train [19] loss 0.51423, dsc 0.48577\n",
      "DEBUG EPOCH AND STEP 3 19\n",
      "Batch train [20] loss 0.57593, dsc 0.42407\n",
      "DEBUG EPOCH AND STEP 3 20\n",
      "Batch train [21] loss 0.59749, dsc 0.40251\n",
      "DEBUG EPOCH AND STEP 3 21\n",
      "Batch train [22] loss 0.49722, dsc 0.50278\n",
      "DEBUG EPOCH AND STEP 3 22\n",
      "Batch train [23] loss 0.54550, dsc 0.45450\n",
      "DEBUG EPOCH AND STEP 3 23\n",
      "Batch train [24] loss 0.47840, dsc 0.52160\n",
      "DEBUG EPOCH AND STEP 3 24\n",
      "Batch train [25] loss 0.45945, dsc 0.54055\n",
      "DEBUG EPOCH AND STEP 3 25\n",
      "Batch train [26] loss 0.63776, dsc 0.36224\n",
      "DEBUG EPOCH AND STEP 3 26\n",
      "Batch train [27] loss 0.46225, dsc 0.53775\n",
      "DEBUG EPOCH AND STEP 3 27\n",
      "Batch train [28] loss 0.57178, dsc 0.42822\n",
      "DEBUG EPOCH AND STEP 3 28\n",
      "Batch train [29] loss 0.53601, dsc 0.46399\n",
      "DEBUG EPOCH AND STEP 3 29\n",
      "Batch train [30] loss 0.54066, dsc 0.45934\n",
      "DEBUG EPOCH AND STEP 3 30\n",
      "Batch train [31] loss 0.48608, dsc 0.51392\n",
      "DEBUG EPOCH AND STEP 3 31\n",
      "Batch train [32] loss 0.50762, dsc 0.49238\n",
      "DEBUG EPOCH AND STEP 3 32\n",
      "Batch train [33] loss 0.47024, dsc 0.52976\n",
      "DEBUG EPOCH AND STEP 3 33\n",
      "Batch train [34] loss 0.49591, dsc 0.50409\n",
      "DEBUG EPOCH AND STEP 3 34\n",
      "Batch train [35] loss 0.47269, dsc 0.52731\n",
      "DEBUG EPOCH AND STEP 3 35\n",
      "Batch train [36] loss 0.50859, dsc 0.49141\n",
      "DEBUG EPOCH AND STEP 3 36\n",
      "Batch train [37] loss 0.50092, dsc 0.49908\n",
      "DEBUG EPOCH AND STEP 3 37\n",
      "Batch train [38] loss 0.45119, dsc 0.54881\n",
      "DEBUG EPOCH AND STEP 3 38\n",
      "Batch train [39] loss 0.56980, dsc 0.43020\n",
      "DEBUG EPOCH AND STEP 3 39\n",
      "Batch train [40] loss 0.46780, dsc 0.53220\n",
      "Epoch [4] train done\n",
      "DEBUG EPOCH AND STEP 3 0\n",
      "Batch eval [1] loss 0.50867, dsc 0.49133\n",
      "DEBUG EPOCH AND STEP 3 1\n",
      "Batch eval [2] loss 0.53920, dsc 0.46080\n",
      "DEBUG EPOCH AND STEP 3 2\n",
      "Batch eval [3] loss 0.49378, dsc 0.50622\n",
      "DEBUG EPOCH AND STEP 3 3\n",
      "Batch eval [4] loss 0.53143, dsc 0.46857\n",
      "DEBUG EPOCH AND STEP 3 4\n",
      "Batch eval [5] loss 0.50932, dsc 0.49068\n",
      "Epoch [4] valid done\n",
      "Epoch [4] T 177.87s, deltaT 44.43s, loss: train 0.51941, valid 0.51648, dsc: train 0.48059, valid 0.48352\n",
      "DEBUG EPOCH AND STEP 4 0\n",
      "Batch train [1] loss 0.51040, dsc 0.48960\n",
      "DEBUG EPOCH AND STEP 4 1\n",
      "Batch train [2] loss 0.49472, dsc 0.50528\n",
      "DEBUG EPOCH AND STEP 4 2\n",
      "Batch train [3] loss 0.47730, dsc 0.52270\n",
      "DEBUG EPOCH AND STEP 4 3\n",
      "Batch train [4] loss 0.46225, dsc 0.53775\n",
      "DEBUG EPOCH AND STEP 4 4\n",
      "Batch train [5] loss 0.41199, dsc 0.58801\n",
      "DEBUG EPOCH AND STEP 4 5\n",
      "Batch train [6] loss 0.50489, dsc 0.49511\n",
      "DEBUG EPOCH AND STEP 4 6\n",
      "Batch train [7] loss 0.57221, dsc 0.42779\n",
      "DEBUG EPOCH AND STEP 4 7\n",
      "Batch train [8] loss 0.43495, dsc 0.56505\n",
      "DEBUG EPOCH AND STEP 4 8\n",
      "Batch train [9] loss 0.54027, dsc 0.45973\n",
      "DEBUG EPOCH AND STEP 4 9\n",
      "Batch train [10] loss 0.49542, dsc 0.50458\n",
      "DEBUG EPOCH AND STEP 4 10\n",
      "Batch train [11] loss 0.54770, dsc 0.45230\n",
      "DEBUG EPOCH AND STEP 4 11\n",
      "Batch train [12] loss 0.45828, dsc 0.54172\n",
      "DEBUG EPOCH AND STEP 4 12\n",
      "Batch train [13] loss 0.46685, dsc 0.53315\n",
      "DEBUG EPOCH AND STEP 4 13\n",
      "Batch train [14] loss 0.52495, dsc 0.47505\n",
      "DEBUG EPOCH AND STEP 4 14\n",
      "Batch train [15] loss 0.48610, dsc 0.51390\n",
      "DEBUG EPOCH AND STEP 4 15\n",
      "Batch train [16] loss 0.53807, dsc 0.46193\n",
      "DEBUG EPOCH AND STEP 4 16\n",
      "Batch train [17] loss 0.53879, dsc 0.46121\n",
      "DEBUG EPOCH AND STEP 4 17\n",
      "Batch train [18] loss 0.50349, dsc 0.49651\n",
      "DEBUG EPOCH AND STEP 4 18\n",
      "Batch train [19] loss 0.55174, dsc 0.44826\n",
      "DEBUG EPOCH AND STEP 4 19\n",
      "Batch train [20] loss 0.48826, dsc 0.51174\n",
      "DEBUG EPOCH AND STEP 4 20\n",
      "Batch train [21] loss 0.49811, dsc 0.50189\n",
      "DEBUG EPOCH AND STEP 4 21\n",
      "Batch train [22] loss 0.53534, dsc 0.46466\n",
      "DEBUG EPOCH AND STEP 4 22\n",
      "Batch train [23] loss 0.51402, dsc 0.48598\n",
      "DEBUG EPOCH AND STEP 4 23\n",
      "Batch train [24] loss 0.45837, dsc 0.54163\n",
      "DEBUG EPOCH AND STEP 4 24\n",
      "Batch train [25] loss 0.53958, dsc 0.46042\n",
      "DEBUG EPOCH AND STEP 4 25\n",
      "Batch train [26] loss 0.48903, dsc 0.51097\n",
      "DEBUG EPOCH AND STEP 4 26\n",
      "Batch train [27] loss 0.52550, dsc 0.47450\n",
      "DEBUG EPOCH AND STEP 4 27\n",
      "Batch train [28] loss 0.55618, dsc 0.44382\n",
      "DEBUG EPOCH AND STEP 4 28\n",
      "Batch train [29] loss 0.54286, dsc 0.45714\n",
      "DEBUG EPOCH AND STEP 4 29\n",
      "Batch train [30] loss 0.47661, dsc 0.52339\n",
      "DEBUG EPOCH AND STEP 4 30\n",
      "Batch train [31] loss 0.49856, dsc 0.50144\n",
      "DEBUG EPOCH AND STEP 4 31\n",
      "Batch train [32] loss 0.57493, dsc 0.42507\n",
      "DEBUG EPOCH AND STEP 4 32\n",
      "Batch train [33] loss 0.55599, dsc 0.44401\n",
      "DEBUG EPOCH AND STEP 4 33\n",
      "Batch train [34] loss 0.48799, dsc 0.51201\n",
      "DEBUG EPOCH AND STEP 4 34\n",
      "Batch train [35] loss 0.46296, dsc 0.53704\n",
      "DEBUG EPOCH AND STEP 4 35\n",
      "Batch train [36] loss 0.51166, dsc 0.48834\n",
      "DEBUG EPOCH AND STEP 4 36\n",
      "Batch train [37] loss 0.59021, dsc 0.40979\n",
      "DEBUG EPOCH AND STEP 4 37\n",
      "Batch train [38] loss 0.51092, dsc 0.48908\n",
      "DEBUG EPOCH AND STEP 4 38\n",
      "Batch train [39] loss 0.53733, dsc 0.46267\n",
      "DEBUG EPOCH AND STEP 4 39\n",
      "Batch train [40] loss 0.45765, dsc 0.54235\n",
      "Epoch [5] train done\n",
      "DEBUG EPOCH AND STEP 4 0\n",
      "Batch eval [1] loss 0.49477, dsc 0.50523\n",
      "DEBUG EPOCH AND STEP 4 1\n",
      "Batch eval [2] loss 0.53889, dsc 0.46111\n",
      "DEBUG EPOCH AND STEP 4 2\n",
      "Batch eval [3] loss 0.53775, dsc 0.46225\n",
      "DEBUG EPOCH AND STEP 4 3\n",
      "Batch eval [4] loss 0.52449, dsc 0.47551\n",
      "DEBUG EPOCH AND STEP 4 4\n",
      "Batch eval [5] loss 0.52008, dsc 0.47992\n",
      "Epoch [5] valid done\n",
      "Epoch [5] T 222.06s, deltaT 44.18s, loss: train 0.50831, valid 0.52320, dsc: train 0.49169, valid 0.47680\n",
      "DEBUG EPOCH AND STEP 5 0\n",
      "Batch train [1] loss 0.48064, dsc 0.51936\n",
      "DEBUG EPOCH AND STEP 5 1\n",
      "Batch train [2] loss 0.51267, dsc 0.48733\n",
      "DEBUG EPOCH AND STEP 5 2\n",
      "Batch train [3] loss 0.53103, dsc 0.46897\n",
      "DEBUG EPOCH AND STEP 5 3\n",
      "Batch train [4] loss 0.49408, dsc 0.50592\n",
      "DEBUG EPOCH AND STEP 5 4\n",
      "Batch train [5] loss 0.46752, dsc 0.53248\n",
      "DEBUG EPOCH AND STEP 5 5\n",
      "Batch train [6] loss 0.49588, dsc 0.50412\n",
      "DEBUG EPOCH AND STEP 5 6\n",
      "Batch train [7] loss 0.48549, dsc 0.51451\n",
      "DEBUG EPOCH AND STEP 5 7\n",
      "Batch train [8] loss 0.50255, dsc 0.49745\n",
      "DEBUG EPOCH AND STEP 5 8\n",
      "Batch train [9] loss 0.51771, dsc 0.48229\n",
      "DEBUG EPOCH AND STEP 5 9\n",
      "Batch train [10] loss 0.51849, dsc 0.48151\n",
      "DEBUG EPOCH AND STEP 5 10\n",
      "Batch train [11] loss 0.46870, dsc 0.53130\n",
      "DEBUG EPOCH AND STEP 5 11\n",
      "Batch train [12] loss 0.46396, dsc 0.53604\n",
      "DEBUG EPOCH AND STEP 5 12\n",
      "Batch train [13] loss 0.50191, dsc 0.49809\n",
      "DEBUG EPOCH AND STEP 5 13\n",
      "Batch train [14] loss 0.46350, dsc 0.53650\n",
      "DEBUG EPOCH AND STEP 5 14\n",
      "Batch train [15] loss 0.50066, dsc 0.49934\n",
      "DEBUG EPOCH AND STEP 5 15\n",
      "Batch train [16] loss 0.55294, dsc 0.44706\n",
      "DEBUG EPOCH AND STEP 5 16\n",
      "Batch train [17] loss 0.56407, dsc 0.43593\n",
      "DEBUG EPOCH AND STEP 5 17\n",
      "Batch train [18] loss 0.53345, dsc 0.46655\n",
      "DEBUG EPOCH AND STEP 5 18\n",
      "Batch train [19] loss 0.48245, dsc 0.51755\n",
      "DEBUG EPOCH AND STEP 5 19\n",
      "Batch train [20] loss 0.52011, dsc 0.47989\n",
      "DEBUG EPOCH AND STEP 5 20\n",
      "Batch train [21] loss 0.54922, dsc 0.45078\n",
      "DEBUG EPOCH AND STEP 5 21\n",
      "Batch train [22] loss 0.48247, dsc 0.51753\n",
      "DEBUG EPOCH AND STEP 5 22\n",
      "Batch train [23] loss 0.54571, dsc 0.45429\n",
      "DEBUG EPOCH AND STEP 5 23\n",
      "Batch train [24] loss 0.53012, dsc 0.46988\n",
      "DEBUG EPOCH AND STEP 5 24\n",
      "Batch train [25] loss 0.50964, dsc 0.49036\n",
      "DEBUG EPOCH AND STEP 5 25\n",
      "Batch train [26] loss 0.56873, dsc 0.43127\n",
      "DEBUG EPOCH AND STEP 5 26\n",
      "Batch train [27] loss 0.49354, dsc 0.50646\n",
      "DEBUG EPOCH AND STEP 5 27\n",
      "Batch train [28] loss 0.52375, dsc 0.47625\n",
      "DEBUG EPOCH AND STEP 5 28\n",
      "Batch train [29] loss 0.53016, dsc 0.46984\n",
      "DEBUG EPOCH AND STEP 5 29\n",
      "Batch train [30] loss 0.50810, dsc 0.49190\n",
      "DEBUG EPOCH AND STEP 5 30\n",
      "Batch train [31] loss 0.50967, dsc 0.49033\n",
      "DEBUG EPOCH AND STEP 5 31\n",
      "Batch train [32] loss 0.48310, dsc 0.51690\n",
      "DEBUG EPOCH AND STEP 5 32\n",
      "Batch train [33] loss 0.51238, dsc 0.48762\n",
      "DEBUG EPOCH AND STEP 5 33\n",
      "Batch train [34] loss 0.54802, dsc 0.45198\n",
      "DEBUG EPOCH AND STEP 5 34\n",
      "Batch train [35] loss 0.47041, dsc 0.52959\n",
      "DEBUG EPOCH AND STEP 5 35\n",
      "Batch train [36] loss 0.45468, dsc 0.54532\n",
      "DEBUG EPOCH AND STEP 5 36\n",
      "Batch train [37] loss 0.51325, dsc 0.48675\n",
      "DEBUG EPOCH AND STEP 5 37\n",
      "Batch train [38] loss 0.60153, dsc 0.39847\n",
      "DEBUG EPOCH AND STEP 5 38\n",
      "Batch train [39] loss 0.49921, dsc 0.50079\n",
      "DEBUG EPOCH AND STEP 5 39\n",
      "Batch train [40] loss 0.46720, dsc 0.53280\n",
      "Epoch [6] train done\n",
      "DEBUG EPOCH AND STEP 5 0\n",
      "Batch eval [1] loss 0.56630, dsc 0.43370\n",
      "DEBUG EPOCH AND STEP 5 1\n",
      "Batch eval [2] loss 0.54827, dsc 0.45173\n",
      "DEBUG EPOCH AND STEP 5 2\n",
      "Batch eval [3] loss 0.51481, dsc 0.48519\n",
      "DEBUG EPOCH AND STEP 5 3\n",
      "Batch eval [4] loss 0.52020, dsc 0.47980\n",
      "DEBUG EPOCH AND STEP 5 4\n",
      "Batch eval [5] loss 0.50003, dsc 0.49997\n",
      "Epoch [6] valid done\n",
      "Epoch [6] T 266.35s, deltaT 44.29s, loss: train 0.50897, valid 0.52992, dsc: train 0.49103, valid 0.47008\n",
      "DEBUG EPOCH AND STEP 6 0\n",
      "Batch train [1] loss 0.45927, dsc 0.54073\n",
      "DEBUG EPOCH AND STEP 6 1\n",
      "Batch train [2] loss 0.47441, dsc 0.52559\n",
      "DEBUG EPOCH AND STEP 6 2\n",
      "Batch train [3] loss 0.47030, dsc 0.52970\n",
      "DEBUG EPOCH AND STEP 6 3\n",
      "Batch train [4] loss 0.46085, dsc 0.53915\n",
      "DEBUG EPOCH AND STEP 6 4\n",
      "Batch train [5] loss 0.47147, dsc 0.52853\n",
      "DEBUG EPOCH AND STEP 6 5\n",
      "Batch train [6] loss 0.57937, dsc 0.42063\n",
      "DEBUG EPOCH AND STEP 6 6\n",
      "Batch train [7] loss 0.53263, dsc 0.46737\n",
      "DEBUG EPOCH AND STEP 6 7\n",
      "Batch train [8] loss 0.51477, dsc 0.48523\n",
      "DEBUG EPOCH AND STEP 6 8\n",
      "Batch train [9] loss 0.49982, dsc 0.50018\n",
      "DEBUG EPOCH AND STEP 6 9\n",
      "Batch train [10] loss 0.52245, dsc 0.47755\n",
      "DEBUG EPOCH AND STEP 6 10\n",
      "Batch train [11] loss 0.50728, dsc 0.49272\n",
      "DEBUG EPOCH AND STEP 6 11\n",
      "Batch train [12] loss 0.48447, dsc 0.51553\n",
      "DEBUG EPOCH AND STEP 6 12\n",
      "Batch train [13] loss 0.48594, dsc 0.51406\n",
      "DEBUG EPOCH AND STEP 6 13\n",
      "Batch train [14] loss 0.53387, dsc 0.46613\n",
      "DEBUG EPOCH AND STEP 6 14\n",
      "Batch train [15] loss 0.51520, dsc 0.48480\n",
      "DEBUG EPOCH AND STEP 6 15\n",
      "Batch train [16] loss 0.60922, dsc 0.39078\n",
      "DEBUG EPOCH AND STEP 6 16\n",
      "Batch train [17] loss 0.52312, dsc 0.47688\n",
      "DEBUG EPOCH AND STEP 6 17\n",
      "Batch train [18] loss 0.50995, dsc 0.49005\n",
      "DEBUG EPOCH AND STEP 6 18\n",
      "Batch train [19] loss 0.56182, dsc 0.43818\n",
      "DEBUG EPOCH AND STEP 6 19\n",
      "Batch train [20] loss 0.51426, dsc 0.48574\n",
      "DEBUG EPOCH AND STEP 6 20\n",
      "Batch train [21] loss 0.45814, dsc 0.54186\n",
      "DEBUG EPOCH AND STEP 6 21\n",
      "Batch train [22] loss 0.50365, dsc 0.49635\n",
      "DEBUG EPOCH AND STEP 6 22\n",
      "Batch train [23] loss 0.46656, dsc 0.53344\n",
      "DEBUG EPOCH AND STEP 6 23\n",
      "Batch train [24] loss 0.48507, dsc 0.51493\n",
      "DEBUG EPOCH AND STEP 6 24\n",
      "Batch train [25] loss 0.47126, dsc 0.52874\n",
      "DEBUG EPOCH AND STEP 6 25\n",
      "Batch train [26] loss 0.55514, dsc 0.44486\n",
      "DEBUG EPOCH AND STEP 6 26\n",
      "Batch train [27] loss 0.45864, dsc 0.54136\n",
      "DEBUG EPOCH AND STEP 6 27\n",
      "Batch train [28] loss 0.46888, dsc 0.53112\n",
      "DEBUG EPOCH AND STEP 6 28\n",
      "Batch train [29] loss 0.39746, dsc 0.60254\n",
      "DEBUG EPOCH AND STEP 6 29\n",
      "Batch train [30] loss 0.48686, dsc 0.51314\n",
      "DEBUG EPOCH AND STEP 6 30\n",
      "Batch train [31] loss 0.42683, dsc 0.57317\n",
      "DEBUG EPOCH AND STEP 6 31\n",
      "Batch train [32] loss 0.45700, dsc 0.54300\n",
      "DEBUG EPOCH AND STEP 6 32\n",
      "Batch train [33] loss 0.42963, dsc 0.57037\n",
      "DEBUG EPOCH AND STEP 6 33\n",
      "Batch train [34] loss 0.45552, dsc 0.54448\n",
      "DEBUG EPOCH AND STEP 6 34\n",
      "Batch train [35] loss 0.46951, dsc 0.53049\n",
      "DEBUG EPOCH AND STEP 6 35\n",
      "Batch train [36] loss 0.45461, dsc 0.54539\n",
      "DEBUG EPOCH AND STEP 6 36\n",
      "Batch train [37] loss 0.45017, dsc 0.54983\n",
      "DEBUG EPOCH AND STEP 6 37\n",
      "Batch train [38] loss 0.46807, dsc 0.53193\n",
      "DEBUG EPOCH AND STEP 6 38\n",
      "Batch train [39] loss 0.50570, dsc 0.49430\n",
      "DEBUG EPOCH AND STEP 6 39\n",
      "Batch train [40] loss 0.54544, dsc 0.45456\n",
      "Epoch [7] train done\n",
      "DEBUG EPOCH AND STEP 6 0\n",
      "Batch eval [1] loss 0.45953, dsc 0.54047\n",
      "DEBUG EPOCH AND STEP 6 1\n",
      "Batch eval [2] loss 0.49897, dsc 0.50103\n",
      "DEBUG EPOCH AND STEP 6 2\n",
      "Batch eval [3] loss 0.47759, dsc 0.52241\n",
      "DEBUG EPOCH AND STEP 6 3\n",
      "Batch eval [4] loss 0.52982, dsc 0.47018\n",
      "DEBUG EPOCH AND STEP 6 4\n",
      "Batch eval [5] loss 0.47016, dsc 0.52984\n",
      "Epoch [7] valid done\n",
      "Epoch [7] T 310.49s, deltaT 44.13s, loss: train 0.49112, valid 0.48722, dsc: train 0.50888, valid 0.51278\n",
      "DEBUG EPOCH AND STEP 7 0\n",
      "Batch train [1] loss 0.38011, dsc 0.61989\n",
      "DEBUG EPOCH AND STEP 7 1\n",
      "Batch train [2] loss 0.49015, dsc 0.50985\n",
      "DEBUG EPOCH AND STEP 7 2\n",
      "Batch train [3] loss 0.48202, dsc 0.51798\n",
      "DEBUG EPOCH AND STEP 7 3\n",
      "Batch train [4] loss 0.49151, dsc 0.50849\n",
      "DEBUG EPOCH AND STEP 7 4\n",
      "Batch train [5] loss 0.45008, dsc 0.54992\n",
      "DEBUG EPOCH AND STEP 7 5\n",
      "Batch train [6] loss 0.44766, dsc 0.55234\n",
      "DEBUG EPOCH AND STEP 7 6\n",
      "Batch train [7] loss 0.46376, dsc 0.53624\n",
      "DEBUG EPOCH AND STEP 7 7\n",
      "Batch train [8] loss 0.58185, dsc 0.41815\n",
      "DEBUG EPOCH AND STEP 7 8\n",
      "Batch train [9] loss 0.53544, dsc 0.46456\n",
      "DEBUG EPOCH AND STEP 7 9\n",
      "Batch train [10] loss 0.56896, dsc 0.43104\n",
      "DEBUG EPOCH AND STEP 7 10\n",
      "Batch train [11] loss 0.42793, dsc 0.57207\n",
      "DEBUG EPOCH AND STEP 7 11\n",
      "Batch train [12] loss 0.45199, dsc 0.54801\n",
      "DEBUG EPOCH AND STEP 7 12\n",
      "Batch train [13] loss 0.54132, dsc 0.45868\n",
      "DEBUG EPOCH AND STEP 7 13\n",
      "Batch train [14] loss 0.48717, dsc 0.51283\n",
      "DEBUG EPOCH AND STEP 7 14\n",
      "Batch train [15] loss 0.46970, dsc 0.53030\n",
      "DEBUG EPOCH AND STEP 7 15\n",
      "Batch train [16] loss 0.43829, dsc 0.56171\n",
      "DEBUG EPOCH AND STEP 7 16\n",
      "Batch train [17] loss 0.49438, dsc 0.50562\n",
      "DEBUG EPOCH AND STEP 7 17\n",
      "Batch train [18] loss 0.48043, dsc 0.51957\n",
      "DEBUG EPOCH AND STEP 7 18\n",
      "Batch train [19] loss 0.50391, dsc 0.49609\n",
      "DEBUG EPOCH AND STEP 7 19\n",
      "Batch train [20] loss 0.47499, dsc 0.52501\n",
      "DEBUG EPOCH AND STEP 7 20\n",
      "Batch train [21] loss 0.43152, dsc 0.56848\n",
      "DEBUG EPOCH AND STEP 7 21\n",
      "Batch train [22] loss 0.48223, dsc 0.51777\n",
      "DEBUG EPOCH AND STEP 7 22\n",
      "Batch train [23] loss 0.46349, dsc 0.53651\n",
      "DEBUG EPOCH AND STEP 7 23\n",
      "Batch train [24] loss 0.55513, dsc 0.44487\n",
      "DEBUG EPOCH AND STEP 7 24\n",
      "Batch train [25] loss 0.48192, dsc 0.51808\n",
      "DEBUG EPOCH AND STEP 7 25\n",
      "Batch train [26] loss 0.45501, dsc 0.54499\n",
      "DEBUG EPOCH AND STEP 7 26\n",
      "Batch train [27] loss 0.41551, dsc 0.58449\n",
      "DEBUG EPOCH AND STEP 7 27\n",
      "Batch train [28] loss 0.48447, dsc 0.51553\n",
      "DEBUG EPOCH AND STEP 7 28\n",
      "Batch train [29] loss 0.44033, dsc 0.55967\n",
      "DEBUG EPOCH AND STEP 7 29\n",
      "Batch train [30] loss 0.50329, dsc 0.49671\n",
      "DEBUG EPOCH AND STEP 7 30\n",
      "Batch train [31] loss 0.41221, dsc 0.58779\n",
      "DEBUG EPOCH AND STEP 7 31\n",
      "Batch train [32] loss 0.46024, dsc 0.53976\n",
      "DEBUG EPOCH AND STEP 7 32\n",
      "Batch train [33] loss 0.49412, dsc 0.50588\n",
      "DEBUG EPOCH AND STEP 7 33\n",
      "Batch train [34] loss 0.45862, dsc 0.54138\n",
      "DEBUG EPOCH AND STEP 7 34\n",
      "Batch train [35] loss 0.44808, dsc 0.55192\n",
      "DEBUG EPOCH AND STEP 7 35\n",
      "Batch train [36] loss 0.45601, dsc 0.54399\n",
      "DEBUG EPOCH AND STEP 7 36\n",
      "Batch train [37] loss 0.45222, dsc 0.54778\n",
      "DEBUG EPOCH AND STEP 7 37\n",
      "Batch train [38] loss 0.44262, dsc 0.55738\n",
      "DEBUG EPOCH AND STEP 7 38\n",
      "Batch train [39] loss 0.45223, dsc 0.54777\n",
      "DEBUG EPOCH AND STEP 7 39\n",
      "Batch train [40] loss 0.47329, dsc 0.52671\n",
      "Epoch [8] train done\n",
      "DEBUG EPOCH AND STEP 7 0\n",
      "Batch eval [1] loss 0.48704, dsc 0.51296\n",
      "DEBUG EPOCH AND STEP 7 1\n",
      "Batch eval [2] loss 0.48465, dsc 0.51535\n",
      "DEBUG EPOCH AND STEP 7 2\n",
      "Batch eval [3] loss 0.46858, dsc 0.53142\n",
      "DEBUG EPOCH AND STEP 7 3\n",
      "Batch eval [4] loss 0.58330, dsc 0.41670\n",
      "DEBUG EPOCH AND STEP 7 4\n",
      "Batch eval [5] loss 0.47815, dsc 0.52185\n",
      "Epoch [8] valid done\n",
      "Epoch [8] T 355.01s, deltaT 44.52s, loss: train 0.47310, valid 0.50034, dsc: train 0.52690, valid 0.49966\n",
      "DEBUG EPOCH AND STEP 8 0\n",
      "Batch train [1] loss 0.54021, dsc 0.45979\n",
      "DEBUG EPOCH AND STEP 8 1\n",
      "Batch train [2] loss 0.37587, dsc 0.62413\n",
      "DEBUG EPOCH AND STEP 8 2\n",
      "Batch train [3] loss 0.44744, dsc 0.55256\n",
      "DEBUG EPOCH AND STEP 8 3\n",
      "Batch train [4] loss 0.42339, dsc 0.57661\n",
      "DEBUG EPOCH AND STEP 8 4\n",
      "Batch train [5] loss 0.42722, dsc 0.57278\n",
      "DEBUG EPOCH AND STEP 8 5\n",
      "Batch train [6] loss 0.46897, dsc 0.53103\n",
      "DEBUG EPOCH AND STEP 8 6\n",
      "Batch train [7] loss 0.43667, dsc 0.56333\n",
      "DEBUG EPOCH AND STEP 8 7\n",
      "Batch train [8] loss 0.47185, dsc 0.52815\n",
      "DEBUG EPOCH AND STEP 8 8\n",
      "Batch train [9] loss 0.48430, dsc 0.51570\n",
      "DEBUG EPOCH AND STEP 8 9\n",
      "Batch train [10] loss 0.42921, dsc 0.57079\n",
      "DEBUG EPOCH AND STEP 8 10\n",
      "Batch train [11] loss 0.52548, dsc 0.47452\n",
      "DEBUG EPOCH AND STEP 8 11\n",
      "Batch train [12] loss 0.47719, dsc 0.52281\n",
      "DEBUG EPOCH AND STEP 8 12\n",
      "Batch train [13] loss 0.52605, dsc 0.47395\n",
      "DEBUG EPOCH AND STEP 8 13\n",
      "Batch train [14] loss 0.40878, dsc 0.59122\n",
      "DEBUG EPOCH AND STEP 8 14\n",
      "Batch train [15] loss 0.44865, dsc 0.55135\n",
      "DEBUG EPOCH AND STEP 8 15\n",
      "Batch train [16] loss 0.44089, dsc 0.55911\n",
      "DEBUG EPOCH AND STEP 8 16\n",
      "Batch train [17] loss 0.45047, dsc 0.54953\n",
      "DEBUG EPOCH AND STEP 8 17\n",
      "Batch train [18] loss 0.44152, dsc 0.55848\n",
      "DEBUG EPOCH AND STEP 8 18\n",
      "Batch train [19] loss 0.47775, dsc 0.52225\n",
      "DEBUG EPOCH AND STEP 8 19\n",
      "Batch train [20] loss 0.45362, dsc 0.54638\n",
      "DEBUG EPOCH AND STEP 8 20\n",
      "Batch train [21] loss 0.41788, dsc 0.58212\n",
      "DEBUG EPOCH AND STEP 8 21\n",
      "Batch train [22] loss 0.41964, dsc 0.58036\n",
      "DEBUG EPOCH AND STEP 8 22\n",
      "Batch train [23] loss 0.45508, dsc 0.54492\n",
      "DEBUG EPOCH AND STEP 8 23\n",
      "Batch train [24] loss 0.47196, dsc 0.52804\n",
      "DEBUG EPOCH AND STEP 8 24\n",
      "Batch train [25] loss 0.49218, dsc 0.50782\n",
      "DEBUG EPOCH AND STEP 8 25\n",
      "Batch train [26] loss 0.46797, dsc 0.53203\n",
      "DEBUG EPOCH AND STEP 8 26\n",
      "Batch train [27] loss 0.46442, dsc 0.53558\n",
      "DEBUG EPOCH AND STEP 8 27\n",
      "Batch train [28] loss 0.43487, dsc 0.56513\n",
      "DEBUG EPOCH AND STEP 8 28\n",
      "Batch train [29] loss 0.55915, dsc 0.44085\n",
      "DEBUG EPOCH AND STEP 8 29\n",
      "Batch train [30] loss 0.40959, dsc 0.59041\n",
      "DEBUG EPOCH AND STEP 8 30\n",
      "Batch train [31] loss 0.45714, dsc 0.54286\n",
      "DEBUG EPOCH AND STEP 8 31\n",
      "Batch train [32] loss 0.51454, dsc 0.48546\n",
      "DEBUG EPOCH AND STEP 8 32\n",
      "Batch train [33] loss 0.48521, dsc 0.51479\n",
      "DEBUG EPOCH AND STEP 8 33\n",
      "Batch train [34] loss 0.44255, dsc 0.55745\n",
      "DEBUG EPOCH AND STEP 8 34\n",
      "Batch train [35] loss 0.42106, dsc 0.57894\n",
      "DEBUG EPOCH AND STEP 8 35\n",
      "Batch train [36] loss 0.52454, dsc 0.47546\n",
      "DEBUG EPOCH AND STEP 8 36\n",
      "Batch train [37] loss 0.42918, dsc 0.57082\n",
      "DEBUG EPOCH AND STEP 8 37\n",
      "Batch train [38] loss 0.46153, dsc 0.53847\n",
      "DEBUG EPOCH AND STEP 8 38\n",
      "Batch train [39] loss 0.39887, dsc 0.60113\n",
      "DEBUG EPOCH AND STEP 8 39\n",
      "Batch train [40] loss 0.44131, dsc 0.55869\n",
      "Epoch [9] train done\n",
      "DEBUG EPOCH AND STEP 8 0\n",
      "Batch eval [1] loss 0.44463, dsc 0.55537\n",
      "DEBUG EPOCH AND STEP 8 1\n",
      "Batch eval [2] loss 0.45202, dsc 0.54798\n",
      "DEBUG EPOCH AND STEP 8 2\n",
      "Batch eval [3] loss 0.44214, dsc 0.55786\n",
      "DEBUG EPOCH AND STEP 8 3\n",
      "Batch eval [4] loss 0.50810, dsc 0.49190\n",
      "DEBUG EPOCH AND STEP 8 4\n",
      "Batch eval [5] loss 0.46230, dsc 0.53770\n",
      "Epoch [9] valid done\n",
      "Epoch [9] T 399.79s, deltaT 44.77s, loss: train 0.45811, valid 0.46184, dsc: train 0.54189, valid 0.53816\n",
      "DEBUG EPOCH AND STEP 9 0\n",
      "Batch train [1] loss 0.43023, dsc 0.56977\n",
      "DEBUG EPOCH AND STEP 9 1\n",
      "Batch train [2] loss 0.42243, dsc 0.57757\n",
      "DEBUG EPOCH AND STEP 9 2\n",
      "Batch train [3] loss 0.51140, dsc 0.48860\n",
      "DEBUG EPOCH AND STEP 9 3\n",
      "Batch train [4] loss 0.46106, dsc 0.53894\n",
      "DEBUG EPOCH AND STEP 9 4\n",
      "Batch train [5] loss 0.49734, dsc 0.50266\n",
      "DEBUG EPOCH AND STEP 9 5\n",
      "Batch train [6] loss 0.41017, dsc 0.58983\n",
      "DEBUG EPOCH AND STEP 9 6\n",
      "Batch train [7] loss 0.40601, dsc 0.59399\n",
      "DEBUG EPOCH AND STEP 9 7\n",
      "Batch train [8] loss 0.43265, dsc 0.56735\n",
      "DEBUG EPOCH AND STEP 9 8\n",
      "Batch train [9] loss 0.43183, dsc 0.56817\n",
      "DEBUG EPOCH AND STEP 9 9\n",
      "Batch train [10] loss 0.47250, dsc 0.52750\n",
      "DEBUG EPOCH AND STEP 9 10\n",
      "Batch train [11] loss 0.43311, dsc 0.56689\n",
      "DEBUG EPOCH AND STEP 9 11\n",
      "Batch train [12] loss 0.41784, dsc 0.58216\n",
      "DEBUG EPOCH AND STEP 9 12\n",
      "Batch train [13] loss 0.44675, dsc 0.55325\n",
      "DEBUG EPOCH AND STEP 9 13\n",
      "Batch train [14] loss 0.42734, dsc 0.57266\n",
      "DEBUG EPOCH AND STEP 9 14\n",
      "Batch train [15] loss 0.46190, dsc 0.53810\n",
      "DEBUG EPOCH AND STEP 9 15\n",
      "Batch train [16] loss 0.45671, dsc 0.54329\n",
      "DEBUG EPOCH AND STEP 9 16\n",
      "Batch train [17] loss 0.44453, dsc 0.55547\n",
      "DEBUG EPOCH AND STEP 9 17\n",
      "Batch train [18] loss 0.48780, dsc 0.51220\n",
      "DEBUG EPOCH AND STEP 9 18\n",
      "Batch train [19] loss 0.41442, dsc 0.58558\n",
      "DEBUG EPOCH AND STEP 9 19\n",
      "Batch train [20] loss 0.39054, dsc 0.60946\n",
      "DEBUG EPOCH AND STEP 9 20\n",
      "Batch train [21] loss 0.45038, dsc 0.54962\n",
      "DEBUG EPOCH AND STEP 9 21\n",
      "Batch train [22] loss 0.45385, dsc 0.54615\n",
      "DEBUG EPOCH AND STEP 9 22\n",
      "Batch train [23] loss 0.57774, dsc 0.42226\n",
      "DEBUG EPOCH AND STEP 9 23\n",
      "Batch train [24] loss 0.44871, dsc 0.55129\n",
      "DEBUG EPOCH AND STEP 9 24\n",
      "Batch train [25] loss 0.38966, dsc 0.61034\n",
      "DEBUG EPOCH AND STEP 9 25\n",
      "Batch train [26] loss 0.48105, dsc 0.51895\n",
      "DEBUG EPOCH AND STEP 9 26\n",
      "Batch train [27] loss 0.45391, dsc 0.54609\n",
      "DEBUG EPOCH AND STEP 9 27\n",
      "Batch train [28] loss 0.47623, dsc 0.52377\n",
      "DEBUG EPOCH AND STEP 9 28\n",
      "Batch train [29] loss 0.45760, dsc 0.54240\n",
      "DEBUG EPOCH AND STEP 9 29\n",
      "Batch train [30] loss 0.44689, dsc 0.55311\n",
      "DEBUG EPOCH AND STEP 9 30\n",
      "Batch train [31] loss 0.41895, dsc 0.58105\n",
      "DEBUG EPOCH AND STEP 9 31\n",
      "Batch train [32] loss 0.48857, dsc 0.51143\n",
      "DEBUG EPOCH AND STEP 9 32\n",
      "Batch train [33] loss 0.45705, dsc 0.54295\n",
      "DEBUG EPOCH AND STEP 9 33\n",
      "Batch train [34] loss 0.56143, dsc 0.43857\n",
      "DEBUG EPOCH AND STEP 9 34\n",
      "Batch train [35] loss 0.40677, dsc 0.59323\n",
      "DEBUG EPOCH AND STEP 9 35\n",
      "Batch train [36] loss 0.37124, dsc 0.62876\n",
      "DEBUG EPOCH AND STEP 9 36\n",
      "Batch train [37] loss 0.47550, dsc 0.52450\n",
      "DEBUG EPOCH AND STEP 9 37\n",
      "Batch train [38] loss 0.42606, dsc 0.57394\n",
      "DEBUG EPOCH AND STEP 9 38\n",
      "Batch train [39] loss 0.42666, dsc 0.57334\n",
      "DEBUG EPOCH AND STEP 9 39\n",
      "Batch train [40] loss 0.44282, dsc 0.55718\n",
      "Epoch [10] train done\n",
      "DEBUG EPOCH AND STEP 9 0\n",
      "Batch eval [1] loss 0.52188, dsc 0.47812\n",
      "DEBUG EPOCH AND STEP 9 1\n",
      "Batch eval [2] loss 0.45458, dsc 0.54542\n",
      "DEBUG EPOCH AND STEP 9 2\n",
      "Batch eval [3] loss 0.47300, dsc 0.52700\n",
      "DEBUG EPOCH AND STEP 9 3\n",
      "Batch eval [4] loss 0.50911, dsc 0.49089\n",
      "DEBUG EPOCH AND STEP 9 4\n",
      "Batch eval [5] loss 0.44196, dsc 0.55804\n",
      "Epoch [10] valid done\n",
      "Epoch [10] T 443.94s, deltaT 44.15s, loss: train 0.44919, valid 0.48011, dsc: train 0.55081, valid 0.51989\n",
      "DEBUG EPOCH AND STEP 10 0\n",
      "Batch train [1] loss 0.38548, dsc 0.61452\n",
      "DEBUG EPOCH AND STEP 10 1\n",
      "Batch train [2] loss 0.40327, dsc 0.59673\n",
      "DEBUG EPOCH AND STEP 10 2\n",
      "Batch train [3] loss 0.43045, dsc 0.56955\n",
      "DEBUG EPOCH AND STEP 10 3\n",
      "Batch train [4] loss 0.46228, dsc 0.53772\n",
      "DEBUG EPOCH AND STEP 10 4\n",
      "Batch train [5] loss 0.43790, dsc 0.56210\n",
      "DEBUG EPOCH AND STEP 10 5\n",
      "Batch train [6] loss 0.41137, dsc 0.58863\n",
      "DEBUG EPOCH AND STEP 10 6\n",
      "Batch train [7] loss 0.45006, dsc 0.54994\n",
      "DEBUG EPOCH AND STEP 10 7\n",
      "Batch train [8] loss 0.47961, dsc 0.52039\n",
      "DEBUG EPOCH AND STEP 10 8\n",
      "Batch train [9] loss 0.51723, dsc 0.48277\n",
      "DEBUG EPOCH AND STEP 10 9\n",
      "Batch train [10] loss 0.43890, dsc 0.56110\n",
      "DEBUG EPOCH AND STEP 10 10\n",
      "Batch train [11] loss 0.40682, dsc 0.59318\n",
      "DEBUG EPOCH AND STEP 10 11\n",
      "Batch train [12] loss 0.48867, dsc 0.51133\n",
      "DEBUG EPOCH AND STEP 10 12\n",
      "Batch train [13] loss 0.47050, dsc 0.52950\n",
      "DEBUG EPOCH AND STEP 10 13\n",
      "Batch train [14] loss 0.43173, dsc 0.56827\n",
      "DEBUG EPOCH AND STEP 10 14\n",
      "Batch train [15] loss 0.45450, dsc 0.54550\n",
      "DEBUG EPOCH AND STEP 10 15\n",
      "Batch train [16] loss 0.52432, dsc 0.47568\n",
      "DEBUG EPOCH AND STEP 10 16\n",
      "Batch train [17] loss 0.48548, dsc 0.51452\n",
      "DEBUG EPOCH AND STEP 10 17\n",
      "Batch train [18] loss 0.42773, dsc 0.57227\n",
      "DEBUG EPOCH AND STEP 10 18\n",
      "Batch train [19] loss 0.44287, dsc 0.55713\n",
      "DEBUG EPOCH AND STEP 10 19\n",
      "Batch train [20] loss 0.50461, dsc 0.49539\n",
      "DEBUG EPOCH AND STEP 10 20\n",
      "Batch train [21] loss 0.50198, dsc 0.49802\n",
      "DEBUG EPOCH AND STEP 10 21\n",
      "Batch train [22] loss 0.44678, dsc 0.55322\n",
      "DEBUG EPOCH AND STEP 10 22\n",
      "Batch train [23] loss 0.40145, dsc 0.59855\n",
      "DEBUG EPOCH AND STEP 10 23\n",
      "Batch train [24] loss 0.45924, dsc 0.54076\n",
      "DEBUG EPOCH AND STEP 10 24\n",
      "Batch train [25] loss 0.44932, dsc 0.55068\n",
      "DEBUG EPOCH AND STEP 10 25\n",
      "Batch train [26] loss 0.44147, dsc 0.55853\n",
      "DEBUG EPOCH AND STEP 10 26\n",
      "Batch train [27] loss 0.45067, dsc 0.54933\n",
      "DEBUG EPOCH AND STEP 10 27\n",
      "Batch train [28] loss 0.42342, dsc 0.57658\n",
      "DEBUG EPOCH AND STEP 10 28\n",
      "Batch train [29] loss 0.43143, dsc 0.56857\n",
      "DEBUG EPOCH AND STEP 10 29\n",
      "Batch train [30] loss 0.44909, dsc 0.55091\n",
      "DEBUG EPOCH AND STEP 10 30\n",
      "Batch train [31] loss 0.45279, dsc 0.54721\n",
      "DEBUG EPOCH AND STEP 10 31\n",
      "Batch train [32] loss 0.44370, dsc 0.55630\n",
      "DEBUG EPOCH AND STEP 10 32\n",
      "Batch train [33] loss 0.46960, dsc 0.53040\n",
      "DEBUG EPOCH AND STEP 10 33\n",
      "Batch train [34] loss 0.53593, dsc 0.46407\n",
      "DEBUG EPOCH AND STEP 10 34\n",
      "Batch train [35] loss 0.38356, dsc 0.61644\n",
      "DEBUG EPOCH AND STEP 10 35\n",
      "Batch train [36] loss 0.43488, dsc 0.56512\n",
      "DEBUG EPOCH AND STEP 10 36\n",
      "Batch train [37] loss 0.41760, dsc 0.58240\n",
      "DEBUG EPOCH AND STEP 10 37\n",
      "Batch train [38] loss 0.45532, dsc 0.54468\n",
      "DEBUG EPOCH AND STEP 10 38\n",
      "Batch train [39] loss 0.44438, dsc 0.55562\n",
      "DEBUG EPOCH AND STEP 10 39\n",
      "Batch train [40] loss 0.38827, dsc 0.61173\n",
      "Epoch [11] train done\n",
      "DEBUG EPOCH AND STEP 10 0\n",
      "Batch eval [1] loss 0.50544, dsc 0.49456\n",
      "DEBUG EPOCH AND STEP 10 1\n",
      "Batch eval [2] loss 0.48560, dsc 0.51440\n",
      "DEBUG EPOCH AND STEP 10 2\n",
      "Batch eval [3] loss 0.48210, dsc 0.51790\n",
      "DEBUG EPOCH AND STEP 10 3\n",
      "Batch eval [4] loss 0.53349, dsc 0.46651\n",
      "DEBUG EPOCH AND STEP 10 4\n",
      "Batch eval [5] loss 0.43585, dsc 0.56415\n",
      "Epoch [11] valid done\n",
      "Epoch [11] T 488.40s, deltaT 44.45s, loss: train 0.44837, valid 0.48850, dsc: train 0.55163, valid 0.51150\n",
      "DEBUG EPOCH AND STEP 11 0\n",
      "Batch train [1] loss 0.44189, dsc 0.55811\n",
      "DEBUG EPOCH AND STEP 11 1\n",
      "Batch train [2] loss 0.45305, dsc 0.54695\n",
      "DEBUG EPOCH AND STEP 11 2\n",
      "Batch train [3] loss 0.42202, dsc 0.57798\n",
      "DEBUG EPOCH AND STEP 11 3\n",
      "Batch train [4] loss 0.46300, dsc 0.53700\n",
      "DEBUG EPOCH AND STEP 11 4\n",
      "Batch train [5] loss 0.37862, dsc 0.62138\n",
      "DEBUG EPOCH AND STEP 11 5\n",
      "Batch train [6] loss 0.38830, dsc 0.61170\n",
      "DEBUG EPOCH AND STEP 11 6\n",
      "Batch train [7] loss 0.44210, dsc 0.55790\n",
      "DEBUG EPOCH AND STEP 11 7\n",
      "Batch train [8] loss 0.42587, dsc 0.57413\n",
      "DEBUG EPOCH AND STEP 11 8\n",
      "Batch train [9] loss 0.45207, dsc 0.54793\n",
      "DEBUG EPOCH AND STEP 11 9\n",
      "Batch train [10] loss 0.46024, dsc 0.53976\n",
      "DEBUG EPOCH AND STEP 11 10\n",
      "Batch train [11] loss 0.47169, dsc 0.52831\n",
      "DEBUG EPOCH AND STEP 11 11\n",
      "Batch train [12] loss 0.39882, dsc 0.60118\n",
      "DEBUG EPOCH AND STEP 11 12\n",
      "Batch train [13] loss 0.43489, dsc 0.56511\n",
      "DEBUG EPOCH AND STEP 11 13\n",
      "Batch train [14] loss 0.46384, dsc 0.53616\n",
      "DEBUG EPOCH AND STEP 11 14\n",
      "Batch train [15] loss 0.43799, dsc 0.56201\n",
      "DEBUG EPOCH AND STEP 11 15\n",
      "Batch train [16] loss 0.40564, dsc 0.59436\n",
      "DEBUG EPOCH AND STEP 11 16\n",
      "Batch train [17] loss 0.43749, dsc 0.56251\n",
      "DEBUG EPOCH AND STEP 11 17\n",
      "Batch train [18] loss 0.46478, dsc 0.53522\n",
      "DEBUG EPOCH AND STEP 11 18\n",
      "Batch train [19] loss 0.43559, dsc 0.56441\n",
      "DEBUG EPOCH AND STEP 11 19\n",
      "Batch train [20] loss 0.40729, dsc 0.59271\n",
      "DEBUG EPOCH AND STEP 11 20\n",
      "Batch train [21] loss 0.56975, dsc 0.43025\n",
      "DEBUG EPOCH AND STEP 11 21\n",
      "Batch train [22] loss 0.42025, dsc 0.57975\n",
      "DEBUG EPOCH AND STEP 11 22\n",
      "Batch train [23] loss 0.41028, dsc 0.58972\n",
      "DEBUG EPOCH AND STEP 11 23\n",
      "Batch train [24] loss 0.53935, dsc 0.46065\n",
      "DEBUG EPOCH AND STEP 11 24\n",
      "Batch train [25] loss 0.43605, dsc 0.56395\n",
      "DEBUG EPOCH AND STEP 11 25\n",
      "Batch train [26] loss 0.44936, dsc 0.55064\n",
      "DEBUG EPOCH AND STEP 11 26\n",
      "Batch train [27] loss 0.48300, dsc 0.51700\n",
      "DEBUG EPOCH AND STEP 11 27\n",
      "Batch train [28] loss 0.48407, dsc 0.51593\n",
      "DEBUG EPOCH AND STEP 11 28\n",
      "Batch train [29] loss 0.45933, dsc 0.54067\n",
      "DEBUG EPOCH AND STEP 11 29\n",
      "Batch train [30] loss 0.45193, dsc 0.54807\n",
      "DEBUG EPOCH AND STEP 11 30\n",
      "Batch train [31] loss 0.44534, dsc 0.55466\n",
      "DEBUG EPOCH AND STEP 11 31\n",
      "Batch train [32] loss 0.39087, dsc 0.60913\n",
      "DEBUG EPOCH AND STEP 11 32\n",
      "Batch train [33] loss 0.44107, dsc 0.55893\n",
      "DEBUG EPOCH AND STEP 11 33\n",
      "Batch train [34] loss 0.46405, dsc 0.53595\n",
      "DEBUG EPOCH AND STEP 11 34\n",
      "Batch train [35] loss 0.39933, dsc 0.60067\n",
      "DEBUG EPOCH AND STEP 11 35\n",
      "Batch train [36] loss 0.41177, dsc 0.58823\n",
      "DEBUG EPOCH AND STEP 11 36\n",
      "Batch train [37] loss 0.48040, dsc 0.51960\n",
      "DEBUG EPOCH AND STEP 11 37\n",
      "Batch train [38] loss 0.44289, dsc 0.55711\n",
      "DEBUG EPOCH AND STEP 11 38\n",
      "Batch train [39] loss 0.43302, dsc 0.56698\n",
      "DEBUG EPOCH AND STEP 11 39\n",
      "Batch train [40] loss 0.39640, dsc 0.60360\n",
      "Epoch [12] train done\n",
      "DEBUG EPOCH AND STEP 11 0\n",
      "Batch eval [1] loss 0.56011, dsc 0.43989\n",
      "DEBUG EPOCH AND STEP 11 1\n",
      "Batch eval [2] loss 0.49950, dsc 0.50050\n",
      "DEBUG EPOCH AND STEP 11 2\n",
      "Batch eval [3] loss 0.50015, dsc 0.49985\n",
      "DEBUG EPOCH AND STEP 11 3\n",
      "Batch eval [4] loss 0.52399, dsc 0.47601\n",
      "DEBUG EPOCH AND STEP 11 4\n",
      "Batch eval [5] loss 0.43492, dsc 0.56508\n",
      "Epoch [12] valid done\n",
      "Epoch [12] T 532.56s, deltaT 44.15s, loss: train 0.44234, valid 0.50373, dsc: train 0.55766, valid 0.49627\n",
      "DEBUG EPOCH AND STEP 12 0\n",
      "Batch train [1] loss 0.43526, dsc 0.56474\n",
      "DEBUG EPOCH AND STEP 12 1\n",
      "Batch train [2] loss 0.45204, dsc 0.54796\n",
      "DEBUG EPOCH AND STEP 12 2\n",
      "Batch train [3] loss 0.37947, dsc 0.62053\n",
      "DEBUG EPOCH AND STEP 12 3\n",
      "Batch train [4] loss 0.41393, dsc 0.58607\n",
      "DEBUG EPOCH AND STEP 12 4\n",
      "Batch train [5] loss 0.36776, dsc 0.63224\n",
      "DEBUG EPOCH AND STEP 12 5\n",
      "Batch train [6] loss 0.41435, dsc 0.58565\n",
      "DEBUG EPOCH AND STEP 12 6\n",
      "Batch train [7] loss 0.43620, dsc 0.56380\n",
      "DEBUG EPOCH AND STEP 12 7\n",
      "Batch train [8] loss 0.37698, dsc 0.62302\n",
      "DEBUG EPOCH AND STEP 12 8\n",
      "Batch train [9] loss 0.44318, dsc 0.55682\n",
      "DEBUG EPOCH AND STEP 12 9\n",
      "Batch train [10] loss 0.42217, dsc 0.57783\n",
      "DEBUG EPOCH AND STEP 12 10\n",
      "Batch train [11] loss 0.41231, dsc 0.58769\n",
      "DEBUG EPOCH AND STEP 12 11\n",
      "Batch train [12] loss 0.37831, dsc 0.62169\n",
      "DEBUG EPOCH AND STEP 12 12\n",
      "Batch train [13] loss 0.46207, dsc 0.53793\n",
      "DEBUG EPOCH AND STEP 12 13\n",
      "Batch train [14] loss 0.40172, dsc 0.59828\n",
      "DEBUG EPOCH AND STEP 12 14\n",
      "Batch train [15] loss 0.43114, dsc 0.56886\n",
      "DEBUG EPOCH AND STEP 12 15\n",
      "Batch train [16] loss 0.47294, dsc 0.52706\n",
      "DEBUG EPOCH AND STEP 12 16\n",
      "Batch train [17] loss 0.38837, dsc 0.61163\n",
      "DEBUG EPOCH AND STEP 12 17\n",
      "Batch train [18] loss 0.39283, dsc 0.60717\n",
      "DEBUG EPOCH AND STEP 12 18\n",
      "Batch train [19] loss 0.42257, dsc 0.57743\n",
      "DEBUG EPOCH AND STEP 12 19\n",
      "Batch train [20] loss 0.34885, dsc 0.65115\n",
      "DEBUG EPOCH AND STEP 12 20\n",
      "Batch train [21] loss 0.40733, dsc 0.59267\n",
      "DEBUG EPOCH AND STEP 12 21\n",
      "Batch train [22] loss 0.43269, dsc 0.56731\n",
      "DEBUG EPOCH AND STEP 12 22\n",
      "Batch train [23] loss 0.48072, dsc 0.51928\n",
      "DEBUG EPOCH AND STEP 12 23\n",
      "Batch train [24] loss 0.42202, dsc 0.57798\n",
      "DEBUG EPOCH AND STEP 12 24\n",
      "Batch train [25] loss 0.39701, dsc 0.60299\n",
      "DEBUG EPOCH AND STEP 12 25\n",
      "Batch train [26] loss 0.44234, dsc 0.55766\n",
      "DEBUG EPOCH AND STEP 12 26\n",
      "Batch train [27] loss 0.39874, dsc 0.60126\n",
      "DEBUG EPOCH AND STEP 12 27\n",
      "Batch train [28] loss 0.38465, dsc 0.61535\n",
      "DEBUG EPOCH AND STEP 12 28\n",
      "Batch train [29] loss 0.42025, dsc 0.57975\n",
      "DEBUG EPOCH AND STEP 12 29\n",
      "Batch train [30] loss 0.45313, dsc 0.54687\n",
      "DEBUG EPOCH AND STEP 12 30\n",
      "Batch train [31] loss 0.38633, dsc 0.61367\n",
      "DEBUG EPOCH AND STEP 12 31\n",
      "Batch train [32] loss 0.46812, dsc 0.53188\n",
      "DEBUG EPOCH AND STEP 12 32\n",
      "Batch train [33] loss 0.42302, dsc 0.57698\n",
      "DEBUG EPOCH AND STEP 12 33\n",
      "Batch train [34] loss 0.46907, dsc 0.53093\n",
      "DEBUG EPOCH AND STEP 12 34\n",
      "Batch train [35] loss 0.41339, dsc 0.58661\n",
      "DEBUG EPOCH AND STEP 12 35\n",
      "Batch train [36] loss 0.42481, dsc 0.57519\n",
      "DEBUG EPOCH AND STEP 12 36\n",
      "Batch train [37] loss 0.38991, dsc 0.61009\n",
      "DEBUG EPOCH AND STEP 12 37\n",
      "Batch train [38] loss 0.35631, dsc 0.64369\n",
      "DEBUG EPOCH AND STEP 12 38\n",
      "Batch train [39] loss 0.39307, dsc 0.60693\n",
      "DEBUG EPOCH AND STEP 12 39\n",
      "Batch train [40] loss 0.40451, dsc 0.59549\n",
      "Epoch [13] train done\n",
      "DEBUG EPOCH AND STEP 12 0\n",
      "Batch eval [1] loss 0.45297, dsc 0.54703\n",
      "DEBUG EPOCH AND STEP 12 1\n",
      "Batch eval [2] loss 0.41583, dsc 0.58417\n",
      "DEBUG EPOCH AND STEP 12 2\n",
      "Batch eval [3] loss 0.42612, dsc 0.57388\n",
      "DEBUG EPOCH AND STEP 12 3\n",
      "Batch eval [4] loss 0.46483, dsc 0.53517\n",
      "DEBUG EPOCH AND STEP 12 4\n",
      "Batch eval [5] loss 0.39947, dsc 0.60053\n",
      "Epoch [13] valid done\n",
      "Epoch [13] T 576.62s, deltaT 44.05s, loss: train 0.41550, valid 0.43184, dsc: train 0.58450, valid 0.56816\n",
      "DEBUG EPOCH AND STEP 13 0\n",
      "Batch train [1] loss 0.40963, dsc 0.59037\n",
      "DEBUG EPOCH AND STEP 13 1\n",
      "Batch train [2] loss 0.37157, dsc 0.62843\n",
      "DEBUG EPOCH AND STEP 13 2\n",
      "Batch train [3] loss 0.49013, dsc 0.50987\n",
      "DEBUG EPOCH AND STEP 13 3\n",
      "Batch train [4] loss 0.37714, dsc 0.62286\n",
      "DEBUG EPOCH AND STEP 13 4\n",
      "Batch train [5] loss 0.40095, dsc 0.59905\n",
      "DEBUG EPOCH AND STEP 13 5\n",
      "Batch train [6] loss 0.46287, dsc 0.53713\n",
      "DEBUG EPOCH AND STEP 13 6\n",
      "Batch train [7] loss 0.38399, dsc 0.61601\n",
      "DEBUG EPOCH AND STEP 13 7\n",
      "Batch train [8] loss 0.40891, dsc 0.59109\n",
      "DEBUG EPOCH AND STEP 13 8\n",
      "Batch train [9] loss 0.43922, dsc 0.56078\n",
      "DEBUG EPOCH AND STEP 13 9\n",
      "Batch train [10] loss 0.35482, dsc 0.64518\n",
      "DEBUG EPOCH AND STEP 13 10\n",
      "Batch train [11] loss 0.37576, dsc 0.62424\n",
      "DEBUG EPOCH AND STEP 13 11\n",
      "Batch train [12] loss 0.38482, dsc 0.61518\n",
      "DEBUG EPOCH AND STEP 13 12\n",
      "Batch train [13] loss 0.39529, dsc 0.60471\n",
      "DEBUG EPOCH AND STEP 13 13\n",
      "Batch train [14] loss 0.39858, dsc 0.60142\n",
      "DEBUG EPOCH AND STEP 13 14\n",
      "Batch train [15] loss 0.35718, dsc 0.64282\n",
      "DEBUG EPOCH AND STEP 13 15\n",
      "Batch train [16] loss 0.40232, dsc 0.59768\n",
      "DEBUG EPOCH AND STEP 13 16\n",
      "Batch train [17] loss 0.35961, dsc 0.64039\n",
      "DEBUG EPOCH AND STEP 13 17\n",
      "Batch train [18] loss 0.36628, dsc 0.63372\n",
      "DEBUG EPOCH AND STEP 13 18\n",
      "Batch train [19] loss 0.39449, dsc 0.60551\n",
      "DEBUG EPOCH AND STEP 13 19\n",
      "Batch train [20] loss 0.41815, dsc 0.58185\n",
      "DEBUG EPOCH AND STEP 13 20\n",
      "Batch train [21] loss 0.39086, dsc 0.60914\n",
      "DEBUG EPOCH AND STEP 13 21\n",
      "Batch train [22] loss 0.42627, dsc 0.57373\n",
      "DEBUG EPOCH AND STEP 13 22\n",
      "Batch train [23] loss 0.37293, dsc 0.62707\n",
      "DEBUG EPOCH AND STEP 13 23\n",
      "Batch train [24] loss 0.34405, dsc 0.65595\n",
      "DEBUG EPOCH AND STEP 13 24\n",
      "Batch train [25] loss 0.39209, dsc 0.60791\n",
      "DEBUG EPOCH AND STEP 13 25\n",
      "Batch train [26] loss 0.37998, dsc 0.62002\n",
      "DEBUG EPOCH AND STEP 13 26\n",
      "Batch train [27] loss 0.37237, dsc 0.62763\n",
      "DEBUG EPOCH AND STEP 13 27\n",
      "Batch train [28] loss 0.41481, dsc 0.58519\n",
      "DEBUG EPOCH AND STEP 13 28\n",
      "Batch train [29] loss 0.37958, dsc 0.62042\n",
      "DEBUG EPOCH AND STEP 13 29\n",
      "Batch train [30] loss 0.35155, dsc 0.64845\n",
      "DEBUG EPOCH AND STEP 13 30\n",
      "Batch train [31] loss 0.35644, dsc 0.64356\n",
      "DEBUG EPOCH AND STEP 13 31\n",
      "Batch train [32] loss 0.39761, dsc 0.60239\n",
      "DEBUG EPOCH AND STEP 13 32\n",
      "Batch train [33] loss 0.36785, dsc 0.63215\n",
      "DEBUG EPOCH AND STEP 13 33\n",
      "Batch train [34] loss 0.38932, dsc 0.61068\n",
      "DEBUG EPOCH AND STEP 13 34\n",
      "Batch train [35] loss 0.34098, dsc 0.65902\n",
      "DEBUG EPOCH AND STEP 13 35\n",
      "Batch train [36] loss 0.42128, dsc 0.57872\n",
      "DEBUG EPOCH AND STEP 13 36\n",
      "Batch train [37] loss 0.39139, dsc 0.60861\n",
      "DEBUG EPOCH AND STEP 13 37\n",
      "Batch train [38] loss 0.39674, dsc 0.60326\n",
      "DEBUG EPOCH AND STEP 13 38\n",
      "Batch train [39] loss 0.39528, dsc 0.60472\n",
      "DEBUG EPOCH AND STEP 13 39\n",
      "Batch train [40] loss 0.34767, dsc 0.65233\n",
      "Epoch [14] train done\n",
      "DEBUG EPOCH AND STEP 13 0\n",
      "Batch eval [1] loss 0.37678, dsc 0.62322\n",
      "DEBUG EPOCH AND STEP 13 1\n",
      "Batch eval [2] loss 0.41735, dsc 0.58265\n",
      "DEBUG EPOCH AND STEP 13 2\n",
      "Batch eval [3] loss 0.44426, dsc 0.55574\n",
      "DEBUG EPOCH AND STEP 13 3\n",
      "Batch eval [4] loss 0.42103, dsc 0.57897\n",
      "DEBUG EPOCH AND STEP 13 4\n",
      "Batch eval [5] loss 0.39693, dsc 0.60307\n",
      "Epoch [14] valid done\n",
      "Epoch [14] T 620.76s, deltaT 44.14s, loss: train 0.38952, valid 0.41127, dsc: train 0.61048, valid 0.58873\n",
      "DEBUG EPOCH AND STEP 14 0\n",
      "Batch train [1] loss 0.34046, dsc 0.65954\n",
      "DEBUG EPOCH AND STEP 14 1\n",
      "Batch train [2] loss 0.37390, dsc 0.62610\n",
      "DEBUG EPOCH AND STEP 14 2\n",
      "Batch train [3] loss 0.39978, dsc 0.60022\n",
      "DEBUG EPOCH AND STEP 14 3\n",
      "Batch train [4] loss 0.37544, dsc 0.62456\n",
      "DEBUG EPOCH AND STEP 14 4\n",
      "Batch train [5] loss 0.37926, dsc 0.62074\n",
      "DEBUG EPOCH AND STEP 14 5\n",
      "Batch train [6] loss 0.36008, dsc 0.63992\n",
      "DEBUG EPOCH AND STEP 14 6\n",
      "Batch train [7] loss 0.40438, dsc 0.59562\n",
      "DEBUG EPOCH AND STEP 14 7\n",
      "Batch train [8] loss 0.37041, dsc 0.62959\n",
      "DEBUG EPOCH AND STEP 14 8\n",
      "Batch train [9] loss 0.41013, dsc 0.58987\n",
      "DEBUG EPOCH AND STEP 14 9\n",
      "Batch train [10] loss 0.49915, dsc 0.50085\n",
      "DEBUG EPOCH AND STEP 14 10\n",
      "Batch train [11] loss 0.38968, dsc 0.61032\n",
      "DEBUG EPOCH AND STEP 14 11\n",
      "Batch train [12] loss 0.38240, dsc 0.61760\n",
      "DEBUG EPOCH AND STEP 14 12\n",
      "Batch train [13] loss 0.36770, dsc 0.63230\n",
      "DEBUG EPOCH AND STEP 14 13\n",
      "Batch train [14] loss 0.40582, dsc 0.59418\n",
      "DEBUG EPOCH AND STEP 14 14\n",
      "Batch train [15] loss 0.37605, dsc 0.62395\n",
      "DEBUG EPOCH AND STEP 14 15\n",
      "Batch train [16] loss 0.40099, dsc 0.59901\n",
      "DEBUG EPOCH AND STEP 14 16\n",
      "Batch train [17] loss 0.37366, dsc 0.62634\n",
      "DEBUG EPOCH AND STEP 14 17\n",
      "Batch train [18] loss 0.38834, dsc 0.61166\n",
      "DEBUG EPOCH AND STEP 14 18\n",
      "Batch train [19] loss 0.38255, dsc 0.61745\n",
      "DEBUG EPOCH AND STEP 14 19\n",
      "Batch train [20] loss 0.39867, dsc 0.60133\n",
      "DEBUG EPOCH AND STEP 14 20\n",
      "Batch train [21] loss 0.34562, dsc 0.65438\n",
      "DEBUG EPOCH AND STEP 14 21\n",
      "Batch train [22] loss 0.38482, dsc 0.61518\n",
      "DEBUG EPOCH AND STEP 14 22\n",
      "Batch train [23] loss 0.37503, dsc 0.62497\n",
      "DEBUG EPOCH AND STEP 14 23\n",
      "Batch train [24] loss 0.38763, dsc 0.61237\n",
      "DEBUG EPOCH AND STEP 14 24\n",
      "Batch train [25] loss 0.37860, dsc 0.62140\n",
      "DEBUG EPOCH AND STEP 14 25\n",
      "Batch train [26] loss 0.34662, dsc 0.65338\n",
      "DEBUG EPOCH AND STEP 14 26\n",
      "Batch train [27] loss 0.35601, dsc 0.64399\n",
      "DEBUG EPOCH AND STEP 14 27\n",
      "Batch train [28] loss 0.39443, dsc 0.60557\n",
      "DEBUG EPOCH AND STEP 14 28\n",
      "Batch train [29] loss 0.37932, dsc 0.62068\n",
      "DEBUG EPOCH AND STEP 14 29\n",
      "Batch train [30] loss 0.44384, dsc 0.55616\n",
      "DEBUG EPOCH AND STEP 14 30\n",
      "Batch train [31] loss 0.40788, dsc 0.59212\n",
      "DEBUG EPOCH AND STEP 14 31\n",
      "Batch train [32] loss 0.36438, dsc 0.63562\n",
      "DEBUG EPOCH AND STEP 14 32\n",
      "Batch train [33] loss 0.43174, dsc 0.56826\n",
      "DEBUG EPOCH AND STEP 14 33\n",
      "Batch train [34] loss 0.39096, dsc 0.60904\n",
      "DEBUG EPOCH AND STEP 14 34\n",
      "Batch train [35] loss 0.36743, dsc 0.63257\n",
      "DEBUG EPOCH AND STEP 14 35\n",
      "Batch train [36] loss 0.45078, dsc 0.54922\n",
      "DEBUG EPOCH AND STEP 14 36\n",
      "Batch train [37] loss 0.35154, dsc 0.64846\n",
      "DEBUG EPOCH AND STEP 14 37\n",
      "Batch train [38] loss 0.39649, dsc 0.60351\n",
      "DEBUG EPOCH AND STEP 14 38\n",
      "Batch train [39] loss 0.41697, dsc 0.58303\n",
      "DEBUG EPOCH AND STEP 14 39\n",
      "Batch train [40] loss 0.41415, dsc 0.58585\n",
      "Epoch [15] train done\n",
      "DEBUG EPOCH AND STEP 14 0\n",
      "Batch eval [1] loss 0.35365, dsc 0.64635\n",
      "DEBUG EPOCH AND STEP 14 1\n",
      "Batch eval [2] loss 0.38506, dsc 0.61494\n",
      "DEBUG EPOCH AND STEP 14 2\n",
      "Batch eval [3] loss 0.40707, dsc 0.59293\n",
      "DEBUG EPOCH AND STEP 14 3\n",
      "Batch eval [4] loss 0.38236, dsc 0.61764\n",
      "DEBUG EPOCH AND STEP 14 4\n",
      "Batch eval [5] loss 0.40356, dsc 0.59644\n",
      "Epoch [15] valid done\n",
      "Epoch [15] T 664.97s, deltaT 44.20s, loss: train 0.38908, valid 0.38634, dsc: train 0.61092, valid 0.61366\n",
      "DEBUG EPOCH AND STEP 15 0\n",
      "Batch train [1] loss 0.41150, dsc 0.58850\n",
      "DEBUG EPOCH AND STEP 15 1\n",
      "Batch train [2] loss 0.34544, dsc 0.65456\n",
      "DEBUG EPOCH AND STEP 15 2\n",
      "Batch train [3] loss 0.38652, dsc 0.61348\n",
      "DEBUG EPOCH AND STEP 15 3\n",
      "Batch train [4] loss 0.34962, dsc 0.65038\n",
      "DEBUG EPOCH AND STEP 15 4\n",
      "Batch train [5] loss 0.38691, dsc 0.61309\n",
      "DEBUG EPOCH AND STEP 15 5\n",
      "Batch train [6] loss 0.40269, dsc 0.59731\n",
      "DEBUG EPOCH AND STEP 15 6\n",
      "Batch train [7] loss 0.36271, dsc 0.63729\n",
      "DEBUG EPOCH AND STEP 15 7\n",
      "Batch train [8] loss 0.35870, dsc 0.64130\n",
      "DEBUG EPOCH AND STEP 15 8\n",
      "Batch train [9] loss 0.46284, dsc 0.53716\n",
      "DEBUG EPOCH AND STEP 15 9\n",
      "Batch train [10] loss 0.37676, dsc 0.62324\n",
      "DEBUG EPOCH AND STEP 15 10\n",
      "Batch train [11] loss 0.38169, dsc 0.61831\n",
      "DEBUG EPOCH AND STEP 15 11\n",
      "Batch train [12] loss 0.40026, dsc 0.59974\n",
      "DEBUG EPOCH AND STEP 15 12\n",
      "Batch train [13] loss 0.39373, dsc 0.60627\n",
      "DEBUG EPOCH AND STEP 15 13\n",
      "Batch train [14] loss 0.40336, dsc 0.59664\n",
      "DEBUG EPOCH AND STEP 15 14\n",
      "Batch train [15] loss 0.37974, dsc 0.62026\n",
      "DEBUG EPOCH AND STEP 15 15\n",
      "Batch train [16] loss 0.42481, dsc 0.57519\n",
      "DEBUG EPOCH AND STEP 15 16\n",
      "Batch train [17] loss 0.42311, dsc 0.57689\n",
      "DEBUG EPOCH AND STEP 15 17\n",
      "Batch train [18] loss 0.39590, dsc 0.60410\n",
      "DEBUG EPOCH AND STEP 15 18\n",
      "Batch train [19] loss 0.38917, dsc 0.61083\n",
      "DEBUG EPOCH AND STEP 15 19\n",
      "Batch train [20] loss 0.44727, dsc 0.55273\n",
      "DEBUG EPOCH AND STEP 15 20\n",
      "Batch train [21] loss 0.41021, dsc 0.58979\n",
      "DEBUG EPOCH AND STEP 15 21\n",
      "Batch train [22] loss 0.36003, dsc 0.63997\n",
      "DEBUG EPOCH AND STEP 15 22\n",
      "Batch train [23] loss 0.36012, dsc 0.63988\n",
      "DEBUG EPOCH AND STEP 15 23\n",
      "Batch train [24] loss 0.34189, dsc 0.65811\n",
      "DEBUG EPOCH AND STEP 15 24\n",
      "Batch train [25] loss 0.40003, dsc 0.59997\n",
      "DEBUG EPOCH AND STEP 15 25\n",
      "Batch train [26] loss 0.37609, dsc 0.62391\n",
      "DEBUG EPOCH AND STEP 15 26\n",
      "Batch train [27] loss 0.41610, dsc 0.58390\n",
      "DEBUG EPOCH AND STEP 15 27\n",
      "Batch train [28] loss 0.38787, dsc 0.61213\n",
      "DEBUG EPOCH AND STEP 15 28\n",
      "Batch train [29] loss 0.33896, dsc 0.66104\n",
      "DEBUG EPOCH AND STEP 15 29\n",
      "Batch train [30] loss 0.37183, dsc 0.62817\n",
      "DEBUG EPOCH AND STEP 15 30\n",
      "Batch train [31] loss 0.37584, dsc 0.62416\n",
      "DEBUG EPOCH AND STEP 15 31\n",
      "Batch train [32] loss 0.33846, dsc 0.66154\n",
      "DEBUG EPOCH AND STEP 15 32\n",
      "Batch train [33] loss 0.36408, dsc 0.63592\n",
      "DEBUG EPOCH AND STEP 15 33\n",
      "Batch train [34] loss 0.37416, dsc 0.62584\n",
      "DEBUG EPOCH AND STEP 15 34\n",
      "Batch train [35] loss 0.34680, dsc 0.65320\n",
      "DEBUG EPOCH AND STEP 15 35\n",
      "Batch train [36] loss 0.39097, dsc 0.60903\n",
      "DEBUG EPOCH AND STEP 15 36\n",
      "Batch train [37] loss 0.32632, dsc 0.67368\n",
      "DEBUG EPOCH AND STEP 15 37\n",
      "Batch train [38] loss 0.36301, dsc 0.63699\n",
      "DEBUG EPOCH AND STEP 15 38\n",
      "Batch train [39] loss 0.35349, dsc 0.64651\n",
      "DEBUG EPOCH AND STEP 15 39\n",
      "Batch train [40] loss 0.42587, dsc 0.57413\n",
      "Epoch [16] train done\n",
      "DEBUG EPOCH AND STEP 15 0\n",
      "Batch eval [1] loss 0.37288, dsc 0.62712\n",
      "DEBUG EPOCH AND STEP 15 1\n",
      "Batch eval [2] loss 0.37946, dsc 0.62054\n",
      "DEBUG EPOCH AND STEP 15 2\n",
      "Batch eval [3] loss 0.40183, dsc 0.59817\n",
      "DEBUG EPOCH AND STEP 15 3\n",
      "Batch eval [4] loss 0.41811, dsc 0.58189\n",
      "DEBUG EPOCH AND STEP 15 4\n",
      "Batch eval [5] loss 0.39326, dsc 0.60674\n",
      "Epoch [16] valid done\n",
      "Epoch [16] T 709.50s, deltaT 44.52s, loss: train 0.38262, valid 0.39311, dsc: train 0.61738, valid 0.60689\n",
      "DEBUG EPOCH AND STEP 16 0\n",
      "Batch train [1] loss 0.42009, dsc 0.57991\n",
      "DEBUG EPOCH AND STEP 16 1\n",
      "Batch train [2] loss 0.37256, dsc 0.62744\n",
      "DEBUG EPOCH AND STEP 16 2\n",
      "Batch train [3] loss 0.36925, dsc 0.63075\n",
      "DEBUG EPOCH AND STEP 16 3\n",
      "Batch train [4] loss 0.32461, dsc 0.67539\n",
      "DEBUG EPOCH AND STEP 16 4\n",
      "Batch train [5] loss 0.48730, dsc 0.51270\n",
      "DEBUG EPOCH AND STEP 16 5\n",
      "Batch train [6] loss 0.38468, dsc 0.61532\n",
      "DEBUG EPOCH AND STEP 16 6\n",
      "Batch train [7] loss 0.36651, dsc 0.63349\n",
      "DEBUG EPOCH AND STEP 16 7\n",
      "Batch train [8] loss 0.39198, dsc 0.60802\n",
      "DEBUG EPOCH AND STEP 16 8\n",
      "Batch train [9] loss 0.38071, dsc 0.61929\n",
      "DEBUG EPOCH AND STEP 16 9\n",
      "Batch train [10] loss 0.34392, dsc 0.65608\n",
      "DEBUG EPOCH AND STEP 16 10\n",
      "Batch train [11] loss 0.40937, dsc 0.59063\n",
      "DEBUG EPOCH AND STEP 16 11\n",
      "Batch train [12] loss 0.36126, dsc 0.63874\n",
      "DEBUG EPOCH AND STEP 16 12\n",
      "Batch train [13] loss 0.32042, dsc 0.67958\n",
      "DEBUG EPOCH AND STEP 16 13\n",
      "Batch train [14] loss 0.39568, dsc 0.60432\n",
      "DEBUG EPOCH AND STEP 16 14\n",
      "Batch train [15] loss 0.37297, dsc 0.62703\n",
      "DEBUG EPOCH AND STEP 16 15\n",
      "Batch train [16] loss 0.37915, dsc 0.62085\n",
      "DEBUG EPOCH AND STEP 16 16\n",
      "Batch train [17] loss 0.36328, dsc 0.63672\n",
      "DEBUG EPOCH AND STEP 16 17\n",
      "Batch train [18] loss 0.33455, dsc 0.66545\n",
      "DEBUG EPOCH AND STEP 16 18\n",
      "Batch train [19] loss 0.36082, dsc 0.63918\n",
      "DEBUG EPOCH AND STEP 16 19\n",
      "Batch train [20] loss 0.38862, dsc 0.61138\n",
      "DEBUG EPOCH AND STEP 16 20\n",
      "Batch train [21] loss 0.34900, dsc 0.65100\n",
      "DEBUG EPOCH AND STEP 16 21\n",
      "Batch train [22] loss 0.37893, dsc 0.62107\n",
      "DEBUG EPOCH AND STEP 16 22\n",
      "Batch train [23] loss 0.38795, dsc 0.61205\n",
      "DEBUG EPOCH AND STEP 16 23\n",
      "Batch train [24] loss 0.39866, dsc 0.60134\n",
      "DEBUG EPOCH AND STEP 16 24\n",
      "Batch train [25] loss 0.35972, dsc 0.64028\n",
      "DEBUG EPOCH AND STEP 16 25\n",
      "Batch train [26] loss 0.33387, dsc 0.66613\n",
      "DEBUG EPOCH AND STEP 16 26\n",
      "Batch train [27] loss 0.37856, dsc 0.62144\n",
      "DEBUG EPOCH AND STEP 16 27\n",
      "Batch train [28] loss 0.38538, dsc 0.61462\n",
      "DEBUG EPOCH AND STEP 16 28\n",
      "Batch train [29] loss 0.39542, dsc 0.60458\n",
      "DEBUG EPOCH AND STEP 16 29\n",
      "Batch train [30] loss 0.36263, dsc 0.63737\n",
      "DEBUG EPOCH AND STEP 16 30\n",
      "Batch train [31] loss 0.34220, dsc 0.65780\n",
      "DEBUG EPOCH AND STEP 16 31\n",
      "Batch train [32] loss 0.37040, dsc 0.62960\n",
      "DEBUG EPOCH AND STEP 16 32\n",
      "Batch train [33] loss 0.41018, dsc 0.58982\n",
      "DEBUG EPOCH AND STEP 16 33\n",
      "Batch train [34] loss 0.36248, dsc 0.63752\n",
      "DEBUG EPOCH AND STEP 16 34\n",
      "Batch train [35] loss 0.40106, dsc 0.59894\n",
      "DEBUG EPOCH AND STEP 16 35\n",
      "Batch train [36] loss 0.36220, dsc 0.63780\n",
      "DEBUG EPOCH AND STEP 16 36\n",
      "Batch train [37] loss 0.42039, dsc 0.57961\n",
      "DEBUG EPOCH AND STEP 16 37\n",
      "Batch train [38] loss 0.37404, dsc 0.62596\n",
      "DEBUG EPOCH AND STEP 16 38\n",
      "Batch train [39] loss 0.34545, dsc 0.65455\n",
      "DEBUG EPOCH AND STEP 16 39\n",
      "Batch train [40] loss 0.47424, dsc 0.52576\n",
      "Epoch [17] train done\n",
      "DEBUG EPOCH AND STEP 16 0\n",
      "Batch eval [1] loss 0.46749, dsc 0.53251\n",
      "DEBUG EPOCH AND STEP 16 1\n",
      "Batch eval [2] loss 0.37984, dsc 0.62016\n",
      "DEBUG EPOCH AND STEP 16 2\n",
      "Batch eval [3] loss 0.40605, dsc 0.59395\n",
      "DEBUG EPOCH AND STEP 16 3\n",
      "Batch eval [4] loss 0.42390, dsc 0.57610\n",
      "DEBUG EPOCH AND STEP 16 4\n",
      "Batch eval [5] loss 0.42407, dsc 0.57593\n",
      "Epoch [17] valid done\n",
      "Epoch [17] T 753.66s, deltaT 44.16s, loss: train 0.37801, valid 0.42027, dsc: train 0.62199, valid 0.57973\n",
      "DEBUG EPOCH AND STEP 17 0\n",
      "Batch train [1] loss 0.34047, dsc 0.65953\n",
      "DEBUG EPOCH AND STEP 17 1\n",
      "Batch train [2] loss 0.35659, dsc 0.64341\n",
      "DEBUG EPOCH AND STEP 17 2\n",
      "Batch train [3] loss 0.33228, dsc 0.66772\n",
      "DEBUG EPOCH AND STEP 17 3\n",
      "Batch train [4] loss 0.33958, dsc 0.66042\n",
      "DEBUG EPOCH AND STEP 17 4\n",
      "Batch train [5] loss 0.34304, dsc 0.65696\n",
      "DEBUG EPOCH AND STEP 17 5\n",
      "Batch train [6] loss 0.40954, dsc 0.59046\n",
      "DEBUG EPOCH AND STEP 17 6\n",
      "Batch train [7] loss 0.37207, dsc 0.62793\n",
      "DEBUG EPOCH AND STEP 17 7\n",
      "Batch train [8] loss 0.38437, dsc 0.61563\n",
      "DEBUG EPOCH AND STEP 17 8\n",
      "Batch train [9] loss 0.32853, dsc 0.67147\n",
      "DEBUG EPOCH AND STEP 17 9\n",
      "Batch train [10] loss 0.36221, dsc 0.63779\n",
      "DEBUG EPOCH AND STEP 17 10\n",
      "Batch train [11] loss 0.35424, dsc 0.64576\n",
      "DEBUG EPOCH AND STEP 17 11\n",
      "Batch train [12] loss 0.34609, dsc 0.65391\n",
      "DEBUG EPOCH AND STEP 17 12\n",
      "Batch train [13] loss 0.40807, dsc 0.59193\n",
      "DEBUG EPOCH AND STEP 17 13\n",
      "Batch train [14] loss 0.30440, dsc 0.69560\n",
      "DEBUG EPOCH AND STEP 17 14\n",
      "Batch train [15] loss 0.38743, dsc 0.61257\n",
      "DEBUG EPOCH AND STEP 17 15\n",
      "Batch train [16] loss 0.44875, dsc 0.55125\n",
      "DEBUG EPOCH AND STEP 17 16\n",
      "Batch train [17] loss 0.33340, dsc 0.66660\n",
      "DEBUG EPOCH AND STEP 17 17\n",
      "Batch train [18] loss 0.35592, dsc 0.64408\n",
      "DEBUG EPOCH AND STEP 17 18\n",
      "Batch train [19] loss 0.38862, dsc 0.61138\n",
      "DEBUG EPOCH AND STEP 17 19\n",
      "Batch train [20] loss 0.36739, dsc 0.63261\n",
      "DEBUG EPOCH AND STEP 17 20\n",
      "Batch train [21] loss 0.36471, dsc 0.63529\n",
      "DEBUG EPOCH AND STEP 17 21\n",
      "Batch train [22] loss 0.34139, dsc 0.65861\n",
      "DEBUG EPOCH AND STEP 17 22\n",
      "Batch train [23] loss 0.39804, dsc 0.60196\n",
      "DEBUG EPOCH AND STEP 17 23\n",
      "Batch train [24] loss 0.37515, dsc 0.62485\n",
      "DEBUG EPOCH AND STEP 17 24\n",
      "Batch train [25] loss 0.35830, dsc 0.64170\n",
      "DEBUG EPOCH AND STEP 17 25\n",
      "Batch train [26] loss 0.39326, dsc 0.60674\n",
      "DEBUG EPOCH AND STEP 17 26\n",
      "Batch train [27] loss 0.38641, dsc 0.61359\n",
      "DEBUG EPOCH AND STEP 17 27\n",
      "Batch train [28] loss 0.37400, dsc 0.62600\n",
      "DEBUG EPOCH AND STEP 17 28\n",
      "Batch train [29] loss 0.34998, dsc 0.65002\n",
      "DEBUG EPOCH AND STEP 17 29\n",
      "Batch train [30] loss 0.36939, dsc 0.63061\n",
      "DEBUG EPOCH AND STEP 17 30\n",
      "Batch train [31] loss 0.37361, dsc 0.62639\n",
      "DEBUG EPOCH AND STEP 17 31\n",
      "Batch train [32] loss 0.41217, dsc 0.58783\n",
      "DEBUG EPOCH AND STEP 17 32\n",
      "Batch train [33] loss 0.44734, dsc 0.55266\n",
      "DEBUG EPOCH AND STEP 17 33\n",
      "Batch train [34] loss 0.42360, dsc 0.57640\n",
      "DEBUG EPOCH AND STEP 17 34\n",
      "Batch train [35] loss 0.43170, dsc 0.56830\n",
      "DEBUG EPOCH AND STEP 17 35\n",
      "Batch train [36] loss 0.36289, dsc 0.63711\n",
      "DEBUG EPOCH AND STEP 17 36\n",
      "Batch train [37] loss 0.34703, dsc 0.65297\n",
      "DEBUG EPOCH AND STEP 17 37\n",
      "Batch train [38] loss 0.37106, dsc 0.62894\n",
      "DEBUG EPOCH AND STEP 17 38\n",
      "Batch train [39] loss 0.37058, dsc 0.62942\n",
      "DEBUG EPOCH AND STEP 17 39\n",
      "Batch train [40] loss 0.34325, dsc 0.65675\n",
      "Epoch [18] train done\n",
      "DEBUG EPOCH AND STEP 17 0\n",
      "Batch eval [1] loss 0.38125, dsc 0.61875\n",
      "DEBUG EPOCH AND STEP 17 1\n",
      "Batch eval [2] loss 0.40833, dsc 0.59167\n",
      "DEBUG EPOCH AND STEP 17 2\n",
      "Batch eval [3] loss 0.38778, dsc 0.61222\n",
      "DEBUG EPOCH AND STEP 17 3\n",
      "Batch eval [4] loss 0.45338, dsc 0.54662\n",
      "DEBUG EPOCH AND STEP 17 4\n",
      "Batch eval [5] loss 0.37483, dsc 0.62517\n",
      "Epoch [18] valid done\n",
      "Epoch [18] T 798.00s, deltaT 44.34s, loss: train 0.37142, valid 0.40111, dsc: train 0.62858, valid 0.59889\n",
      "DEBUG EPOCH AND STEP 18 0\n",
      "Batch train [1] loss 0.39881, dsc 0.60119\n",
      "DEBUG EPOCH AND STEP 18 1\n",
      "Batch train [2] loss 0.45138, dsc 0.54862\n",
      "DEBUG EPOCH AND STEP 18 2\n",
      "Batch train [3] loss 0.33455, dsc 0.66545\n",
      "DEBUG EPOCH AND STEP 18 3\n",
      "Batch train [4] loss 0.35651, dsc 0.64349\n",
      "DEBUG EPOCH AND STEP 18 4\n",
      "Batch train [5] loss 0.40174, dsc 0.59826\n",
      "DEBUG EPOCH AND STEP 18 5\n",
      "Batch train [6] loss 0.36667, dsc 0.63333\n",
      "DEBUG EPOCH AND STEP 18 6\n",
      "Batch train [7] loss 0.34855, dsc 0.65145\n",
      "DEBUG EPOCH AND STEP 18 7\n",
      "Batch train [8] loss 0.39170, dsc 0.60830\n",
      "DEBUG EPOCH AND STEP 18 8\n",
      "Batch train [9] loss 0.40509, dsc 0.59491\n",
      "DEBUG EPOCH AND STEP 18 9\n",
      "Batch train [10] loss 0.33285, dsc 0.66715\n",
      "DEBUG EPOCH AND STEP 18 10\n",
      "Batch train [11] loss 0.34023, dsc 0.65977\n",
      "DEBUG EPOCH AND STEP 18 11\n",
      "Batch train [12] loss 0.32428, dsc 0.67572\n",
      "DEBUG EPOCH AND STEP 18 12\n",
      "Batch train [13] loss 0.38671, dsc 0.61329\n",
      "DEBUG EPOCH AND STEP 18 13\n",
      "Batch train [14] loss 0.35000, dsc 0.65000\n",
      "DEBUG EPOCH AND STEP 18 14\n",
      "Batch train [15] loss 0.33145, dsc 0.66855\n",
      "DEBUG EPOCH AND STEP 18 15\n",
      "Batch train [16] loss 0.32739, dsc 0.67261\n",
      "DEBUG EPOCH AND STEP 18 16\n",
      "Batch train [17] loss 0.37056, dsc 0.62944\n",
      "DEBUG EPOCH AND STEP 18 17\n",
      "Batch train [18] loss 0.43945, dsc 0.56055\n",
      "DEBUG EPOCH AND STEP 18 18\n",
      "Batch train [19] loss 0.40652, dsc 0.59348\n",
      "DEBUG EPOCH AND STEP 18 19\n",
      "Batch train [20] loss 0.34156, dsc 0.65844\n",
      "DEBUG EPOCH AND STEP 18 20\n",
      "Batch train [21] loss 0.40138, dsc 0.59862\n",
      "DEBUG EPOCH AND STEP 18 21\n",
      "Batch train [22] loss 0.34950, dsc 0.65050\n",
      "DEBUG EPOCH AND STEP 18 22\n",
      "Batch train [23] loss 0.37650, dsc 0.62350\n",
      "DEBUG EPOCH AND STEP 18 23\n",
      "Batch train [24] loss 0.36841, dsc 0.63159\n",
      "DEBUG EPOCH AND STEP 18 24\n",
      "Batch train [25] loss 0.34622, dsc 0.65378\n",
      "DEBUG EPOCH AND STEP 18 25\n",
      "Batch train [26] loss 0.38120, dsc 0.61880\n",
      "DEBUG EPOCH AND STEP 18 26\n",
      "Batch train [27] loss 0.36413, dsc 0.63587\n",
      "DEBUG EPOCH AND STEP 18 27\n",
      "Batch train [28] loss 0.35455, dsc 0.64545\n",
      "DEBUG EPOCH AND STEP 18 28\n",
      "Batch train [29] loss 0.37002, dsc 0.62998\n",
      "DEBUG EPOCH AND STEP 18 29\n",
      "Batch train [30] loss 0.36667, dsc 0.63333\n",
      "DEBUG EPOCH AND STEP 18 30\n",
      "Batch train [31] loss 0.41159, dsc 0.58841\n",
      "DEBUG EPOCH AND STEP 18 31\n",
      "Batch train [32] loss 0.36528, dsc 0.63472\n",
      "DEBUG EPOCH AND STEP 18 32\n",
      "Batch train [33] loss 0.35398, dsc 0.64602\n",
      "DEBUG EPOCH AND STEP 18 33\n",
      "Batch train [34] loss 0.33232, dsc 0.66768\n",
      "DEBUG EPOCH AND STEP 18 34\n",
      "Batch train [35] loss 0.35917, dsc 0.64083\n",
      "DEBUG EPOCH AND STEP 18 35\n",
      "Batch train [36] loss 0.35501, dsc 0.64499\n",
      "DEBUG EPOCH AND STEP 18 36\n",
      "Batch train [37] loss 0.36418, dsc 0.63582\n",
      "DEBUG EPOCH AND STEP 18 37\n",
      "Batch train [38] loss 0.35689, dsc 0.64311\n",
      "DEBUG EPOCH AND STEP 18 38\n",
      "Batch train [39] loss 0.36835, dsc 0.63165\n",
      "DEBUG EPOCH AND STEP 18 39\n",
      "Batch train [40] loss 0.36891, dsc 0.63109\n",
      "Epoch [19] train done\n",
      "DEBUG EPOCH AND STEP 18 0\n",
      "Batch eval [1] loss 0.36700, dsc 0.63300\n",
      "DEBUG EPOCH AND STEP 18 1\n",
      "Batch eval [2] loss 0.36741, dsc 0.63259\n",
      "DEBUG EPOCH AND STEP 18 2\n",
      "Batch eval [3] loss 0.37385, dsc 0.62615\n",
      "DEBUG EPOCH AND STEP 18 3\n",
      "Batch eval [4] loss 0.44290, dsc 0.55710\n",
      "DEBUG EPOCH AND STEP 18 4\n",
      "Batch eval [5] loss 0.38080, dsc 0.61920\n",
      "Epoch [19] valid done\n",
      "Epoch [19] T 843.35s, deltaT 45.34s, loss: train 0.36801, valid 0.38639, dsc: train 0.63199, valid 0.61361\n",
      "DEBUG EPOCH AND STEP 19 0\n",
      "Batch train [1] loss 0.29672, dsc 0.70328\n",
      "DEBUG EPOCH AND STEP 19 1\n",
      "Batch train [2] loss 0.37471, dsc 0.62529\n",
      "DEBUG EPOCH AND STEP 19 2\n",
      "Batch train [3] loss 0.36257, dsc 0.63743\n",
      "DEBUG EPOCH AND STEP 19 3\n",
      "Batch train [4] loss 0.35870, dsc 0.64130\n",
      "DEBUG EPOCH AND STEP 19 4\n",
      "Batch train [5] loss 0.32491, dsc 0.67509\n",
      "DEBUG EPOCH AND STEP 19 5\n",
      "Batch train [6] loss 0.35103, dsc 0.64897\n",
      "DEBUG EPOCH AND STEP 19 6\n",
      "Batch train [7] loss 0.37767, dsc 0.62233\n",
      "DEBUG EPOCH AND STEP 19 7\n",
      "Batch train [8] loss 0.35432, dsc 0.64568\n",
      "DEBUG EPOCH AND STEP 19 8\n",
      "Batch train [9] loss 0.39488, dsc 0.60512\n",
      "DEBUG EPOCH AND STEP 19 9\n",
      "Batch train [10] loss 0.38063, dsc 0.61937\n",
      "DEBUG EPOCH AND STEP 19 10\n",
      "Batch train [11] loss 0.43499, dsc 0.56501\n",
      "DEBUG EPOCH AND STEP 19 11\n",
      "Batch train [12] loss 0.41471, dsc 0.58529\n",
      "DEBUG EPOCH AND STEP 19 12\n",
      "Batch train [13] loss 0.35022, dsc 0.64978\n",
      "DEBUG EPOCH AND STEP 19 13\n",
      "Batch train [14] loss 0.44598, dsc 0.55402\n",
      "DEBUG EPOCH AND STEP 19 14\n",
      "Batch train [15] loss 0.42843, dsc 0.57157\n",
      "DEBUG EPOCH AND STEP 19 15\n",
      "Batch train [16] loss 0.39424, dsc 0.60576\n",
      "DEBUG EPOCH AND STEP 19 16\n",
      "Batch train [17] loss 0.35048, dsc 0.64952\n",
      "DEBUG EPOCH AND STEP 19 17\n",
      "Batch train [18] loss 0.35322, dsc 0.64678\n",
      "DEBUG EPOCH AND STEP 19 18\n",
      "Batch train [19] loss 0.35652, dsc 0.64348\n",
      "DEBUG EPOCH AND STEP 19 19\n",
      "Batch train [20] loss 0.34827, dsc 0.65173\n",
      "DEBUG EPOCH AND STEP 19 20\n",
      "Batch train [21] loss 0.35946, dsc 0.64054\n",
      "DEBUG EPOCH AND STEP 19 21\n",
      "Batch train [22] loss 0.35921, dsc 0.64079\n",
      "DEBUG EPOCH AND STEP 19 22\n",
      "Batch train [23] loss 0.34653, dsc 0.65347\n",
      "DEBUG EPOCH AND STEP 19 23\n",
      "Batch train [24] loss 0.35141, dsc 0.64859\n",
      "DEBUG EPOCH AND STEP 19 24\n",
      "Batch train [25] loss 0.35085, dsc 0.64915\n",
      "DEBUG EPOCH AND STEP 19 25\n",
      "Batch train [26] loss 0.35568, dsc 0.64432\n",
      "DEBUG EPOCH AND STEP 19 26\n",
      "Batch train [27] loss 0.35978, dsc 0.64022\n",
      "DEBUG EPOCH AND STEP 19 27\n",
      "Batch train [28] loss 0.36869, dsc 0.63131\n",
      "DEBUG EPOCH AND STEP 19 28\n",
      "Batch train [29] loss 0.35757, dsc 0.64243\n",
      "DEBUG EPOCH AND STEP 19 29\n",
      "Batch train [30] loss 0.32606, dsc 0.67394\n",
      "DEBUG EPOCH AND STEP 19 30\n",
      "Batch train [31] loss 0.32398, dsc 0.67602\n",
      "DEBUG EPOCH AND STEP 19 31\n",
      "Batch train [32] loss 0.34911, dsc 0.65089\n",
      "DEBUG EPOCH AND STEP 19 32\n",
      "Batch train [33] loss 0.35611, dsc 0.64389\n",
      "DEBUG EPOCH AND STEP 19 33\n",
      "Batch train [34] loss 0.37021, dsc 0.62979\n",
      "DEBUG EPOCH AND STEP 19 34\n",
      "Batch train [35] loss 0.38972, dsc 0.61028\n",
      "DEBUG EPOCH AND STEP 19 35\n",
      "Batch train [36] loss 0.36334, dsc 0.63666\n",
      "DEBUG EPOCH AND STEP 19 36\n",
      "Batch train [37] loss 0.33226, dsc 0.66774\n",
      "DEBUG EPOCH AND STEP 19 37\n",
      "Batch train [38] loss 0.35332, dsc 0.64668\n",
      "DEBUG EPOCH AND STEP 19 38\n",
      "Batch train [39] loss 0.38524, dsc 0.61476\n",
      "DEBUG EPOCH AND STEP 19 39\n",
      "Batch train [40] loss 0.35829, dsc 0.64171\n",
      "Epoch [20] train done\n",
      "DEBUG EPOCH AND STEP 19 0\n",
      "Batch eval [1] loss 0.33348, dsc 0.66652\n",
      "DEBUG EPOCH AND STEP 19 1\n",
      "Batch eval [2] loss 0.38239, dsc 0.61761\n",
      "DEBUG EPOCH AND STEP 19 2\n",
      "Batch eval [3] loss 0.43058, dsc 0.56942\n",
      "DEBUG EPOCH AND STEP 19 3\n",
      "Batch eval [4] loss 0.41657, dsc 0.58343\n",
      "DEBUG EPOCH AND STEP 19 4\n",
      "Batch eval [5] loss 0.38766, dsc 0.61234\n",
      "Epoch [20] valid done\n",
      "Epoch [20] T 888.13s, deltaT 44.77s, loss: train 0.36425, valid 0.39014, dsc: train 0.63575, valid 0.60987\n",
      "DEBUG EPOCH AND STEP 20 0\n",
      "Batch train [1] loss 0.42109, dsc 0.57891\n",
      "DEBUG EPOCH AND STEP 20 1\n",
      "Batch train [2] loss 0.34980, dsc 0.65020\n",
      "DEBUG EPOCH AND STEP 20 2\n",
      "Batch train [3] loss 0.34893, dsc 0.65107\n",
      "DEBUG EPOCH AND STEP 20 3\n",
      "Batch train [4] loss 0.42448, dsc 0.57552\n",
      "DEBUG EPOCH AND STEP 20 4\n",
      "Batch train [5] loss 0.34094, dsc 0.65906\n",
      "DEBUG EPOCH AND STEP 20 5\n",
      "Batch train [6] loss 0.34394, dsc 0.65606\n",
      "DEBUG EPOCH AND STEP 20 6\n",
      "Batch train [7] loss 0.30298, dsc 0.69702\n",
      "DEBUG EPOCH AND STEP 20 7\n",
      "Batch train [8] loss 0.33659, dsc 0.66341\n",
      "DEBUG EPOCH AND STEP 20 8\n",
      "Batch train [9] loss 0.32496, dsc 0.67504\n",
      "DEBUG EPOCH AND STEP 20 9\n",
      "Batch train [10] loss 0.37883, dsc 0.62117\n",
      "DEBUG EPOCH AND STEP 20 10\n",
      "Batch train [11] loss 0.33249, dsc 0.66751\n",
      "DEBUG EPOCH AND STEP 20 11\n",
      "Batch train [12] loss 0.34557, dsc 0.65443\n",
      "DEBUG EPOCH AND STEP 20 12\n",
      "Batch train [13] loss 0.34071, dsc 0.65929\n",
      "DEBUG EPOCH AND STEP 20 13\n",
      "Batch train [14] loss 0.33259, dsc 0.66741\n",
      "DEBUG EPOCH AND STEP 20 14\n",
      "Batch train [15] loss 0.42162, dsc 0.57838\n",
      "DEBUG EPOCH AND STEP 20 15\n",
      "Batch train [16] loss 0.34435, dsc 0.65565\n",
      "DEBUG EPOCH AND STEP 20 16\n",
      "Batch train [17] loss 0.43187, dsc 0.56813\n",
      "DEBUG EPOCH AND STEP 20 17\n",
      "Batch train [18] loss 0.38704, dsc 0.61296\n",
      "DEBUG EPOCH AND STEP 20 18\n",
      "Batch train [19] loss 0.32713, dsc 0.67287\n",
      "DEBUG EPOCH AND STEP 20 19\n",
      "Batch train [20] loss 0.36205, dsc 0.63795\n",
      "DEBUG EPOCH AND STEP 20 20\n",
      "Batch train [21] loss 0.36010, dsc 0.63990\n",
      "DEBUG EPOCH AND STEP 20 21\n",
      "Batch train [22] loss 0.39378, dsc 0.60622\n",
      "DEBUG EPOCH AND STEP 20 22\n",
      "Batch train [23] loss 0.36712, dsc 0.63288\n",
      "DEBUG EPOCH AND STEP 20 23\n",
      "Batch train [24] loss 0.39121, dsc 0.60879\n",
      "DEBUG EPOCH AND STEP 20 24\n",
      "Batch train [25] loss 0.35114, dsc 0.64886\n",
      "DEBUG EPOCH AND STEP 20 25\n",
      "Batch train [26] loss 0.37894, dsc 0.62106\n",
      "DEBUG EPOCH AND STEP 20 26\n",
      "Batch train [27] loss 0.39167, dsc 0.60833\n",
      "DEBUG EPOCH AND STEP 20 27\n",
      "Batch train [28] loss 0.37518, dsc 0.62482\n",
      "DEBUG EPOCH AND STEP 20 28\n",
      "Batch train [29] loss 0.37592, dsc 0.62408\n",
      "DEBUG EPOCH AND STEP 20 29\n",
      "Batch train [30] loss 0.34048, dsc 0.65952\n",
      "DEBUG EPOCH AND STEP 20 30\n",
      "Batch train [31] loss 0.35661, dsc 0.64339\n",
      "DEBUG EPOCH AND STEP 20 31\n",
      "Batch train [32] loss 0.36423, dsc 0.63577\n",
      "DEBUG EPOCH AND STEP 20 32\n",
      "Batch train [33] loss 0.36096, dsc 0.63904\n",
      "DEBUG EPOCH AND STEP 20 33\n",
      "Batch train [34] loss 0.37327, dsc 0.62673\n",
      "DEBUG EPOCH AND STEP 20 34\n",
      "Batch train [35] loss 0.34793, dsc 0.65207\n",
      "DEBUG EPOCH AND STEP 20 35\n",
      "Batch train [36] loss 0.35458, dsc 0.64542\n",
      "DEBUG EPOCH AND STEP 20 36\n",
      "Batch train [37] loss 0.31725, dsc 0.68275\n",
      "DEBUG EPOCH AND STEP 20 37\n",
      "Batch train [38] loss 0.35822, dsc 0.64178\n",
      "DEBUG EPOCH AND STEP 20 38\n",
      "Batch train [39] loss 0.38081, dsc 0.61919\n",
      "DEBUG EPOCH AND STEP 20 39\n",
      "Batch train [40] loss 0.35753, dsc 0.64247\n",
      "Epoch [21] train done\n",
      "DEBUG EPOCH AND STEP 20 0\n",
      "Batch eval [1] loss 0.39518, dsc 0.60482\n",
      "DEBUG EPOCH AND STEP 20 1\n",
      "Batch eval [2] loss 0.38643, dsc 0.61357\n",
      "DEBUG EPOCH AND STEP 20 2\n",
      "Batch eval [3] loss 0.43578, dsc 0.56422\n",
      "DEBUG EPOCH AND STEP 20 3\n",
      "Batch eval [4] loss 0.41204, dsc 0.58796\n",
      "DEBUG EPOCH AND STEP 20 4\n",
      "Batch eval [5] loss 0.36924, dsc 0.63076\n",
      "Epoch [21] valid done\n",
      "Epoch [21] T 932.22s, deltaT 44.09s, loss: train 0.36237, valid 0.39974, dsc: train 0.63763, valid 0.60026\n",
      "DEBUG EPOCH AND STEP 21 0\n",
      "Batch train [1] loss 0.32953, dsc 0.67047\n",
      "DEBUG EPOCH AND STEP 21 1\n",
      "Batch train [2] loss 0.32270, dsc 0.67730\n",
      "DEBUG EPOCH AND STEP 21 2\n",
      "Batch train [3] loss 0.45006, dsc 0.54994\n",
      "DEBUG EPOCH AND STEP 21 3\n",
      "Batch train [4] loss 0.39971, dsc 0.60029\n",
      "DEBUG EPOCH AND STEP 21 4\n",
      "Batch train [5] loss 0.38562, dsc 0.61438\n",
      "DEBUG EPOCH AND STEP 21 5\n",
      "Batch train [6] loss 0.37605, dsc 0.62395\n",
      "DEBUG EPOCH AND STEP 21 6\n",
      "Batch train [7] loss 0.36802, dsc 0.63198\n",
      "DEBUG EPOCH AND STEP 21 7\n",
      "Batch train [8] loss 0.42935, dsc 0.57065\n",
      "DEBUG EPOCH AND STEP 21 8\n",
      "Batch train [9] loss 0.34528, dsc 0.65472\n",
      "DEBUG EPOCH AND STEP 21 9\n",
      "Batch train [10] loss 0.38306, dsc 0.61694\n",
      "DEBUG EPOCH AND STEP 21 10\n",
      "Batch train [11] loss 0.34103, dsc 0.65897\n",
      "DEBUG EPOCH AND STEP 21 11\n",
      "Batch train [12] loss 0.34538, dsc 0.65462\n",
      "DEBUG EPOCH AND STEP 21 12\n",
      "Batch train [13] loss 0.30669, dsc 0.69331\n",
      "DEBUG EPOCH AND STEP 21 13\n",
      "Batch train [14] loss 0.35310, dsc 0.64690\n",
      "DEBUG EPOCH AND STEP 21 14\n",
      "Batch train [15] loss 0.37853, dsc 0.62147\n",
      "DEBUG EPOCH AND STEP 21 15\n",
      "Batch train [16] loss 0.37352, dsc 0.62648\n",
      "DEBUG EPOCH AND STEP 21 16\n",
      "Batch train [17] loss 0.31942, dsc 0.68058\n",
      "DEBUG EPOCH AND STEP 21 17\n",
      "Batch train [18] loss 0.30942, dsc 0.69058\n",
      "DEBUG EPOCH AND STEP 21 18\n",
      "Batch train [19] loss 0.36278, dsc 0.63722\n",
      "DEBUG EPOCH AND STEP 21 19\n",
      "Batch train [20] loss 0.37329, dsc 0.62671\n",
      "DEBUG EPOCH AND STEP 21 20\n",
      "Batch train [21] loss 0.40610, dsc 0.59390\n",
      "DEBUG EPOCH AND STEP 21 21\n",
      "Batch train [22] loss 0.33555, dsc 0.66445\n",
      "DEBUG EPOCH AND STEP 21 22\n",
      "Batch train [23] loss 0.40909, dsc 0.59091\n",
      "DEBUG EPOCH AND STEP 21 23\n",
      "Batch train [24] loss 0.36761, dsc 0.63239\n",
      "DEBUG EPOCH AND STEP 21 24\n",
      "Batch train [25] loss 0.35880, dsc 0.64120\n",
      "DEBUG EPOCH AND STEP 21 25\n",
      "Batch train [26] loss 0.38635, dsc 0.61365\n",
      "DEBUG EPOCH AND STEP 21 26\n",
      "Batch train [27] loss 0.35822, dsc 0.64178\n",
      "DEBUG EPOCH AND STEP 21 27\n",
      "Batch train [28] loss 0.36658, dsc 0.63342\n",
      "DEBUG EPOCH AND STEP 21 28\n",
      "Batch train [29] loss 0.35095, dsc 0.64905\n",
      "DEBUG EPOCH AND STEP 21 29\n",
      "Batch train [30] loss 0.35191, dsc 0.64809\n",
      "DEBUG EPOCH AND STEP 21 30\n",
      "Batch train [31] loss 0.35074, dsc 0.64926\n",
      "DEBUG EPOCH AND STEP 21 31\n",
      "Batch train [32] loss 0.36711, dsc 0.63289\n",
      "DEBUG EPOCH AND STEP 21 32\n",
      "Batch train [33] loss 0.38508, dsc 0.61492\n",
      "DEBUG EPOCH AND STEP 21 33\n",
      "Batch train [34] loss 0.34284, dsc 0.65716\n",
      "DEBUG EPOCH AND STEP 21 34\n",
      "Batch train [35] loss 0.36493, dsc 0.63507\n",
      "DEBUG EPOCH AND STEP 21 35\n",
      "Batch train [36] loss 0.32451, dsc 0.67549\n",
      "DEBUG EPOCH AND STEP 21 36\n",
      "Batch train [37] loss 0.33790, dsc 0.66210\n",
      "DEBUG EPOCH AND STEP 21 37\n",
      "Batch train [38] loss 0.38767, dsc 0.61233\n",
      "DEBUG EPOCH AND STEP 21 38\n",
      "Batch train [39] loss 0.31303, dsc 0.68697\n",
      "DEBUG EPOCH AND STEP 21 39\n",
      "Batch train [40] loss 0.36687, dsc 0.63313\n",
      "Epoch [22] train done\n",
      "DEBUG EPOCH AND STEP 21 0\n",
      "Batch eval [1] loss 0.33969, dsc 0.66031\n",
      "DEBUG EPOCH AND STEP 21 1\n",
      "Batch eval [2] loss 0.36337, dsc 0.63663\n",
      "DEBUG EPOCH AND STEP 21 2\n",
      "Batch eval [3] loss 0.41276, dsc 0.58724\n",
      "DEBUG EPOCH AND STEP 21 3\n",
      "Batch eval [4] loss 0.39796, dsc 0.60204\n",
      "DEBUG EPOCH AND STEP 21 4\n",
      "Batch eval [5] loss 0.39702, dsc 0.60298\n",
      "Epoch [22] valid done\n",
      "Epoch [22] T 977.32s, deltaT 45.09s, loss: train 0.36211, valid 0.38216, dsc: train 0.63789, valid 0.61784\n",
      "DEBUG EPOCH AND STEP 22 0\n",
      "Batch train [1] loss 0.34569, dsc 0.65431\n",
      "DEBUG EPOCH AND STEP 22 1\n",
      "Batch train [2] loss 0.36554, dsc 0.63446\n",
      "DEBUG EPOCH AND STEP 22 2\n",
      "Batch train [3] loss 0.33206, dsc 0.66794\n",
      "DEBUG EPOCH AND STEP 22 3\n",
      "Batch train [4] loss 0.31821, dsc 0.68179\n",
      "DEBUG EPOCH AND STEP 22 4\n",
      "Batch train [5] loss 0.36136, dsc 0.63864\n",
      "DEBUG EPOCH AND STEP 22 5\n",
      "Batch train [6] loss 0.31644, dsc 0.68356\n",
      "DEBUG EPOCH AND STEP 22 6\n",
      "Batch train [7] loss 0.31491, dsc 0.68509\n",
      "DEBUG EPOCH AND STEP 22 7\n",
      "Batch train [8] loss 0.42474, dsc 0.57526\n",
      "DEBUG EPOCH AND STEP 22 8\n",
      "Batch train [9] loss 0.36025, dsc 0.63975\n",
      "DEBUG EPOCH AND STEP 22 9\n",
      "Batch train [10] loss 0.35627, dsc 0.64373\n",
      "DEBUG EPOCH AND STEP 22 10\n",
      "Batch train [11] loss 0.37037, dsc 0.62963\n",
      "DEBUG EPOCH AND STEP 22 11\n",
      "Batch train [12] loss 0.34573, dsc 0.65427\n",
      "DEBUG EPOCH AND STEP 22 12\n",
      "Batch train [13] loss 0.35595, dsc 0.64405\n",
      "DEBUG EPOCH AND STEP 22 13\n",
      "Batch train [14] loss 0.31910, dsc 0.68090\n",
      "DEBUG EPOCH AND STEP 22 14\n",
      "Batch train [15] loss 0.35719, dsc 0.64281\n",
      "DEBUG EPOCH AND STEP 22 15\n",
      "Batch train [16] loss 0.38543, dsc 0.61457\n",
      "DEBUG EPOCH AND STEP 22 16\n",
      "Batch train [17] loss 0.33108, dsc 0.66892\n",
      "DEBUG EPOCH AND STEP 22 17\n",
      "Batch train [18] loss 0.37598, dsc 0.62402\n",
      "DEBUG EPOCH AND STEP 22 18\n",
      "Batch train [19] loss 0.36574, dsc 0.63426\n",
      "DEBUG EPOCH AND STEP 22 19\n",
      "Batch train [20] loss 0.34670, dsc 0.65330\n",
      "DEBUG EPOCH AND STEP 22 20\n",
      "Batch train [21] loss 0.35354, dsc 0.64646\n",
      "DEBUG EPOCH AND STEP 22 21\n",
      "Batch train [22] loss 0.32792, dsc 0.67208\n",
      "DEBUG EPOCH AND STEP 22 22\n",
      "Batch train [23] loss 0.33050, dsc 0.66950\n",
      "DEBUG EPOCH AND STEP 22 23\n",
      "Batch train [24] loss 0.42920, dsc 0.57080\n",
      "DEBUG EPOCH AND STEP 22 24\n",
      "Batch train [25] loss 0.37029, dsc 0.62971\n",
      "DEBUG EPOCH AND STEP 22 25\n",
      "Batch train [26] loss 0.34645, dsc 0.65355\n",
      "DEBUG EPOCH AND STEP 22 26\n",
      "Batch train [27] loss 0.35599, dsc 0.64401\n",
      "DEBUG EPOCH AND STEP 22 27\n",
      "Batch train [28] loss 0.37132, dsc 0.62868\n",
      "DEBUG EPOCH AND STEP 22 28\n",
      "Batch train [29] loss 0.31668, dsc 0.68332\n",
      "DEBUG EPOCH AND STEP 22 29\n",
      "Batch train [30] loss 0.29341, dsc 0.70659\n",
      "DEBUG EPOCH AND STEP 22 30\n",
      "Batch train [31] loss 0.34450, dsc 0.65550\n",
      "DEBUG EPOCH AND STEP 22 31\n",
      "Batch train [32] loss 0.45645, dsc 0.54355\n",
      "DEBUG EPOCH AND STEP 22 32\n",
      "Batch train [33] loss 0.36097, dsc 0.63903\n",
      "DEBUG EPOCH AND STEP 22 33\n",
      "Batch train [34] loss 0.33187, dsc 0.66813\n",
      "DEBUG EPOCH AND STEP 22 34\n",
      "Batch train [35] loss 0.34396, dsc 0.65604\n",
      "DEBUG EPOCH AND STEP 22 35\n",
      "Batch train [36] loss 0.33859, dsc 0.66141\n",
      "DEBUG EPOCH AND STEP 22 36\n",
      "Batch train [37] loss 0.40079, dsc 0.59921\n",
      "DEBUG EPOCH AND STEP 22 37\n",
      "Batch train [38] loss 0.38795, dsc 0.61205\n",
      "DEBUG EPOCH AND STEP 22 38\n",
      "Batch train [39] loss 0.34381, dsc 0.65619\n",
      "DEBUG EPOCH AND STEP 22 39\n",
      "Batch train [40] loss 0.36984, dsc 0.63016\n",
      "Epoch [23] train done\n",
      "DEBUG EPOCH AND STEP 22 0\n",
      "Batch eval [1] loss 0.31649, dsc 0.68351\n",
      "DEBUG EPOCH AND STEP 22 1\n",
      "Batch eval [2] loss 0.40366, dsc 0.59634\n",
      "DEBUG EPOCH AND STEP 22 2\n",
      "Batch eval [3] loss 0.39352, dsc 0.60648\n",
      "DEBUG EPOCH AND STEP 22 3\n",
      "Batch eval [4] loss 0.39599, dsc 0.60401\n",
      "DEBUG EPOCH AND STEP 22 4\n",
      "Batch eval [5] loss 0.35513, dsc 0.64487\n",
      "Epoch [23] valid done\n",
      "Epoch [23] T 1022.17s, deltaT 44.85s, loss: train 0.35557, valid 0.37296, dsc: train 0.64443, valid 0.62704\n",
      "DEBUG EPOCH AND STEP 23 0\n",
      "Batch train [1] loss 0.32475, dsc 0.67525\n",
      "DEBUG EPOCH AND STEP 23 1\n",
      "Batch train [2] loss 0.35801, dsc 0.64199\n",
      "DEBUG EPOCH AND STEP 23 2\n",
      "Batch train [3] loss 0.34883, dsc 0.65117\n",
      "DEBUG EPOCH AND STEP 23 3\n",
      "Batch train [4] loss 0.35872, dsc 0.64128\n",
      "DEBUG EPOCH AND STEP 23 4\n",
      "Batch train [5] loss 0.31899, dsc 0.68101\n",
      "DEBUG EPOCH AND STEP 23 5\n",
      "Batch train [6] loss 0.38943, dsc 0.61057\n",
      "DEBUG EPOCH AND STEP 23 6\n",
      "Batch train [7] loss 0.35713, dsc 0.64287\n",
      "DEBUG EPOCH AND STEP 23 7\n",
      "Batch train [8] loss 0.33770, dsc 0.66230\n",
      "DEBUG EPOCH AND STEP 23 8\n",
      "Batch train [9] loss 0.35605, dsc 0.64395\n",
      "DEBUG EPOCH AND STEP 23 9\n",
      "Batch train [10] loss 0.36615, dsc 0.63385\n",
      "DEBUG EPOCH AND STEP 23 10\n",
      "Batch train [11] loss 0.36132, dsc 0.63868\n",
      "DEBUG EPOCH AND STEP 23 11\n",
      "Batch train [12] loss 0.38326, dsc 0.61674\n",
      "DEBUG EPOCH AND STEP 23 12\n",
      "Batch train [13] loss 0.37574, dsc 0.62426\n",
      "DEBUG EPOCH AND STEP 23 13\n",
      "Batch train [14] loss 0.33909, dsc 0.66091\n",
      "DEBUG EPOCH AND STEP 23 14\n",
      "Batch train [15] loss 0.37063, dsc 0.62937\n",
      "DEBUG EPOCH AND STEP 23 15\n",
      "Batch train [16] loss 0.38324, dsc 0.61676\n",
      "DEBUG EPOCH AND STEP 23 16\n",
      "Batch train [17] loss 0.38041, dsc 0.61959\n",
      "DEBUG EPOCH AND STEP 23 17\n",
      "Batch train [18] loss 0.43390, dsc 0.56610\n",
      "DEBUG EPOCH AND STEP 23 18\n",
      "Batch train [19] loss 0.38345, dsc 0.61655\n",
      "DEBUG EPOCH AND STEP 23 19\n",
      "Batch train [20] loss 0.34015, dsc 0.65985\n",
      "DEBUG EPOCH AND STEP 23 20\n",
      "Batch train [21] loss 0.34762, dsc 0.65238\n",
      "DEBUG EPOCH AND STEP 23 21\n",
      "Batch train [22] loss 0.36159, dsc 0.63841\n",
      "DEBUG EPOCH AND STEP 23 22\n",
      "Batch train [23] loss 0.33856, dsc 0.66144\n",
      "DEBUG EPOCH AND STEP 23 23\n",
      "Batch train [24] loss 0.34308, dsc 0.65692\n",
      "DEBUG EPOCH AND STEP 23 24\n",
      "Batch train [25] loss 0.35335, dsc 0.64665\n",
      "DEBUG EPOCH AND STEP 23 25\n",
      "Batch train [26] loss 0.32992, dsc 0.67008\n",
      "DEBUG EPOCH AND STEP 23 26\n",
      "Batch train [27] loss 0.38236, dsc 0.61764\n",
      "DEBUG EPOCH AND STEP 23 27\n",
      "Batch train [28] loss 0.37222, dsc 0.62778\n",
      "DEBUG EPOCH AND STEP 23 28\n",
      "Batch train [29] loss 0.36112, dsc 0.63888\n",
      "DEBUG EPOCH AND STEP 23 29\n",
      "Batch train [30] loss 0.34862, dsc 0.65138\n",
      "DEBUG EPOCH AND STEP 23 30\n",
      "Batch train [31] loss 0.35669, dsc 0.64331\n",
      "DEBUG EPOCH AND STEP 23 31\n",
      "Batch train [32] loss 0.34414, dsc 0.65586\n",
      "DEBUG EPOCH AND STEP 23 32\n",
      "Batch train [33] loss 0.30400, dsc 0.69600\n",
      "DEBUG EPOCH AND STEP 23 33\n",
      "Batch train [34] loss 0.33032, dsc 0.66968\n",
      "DEBUG EPOCH AND STEP 23 34\n",
      "Batch train [35] loss 0.46727, dsc 0.53273\n",
      "DEBUG EPOCH AND STEP 23 35\n",
      "Batch train [36] loss 0.32729, dsc 0.67271\n",
      "DEBUG EPOCH AND STEP 23 36\n",
      "Batch train [37] loss 0.35005, dsc 0.64995\n",
      "DEBUG EPOCH AND STEP 23 37\n",
      "Batch train [38] loss 0.39635, dsc 0.60365\n",
      "DEBUG EPOCH AND STEP 23 38\n",
      "Batch train [39] loss 0.30516, dsc 0.69484\n",
      "DEBUG EPOCH AND STEP 23 39\n",
      "Batch train [40] loss 0.33064, dsc 0.66936\n",
      "Epoch [24] train done\n",
      "DEBUG EPOCH AND STEP 23 0\n",
      "Batch eval [1] loss 0.35019, dsc 0.64981\n",
      "DEBUG EPOCH AND STEP 23 1\n",
      "Batch eval [2] loss 0.39187, dsc 0.60813\n",
      "DEBUG EPOCH AND STEP 23 2\n",
      "Batch eval [3] loss 0.38143, dsc 0.61857\n",
      "DEBUG EPOCH AND STEP 23 3\n",
      "Batch eval [4] loss 0.40068, dsc 0.59932\n",
      "DEBUG EPOCH AND STEP 23 4\n",
      "Batch eval [5] loss 0.38207, dsc 0.61793\n",
      "Epoch [24] valid done\n",
      "Epoch [24] T 1066.46s, deltaT 44.28s, loss: train 0.35793, valid 0.38125, dsc: train 0.64207, valid 0.61875\n",
      "DEBUG EPOCH AND STEP 24 0\n",
      "Batch train [1] loss 0.30661, dsc 0.69339\n",
      "DEBUG EPOCH AND STEP 24 1\n",
      "Batch train [2] loss 0.39062, dsc 0.60938\n",
      "DEBUG EPOCH AND STEP 24 2\n",
      "Batch train [3] loss 0.42508, dsc 0.57492\n",
      "DEBUG EPOCH AND STEP 24 3\n",
      "Batch train [4] loss 0.33244, dsc 0.66756\n",
      "DEBUG EPOCH AND STEP 24 4\n",
      "Batch train [5] loss 0.33581, dsc 0.66419\n",
      "DEBUG EPOCH AND STEP 24 5\n",
      "Batch train [6] loss 0.33736, dsc 0.66264\n",
      "DEBUG EPOCH AND STEP 24 6\n",
      "Batch train [7] loss 0.40120, dsc 0.59880\n",
      "DEBUG EPOCH AND STEP 24 7\n",
      "Batch train [8] loss 0.30786, dsc 0.69214\n",
      "DEBUG EPOCH AND STEP 24 8\n",
      "Batch train [9] loss 0.35148, dsc 0.64852\n",
      "DEBUG EPOCH AND STEP 24 9\n",
      "Batch train [10] loss 0.34091, dsc 0.65909\n",
      "DEBUG EPOCH AND STEP 24 10\n",
      "Batch train [11] loss 0.33001, dsc 0.66999\n",
      "DEBUG EPOCH AND STEP 24 11\n",
      "Batch train [12] loss 0.38399, dsc 0.61601\n",
      "DEBUG EPOCH AND STEP 24 12\n",
      "Batch train [13] loss 0.38377, dsc 0.61623\n",
      "DEBUG EPOCH AND STEP 24 13\n",
      "Batch train [14] loss 0.36403, dsc 0.63597\n",
      "DEBUG EPOCH AND STEP 24 14\n",
      "Batch train [15] loss 0.32886, dsc 0.67114\n",
      "DEBUG EPOCH AND STEP 24 15\n",
      "Batch train [16] loss 0.31822, dsc 0.68178\n",
      "DEBUG EPOCH AND STEP 24 16\n",
      "Batch train [17] loss 0.36743, dsc 0.63257\n",
      "DEBUG EPOCH AND STEP 24 17\n",
      "Batch train [18] loss 0.33820, dsc 0.66180\n",
      "DEBUG EPOCH AND STEP 24 18\n",
      "Batch train [19] loss 0.35217, dsc 0.64783\n",
      "DEBUG EPOCH AND STEP 24 19\n",
      "Batch train [20] loss 0.38327, dsc 0.61673\n",
      "DEBUG EPOCH AND STEP 24 20\n",
      "Batch train [21] loss 0.36013, dsc 0.63987\n",
      "DEBUG EPOCH AND STEP 24 21\n",
      "Batch train [22] loss 0.31424, dsc 0.68576\n",
      "DEBUG EPOCH AND STEP 24 22\n",
      "Batch train [23] loss 0.32762, dsc 0.67238\n",
      "DEBUG EPOCH AND STEP 24 23\n",
      "Batch train [24] loss 0.33747, dsc 0.66253\n",
      "DEBUG EPOCH AND STEP 24 24\n",
      "Batch train [25] loss 0.34541, dsc 0.65459\n",
      "DEBUG EPOCH AND STEP 24 25\n",
      "Batch train [26] loss 0.34916, dsc 0.65084\n",
      "DEBUG EPOCH AND STEP 24 26\n",
      "Batch train [27] loss 0.32207, dsc 0.67793\n",
      "DEBUG EPOCH AND STEP 24 27\n",
      "Batch train [28] loss 0.37390, dsc 0.62610\n",
      "DEBUG EPOCH AND STEP 24 28\n",
      "Batch train [29] loss 0.34024, dsc 0.65976\n",
      "DEBUG EPOCH AND STEP 24 29\n",
      "Batch train [30] loss 0.36655, dsc 0.63345\n",
      "DEBUG EPOCH AND STEP 24 30\n",
      "Batch train [31] loss 0.35159, dsc 0.64841\n",
      "DEBUG EPOCH AND STEP 24 31\n",
      "Batch train [32] loss 0.36018, dsc 0.63982\n",
      "DEBUG EPOCH AND STEP 24 32\n",
      "Batch train [33] loss 0.34685, dsc 0.65315\n",
      "DEBUG EPOCH AND STEP 24 33\n",
      "Batch train [34] loss 0.38217, dsc 0.61783\n",
      "DEBUG EPOCH AND STEP 24 34\n",
      "Batch train [35] loss 0.35421, dsc 0.64579\n",
      "DEBUG EPOCH AND STEP 24 35\n",
      "Batch train [36] loss 0.33396, dsc 0.66604\n",
      "DEBUG EPOCH AND STEP 24 36\n",
      "Batch train [37] loss 0.31748, dsc 0.68252\n",
      "DEBUG EPOCH AND STEP 24 37\n",
      "Batch train [38] loss 0.32633, dsc 0.67367\n",
      "DEBUG EPOCH AND STEP 24 38\n",
      "Batch train [39] loss 0.34437, dsc 0.65563\n",
      "DEBUG EPOCH AND STEP 24 39\n",
      "Batch train [40] loss 0.33971, dsc 0.66029\n",
      "Epoch [25] train done\n",
      "DEBUG EPOCH AND STEP 24 0\n",
      "Batch eval [1] loss 0.35075, dsc 0.64925\n",
      "DEBUG EPOCH AND STEP 24 1\n",
      "Batch eval [2] loss 0.35318, dsc 0.64682\n",
      "DEBUG EPOCH AND STEP 24 2\n",
      "Batch eval [3] loss 0.36551, dsc 0.63449\n",
      "DEBUG EPOCH AND STEP 24 3\n",
      "Batch eval [4] loss 0.41323, dsc 0.58677\n",
      "DEBUG EPOCH AND STEP 24 4\n",
      "Batch eval [5] loss 0.37348, dsc 0.62652\n",
      "Epoch [25] valid done\n",
      "Epoch [25] T 1110.62s, deltaT 44.15s, loss: train 0.34932, valid 0.37123, dsc: train 0.65068, valid 0.62877\n",
      "DEBUG EPOCH AND STEP 25 0\n",
      "Batch train [1] loss 0.34418, dsc 0.65582\n",
      "DEBUG EPOCH AND STEP 25 1\n",
      "Batch train [2] loss 0.29718, dsc 0.70282\n",
      "DEBUG EPOCH AND STEP 25 2\n",
      "Batch train [3] loss 0.34503, dsc 0.65497\n",
      "DEBUG EPOCH AND STEP 25 3\n",
      "Batch train [4] loss 0.33761, dsc 0.66239\n",
      "DEBUG EPOCH AND STEP 25 4\n",
      "Batch train [5] loss 0.33063, dsc 0.66937\n",
      "DEBUG EPOCH AND STEP 25 5\n",
      "Batch train [6] loss 0.35889, dsc 0.64111\n",
      "DEBUG EPOCH AND STEP 25 6\n",
      "Batch train [7] loss 0.36603, dsc 0.63397\n",
      "DEBUG EPOCH AND STEP 25 7\n",
      "Batch train [8] loss 0.33215, dsc 0.66785\n",
      "DEBUG EPOCH AND STEP 25 8\n",
      "Batch train [9] loss 0.38514, dsc 0.61486\n",
      "DEBUG EPOCH AND STEP 25 9\n",
      "Batch train [10] loss 0.34203, dsc 0.65797\n",
      "DEBUG EPOCH AND STEP 25 10\n",
      "Batch train [11] loss 0.31552, dsc 0.68448\n",
      "DEBUG EPOCH AND STEP 25 11\n",
      "Batch train [12] loss 0.32512, dsc 0.67488\n",
      "DEBUG EPOCH AND STEP 25 12\n",
      "Batch train [13] loss 0.35145, dsc 0.64855\n",
      "DEBUG EPOCH AND STEP 25 13\n",
      "Batch train [14] loss 0.33441, dsc 0.66559\n",
      "DEBUG EPOCH AND STEP 25 14\n",
      "Batch train [15] loss 0.33165, dsc 0.66835\n",
      "DEBUG EPOCH AND STEP 25 15\n",
      "Batch train [16] loss 0.36222, dsc 0.63778\n",
      "DEBUG EPOCH AND STEP 25 16\n",
      "Batch train [17] loss 0.34668, dsc 0.65332\n",
      "DEBUG EPOCH AND STEP 25 17\n",
      "Batch train [18] loss 0.29735, dsc 0.70265\n",
      "DEBUG EPOCH AND STEP 25 18\n",
      "Batch train [19] loss 0.30925, dsc 0.69075\n",
      "DEBUG EPOCH AND STEP 25 19\n",
      "Batch train [20] loss 0.31915, dsc 0.68085\n",
      "DEBUG EPOCH AND STEP 25 20\n",
      "Batch train [21] loss 0.43947, dsc 0.56053\n",
      "DEBUG EPOCH AND STEP 25 21\n",
      "Batch train [22] loss 0.33784, dsc 0.66216\n",
      "DEBUG EPOCH AND STEP 25 22\n",
      "Batch train [23] loss 0.36955, dsc 0.63045\n",
      "DEBUG EPOCH AND STEP 25 23\n",
      "Batch train [24] loss 0.36913, dsc 0.63087\n",
      "DEBUG EPOCH AND STEP 25 24\n",
      "Batch train [25] loss 0.35318, dsc 0.64682\n",
      "DEBUG EPOCH AND STEP 25 25\n",
      "Batch train [26] loss 0.32280, dsc 0.67720\n",
      "DEBUG EPOCH AND STEP 25 26\n",
      "Batch train [27] loss 0.37693, dsc 0.62307\n",
      "DEBUG EPOCH AND STEP 25 27\n",
      "Batch train [28] loss 0.32661, dsc 0.67339\n",
      "DEBUG EPOCH AND STEP 25 28\n",
      "Batch train [29] loss 0.33941, dsc 0.66059\n",
      "DEBUG EPOCH AND STEP 25 29\n",
      "Batch train [30] loss 0.33884, dsc 0.66116\n",
      "DEBUG EPOCH AND STEP 25 30\n",
      "Batch train [31] loss 0.34831, dsc 0.65169\n",
      "DEBUG EPOCH AND STEP 25 31\n",
      "Batch train [32] loss 0.39697, dsc 0.60303\n",
      "DEBUG EPOCH AND STEP 25 32\n",
      "Batch train [33] loss 0.34060, dsc 0.65940\n",
      "DEBUG EPOCH AND STEP 25 33\n",
      "Batch train [34] loss 0.33856, dsc 0.66144\n",
      "DEBUG EPOCH AND STEP 25 34\n",
      "Batch train [35] loss 0.35766, dsc 0.64234\n",
      "DEBUG EPOCH AND STEP 25 35\n",
      "Batch train [36] loss 0.37651, dsc 0.62349\n",
      "DEBUG EPOCH AND STEP 25 36\n",
      "Batch train [37] loss 0.40694, dsc 0.59306\n",
      "DEBUG EPOCH AND STEP 25 37\n",
      "Batch train [38] loss 0.38886, dsc 0.61114\n",
      "DEBUG EPOCH AND STEP 25 38\n",
      "Batch train [39] loss 0.31644, dsc 0.68356\n",
      "DEBUG EPOCH AND STEP 25 39\n",
      "Batch train [40] loss 0.33089, dsc 0.66911\n",
      "Epoch [26] train done\n",
      "DEBUG EPOCH AND STEP 25 0\n",
      "Batch eval [1] loss 0.33895, dsc 0.66105\n",
      "DEBUG EPOCH AND STEP 25 1\n",
      "Batch eval [2] loss 0.38356, dsc 0.61644\n",
      "DEBUG EPOCH AND STEP 25 2\n",
      "Batch eval [3] loss 0.41011, dsc 0.58989\n",
      "DEBUG EPOCH AND STEP 25 3\n",
      "Batch eval [4] loss 0.38833, dsc 0.61167\n",
      "DEBUG EPOCH AND STEP 25 4\n",
      "Batch eval [5] loss 0.36470, dsc 0.63530\n",
      "Epoch [26] valid done\n",
      "Epoch [26] T 1154.82s, deltaT 44.20s, loss: train 0.34768, valid 0.37713, dsc: train 0.65232, valid 0.62287\n",
      "DEBUG EPOCH AND STEP 26 0\n",
      "Batch train [1] loss 0.32535, dsc 0.67465\n",
      "DEBUG EPOCH AND STEP 26 1\n",
      "Batch train [2] loss 0.34753, dsc 0.65247\n",
      "DEBUG EPOCH AND STEP 26 2\n",
      "Batch train [3] loss 0.42477, dsc 0.57523\n",
      "DEBUG EPOCH AND STEP 26 3\n",
      "Batch train [4] loss 0.34885, dsc 0.65115\n",
      "DEBUG EPOCH AND STEP 26 4\n",
      "Batch train [5] loss 0.32146, dsc 0.67854\n",
      "DEBUG EPOCH AND STEP 26 5\n",
      "Batch train [6] loss 0.35199, dsc 0.64801\n",
      "DEBUG EPOCH AND STEP 26 6\n",
      "Batch train [7] loss 0.34925, dsc 0.65075\n",
      "DEBUG EPOCH AND STEP 26 7\n",
      "Batch train [8] loss 0.32097, dsc 0.67903\n",
      "DEBUG EPOCH AND STEP 26 8\n",
      "Batch train [9] loss 0.39416, dsc 0.60584\n",
      "DEBUG EPOCH AND STEP 26 9\n",
      "Batch train [10] loss 0.35946, dsc 0.64054\n",
      "DEBUG EPOCH AND STEP 26 10\n",
      "Batch train [11] loss 0.36622, dsc 0.63378\n",
      "DEBUG EPOCH AND STEP 26 11\n",
      "Batch train [12] loss 0.35979, dsc 0.64021\n",
      "DEBUG EPOCH AND STEP 26 12\n",
      "Batch train [13] loss 0.32832, dsc 0.67168\n",
      "DEBUG EPOCH AND STEP 26 13\n",
      "Batch train [14] loss 0.35450, dsc 0.64550\n",
      "DEBUG EPOCH AND STEP 26 14\n",
      "Batch train [15] loss 0.34828, dsc 0.65172\n",
      "DEBUG EPOCH AND STEP 26 15\n",
      "Batch train [16] loss 0.35254, dsc 0.64746\n",
      "DEBUG EPOCH AND STEP 26 16\n",
      "Batch train [17] loss 0.33881, dsc 0.66119\n",
      "DEBUG EPOCH AND STEP 26 17\n",
      "Batch train [18] loss 0.34535, dsc 0.65465\n",
      "DEBUG EPOCH AND STEP 26 18\n",
      "Batch train [19] loss 0.39624, dsc 0.60376\n",
      "DEBUG EPOCH AND STEP 26 19\n",
      "Batch train [20] loss 0.33225, dsc 0.66775\n",
      "DEBUG EPOCH AND STEP 26 20\n",
      "Batch train [21] loss 0.37600, dsc 0.62400\n",
      "DEBUG EPOCH AND STEP 26 21\n",
      "Batch train [22] loss 0.33715, dsc 0.66285\n",
      "DEBUG EPOCH AND STEP 26 22\n",
      "Batch train [23] loss 0.34389, dsc 0.65611\n",
      "DEBUG EPOCH AND STEP 26 23\n",
      "Batch train [24] loss 0.37664, dsc 0.62336\n",
      "DEBUG EPOCH AND STEP 26 24\n",
      "Batch train [25] loss 0.33257, dsc 0.66743\n",
      "DEBUG EPOCH AND STEP 26 25\n",
      "Batch train [26] loss 0.36832, dsc 0.63168\n",
      "DEBUG EPOCH AND STEP 26 26\n",
      "Batch train [27] loss 0.33126, dsc 0.66874\n",
      "DEBUG EPOCH AND STEP 26 27\n",
      "Batch train [28] loss 0.36166, dsc 0.63834\n",
      "DEBUG EPOCH AND STEP 26 28\n",
      "Batch train [29] loss 0.33704, dsc 0.66296\n",
      "DEBUG EPOCH AND STEP 26 29\n",
      "Batch train [30] loss 0.33769, dsc 0.66231\n",
      "DEBUG EPOCH AND STEP 26 30\n",
      "Batch train [31] loss 0.35506, dsc 0.64494\n",
      "DEBUG EPOCH AND STEP 26 31\n",
      "Batch train [32] loss 0.33814, dsc 0.66186\n",
      "DEBUG EPOCH AND STEP 26 32\n",
      "Batch train [33] loss 0.28964, dsc 0.71036\n",
      "DEBUG EPOCH AND STEP 26 33\n",
      "Batch train [34] loss 0.42657, dsc 0.57343\n",
      "DEBUG EPOCH AND STEP 26 34\n",
      "Batch train [35] loss 0.34033, dsc 0.65967\n",
      "DEBUG EPOCH AND STEP 26 35\n",
      "Batch train [36] loss 0.31969, dsc 0.68031\n",
      "DEBUG EPOCH AND STEP 26 36\n",
      "Batch train [37] loss 0.36707, dsc 0.63293\n",
      "DEBUG EPOCH AND STEP 26 37\n",
      "Batch train [38] loss 0.40703, dsc 0.59297\n",
      "DEBUG EPOCH AND STEP 26 38\n",
      "Batch train [39] loss 0.32990, dsc 0.67010\n",
      "DEBUG EPOCH AND STEP 26 39\n",
      "Batch train [40] loss 0.32843, dsc 0.67157\n",
      "Epoch [27] train done\n",
      "DEBUG EPOCH AND STEP 26 0\n",
      "Batch eval [1] loss 0.42568, dsc 0.57432\n",
      "DEBUG EPOCH AND STEP 26 1\n",
      "Batch eval [2] loss 0.35898, dsc 0.64102\n",
      "DEBUG EPOCH AND STEP 26 2\n",
      "Batch eval [3] loss 0.41303, dsc 0.58697\n",
      "DEBUG EPOCH AND STEP 26 3\n",
      "Batch eval [4] loss 0.36369, dsc 0.63631\n",
      "DEBUG EPOCH AND STEP 26 4\n",
      "Batch eval [5] loss 0.38808, dsc 0.61192\n",
      "Epoch [27] valid done\n",
      "Epoch [27] T 1199.01s, deltaT 44.18s, loss: train 0.35175, valid 0.38989, dsc: train 0.64825, valid 0.61011\n",
      "DEBUG EPOCH AND STEP 27 0\n",
      "Batch train [1] loss 0.33065, dsc 0.66935\n",
      "DEBUG EPOCH AND STEP 27 1\n",
      "Batch train [2] loss 0.31983, dsc 0.68017\n",
      "DEBUG EPOCH AND STEP 27 2\n",
      "Batch train [3] loss 0.32303, dsc 0.67697\n",
      "DEBUG EPOCH AND STEP 27 3\n",
      "Batch train [4] loss 0.31252, dsc 0.68748\n",
      "DEBUG EPOCH AND STEP 27 4\n",
      "Batch train [5] loss 0.31695, dsc 0.68305\n",
      "DEBUG EPOCH AND STEP 27 5\n",
      "Batch train [6] loss 0.37681, dsc 0.62319\n",
      "DEBUG EPOCH AND STEP 27 6\n",
      "Batch train [7] loss 0.38246, dsc 0.61754\n",
      "DEBUG EPOCH AND STEP 27 7\n",
      "Batch train [8] loss 0.38776, dsc 0.61224\n",
      "DEBUG EPOCH AND STEP 27 8\n",
      "Batch train [9] loss 0.36535, dsc 0.63465\n",
      "DEBUG EPOCH AND STEP 27 9\n",
      "Batch train [10] loss 0.36979, dsc 0.63021\n",
      "DEBUG EPOCH AND STEP 27 10\n",
      "Batch train [11] loss 0.36286, dsc 0.63714\n",
      "DEBUG EPOCH AND STEP 27 11\n",
      "Batch train [12] loss 0.33357, dsc 0.66643\n",
      "DEBUG EPOCH AND STEP 27 12\n",
      "Batch train [13] loss 0.32844, dsc 0.67156\n",
      "DEBUG EPOCH AND STEP 27 13\n",
      "Batch train [14] loss 0.35173, dsc 0.64827\n",
      "DEBUG EPOCH AND STEP 27 14\n",
      "Batch train [15] loss 0.37096, dsc 0.62904\n",
      "DEBUG EPOCH AND STEP 27 15\n",
      "Batch train [16] loss 0.32987, dsc 0.67013\n",
      "DEBUG EPOCH AND STEP 27 16\n",
      "Batch train [17] loss 0.30968, dsc 0.69032\n",
      "DEBUG EPOCH AND STEP 27 17\n",
      "Batch train [18] loss 0.35643, dsc 0.64357\n",
      "DEBUG EPOCH AND STEP 27 18\n",
      "Batch train [19] loss 0.42716, dsc 0.57284\n",
      "DEBUG EPOCH AND STEP 27 19\n",
      "Batch train [20] loss 0.35132, dsc 0.64868\n",
      "DEBUG EPOCH AND STEP 27 20\n",
      "Batch train [21] loss 0.33701, dsc 0.66299\n",
      "DEBUG EPOCH AND STEP 27 21\n",
      "Batch train [22] loss 0.35796, dsc 0.64204\n",
      "DEBUG EPOCH AND STEP 27 22\n",
      "Batch train [23] loss 0.33916, dsc 0.66084\n",
      "DEBUG EPOCH AND STEP 27 23\n",
      "Batch train [24] loss 0.35945, dsc 0.64055\n",
      "DEBUG EPOCH AND STEP 27 24\n",
      "Batch train [25] loss 0.34896, dsc 0.65104\n",
      "DEBUG EPOCH AND STEP 27 25\n",
      "Batch train [26] loss 0.35944, dsc 0.64056\n",
      "DEBUG EPOCH AND STEP 27 26\n",
      "Batch train [27] loss 0.41634, dsc 0.58366\n",
      "DEBUG EPOCH AND STEP 27 27\n",
      "Batch train [28] loss 0.34767, dsc 0.65233\n",
      "DEBUG EPOCH AND STEP 27 28\n",
      "Batch train [29] loss 0.40917, dsc 0.59083\n",
      "DEBUG EPOCH AND STEP 27 29\n",
      "Batch train [30] loss 0.34302, dsc 0.65698\n",
      "DEBUG EPOCH AND STEP 27 30\n",
      "Batch train [31] loss 0.34581, dsc 0.65419\n",
      "DEBUG EPOCH AND STEP 27 31\n",
      "Batch train [32] loss 0.31712, dsc 0.68288\n",
      "DEBUG EPOCH AND STEP 27 32\n",
      "Batch train [33] loss 0.41724, dsc 0.58276\n",
      "DEBUG EPOCH AND STEP 27 33\n",
      "Batch train [34] loss 0.36494, dsc 0.63506\n",
      "DEBUG EPOCH AND STEP 27 34\n",
      "Batch train [35] loss 0.37141, dsc 0.62859\n",
      "DEBUG EPOCH AND STEP 27 35\n",
      "Batch train [36] loss 0.30508, dsc 0.69492\n",
      "DEBUG EPOCH AND STEP 27 36\n",
      "Batch train [37] loss 0.37367, dsc 0.62633\n",
      "DEBUG EPOCH AND STEP 27 37\n",
      "Batch train [38] loss 0.38794, dsc 0.61206\n",
      "DEBUG EPOCH AND STEP 27 38\n",
      "Batch train [39] loss 0.30983, dsc 0.69017\n",
      "DEBUG EPOCH AND STEP 27 39\n",
      "Batch train [40] loss 0.31619, dsc 0.68381\n",
      "Epoch [28] train done\n",
      "DEBUG EPOCH AND STEP 27 0\n",
      "Batch eval [1] loss 0.39466, dsc 0.60534\n",
      "DEBUG EPOCH AND STEP 27 1\n",
      "Batch eval [2] loss 0.40072, dsc 0.59928\n",
      "DEBUG EPOCH AND STEP 27 2\n",
      "Batch eval [3] loss 0.44791, dsc 0.55209\n",
      "DEBUG EPOCH AND STEP 27 3\n",
      "Batch eval [4] loss 0.40634, dsc 0.59366\n",
      "DEBUG EPOCH AND STEP 27 4\n",
      "Batch eval [5] loss 0.42553, dsc 0.57447\n",
      "Epoch [28] valid done\n",
      "Epoch [28] T 1243.18s, deltaT 44.16s, loss: train 0.35336, valid 0.41503, dsc: train 0.64664, valid 0.58497\n",
      "DEBUG EPOCH AND STEP 28 0\n",
      "Batch train [1] loss 0.35851, dsc 0.64149\n",
      "DEBUG EPOCH AND STEP 28 1\n",
      "Batch train [2] loss 0.35204, dsc 0.64796\n",
      "DEBUG EPOCH AND STEP 28 2\n",
      "Batch train [3] loss 0.36633, dsc 0.63367\n",
      "DEBUG EPOCH AND STEP 28 3\n",
      "Batch train [4] loss 0.34798, dsc 0.65202\n",
      "DEBUG EPOCH AND STEP 28 4\n",
      "Batch train [5] loss 0.33931, dsc 0.66069\n",
      "DEBUG EPOCH AND STEP 28 5\n",
      "Batch train [6] loss 0.35459, dsc 0.64541\n",
      "DEBUG EPOCH AND STEP 28 6\n",
      "Batch train [7] loss 0.41917, dsc 0.58083\n",
      "DEBUG EPOCH AND STEP 28 7\n",
      "Batch train [8] loss 0.31704, dsc 0.68296\n",
      "DEBUG EPOCH AND STEP 28 8\n",
      "Batch train [9] loss 0.39799, dsc 0.60201\n",
      "DEBUG EPOCH AND STEP 28 9\n",
      "Batch train [10] loss 0.42823, dsc 0.57177\n",
      "DEBUG EPOCH AND STEP 28 10\n",
      "Batch train [11] loss 0.37291, dsc 0.62709\n",
      "DEBUG EPOCH AND STEP 28 11\n",
      "Batch train [12] loss 0.41096, dsc 0.58904\n",
      "DEBUG EPOCH AND STEP 28 12\n",
      "Batch train [13] loss 0.35778, dsc 0.64222\n",
      "DEBUG EPOCH AND STEP 28 13\n",
      "Batch train [14] loss 0.35921, dsc 0.64079\n",
      "DEBUG EPOCH AND STEP 28 14\n",
      "Batch train [15] loss 0.36328, dsc 0.63672\n",
      "DEBUG EPOCH AND STEP 28 15\n",
      "Batch train [16] loss 0.35854, dsc 0.64146\n",
      "DEBUG EPOCH AND STEP 28 16\n",
      "Batch train [17] loss 0.31771, dsc 0.68229\n",
      "DEBUG EPOCH AND STEP 28 17\n",
      "Batch train [18] loss 0.31084, dsc 0.68916\n",
      "DEBUG EPOCH AND STEP 28 18\n",
      "Batch train [19] loss 0.33040, dsc 0.66960\n",
      "DEBUG EPOCH AND STEP 28 19\n",
      "Batch train [20] loss 0.39170, dsc 0.60830\n",
      "DEBUG EPOCH AND STEP 28 20\n",
      "Batch train [21] loss 0.35010, dsc 0.64990\n",
      "DEBUG EPOCH AND STEP 28 21\n",
      "Batch train [22] loss 0.29760, dsc 0.70240\n",
      "DEBUG EPOCH AND STEP 28 22\n",
      "Batch train [23] loss 0.32263, dsc 0.67737\n",
      "DEBUG EPOCH AND STEP 28 23\n",
      "Batch train [24] loss 0.33276, dsc 0.66724\n",
      "DEBUG EPOCH AND STEP 28 24\n",
      "Batch train [25] loss 0.37323, dsc 0.62677\n",
      "DEBUG EPOCH AND STEP 28 25\n",
      "Batch train [26] loss 0.37843, dsc 0.62157\n",
      "DEBUG EPOCH AND STEP 28 26\n",
      "Batch train [27] loss 0.32912, dsc 0.67088\n",
      "DEBUG EPOCH AND STEP 28 27\n",
      "Batch train [28] loss 0.34855, dsc 0.65145\n",
      "DEBUG EPOCH AND STEP 28 28\n",
      "Batch train [29] loss 0.29654, dsc 0.70346\n",
      "DEBUG EPOCH AND STEP 28 29\n",
      "Batch train [30] loss 0.37029, dsc 0.62971\n",
      "DEBUG EPOCH AND STEP 28 30\n",
      "Batch train [31] loss 0.34240, dsc 0.65760\n",
      "DEBUG EPOCH AND STEP 28 31\n",
      "Batch train [32] loss 0.31131, dsc 0.68869\n",
      "DEBUG EPOCH AND STEP 28 32\n",
      "Batch train [33] loss 0.35312, dsc 0.64688\n",
      "DEBUG EPOCH AND STEP 28 33\n",
      "Batch train [34] loss 0.34574, dsc 0.65426\n",
      "DEBUG EPOCH AND STEP 28 34\n",
      "Batch train [35] loss 0.37386, dsc 0.62614\n",
      "DEBUG EPOCH AND STEP 28 35\n",
      "Batch train [36] loss 0.31899, dsc 0.68101\n",
      "DEBUG EPOCH AND STEP 28 36\n",
      "Batch train [37] loss 0.33029, dsc 0.66971\n",
      "DEBUG EPOCH AND STEP 28 37\n",
      "Batch train [38] loss 0.34376, dsc 0.65624\n",
      "DEBUG EPOCH AND STEP 28 38\n",
      "Batch train [39] loss 0.32398, dsc 0.67602\n",
      "DEBUG EPOCH AND STEP 28 39\n",
      "Batch train [40] loss 0.35051, dsc 0.64949\n",
      "Epoch [29] train done\n",
      "DEBUG EPOCH AND STEP 28 0\n",
      "Batch eval [1] loss 0.34464, dsc 0.65536\n",
      "DEBUG EPOCH AND STEP 28 1\n",
      "Batch eval [2] loss 0.35880, dsc 0.64120\n",
      "DEBUG EPOCH AND STEP 28 2\n",
      "Batch eval [3] loss 0.37446, dsc 0.62554\n",
      "DEBUG EPOCH AND STEP 28 3\n",
      "Batch eval [4] loss 0.38740, dsc 0.61260\n",
      "DEBUG EPOCH AND STEP 28 4\n",
      "Batch eval [5] loss 0.39117, dsc 0.60883\n",
      "Epoch [29] valid done\n",
      "Epoch [29] T 1287.33s, deltaT 44.15s, loss: train 0.35119, valid 0.37129, dsc: train 0.64881, valid 0.62871\n",
      "DEBUG EPOCH AND STEP 29 0\n",
      "Batch train [1] loss 0.36836, dsc 0.63164\n",
      "DEBUG EPOCH AND STEP 29 1\n",
      "Batch train [2] loss 0.35111, dsc 0.64889\n",
      "DEBUG EPOCH AND STEP 29 2\n",
      "Batch train [3] loss 0.31417, dsc 0.68583\n",
      "DEBUG EPOCH AND STEP 29 3\n",
      "Batch train [4] loss 0.32871, dsc 0.67129\n",
      "DEBUG EPOCH AND STEP 29 4\n",
      "Batch train [5] loss 0.31438, dsc 0.68562\n",
      "DEBUG EPOCH AND STEP 29 5\n",
      "Batch train [6] loss 0.34407, dsc 0.65593\n",
      "DEBUG EPOCH AND STEP 29 6\n",
      "Batch train [7] loss 0.35268, dsc 0.64732\n",
      "DEBUG EPOCH AND STEP 29 7\n",
      "Batch train [8] loss 0.35703, dsc 0.64297\n",
      "DEBUG EPOCH AND STEP 29 8\n",
      "Batch train [9] loss 0.37063, dsc 0.62937\n",
      "DEBUG EPOCH AND STEP 29 9\n",
      "Batch train [10] loss 0.30244, dsc 0.69756\n",
      "DEBUG EPOCH AND STEP 29 10\n",
      "Batch train [11] loss 0.32933, dsc 0.67067\n",
      "DEBUG EPOCH AND STEP 29 11\n",
      "Batch train [12] loss 0.32079, dsc 0.67921\n",
      "DEBUG EPOCH AND STEP 29 12\n",
      "Batch train [13] loss 0.30748, dsc 0.69252\n",
      "DEBUG EPOCH AND STEP 29 13\n",
      "Batch train [14] loss 0.33351, dsc 0.66649\n",
      "DEBUG EPOCH AND STEP 29 14\n",
      "Batch train [15] loss 0.34209, dsc 0.65791\n",
      "DEBUG EPOCH AND STEP 29 15\n",
      "Batch train [16] loss 0.32305, dsc 0.67695\n",
      "DEBUG EPOCH AND STEP 29 16\n",
      "Batch train [17] loss 0.36700, dsc 0.63300\n",
      "DEBUG EPOCH AND STEP 29 17\n",
      "Batch train [18] loss 0.40832, dsc 0.59168\n",
      "DEBUG EPOCH AND STEP 29 18\n",
      "Batch train [19] loss 0.34135, dsc 0.65865\n",
      "DEBUG EPOCH AND STEP 29 19\n",
      "Batch train [20] loss 0.37010, dsc 0.62990\n",
      "DEBUG EPOCH AND STEP 29 20\n",
      "Batch train [21] loss 0.35779, dsc 0.64221\n",
      "DEBUG EPOCH AND STEP 29 21\n",
      "Batch train [22] loss 0.33571, dsc 0.66429\n",
      "DEBUG EPOCH AND STEP 29 22\n",
      "Batch train [23] loss 0.35805, dsc 0.64195\n",
      "DEBUG EPOCH AND STEP 29 23\n",
      "Batch train [24] loss 0.34348, dsc 0.65652\n",
      "DEBUG EPOCH AND STEP 29 24\n",
      "Batch train [25] loss 0.36386, dsc 0.63614\n",
      "DEBUG EPOCH AND STEP 29 25\n",
      "Batch train [26] loss 0.32709, dsc 0.67291\n",
      "DEBUG EPOCH AND STEP 29 26\n",
      "Batch train [27] loss 0.38914, dsc 0.61086\n",
      "DEBUG EPOCH AND STEP 29 27\n",
      "Batch train [28] loss 0.35184, dsc 0.64816\n",
      "DEBUG EPOCH AND STEP 29 28\n",
      "Batch train [29] loss 0.32491, dsc 0.67509\n",
      "DEBUG EPOCH AND STEP 29 29\n",
      "Batch train [30] loss 0.37861, dsc 0.62139\n",
      "DEBUG EPOCH AND STEP 29 30\n",
      "Batch train [31] loss 0.44220, dsc 0.55780\n",
      "DEBUG EPOCH AND STEP 29 31\n",
      "Batch train [32] loss 0.34779, dsc 0.65221\n",
      "DEBUG EPOCH AND STEP 29 32\n",
      "Batch train [33] loss 0.31577, dsc 0.68423\n",
      "DEBUG EPOCH AND STEP 29 33\n",
      "Batch train [34] loss 0.31843, dsc 0.68157\n",
      "DEBUG EPOCH AND STEP 29 34\n",
      "Batch train [35] loss 0.35254, dsc 0.64746\n",
      "DEBUG EPOCH AND STEP 29 35\n",
      "Batch train [36] loss 0.27652, dsc 0.72348\n",
      "DEBUG EPOCH AND STEP 29 36\n",
      "Batch train [37] loss 0.37486, dsc 0.62514\n",
      "DEBUG EPOCH AND STEP 29 37\n",
      "Batch train [38] loss 0.36390, dsc 0.63610\n",
      "DEBUG EPOCH AND STEP 29 38\n",
      "Batch train [39] loss 0.40086, dsc 0.59914\n",
      "DEBUG EPOCH AND STEP 29 39\n",
      "Batch train [40] loss 0.31554, dsc 0.68446\n",
      "Epoch [30] train done\n",
      "DEBUG EPOCH AND STEP 29 0\n",
      "Batch eval [1] loss 0.35892, dsc 0.64108\n",
      "DEBUG EPOCH AND STEP 29 1\n",
      "Batch eval [2] loss 0.35110, dsc 0.64890\n",
      "DEBUG EPOCH AND STEP 29 2\n",
      "Batch eval [3] loss 0.38493, dsc 0.61507\n",
      "DEBUG EPOCH AND STEP 29 3\n",
      "Batch eval [4] loss 0.38284, dsc 0.61716\n",
      "DEBUG EPOCH AND STEP 29 4\n",
      "Batch eval [5] loss 0.36771, dsc 0.63229\n",
      "Epoch [30] valid done\n",
      "Epoch [30] T 1331.97s, deltaT 44.64s, loss: train 0.34714, valid 0.36910, dsc: train 0.65286, valid 0.63090\n",
      "DEBUG EPOCH AND STEP 30 0\n",
      "Batch train [1] loss 0.33297, dsc 0.66703\n",
      "DEBUG EPOCH AND STEP 30 1\n",
      "Batch train [2] loss 0.31471, dsc 0.68529\n",
      "DEBUG EPOCH AND STEP 30 2\n",
      "Batch train [3] loss 0.35758, dsc 0.64242\n",
      "DEBUG EPOCH AND STEP 30 3\n",
      "Batch train [4] loss 0.31210, dsc 0.68790\n",
      "DEBUG EPOCH AND STEP 30 4\n",
      "Batch train [5] loss 0.35696, dsc 0.64304\n",
      "DEBUG EPOCH AND STEP 30 5\n",
      "Batch train [6] loss 0.34371, dsc 0.65629\n",
      "DEBUG EPOCH AND STEP 30 6\n",
      "Batch train [7] loss 0.36002, dsc 0.63998\n",
      "DEBUG EPOCH AND STEP 30 7\n",
      "Batch train [8] loss 0.37008, dsc 0.62992\n",
      "DEBUG EPOCH AND STEP 30 8\n",
      "Batch train [9] loss 0.33874, dsc 0.66126\n",
      "DEBUG EPOCH AND STEP 30 9\n",
      "Batch train [10] loss 0.30295, dsc 0.69705\n",
      "DEBUG EPOCH AND STEP 30 10\n",
      "Batch train [11] loss 0.36569, dsc 0.63431\n",
      "DEBUG EPOCH AND STEP 30 11\n",
      "Batch train [12] loss 0.35688, dsc 0.64312\n",
      "DEBUG EPOCH AND STEP 30 12\n",
      "Batch train [13] loss 0.36488, dsc 0.63512\n",
      "DEBUG EPOCH AND STEP 30 13\n",
      "Batch train [14] loss 0.34506, dsc 0.65494\n",
      "DEBUG EPOCH AND STEP 30 14\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a8fc3e8d71dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mshow_model_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/train_loop.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model_info)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch [%d] train done'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/iterate_model.py\u001b[0m in \u001b[0;36miterate_model\u001b[0;34m(dataloader, model, optimizer, loss_func, device, is_eval)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             item_loss, item_dsc, inputs_len = loss_batch(model, optimizer, loss_func, inputs, labels,\n\u001b[0m\u001b[1;32m     32\u001b[0m                                                          calc_backward=not is_eval)\n\u001b[1;32m     33\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/src/model_and_training/loss_batch.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, optimizer, loss_func, model_input, true_output, calc_backward)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalc_backward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "from src.model_and_training.unet_architecture_v3 import UNetV3\n",
    "from src.model_and_training.unet_architecture_v2 import UNetV2\n",
    "\n",
    "log_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f'{log_date}_3d_unet_model3'\n",
    "\n",
    "print(f'Training model with dataset MODEL3')\n",
    "print(f'folder \\'{model_name}\\'')\n",
    "model_info = prepare_model(epochs=50,\n",
    "                           learning_rate=3e-4,\n",
    "                           in_channels=8,\n",
    "                           input_data_channels=1,\n",
    "                           output_label_channels=1,\n",
    "                           dropout_rate=0.2,\n",
    "                           train_batch_size=1,\n",
    "                           model_name=model_name,\n",
    "                           train_dataset=train_dataset, \n",
    "                           valid_dataset=valid_dataset, \n",
    "                           test_dataset=test_dataset,\n",
    "                           model_class=UNetV3) # UNetV3\n",
    "show_model_info(model_info)\n",
    "print('\\n\\n')\n",
    "train_loop(model_info)\n",
    "print('\\n\\n')\n",
    "\n",
    "# UNetV3\n",
    "# Epoch [50] train done\n",
    "# Batch eval [1] loss 0.37472, dsc 0.62528\n",
    "# Batch eval [2] loss 0.39908, dsc 0.60092\n",
    "# Batch eval [3] loss 0.39951, dsc 0.60049\n",
    "# Batch eval [4] loss 0.38327, dsc 0.61673\n",
    "# Batch eval [5] loss 0.36132, dsc 0.63868\n",
    "# Epoch [50] valid done\n",
    "# Epoch [50] T 2145.86s, deltaT 43.58s, loss: train 0.33236, valid 0.38358, dsc: train 0.66764, valid 0.61642\n",
    "\n",
    "# UNetV2\n",
    "# Epoch [50] train done\n",
    "# Batch eval [1] loss 0.23973, dsc 0.76027\n",
    "# Batch eval [2] loss 0.24580, dsc 0.75420\n",
    "# Batch eval [3] loss 0.25798, dsc 0.74202\n",
    "# Batch eval [4] loss 0.24973, dsc 0.75027\n",
    "# Batch eval [5] loss 0.26769, dsc 0.73231\n",
    "# Epoch [50] valid done\n",
    "# Epoch [50] T 1410.82s, deltaT 28.02s, loss: train 0.20945, valid 0.25219, dsc: train 0.79055, valid 0.74781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display((Markdown(\"## Model evaluation\"),))\n",
    "\n",
    "display((Markdown(\"### Train Eval\"),))\n",
    "show_model_dataset_pred_preview(model_info, train_dataset, max_slices=MAX_PADDING_SLICES, default_slice=90)\n",
    "\n",
    "display((Markdown(\"### Valid Eval\"),))\n",
    "show_model_dataset_pred_preview(model_info, valid_dataset, max_slices=MAX_PADDING_SLICES, default_slice=90)\n",
    "\n",
    "# display(Markdown(\"### Test Eval\"))\n",
    "# eval_image_dataset(test_dataset, 78, 'test_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
