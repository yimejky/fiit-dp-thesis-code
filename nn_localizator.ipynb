{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "from src.consts import IN_COLAB, DATASET_MAX_BOUNDING_BOX, DESIRE_BOUNDING_BOX_SIZE\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Found Google Colab')\n",
    "    !pip3 install torch torchvision torchsummary\n",
    "    !pip3 install simpleitk\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import src.dataset.oars_labels_consts as OARS_LABELS\n",
    "from src.helpers.threshold_calc_helpers import get_threshold_info_df\n",
    "from src.helpers.show_model_dataset_pred_preview import show_model_dataset_pred_preview\n",
    "from src.dataset.dataset_cut_helpers import get_full_res_cut, get_cut_lists\n",
    "from src.dataset.get_dataset import get_dataset\n",
    "from src.dataset.get_dataset_info import get_dataset_info\n",
    "from src.dataset.preview_dataset import preview_dataset\n",
    "from src.model_and_training.prepare_model import prepare_model\n",
    "from src.model_and_training.train_loop import train_loop\n",
    "from src.model_and_training.training_helpers import show_model_info\n",
    "from src.helpers.show_cuda_usage import show_cuda_usage\n",
    "from src.helpers.threshold_calc_helpers import get_rescaled_preds\n",
    "from src.dataset.split_dataset import split_dataset, copy_split_dataset\n",
    "from src.helpers.compare_prediction_with_ground_true import compare_prediction_with_ground_true\n",
    "from src.helpers.get_img_outliers_pixels import get_img_outliers_pixels\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "torch.manual_seed(20)\n",
    "logging.basicConfig(filename='nn_local.log', level=logging.DEBUG)\n",
    "\n",
    "print('Dataset biggest bounding box wihtout spinal cord', DATASET_MAX_BOUNDING_BOX)\n",
    "print('Cut target size', DESIRE_BOUNDING_BOX_SIZE)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low resolution NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading low res dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 16x dataset\n",
      "normalizing dataset\n",
      "normalizing done\n",
      "filtering labels\n",
      "filtering labels done\n",
      "dilatating 1x dataset\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n",
      "data type: float64 int8\n",
      "low res dataset RAM sizes in GB 0.06866455078125\n",
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "\n",
    "low_res_dataset = get_dataset(dataset_size=50, shrink_factor=16, filter_labels=filter_labels, unify_labels=True)\n",
    "low_res_dataset.dilatate_labels(repeat=1)\n",
    "low_res_dataset.to_numpy()\n",
    "low_res_dataset.show_data_type()\n",
    "print('low res dataset RAM sizes in GB', low_res_dataset.get_data_size() / 1024**3)\n",
    "\n",
    "low_res_split_dataset_obj = split_dataset(low_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "get_dataset_info(low_res_dataset, low_res_split_dataset_obj)\n",
    "train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset = itemgetter(\n",
    "    'train_dataset', 'valid_dataset', 'test_dataset')(low_res_split_dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 12.505709639268096, min -0.40698009878688973\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e75d874612f414e8b00fcbe01e02046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=79, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b4ab89dd674adaaa4ad099c670c66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(low_res_dataset, preview_index=0, show_hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training low res model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device running \"cuda\"\n",
      "max output channels 128\n",
      "Model number of params: 1193537, trainable 1193537\n",
      "Running training loop\n",
      "Batch train [1] loss 0.97630, dsc 0.02370\n",
      "Batch train [2] loss 0.97167, dsc 0.02833\n",
      "Batch train [3] loss 0.97257, dsc 0.02743\n",
      "Batch train [4] loss 0.96968, dsc 0.03032\n",
      "Batch train [5] loss 0.97364, dsc 0.02636\n",
      "Batch train [6] loss 0.96659, dsc 0.03341\n",
      "Batch train [7] loss 0.95241, dsc 0.04759\n",
      "Batch train [8] loss 0.96548, dsc 0.03452\n",
      "Batch train [9] loss 0.96903, dsc 0.03097\n",
      "Batch train [10] loss 0.96693, dsc 0.03307\n",
      "Batch train [11] loss 0.96506, dsc 0.03494\n",
      "Batch train [12] loss 0.97499, dsc 0.02501\n",
      "Batch train [13] loss 0.95383, dsc 0.04617\n",
      "Batch train [14] loss 0.95650, dsc 0.04350\n",
      "Batch train [15] loss 0.95467, dsc 0.04533\n",
      "Batch train [16] loss 0.96143, dsc 0.03857\n",
      "Batch train [17] loss 0.96529, dsc 0.03471\n",
      "Batch train [18] loss 0.96913, dsc 0.03087\n",
      "Batch train [19] loss 0.96069, dsc 0.03931\n",
      "Batch train [20] loss 0.96139, dsc 0.03861\n",
      "Batch train [21] loss 0.95838, dsc 0.04162\n",
      "Batch train [22] loss 0.97222, dsc 0.02778\n",
      "Batch train [23] loss 0.95840, dsc 0.04160\n",
      "Batch train [24] loss 0.96059, dsc 0.03941\n",
      "Batch train [25] loss 0.95558, dsc 0.04442\n",
      "Batch train [26] loss 0.95188, dsc 0.04812\n",
      "Batch train [27] loss 0.96539, dsc 0.03461\n",
      "Batch train [28] loss 0.95480, dsc 0.04520\n",
      "Batch train [29] loss 0.96610, dsc 0.03390\n",
      "Batch train [30] loss 0.95619, dsc 0.04381\n",
      "Batch train [31] loss 0.94884, dsc 0.05116\n",
      "Batch train [32] loss 0.95539, dsc 0.04461\n",
      "Batch train [33] loss 0.94564, dsc 0.05436\n",
      "Batch train [34] loss 0.95596, dsc 0.04404\n",
      "Batch train [35] loss 0.94251, dsc 0.05749\n",
      "Batch train [36] loss 0.95471, dsc 0.04529\n",
      "Batch train [37] loss 0.95557, dsc 0.04443\n",
      "Batch train [38] loss 0.96648, dsc 0.03352\n",
      "Batch train [39] loss 0.95872, dsc 0.04128\n",
      "Batch train [40] loss 0.95796, dsc 0.04204\n",
      "Epoch [1] train done\n",
      "Batch eval [1] loss 0.97566, dsc 0.02434\n",
      "Batch eval [2] loss 0.97930, dsc 0.02070\n",
      "Batch eval [3] loss 0.97635, dsc 0.02365\n",
      "Batch eval [4] loss 0.98081, dsc 0.01919\n",
      "Batch eval [5] loss 0.97587, dsc 0.02413\n",
      "Epoch [1] valid done\n",
      "Epoch [1] T 7.53s, deltaT 7.53s, loss: train 0.96122, valid 0.97760, dsc: train 0.03878, valid 0.02240\n",
      "Batch train [1] loss 0.94785, dsc 0.05215\n",
      "Batch train [2] loss 0.95496, dsc 0.04504\n",
      "Batch train [3] loss 0.96261, dsc 0.03739\n",
      "Batch train [4] loss 0.97081, dsc 0.02919\n",
      "Batch train [5] loss 0.95816, dsc 0.04184\n",
      "Batch train [6] loss 0.95415, dsc 0.04585\n",
      "Batch train [7] loss 0.96336, dsc 0.03664\n",
      "Batch train [8] loss 0.96408, dsc 0.03592\n",
      "Batch train [9] loss 0.94356, dsc 0.05644\n",
      "Batch train [10] loss 0.94787, dsc 0.05213\n",
      "Batch train [11] loss 0.95912, dsc 0.04088\n",
      "Batch train [12] loss 0.96537, dsc 0.03463\n",
      "Batch train [13] loss 0.95126, dsc 0.04874\n",
      "Batch train [14] loss 0.95720, dsc 0.04280\n",
      "Batch train [15] loss 0.95410, dsc 0.04590\n",
      "Batch train [16] loss 0.95638, dsc 0.04362\n",
      "Batch train [17] loss 0.95181, dsc 0.04819\n",
      "Batch train [18] loss 0.94543, dsc 0.05457\n",
      "Batch train [19] loss 0.95217, dsc 0.04783\n",
      "Batch train [20] loss 0.96122, dsc 0.03878\n",
      "Batch train [21] loss 0.96857, dsc 0.03143\n",
      "Batch train [22] loss 0.96436, dsc 0.03564\n",
      "Batch train [23] loss 0.95860, dsc 0.04140\n",
      "Batch train [24] loss 0.96375, dsc 0.03625\n",
      "Batch train [25] loss 0.95248, dsc 0.04752\n",
      "Batch train [26] loss 0.94672, dsc 0.05328\n",
      "Batch train [27] loss 0.95017, dsc 0.04983\n",
      "Batch train [28] loss 0.94750, dsc 0.05250\n",
      "Batch train [29] loss 0.93756, dsc 0.06244\n",
      "Batch train [30] loss 0.94442, dsc 0.05558\n",
      "Batch train [31] loss 0.95474, dsc 0.04526\n",
      "Batch train [32] loss 0.95201, dsc 0.04799\n",
      "Batch train [33] loss 0.95447, dsc 0.04553\n",
      "Batch train [34] loss 0.95426, dsc 0.04574\n",
      "Batch train [35] loss 0.95474, dsc 0.04526\n",
      "Batch train [36] loss 0.95281, dsc 0.04719\n",
      "Batch train [37] loss 0.95223, dsc 0.04777\n",
      "Batch train [38] loss 0.93665, dsc 0.06335\n",
      "Batch train [39] loss 0.95697, dsc 0.04303\n",
      "Batch train [40] loss 0.95481, dsc 0.04519\n",
      "Epoch [2] train done\n",
      "Batch eval [1] loss 0.94683, dsc 0.05317\n",
      "Batch eval [2] loss 0.95524, dsc 0.04476\n",
      "Batch eval [3] loss 0.95102, dsc 0.04898\n",
      "Batch eval [4] loss 0.95889, dsc 0.04111\n",
      "Batch eval [5] loss 0.94833, dsc 0.05167\n",
      "Epoch [2] valid done\n",
      "Epoch [2] T 15.23s, deltaT 7.71s, loss: train 0.95448, valid 0.95206, dsc: train 0.04552, valid 0.04794\n",
      "Batch train [1] loss 0.96267, dsc 0.03733\n",
      "Batch train [2] loss 0.96080, dsc 0.03920\n",
      "Batch train [3] loss 0.95160, dsc 0.04840\n",
      "Batch train [4] loss 0.94568, dsc 0.05432\n",
      "Batch train [5] loss 0.96790, dsc 0.03210\n",
      "Batch train [6] loss 0.94264, dsc 0.05736\n",
      "Batch train [7] loss 0.93527, dsc 0.06473\n",
      "Batch train [8] loss 0.96166, dsc 0.03834\n",
      "Batch train [9] loss 0.93837, dsc 0.06163\n",
      "Batch train [10] loss 0.95297, dsc 0.04703\n",
      "Batch train [11] loss 0.95845, dsc 0.04155\n",
      "Batch train [12] loss 0.96018, dsc 0.03982\n",
      "Batch train [13] loss 0.94764, dsc 0.05236\n",
      "Batch train [14] loss 0.94947, dsc 0.05053\n",
      "Batch train [15] loss 0.94918, dsc 0.05082\n",
      "Batch train [16] loss 0.95444, dsc 0.04556\n",
      "Batch train [17] loss 0.94810, dsc 0.05190\n",
      "Batch train [18] loss 0.95358, dsc 0.04642\n",
      "Batch train [19] loss 0.95231, dsc 0.04769\n",
      "Batch train [20] loss 0.94701, dsc 0.05299\n",
      "Batch train [21] loss 0.95514, dsc 0.04486\n",
      "Batch train [22] loss 0.95268, dsc 0.04732\n",
      "Batch train [23] loss 0.95163, dsc 0.04837\n",
      "Batch train [24] loss 0.94767, dsc 0.05233\n",
      "Batch train [25] loss 0.95165, dsc 0.04835\n",
      "Batch train [26] loss 0.96092, dsc 0.03908\n",
      "Batch train [27] loss 0.94951, dsc 0.05049\n",
      "Batch train [28] loss 0.95480, dsc 0.04520\n",
      "Batch train [29] loss 0.94824, dsc 0.05176\n",
      "Batch train [30] loss 0.93775, dsc 0.06225\n",
      "Batch train [31] loss 0.94089, dsc 0.05911\n",
      "Batch train [32] loss 0.94205, dsc 0.05795\n",
      "Batch train [33] loss 0.95198, dsc 0.04802\n",
      "Batch train [34] loss 0.95626, dsc 0.04374\n",
      "Batch train [35] loss 0.93850, dsc 0.06150\n",
      "Batch train [36] loss 0.94902, dsc 0.05098\n",
      "Batch train [37] loss 0.96462, dsc 0.03538\n",
      "Batch train [38] loss 0.93124, dsc 0.06876\n",
      "Batch train [39] loss 0.94439, dsc 0.05561\n",
      "Batch train [40] loss 0.94971, dsc 0.05029\n",
      "Epoch [3] train done\n",
      "Batch eval [1] loss 0.94189, dsc 0.05811\n",
      "Batch eval [2] loss 0.95095, dsc 0.04905\n",
      "Batch eval [3] loss 0.94386, dsc 0.05614\n",
      "Batch eval [4] loss 0.95514, dsc 0.04486\n",
      "Batch eval [5] loss 0.94207, dsc 0.05793\n",
      "Epoch [3] valid done\n",
      "Epoch [3] T 22.78s, deltaT 7.54s, loss: train 0.95046, valid 0.94678, dsc: train 0.04954, valid 0.05322\n",
      "Batch train [1] loss 0.94461, dsc 0.05539\n",
      "Batch train [2] loss 0.95956, dsc 0.04044\n",
      "Batch train [3] loss 0.93815, dsc 0.06185\n",
      "Batch train [4] loss 0.95302, dsc 0.04698\n",
      "Batch train [5] loss 0.94975, dsc 0.05025\n",
      "Batch train [6] loss 0.94974, dsc 0.05026\n",
      "Batch train [7] loss 0.95148, dsc 0.04852\n",
      "Batch train [8] loss 0.94611, dsc 0.05389\n",
      "Batch train [9] loss 0.94858, dsc 0.05142\n",
      "Batch train [10] loss 0.95200, dsc 0.04800\n",
      "Batch train [11] loss 0.92986, dsc 0.07014\n",
      "Batch train [12] loss 0.94218, dsc 0.05782\n",
      "Batch train [13] loss 0.94436, dsc 0.05564\n",
      "Batch train [14] loss 0.94345, dsc 0.05655\n",
      "Batch train [15] loss 0.94457, dsc 0.05543\n",
      "Batch train [16] loss 0.93578, dsc 0.06422\n",
      "Batch train [17] loss 0.95661, dsc 0.04339\n",
      "Batch train [18] loss 0.96319, dsc 0.03681\n",
      "Batch train [19] loss 0.94528, dsc 0.05472\n",
      "Batch train [20] loss 0.93783, dsc 0.06217\n",
      "Batch train [21] loss 0.96384, dsc 0.03616\n",
      "Batch train [22] loss 0.95717, dsc 0.04283\n",
      "Batch train [23] loss 0.94530, dsc 0.05470\n",
      "Batch train [24] loss 0.95729, dsc 0.04271\n",
      "Batch train [25] loss 0.95468, dsc 0.04532\n",
      "Batch train [26] loss 0.94456, dsc 0.05544\n",
      "Batch train [27] loss 0.94780, dsc 0.05220\n",
      "Batch train [28] loss 0.94321, dsc 0.05679\n",
      "Batch train [29] loss 0.95252, dsc 0.04748\n",
      "Batch train [30] loss 0.94636, dsc 0.05364\n",
      "Batch train [31] loss 0.92603, dsc 0.07397\n",
      "Batch train [32] loss 0.92924, dsc 0.07076\n",
      "Batch train [33] loss 0.95237, dsc 0.04763\n",
      "Batch train [34] loss 0.93381, dsc 0.06619\n",
      "Batch train [35] loss 0.94562, dsc 0.05438\n",
      "Batch train [36] loss 0.94712, dsc 0.05288\n",
      "Batch train [37] loss 0.94412, dsc 0.05588\n",
      "Batch train [38] loss 0.93542, dsc 0.06458\n",
      "Batch train [39] loss 0.93642, dsc 0.06358\n",
      "Batch train [40] loss 0.94512, dsc 0.05488\n",
      "Epoch [4] train done\n",
      "Batch eval [1] loss 0.92717, dsc 0.07283\n",
      "Batch eval [2] loss 0.93931, dsc 0.06069\n",
      "Batch eval [3] loss 0.93051, dsc 0.06949\n",
      "Batch eval [4] loss 0.94416, dsc 0.05584\n",
      "Batch eval [5] loss 0.92911, dsc 0.07089\n",
      "Epoch [4] valid done\n",
      "Epoch [4] T 30.31s, deltaT 7.53s, loss: train 0.94610, valid 0.93405, dsc: train 0.05390, valid 0.06595\n",
      "Batch train [1] loss 0.94579, dsc 0.05421\n",
      "Batch train [2] loss 0.94181, dsc 0.05819\n",
      "Batch train [3] loss 0.96195, dsc 0.03805\n",
      "Batch train [4] loss 0.93218, dsc 0.06782\n",
      "Batch train [5] loss 0.93303, dsc 0.06697\n",
      "Batch train [6] loss 0.94579, dsc 0.05421\n",
      "Batch train [7] loss 0.94396, dsc 0.05604\n",
      "Batch train [8] loss 0.94507, dsc 0.05493\n",
      "Batch train [9] loss 0.93729, dsc 0.06271\n",
      "Batch train [10] loss 0.95207, dsc 0.04793\n",
      "Batch train [11] loss 0.94622, dsc 0.05378\n",
      "Batch train [12] loss 0.94745, dsc 0.05255\n",
      "Batch train [13] loss 0.94101, dsc 0.05899\n",
      "Batch train [14] loss 0.94966, dsc 0.05034\n",
      "Batch train [15] loss 0.94911, dsc 0.05089\n",
      "Batch train [16] loss 0.93336, dsc 0.06664\n",
      "Batch train [17] loss 0.93793, dsc 0.06207\n",
      "Batch train [18] loss 0.94211, dsc 0.05789\n",
      "Batch train [19] loss 0.92957, dsc 0.07043\n",
      "Batch train [20] loss 0.94622, dsc 0.05378\n",
      "Batch train [21] loss 0.95347, dsc 0.04653\n",
      "Batch train [22] loss 0.92679, dsc 0.07321\n",
      "Batch train [23] loss 0.92373, dsc 0.07627\n",
      "Batch train [24] loss 0.93082, dsc 0.06918\n",
      "Batch train [25] loss 0.95079, dsc 0.04921\n",
      "Batch train [26] loss 0.93518, dsc 0.06482\n",
      "Batch train [27] loss 0.91878, dsc 0.08122\n",
      "Batch train [28] loss 0.94138, dsc 0.05862\n",
      "Batch train [29] loss 0.95245, dsc 0.04755\n",
      "Batch train [30] loss 0.95156, dsc 0.04844\n",
      "Batch train [31] loss 0.95780, dsc 0.04220\n",
      "Batch train [32] loss 0.93909, dsc 0.06091\n",
      "Batch train [33] loss 0.93568, dsc 0.06432\n",
      "Batch train [34] loss 0.93718, dsc 0.06282\n",
      "Batch train [35] loss 0.93692, dsc 0.06308\n",
      "Batch train [36] loss 0.93730, dsc 0.06270\n",
      "Batch train [37] loss 0.93975, dsc 0.06025\n",
      "Batch train [38] loss 0.93371, dsc 0.06629\n",
      "Batch train [39] loss 0.94033, dsc 0.05967\n",
      "Batch train [40] loss 0.91664, dsc 0.08336\n",
      "Epoch [5] train done\n",
      "Batch eval [1] loss 0.92482, dsc 0.07518\n",
      "Batch eval [2] loss 0.93689, dsc 0.06311\n",
      "Batch eval [3] loss 0.92771, dsc 0.07229\n",
      "Batch eval [4] loss 0.94255, dsc 0.05745\n",
      "Batch eval [5] loss 0.92668, dsc 0.07332\n",
      "Epoch [5] valid done\n",
      "Epoch [5] T 37.83s, deltaT 7.52s, loss: train 0.94052, valid 0.93173, dsc: train 0.05948, valid 0.06827\n",
      "Batch train [1] loss 0.92072, dsc 0.07928\n",
      "Batch train [2] loss 0.91544, dsc 0.08456\n",
      "Batch train [3] loss 0.91569, dsc 0.08431\n",
      "Batch train [4] loss 0.94543, dsc 0.05457\n",
      "Batch train [5] loss 0.94025, dsc 0.05975\n",
      "Batch train [6] loss 0.92329, dsc 0.07671\n",
      "Batch train [7] loss 0.93148, dsc 0.06852\n",
      "Batch train [8] loss 0.93104, dsc 0.06896\n",
      "Batch train [9] loss 0.94233, dsc 0.05767\n",
      "Batch train [10] loss 0.93735, dsc 0.06265\n",
      "Batch train [11] loss 0.93198, dsc 0.06802\n",
      "Batch train [12] loss 0.92494, dsc 0.07506\n",
      "Batch train [13] loss 0.95645, dsc 0.04355\n",
      "Batch train [14] loss 0.93434, dsc 0.06566\n",
      "Batch train [15] loss 0.92239, dsc 0.07761\n",
      "Batch train [16] loss 0.92622, dsc 0.07378\n",
      "Batch train [17] loss 0.93142, dsc 0.06858\n",
      "Batch train [18] loss 0.94347, dsc 0.05653\n",
      "Batch train [19] loss 0.93559, dsc 0.06441\n",
      "Batch train [20] loss 0.93218, dsc 0.06782\n",
      "Batch train [21] loss 0.92307, dsc 0.07693\n",
      "Batch train [22] loss 0.94692, dsc 0.05308\n",
      "Batch train [23] loss 0.93357, dsc 0.06643\n",
      "Batch train [24] loss 0.93120, dsc 0.06880\n",
      "Batch train [25] loss 0.94746, dsc 0.05254\n",
      "Batch train [26] loss 0.93239, dsc 0.06761\n",
      "Batch train [27] loss 0.93551, dsc 0.06449\n",
      "Batch train [28] loss 0.95296, dsc 0.04704\n",
      "Batch train [29] loss 0.93395, dsc 0.06605\n",
      "Batch train [30] loss 0.94673, dsc 0.05327\n",
      "Batch train [31] loss 0.92956, dsc 0.07044\n",
      "Batch train [32] loss 0.93414, dsc 0.06586\n",
      "Batch train [33] loss 0.93357, dsc 0.06643\n",
      "Batch train [34] loss 0.91741, dsc 0.08259\n",
      "Batch train [35] loss 0.93755, dsc 0.06245\n",
      "Batch train [36] loss 0.94305, dsc 0.05695\n",
      "Batch train [37] loss 0.93331, dsc 0.06669\n",
      "Batch train [38] loss 0.94220, dsc 0.05780\n",
      "Batch train [39] loss 0.92534, dsc 0.07466\n",
      "Batch train [40] loss 0.93538, dsc 0.06462\n",
      "Epoch [6] train done\n",
      "Batch eval [1] loss 0.91760, dsc 0.08240\n",
      "Batch eval [2] loss 0.92903, dsc 0.07097\n",
      "Batch eval [3] loss 0.91965, dsc 0.08035\n",
      "Batch eval [4] loss 0.93693, dsc 0.06307\n",
      "Batch eval [5] loss 0.91986, dsc 0.08014\n",
      "Epoch [6] valid done\n",
      "Epoch [6] T 45.29s, deltaT 7.46s, loss: train 0.93393, valid 0.92461, dsc: train 0.06607, valid 0.07539\n",
      "Batch train [1] loss 0.91135, dsc 0.08865\n",
      "Batch train [2] loss 0.92730, dsc 0.07270\n",
      "Batch train [3] loss 0.94469, dsc 0.05531\n",
      "Batch train [4] loss 0.91765, dsc 0.08235\n",
      "Batch train [5] loss 0.93197, dsc 0.06803\n",
      "Batch train [6] loss 0.94416, dsc 0.05584\n",
      "Batch train [7] loss 0.93219, dsc 0.06781\n",
      "Batch train [8] loss 0.95032, dsc 0.04968\n",
      "Batch train [9] loss 0.93110, dsc 0.06890\n",
      "Batch train [10] loss 0.91246, dsc 0.08754\n",
      "Batch train [11] loss 0.92142, dsc 0.07858\n",
      "Batch train [12] loss 0.94213, dsc 0.05787\n",
      "Batch train [13] loss 0.91653, dsc 0.08347\n",
      "Batch train [14] loss 0.92326, dsc 0.07674\n",
      "Batch train [15] loss 0.90306, dsc 0.09694\n",
      "Batch train [16] loss 0.92288, dsc 0.07712\n",
      "Batch train [17] loss 0.93662, dsc 0.06338\n",
      "Batch train [18] loss 0.91125, dsc 0.08875\n",
      "Batch train [19] loss 0.92766, dsc 0.07234\n",
      "Batch train [20] loss 0.92323, dsc 0.07677\n",
      "Batch train [21] loss 0.92628, dsc 0.07372\n",
      "Batch train [22] loss 0.91487, dsc 0.08513\n",
      "Batch train [23] loss 0.92193, dsc 0.07807\n",
      "Batch train [24] loss 0.93865, dsc 0.06135\n",
      "Batch train [25] loss 0.91845, dsc 0.08155\n",
      "Batch train [26] loss 0.93093, dsc 0.06907\n",
      "Batch train [27] loss 0.92542, dsc 0.07458\n",
      "Batch train [28] loss 0.89867, dsc 0.10133\n",
      "Batch train [29] loss 0.93391, dsc 0.06609\n",
      "Batch train [30] loss 0.92607, dsc 0.07393\n",
      "Batch train [31] loss 0.90810, dsc 0.09190\n",
      "Batch train [32] loss 0.92188, dsc 0.07812\n",
      "Batch train [33] loss 0.92170, dsc 0.07830\n",
      "Batch train [34] loss 0.92867, dsc 0.07133\n",
      "Batch train [35] loss 0.92766, dsc 0.07234\n",
      "Batch train [36] loss 0.92321, dsc 0.07679\n",
      "Batch train [37] loss 0.94628, dsc 0.05372\n",
      "Batch train [38] loss 0.91429, dsc 0.08571\n",
      "Batch train [39] loss 0.93433, dsc 0.06567\n",
      "Batch train [40] loss 0.91776, dsc 0.08224\n",
      "Epoch [7] train done\n",
      "Batch eval [1] loss 0.91560, dsc 0.08440\n",
      "Batch eval [2] loss 0.92498, dsc 0.07502\n",
      "Batch eval [3] loss 0.91613, dsc 0.08387\n",
      "Batch eval [4] loss 0.93361, dsc 0.06639\n",
      "Batch eval [5] loss 0.91517, dsc 0.08483\n",
      "Epoch [7] valid done\n",
      "Epoch [7] T 52.88s, deltaT 7.59s, loss: train 0.92526, valid 0.92110, dsc: train 0.07474, valid 0.07890\n",
      "Batch train [1] loss 0.91913, dsc 0.08087\n",
      "Batch train [2] loss 0.91332, dsc 0.08668\n",
      "Batch train [3] loss 0.93625, dsc 0.06375\n",
      "Batch train [4] loss 0.91992, dsc 0.08008\n",
      "Batch train [5] loss 0.91407, dsc 0.08593\n",
      "Batch train [6] loss 0.92916, dsc 0.07084\n",
      "Batch train [7] loss 0.92076, dsc 0.07924\n",
      "Batch train [8] loss 0.90129, dsc 0.09871\n",
      "Batch train [9] loss 0.91426, dsc 0.08574\n",
      "Batch train [10] loss 0.91945, dsc 0.08055\n",
      "Batch train [11] loss 0.92415, dsc 0.07585\n",
      "Batch train [12] loss 0.92006, dsc 0.07994\n",
      "Batch train [13] loss 0.91552, dsc 0.08448\n",
      "Batch train [14] loss 0.90294, dsc 0.09706\n",
      "Batch train [15] loss 0.92723, dsc 0.07277\n",
      "Batch train [16] loss 0.90415, dsc 0.09585\n",
      "Batch train [17] loss 0.90226, dsc 0.09774\n",
      "Batch train [18] loss 0.92951, dsc 0.07049\n",
      "Batch train [19] loss 0.90876, dsc 0.09124\n",
      "Batch train [20] loss 0.91570, dsc 0.08430\n",
      "Batch train [21] loss 0.94119, dsc 0.05881\n",
      "Batch train [22] loss 0.93901, dsc 0.06099\n",
      "Batch train [23] loss 0.90970, dsc 0.09030\n",
      "Batch train [24] loss 0.90639, dsc 0.09361\n",
      "Batch train [25] loss 0.90704, dsc 0.09296\n",
      "Batch train [26] loss 0.92606, dsc 0.07394\n",
      "Batch train [27] loss 0.92944, dsc 0.07056\n",
      "Batch train [28] loss 0.88322, dsc 0.11678\n",
      "Batch train [29] loss 0.91297, dsc 0.08703\n",
      "Batch train [30] loss 0.92857, dsc 0.07143\n",
      "Batch train [31] loss 0.91416, dsc 0.08584\n",
      "Batch train [32] loss 0.88988, dsc 0.11012\n",
      "Batch train [33] loss 0.90785, dsc 0.09215\n",
      "Batch train [34] loss 0.90676, dsc 0.09324\n",
      "Batch train [35] loss 0.91571, dsc 0.08429\n",
      "Batch train [36] loss 0.91629, dsc 0.08371\n",
      "Batch train [37] loss 0.88304, dsc 0.11696\n",
      "Batch train [38] loss 0.90973, dsc 0.09027\n",
      "Batch train [39] loss 0.88805, dsc 0.11195\n",
      "Batch train [40] loss 0.87566, dsc 0.12434\n",
      "Epoch [8] train done\n",
      "Batch eval [1] loss 0.90001, dsc 0.09999\n",
      "Batch eval [2] loss 0.91105, dsc 0.08895\n",
      "Batch eval [3] loss 0.90284, dsc 0.09716\n",
      "Batch eval [4] loss 0.92662, dsc 0.07338\n",
      "Batch eval [5] loss 0.90237, dsc 0.09763\n",
      "Epoch [8] valid done\n",
      "Epoch [8] T 60.68s, deltaT 7.81s, loss: train 0.91322, valid 0.90858, dsc: train 0.08678, valid 0.09142\n",
      "Batch train [1] loss 0.90801, dsc 0.09199\n",
      "Batch train [2] loss 0.90075, dsc 0.09925\n",
      "Batch train [3] loss 0.89581, dsc 0.10419\n",
      "Batch train [4] loss 0.91333, dsc 0.08667\n",
      "Batch train [5] loss 0.90656, dsc 0.09344\n",
      "Batch train [6] loss 0.90564, dsc 0.09436\n",
      "Batch train [7] loss 0.89077, dsc 0.10923\n",
      "Batch train [8] loss 0.87002, dsc 0.12998\n",
      "Batch train [9] loss 0.91030, dsc 0.08970\n",
      "Batch train [10] loss 0.93149, dsc 0.06851\n",
      "Batch train [11] loss 0.90316, dsc 0.09684\n",
      "Batch train [12] loss 0.89665, dsc 0.10335\n",
      "Batch train [13] loss 0.91358, dsc 0.08642\n",
      "Batch train [14] loss 0.91724, dsc 0.08276\n",
      "Batch train [15] loss 0.87189, dsc 0.12811\n",
      "Batch train [16] loss 0.89435, dsc 0.10565\n",
      "Batch train [17] loss 0.91580, dsc 0.08420\n",
      "Batch train [18] loss 0.89477, dsc 0.10523\n",
      "Batch train [19] loss 0.91737, dsc 0.08263\n",
      "Batch train [20] loss 0.88242, dsc 0.11758\n",
      "Batch train [21] loss 0.88804, dsc 0.11196\n",
      "Batch train [22] loss 0.89200, dsc 0.10800\n",
      "Batch train [23] loss 0.91718, dsc 0.08282\n",
      "Batch train [24] loss 0.86215, dsc 0.13785\n",
      "Batch train [25] loss 0.88893, dsc 0.11107\n",
      "Batch train [26] loss 0.89750, dsc 0.10250\n",
      "Batch train [27] loss 0.88409, dsc 0.11591\n",
      "Batch train [28] loss 0.89325, dsc 0.10675\n",
      "Batch train [29] loss 0.92941, dsc 0.07059\n",
      "Batch train [30] loss 0.88859, dsc 0.11141\n",
      "Batch train [31] loss 0.86748, dsc 0.13252\n",
      "Batch train [32] loss 0.87193, dsc 0.12807\n",
      "Batch train [33] loss 0.89559, dsc 0.10441\n",
      "Batch train [34] loss 0.90181, dsc 0.09819\n",
      "Batch train [35] loss 0.86514, dsc 0.13486\n",
      "Batch train [36] loss 0.88707, dsc 0.11293\n",
      "Batch train [37] loss 0.90819, dsc 0.09181\n",
      "Batch train [38] loss 0.88720, dsc 0.11280\n",
      "Batch train [39] loss 0.86012, dsc 0.13988\n",
      "Batch train [40] loss 0.88069, dsc 0.11931\n",
      "Epoch [9] train done\n",
      "Batch eval [1] loss 0.87468, dsc 0.12532\n",
      "Batch eval [2] loss 0.88766, dsc 0.11234\n",
      "Batch eval [3] loss 0.87574, dsc 0.12426\n",
      "Batch eval [4] loss 0.90140, dsc 0.09860\n",
      "Batch eval [5] loss 0.87201, dsc 0.12799\n",
      "Epoch [9] valid done\n",
      "Epoch [9] T 68.34s, deltaT 7.65s, loss: train 0.89516, valid 0.88230, dsc: train 0.10484, valid 0.11770\n",
      "Batch train [1] loss 0.90382, dsc 0.09618\n",
      "Batch train [2] loss 0.87372, dsc 0.12628\n",
      "Batch train [3] loss 0.91545, dsc 0.08455\n",
      "Batch train [4] loss 0.85907, dsc 0.14093\n",
      "Batch train [5] loss 0.91503, dsc 0.08497\n",
      "Batch train [6] loss 0.85290, dsc 0.14710\n",
      "Batch train [7] loss 0.85801, dsc 0.14199\n",
      "Batch train [8] loss 0.84834, dsc 0.15166\n",
      "Batch train [9] loss 0.86642, dsc 0.13358\n",
      "Batch train [10] loss 0.87307, dsc 0.12693\n",
      "Batch train [11] loss 0.87545, dsc 0.12455\n",
      "Batch train [12] loss 0.86609, dsc 0.13391\n",
      "Batch train [13] loss 0.86840, dsc 0.13160\n",
      "Batch train [14] loss 0.85459, dsc 0.14541\n",
      "Batch train [15] loss 0.87548, dsc 0.12452\n",
      "Batch train [16] loss 0.88064, dsc 0.11936\n",
      "Batch train [17] loss 0.86196, dsc 0.13804\n",
      "Batch train [18] loss 0.87000, dsc 0.13000\n",
      "Batch train [19] loss 0.84101, dsc 0.15899\n",
      "Batch train [20] loss 0.85538, dsc 0.14462\n",
      "Batch train [21] loss 0.87957, dsc 0.12043\n",
      "Batch train [22] loss 0.86005, dsc 0.13995\n",
      "Batch train [23] loss 0.85187, dsc 0.14813\n",
      "Batch train [24] loss 0.82007, dsc 0.17993\n",
      "Batch train [25] loss 0.84565, dsc 0.15435\n",
      "Batch train [26] loss 0.87248, dsc 0.12752\n",
      "Batch train [27] loss 0.80396, dsc 0.19604\n",
      "Batch train [28] loss 0.83300, dsc 0.16700\n",
      "Batch train [29] loss 0.85070, dsc 0.14930\n",
      "Batch train [30] loss 0.84645, dsc 0.15355\n",
      "Batch train [31] loss 0.79542, dsc 0.20458\n",
      "Batch train [32] loss 0.86985, dsc 0.13015\n",
      "Batch train [33] loss 0.85405, dsc 0.14595\n",
      "Batch train [34] loss 0.85767, dsc 0.14233\n",
      "Batch train [35] loss 0.84036, dsc 0.15964\n",
      "Batch train [36] loss 0.79675, dsc 0.20325\n",
      "Batch train [37] loss 0.83113, dsc 0.16887\n",
      "Batch train [38] loss 0.82501, dsc 0.17499\n",
      "Batch train [39] loss 0.81990, dsc 0.18010\n",
      "Batch train [40] loss 0.86310, dsc 0.13690\n",
      "Epoch [10] train done\n",
      "Batch eval [1] loss 0.83931, dsc 0.16069\n",
      "Batch eval [2] loss 0.85938, dsc 0.14062\n",
      "Batch eval [3] loss 0.84793, dsc 0.15207\n",
      "Batch eval [4] loss 0.85845, dsc 0.14155\n",
      "Batch eval [5] loss 0.83997, dsc 0.16003\n",
      "Epoch [10] valid done\n",
      "Epoch [10] T 76.11s, deltaT 7.77s, loss: train 0.85580, valid 0.84901, dsc: train 0.14420, valid 0.15099\n",
      "Batch train [1] loss 0.80986, dsc 0.19014\n",
      "Batch train [2] loss 0.84404, dsc 0.15596\n",
      "Batch train [3] loss 0.80044, dsc 0.19956\n",
      "Batch train [4] loss 0.83335, dsc 0.16665\n",
      "Batch train [5] loss 0.87926, dsc 0.12074\n",
      "Batch train [6] loss 0.82884, dsc 0.17116\n",
      "Batch train [7] loss 0.82716, dsc 0.17284\n",
      "Batch train [8] loss 0.80446, dsc 0.19554\n",
      "Batch train [9] loss 0.84565, dsc 0.15435\n",
      "Batch train [10] loss 0.80559, dsc 0.19441\n",
      "Batch train [11] loss 0.77408, dsc 0.22592\n",
      "Batch train [12] loss 0.84020, dsc 0.15980\n",
      "Batch train [13] loss 0.80154, dsc 0.19846\n",
      "Batch train [14] loss 0.83314, dsc 0.16686\n",
      "Batch train [15] loss 0.76065, dsc 0.23935\n",
      "Batch train [16] loss 0.81234, dsc 0.18766\n",
      "Batch train [17] loss 0.79910, dsc 0.20090\n",
      "Batch train [18] loss 0.82160, dsc 0.17840\n",
      "Batch train [19] loss 0.79902, dsc 0.20098\n",
      "Batch train [20] loss 0.81018, dsc 0.18982\n",
      "Batch train [21] loss 0.80421, dsc 0.19579\n",
      "Batch train [22] loss 0.81321, dsc 0.18679\n",
      "Batch train [23] loss 0.78704, dsc 0.21296\n",
      "Batch train [24] loss 0.81786, dsc 0.18214\n",
      "Batch train [25] loss 0.80018, dsc 0.19982\n",
      "Batch train [26] loss 0.84679, dsc 0.15321\n",
      "Batch train [27] loss 0.82769, dsc 0.17231\n",
      "Batch train [28] loss 0.82448, dsc 0.17552\n",
      "Batch train [29] loss 0.78654, dsc 0.21346\n",
      "Batch train [30] loss 0.75714, dsc 0.24286\n",
      "Batch train [31] loss 0.75141, dsc 0.24859\n",
      "Batch train [32] loss 0.78389, dsc 0.21611\n",
      "Batch train [33] loss 0.78366, dsc 0.21634\n",
      "Batch train [34] loss 0.72524, dsc 0.27476\n",
      "Batch train [35] loss 0.74455, dsc 0.25545\n",
      "Batch train [36] loss 0.76237, dsc 0.23763\n",
      "Batch train [37] loss 0.78192, dsc 0.21808\n",
      "Batch train [38] loss 0.76860, dsc 0.23140\n",
      "Batch train [39] loss 0.80702, dsc 0.19298\n",
      "Batch train [40] loss 0.75692, dsc 0.24308\n",
      "Epoch [11] train done\n",
      "Batch eval [1] loss 0.72455, dsc 0.27545\n",
      "Batch eval [2] loss 0.75752, dsc 0.24248\n",
      "Batch eval [3] loss 0.73734, dsc 0.26266\n",
      "Batch eval [4] loss 0.78661, dsc 0.21339\n",
      "Batch eval [5] loss 0.73868, dsc 0.26132\n",
      "Epoch [11] valid done\n",
      "Epoch [11] T 83.93s, deltaT 7.82s, loss: train 0.80153, valid 0.74894, dsc: train 0.19847, valid 0.25106\n",
      "Batch train [1] loss 0.70341, dsc 0.29659\n",
      "Batch train [2] loss 0.74716, dsc 0.25284\n",
      "Batch train [3] loss 0.73587, dsc 0.26413\n",
      "Batch train [4] loss 0.82299, dsc 0.17701\n",
      "Batch train [5] loss 0.74338, dsc 0.25662\n",
      "Batch train [6] loss 0.75678, dsc 0.24322\n",
      "Batch train [7] loss 0.75267, dsc 0.24733\n",
      "Batch train [8] loss 0.73542, dsc 0.26458\n",
      "Batch train [9] loss 0.74648, dsc 0.25352\n",
      "Batch train [10] loss 0.73498, dsc 0.26502\n",
      "Batch train [11] loss 0.72969, dsc 0.27031\n",
      "Batch train [12] loss 0.76187, dsc 0.23813\n",
      "Batch train [13] loss 0.72982, dsc 0.27018\n",
      "Batch train [14] loss 0.73129, dsc 0.26871\n",
      "Batch train [15] loss 0.69357, dsc 0.30643\n",
      "Batch train [16] loss 0.77622, dsc 0.22378\n",
      "Batch train [17] loss 0.75343, dsc 0.24657\n",
      "Batch train [18] loss 0.69287, dsc 0.30713\n",
      "Batch train [19] loss 0.66355, dsc 0.33645\n",
      "Batch train [20] loss 0.72105, dsc 0.27895\n",
      "Batch train [21] loss 0.72359, dsc 0.27641\n",
      "Batch train [22] loss 0.75645, dsc 0.24355\n",
      "Batch train [23] loss 0.74333, dsc 0.25667\n",
      "Batch train [24] loss 0.74315, dsc 0.25685\n",
      "Batch train [25] loss 0.75545, dsc 0.24455\n",
      "Batch train [26] loss 0.75102, dsc 0.24898\n",
      "Batch train [27] loss 0.69830, dsc 0.30170\n",
      "Batch train [28] loss 0.66193, dsc 0.33807\n",
      "Batch train [29] loss 0.72340, dsc 0.27660\n",
      "Batch train [30] loss 0.65666, dsc 0.34334\n",
      "Batch train [31] loss 0.70093, dsc 0.29907\n",
      "Batch train [32] loss 0.69841, dsc 0.30159\n",
      "Batch train [33] loss 0.69065, dsc 0.30935\n",
      "Batch train [34] loss 0.67878, dsc 0.32122\n",
      "Batch train [35] loss 0.67469, dsc 0.32531\n",
      "Batch train [36] loss 0.73616, dsc 0.26384\n",
      "Batch train [37] loss 0.68545, dsc 0.31455\n",
      "Batch train [38] loss 0.63846, dsc 0.36154\n",
      "Batch train [39] loss 0.76923, dsc 0.23077\n",
      "Batch train [40] loss 0.69468, dsc 0.30532\n",
      "Epoch [12] train done\n",
      "Batch eval [1] loss 0.64723, dsc 0.35277\n",
      "Batch eval [2] loss 0.68171, dsc 0.31829\n",
      "Batch eval [3] loss 0.65609, dsc 0.34391\n",
      "Batch eval [4] loss 0.72614, dsc 0.27386\n",
      "Batch eval [5] loss 0.66505, dsc 0.33495\n",
      "Epoch [12] valid done\n",
      "Epoch [12] T 91.73s, deltaT 7.80s, loss: train 0.72283, valid 0.67524, dsc: train 0.27717, valid 0.32476\n",
      "Batch train [1] loss 0.70672, dsc 0.29328\n",
      "Batch train [2] loss 0.62728, dsc 0.37272\n",
      "Batch train [3] loss 0.70728, dsc 0.29272\n",
      "Batch train [4] loss 0.61772, dsc 0.38228\n",
      "Batch train [5] loss 0.64220, dsc 0.35780\n",
      "Batch train [6] loss 0.70405, dsc 0.29595\n",
      "Batch train [7] loss 0.65821, dsc 0.34179\n",
      "Batch train [8] loss 0.65743, dsc 0.34257\n",
      "Batch train [9] loss 0.64620, dsc 0.35380\n",
      "Batch train [10] loss 0.64281, dsc 0.35719\n",
      "Batch train [11] loss 0.63304, dsc 0.36696\n",
      "Batch train [12] loss 0.60755, dsc 0.39245\n",
      "Batch train [13] loss 0.67007, dsc 0.32993\n",
      "Batch train [14] loss 0.64133, dsc 0.35867\n",
      "Batch train [15] loss 0.67028, dsc 0.32972\n",
      "Batch train [16] loss 0.72401, dsc 0.27599\n",
      "Batch train [17] loss 0.64061, dsc 0.35939\n",
      "Batch train [18] loss 0.61002, dsc 0.38998\n",
      "Batch train [19] loss 0.63000, dsc 0.37000\n",
      "Batch train [20] loss 0.63872, dsc 0.36128\n",
      "Batch train [21] loss 0.64458, dsc 0.35542\n",
      "Batch train [22] loss 0.66919, dsc 0.33081\n",
      "Batch train [23] loss 0.64726, dsc 0.35274\n",
      "Batch train [24] loss 0.60574, dsc 0.39426\n",
      "Batch train [25] loss 0.62460, dsc 0.37540\n",
      "Batch train [26] loss 0.61794, dsc 0.38206\n",
      "Batch train [27] loss 0.59332, dsc 0.40668\n",
      "Batch train [28] loss 0.65490, dsc 0.34510\n",
      "Batch train [29] loss 0.70609, dsc 0.29391\n",
      "Batch train [30] loss 0.60164, dsc 0.39836\n",
      "Batch train [31] loss 0.65278, dsc 0.34722\n",
      "Batch train [32] loss 0.60207, dsc 0.39793\n",
      "Batch train [33] loss 0.58216, dsc 0.41784\n",
      "Batch train [34] loss 0.57081, dsc 0.42919\n",
      "Batch train [35] loss 0.60315, dsc 0.39685\n",
      "Batch train [36] loss 0.52516, dsc 0.47484\n",
      "Batch train [37] loss 0.53357, dsc 0.46643\n",
      "Batch train [38] loss 0.50496, dsc 0.49504\n",
      "Batch train [39] loss 0.53816, dsc 0.46184\n",
      "Batch train [40] loss 0.58357, dsc 0.41643\n",
      "Epoch [13] train done\n",
      "Batch eval [1] loss 0.54659, dsc 0.45341\n",
      "Batch eval [2] loss 0.58694, dsc 0.41306\n",
      "Batch eval [3] loss 0.54514, dsc 0.45486\n",
      "Batch eval [4] loss 0.62386, dsc 0.37614\n",
      "Batch eval [5] loss 0.56237, dsc 0.43763\n",
      "Epoch [13] valid done\n",
      "Epoch [13] T 99.61s, deltaT 7.88s, loss: train 0.62843, valid 0.57298, dsc: train 0.37157, valid 0.42702\n",
      "Batch train [1] loss 0.56109, dsc 0.43891\n",
      "Batch train [2] loss 0.57954, dsc 0.42046\n",
      "Batch train [3] loss 0.48514, dsc 0.51486\n",
      "Batch train [4] loss 0.60252, dsc 0.39748\n",
      "Batch train [5] loss 0.51162, dsc 0.48838\n",
      "Batch train [6] loss 0.53231, dsc 0.46769\n",
      "Batch train [7] loss 0.55428, dsc 0.44572\n",
      "Batch train [8] loss 0.54248, dsc 0.45752\n",
      "Batch train [9] loss 0.54088, dsc 0.45912\n",
      "Batch train [10] loss 0.59771, dsc 0.40229\n",
      "Batch train [11] loss 0.53043, dsc 0.46957\n",
      "Batch train [12] loss 0.54333, dsc 0.45667\n",
      "Batch train [13] loss 0.60749, dsc 0.39251\n",
      "Batch train [14] loss 0.49049, dsc 0.50951\n",
      "Batch train [15] loss 0.58938, dsc 0.41062\n",
      "Batch train [16] loss 0.49437, dsc 0.50563\n",
      "Batch train [17] loss 0.58138, dsc 0.41862\n",
      "Batch train [18] loss 0.53888, dsc 0.46112\n",
      "Batch train [19] loss 0.47678, dsc 0.52322\n",
      "Batch train [20] loss 0.52328, dsc 0.47672\n",
      "Batch train [21] loss 0.52684, dsc 0.47316\n",
      "Batch train [22] loss 0.51468, dsc 0.48532\n",
      "Batch train [23] loss 0.50672, dsc 0.49328\n",
      "Batch train [24] loss 0.51501, dsc 0.48499\n",
      "Batch train [25] loss 0.53798, dsc 0.46202\n",
      "Batch train [26] loss 0.61831, dsc 0.38169\n",
      "Batch train [27] loss 0.52334, dsc 0.47666\n",
      "Batch train [28] loss 0.54163, dsc 0.45837\n",
      "Batch train [29] loss 0.52695, dsc 0.47305\n",
      "Batch train [30] loss 0.48152, dsc 0.51848\n",
      "Batch train [31] loss 0.52303, dsc 0.47697\n",
      "Batch train [32] loss 0.53174, dsc 0.46826\n",
      "Batch train [33] loss 0.49942, dsc 0.50058\n",
      "Batch train [34] loss 0.60330, dsc 0.39670\n",
      "Batch train [35] loss 0.51102, dsc 0.48898\n",
      "Batch train [36] loss 0.53714, dsc 0.46286\n",
      "Batch train [37] loss 0.47229, dsc 0.52771\n",
      "Batch train [38] loss 0.43496, dsc 0.56504\n",
      "Batch train [39] loss 0.50712, dsc 0.49288\n",
      "Batch train [40] loss 0.49333, dsc 0.50667\n",
      "Epoch [14] train done\n",
      "Batch eval [1] loss 0.51585, dsc 0.48415\n",
      "Batch eval [2] loss 0.55229, dsc 0.44771\n",
      "Batch eval [3] loss 0.49988, dsc 0.50012\n",
      "Batch eval [4] loss 0.59640, dsc 0.40360\n",
      "Batch eval [5] loss 0.51752, dsc 0.48248\n",
      "Epoch [14] valid done\n",
      "Epoch [14] T 107.43s, deltaT 7.82s, loss: train 0.53224, valid 0.53639, dsc: train 0.46776, valid 0.46361\n",
      "Batch train [1] loss 0.60748, dsc 0.39252\n",
      "Batch train [2] loss 0.44757, dsc 0.55243\n",
      "Batch train [3] loss 0.43469, dsc 0.56531\n",
      "Batch train [4] loss 0.52711, dsc 0.47289\n",
      "Batch train [5] loss 0.50471, dsc 0.49529\n",
      "Batch train [6] loss 0.45067, dsc 0.54933\n",
      "Batch train [7] loss 0.46540, dsc 0.53460\n",
      "Batch train [8] loss 0.48009, dsc 0.51991\n",
      "Batch train [9] loss 0.43528, dsc 0.56472\n",
      "Batch train [10] loss 0.50885, dsc 0.49115\n",
      "Batch train [11] loss 0.49696, dsc 0.50304\n",
      "Batch train [12] loss 0.45359, dsc 0.54641\n",
      "Batch train [13] loss 0.46091, dsc 0.53909\n",
      "Batch train [14] loss 0.46189, dsc 0.53811\n",
      "Batch train [15] loss 0.43084, dsc 0.56916\n",
      "Batch train [16] loss 0.44607, dsc 0.55393\n",
      "Batch train [17] loss 0.41962, dsc 0.58038\n",
      "Batch train [18] loss 0.44444, dsc 0.55556\n",
      "Batch train [19] loss 0.47815, dsc 0.52185\n",
      "Batch train [20] loss 0.43584, dsc 0.56416\n",
      "Batch train [21] loss 0.43963, dsc 0.56037\n",
      "Batch train [22] loss 0.47461, dsc 0.52539\n",
      "Batch train [23] loss 0.43808, dsc 0.56192\n",
      "Batch train [24] loss 0.38021, dsc 0.61979\n",
      "Batch train [25] loss 0.42514, dsc 0.57486\n",
      "Batch train [26] loss 0.47919, dsc 0.52081\n",
      "Batch train [27] loss 0.45956, dsc 0.54044\n",
      "Batch train [28] loss 0.38381, dsc 0.61619\n",
      "Batch train [29] loss 0.43876, dsc 0.56124\n",
      "Batch train [30] loss 0.36636, dsc 0.63364\n",
      "Batch train [31] loss 0.38686, dsc 0.61314\n",
      "Batch train [32] loss 0.42809, dsc 0.57191\n",
      "Batch train [33] loss 0.53474, dsc 0.46526\n",
      "Batch train [34] loss 0.41908, dsc 0.58092\n",
      "Batch train [35] loss 0.47018, dsc 0.52982\n",
      "Batch train [36] loss 0.40110, dsc 0.59890\n",
      "Batch train [37] loss 0.39588, dsc 0.60412\n",
      "Batch train [38] loss 0.44215, dsc 0.55785\n",
      "Batch train [39] loss 0.42144, dsc 0.57856\n",
      "Batch train [40] loss 0.38474, dsc 0.61526\n",
      "Epoch [15] train done\n",
      "Batch eval [1] loss 0.44680, dsc 0.55320\n",
      "Batch eval [2] loss 0.44546, dsc 0.55454\n",
      "Batch eval [3] loss 0.47529, dsc 0.52471\n",
      "Batch eval [4] loss 0.42528, dsc 0.57472\n",
      "Batch eval [5] loss 0.40928, dsc 0.59072\n",
      "Epoch [15] valid done\n",
      "Epoch [15] T 115.22s, deltaT 7.79s, loss: train 0.44899, valid 0.44042, dsc: train 0.55101, valid 0.55958\n",
      "Batch train [1] loss 0.38560, dsc 0.61440\n",
      "Batch train [2] loss 0.38616, dsc 0.61384\n",
      "Batch train [3] loss 0.39857, dsc 0.60143\n",
      "Batch train [4] loss 0.39282, dsc 0.60718\n",
      "Batch train [5] loss 0.33718, dsc 0.66282\n",
      "Batch train [6] loss 0.45068, dsc 0.54932\n",
      "Batch train [7] loss 0.39604, dsc 0.60396\n",
      "Batch train [8] loss 0.43173, dsc 0.56827\n",
      "Batch train [9] loss 0.42486, dsc 0.57514\n",
      "Batch train [10] loss 0.40927, dsc 0.59073\n",
      "Batch train [11] loss 0.37786, dsc 0.62214\n",
      "Batch train [12] loss 0.39591, dsc 0.60409\n",
      "Batch train [13] loss 0.37833, dsc 0.62167\n",
      "Batch train [14] loss 0.49975, dsc 0.50025\n",
      "Batch train [15] loss 0.38707, dsc 0.61293\n",
      "Batch train [16] loss 0.33451, dsc 0.66549\n",
      "Batch train [17] loss 0.40014, dsc 0.59986\n",
      "Batch train [18] loss 0.36439, dsc 0.63561\n",
      "Batch train [19] loss 0.37519, dsc 0.62481\n",
      "Batch train [20] loss 0.37310, dsc 0.62690\n",
      "Batch train [21] loss 0.33849, dsc 0.66151\n",
      "Batch train [22] loss 0.37645, dsc 0.62355\n",
      "Batch train [23] loss 0.31118, dsc 0.68882\n",
      "Batch train [24] loss 0.35009, dsc 0.64991\n",
      "Batch train [25] loss 0.38006, dsc 0.61994\n",
      "Batch train [26] loss 0.36388, dsc 0.63612\n",
      "Batch train [27] loss 0.32935, dsc 0.67065\n",
      "Batch train [28] loss 0.34884, dsc 0.65116\n",
      "Batch train [29] loss 0.36315, dsc 0.63685\n",
      "Batch train [30] loss 0.38375, dsc 0.61625\n",
      "Batch train [31] loss 0.33439, dsc 0.66561\n",
      "Batch train [32] loss 0.36854, dsc 0.63146\n",
      "Batch train [33] loss 0.32791, dsc 0.67209\n",
      "Batch train [34] loss 0.37720, dsc 0.62280\n",
      "Batch train [35] loss 0.38657, dsc 0.61343\n",
      "Batch train [36] loss 0.35224, dsc 0.64776\n",
      "Batch train [37] loss 0.37736, dsc 0.62264\n",
      "Batch train [38] loss 0.32960, dsc 0.67040\n",
      "Batch train [39] loss 0.33727, dsc 0.66273\n",
      "Batch train [40] loss 0.47259, dsc 0.52741\n",
      "Epoch [16] train done\n",
      "Batch eval [1] loss 0.34769, dsc 0.65231\n",
      "Batch eval [2] loss 0.37541, dsc 0.62459\n",
      "Batch eval [3] loss 0.36128, dsc 0.63872\n",
      "Batch eval [4] loss 0.36307, dsc 0.63693\n",
      "Batch eval [5] loss 0.33988, dsc 0.66012\n",
      "Epoch [16] valid done\n",
      "Epoch [16] T 123.00s, deltaT 7.78s, loss: train 0.37770, valid 0.35746, dsc: train 0.62230, valid 0.64254\n",
      "Batch train [1] loss 0.33090, dsc 0.66910\n",
      "Batch train [2] loss 0.34546, dsc 0.65454\n",
      "Batch train [3] loss 0.33155, dsc 0.66845\n",
      "Batch train [4] loss 0.32191, dsc 0.67809\n",
      "Batch train [5] loss 0.43429, dsc 0.56571\n",
      "Batch train [6] loss 0.33545, dsc 0.66455\n",
      "Batch train [7] loss 0.37640, dsc 0.62360\n",
      "Batch train [8] loss 0.33441, dsc 0.66559\n",
      "Batch train [9] loss 0.31323, dsc 0.68677\n",
      "Batch train [10] loss 0.33842, dsc 0.66158\n",
      "Batch train [11] loss 0.32494, dsc 0.67506\n",
      "Batch train [12] loss 0.32471, dsc 0.67529\n",
      "Batch train [13] loss 0.30533, dsc 0.69467\n",
      "Batch train [14] loss 0.30707, dsc 0.69293\n",
      "Batch train [15] loss 0.34404, dsc 0.65596\n",
      "Batch train [16] loss 0.28530, dsc 0.71470\n",
      "Batch train [17] loss 0.34617, dsc 0.65383\n",
      "Batch train [18] loss 0.34691, dsc 0.65309\n",
      "Batch train [19] loss 0.29988, dsc 0.70012\n",
      "Batch train [20] loss 0.31075, dsc 0.68925\n",
      "Batch train [21] loss 0.30422, dsc 0.69578\n",
      "Batch train [22] loss 0.35473, dsc 0.64527\n",
      "Batch train [23] loss 0.27258, dsc 0.72742\n",
      "Batch train [24] loss 0.30402, dsc 0.69598\n",
      "Batch train [25] loss 0.28280, dsc 0.71720\n",
      "Batch train [26] loss 0.29185, dsc 0.70815\n",
      "Batch train [27] loss 0.32607, dsc 0.67393\n",
      "Batch train [28] loss 0.31080, dsc 0.68920\n",
      "Batch train [29] loss 0.29841, dsc 0.70159\n",
      "Batch train [30] loss 0.31773, dsc 0.68227\n",
      "Batch train [31] loss 0.30894, dsc 0.69106\n",
      "Batch train [32] loss 0.28423, dsc 0.71577\n",
      "Batch train [33] loss 0.29338, dsc 0.70662\n",
      "Batch train [34] loss 0.31657, dsc 0.68343\n",
      "Batch train [35] loss 0.32405, dsc 0.67595\n",
      "Batch train [36] loss 0.35224, dsc 0.64776\n",
      "Batch train [37] loss 0.28144, dsc 0.71856\n",
      "Batch train [38] loss 0.32756, dsc 0.67244\n",
      "Batch train [39] loss 0.40775, dsc 0.59225\n",
      "Batch train [40] loss 0.33869, dsc 0.66131\n",
      "Epoch [17] train done\n",
      "Batch eval [1] loss 0.33394, dsc 0.66606\n",
      "Batch eval [2] loss 0.35995, dsc 0.64005\n",
      "Batch eval [3] loss 0.34694, dsc 0.65306\n",
      "Batch eval [4] loss 0.35246, dsc 0.64754\n",
      "Batch eval [5] loss 0.33355, dsc 0.66645\n",
      "Epoch [17] valid done\n",
      "Epoch [17] T 130.87s, deltaT 7.87s, loss: train 0.32388, valid 0.34537, dsc: train 0.67612, valid 0.65463\n",
      "Batch train [1] loss 0.28630, dsc 0.71370\n",
      "Batch train [2] loss 0.31631, dsc 0.68369\n",
      "Batch train [3] loss 0.27195, dsc 0.72805\n",
      "Batch train [4] loss 0.39882, dsc 0.60118\n",
      "Batch train [5] loss 0.24670, dsc 0.75330\n",
      "Batch train [6] loss 0.27307, dsc 0.72693\n",
      "Batch train [7] loss 0.25737, dsc 0.74263\n",
      "Batch train [8] loss 0.28044, dsc 0.71956\n",
      "Batch train [9] loss 0.30747, dsc 0.69253\n",
      "Batch train [10] loss 0.39971, dsc 0.60029\n",
      "Batch train [11] loss 0.27789, dsc 0.72211\n",
      "Batch train [12] loss 0.29680, dsc 0.70320\n",
      "Batch train [13] loss 0.33575, dsc 0.66425\n",
      "Batch train [14] loss 0.28111, dsc 0.71889\n",
      "Batch train [15] loss 0.29500, dsc 0.70500\n",
      "Batch train [16] loss 0.26710, dsc 0.73290\n",
      "Batch train [17] loss 0.27537, dsc 0.72463\n",
      "Batch train [18] loss 0.31592, dsc 0.68408\n",
      "Batch train [19] loss 0.27472, dsc 0.72528\n",
      "Batch train [20] loss 0.27947, dsc 0.72053\n",
      "Batch train [21] loss 0.28893, dsc 0.71107\n",
      "Batch train [22] loss 0.29833, dsc 0.70167\n",
      "Batch train [23] loss 0.25550, dsc 0.74450\n",
      "Batch train [24] loss 0.27694, dsc 0.72306\n",
      "Batch train [25] loss 0.27136, dsc 0.72864\n",
      "Batch train [26] loss 0.25569, dsc 0.74431\n",
      "Batch train [27] loss 0.28576, dsc 0.71424\n",
      "Batch train [28] loss 0.24714, dsc 0.75286\n",
      "Batch train [29] loss 0.25685, dsc 0.74315\n",
      "Batch train [30] loss 0.23877, dsc 0.76123\n",
      "Batch train [31] loss 0.25885, dsc 0.74115\n",
      "Batch train [32] loss 0.30586, dsc 0.69414\n",
      "Batch train [33] loss 0.29654, dsc 0.70346\n",
      "Batch train [34] loss 0.29049, dsc 0.70951\n",
      "Batch train [35] loss 0.25544, dsc 0.74456\n",
      "Batch train [36] loss 0.25205, dsc 0.74795\n",
      "Batch train [37] loss 0.20928, dsc 0.79072\n",
      "Batch train [38] loss 0.27003, dsc 0.72997\n",
      "Batch train [39] loss 0.24882, dsc 0.75118\n",
      "Batch train [40] loss 0.26335, dsc 0.73665\n",
      "Epoch [18] train done\n",
      "Batch eval [1] loss 0.24857, dsc 0.75143\n",
      "Batch eval [2] loss 0.29001, dsc 0.70999\n",
      "Batch eval [3] loss 0.27638, dsc 0.72362\n",
      "Batch eval [4] loss 0.29974, dsc 0.70026\n",
      "Batch eval [5] loss 0.26907, dsc 0.73093\n",
      "Epoch [18] valid done\n",
      "Epoch [18] T 138.57s, deltaT 7.69s, loss: train 0.28158, valid 0.27675, dsc: train 0.71842, valid 0.72325\n",
      "Batch train [1] loss 0.29644, dsc 0.70356\n",
      "Batch train [2] loss 0.27862, dsc 0.72138\n",
      "Batch train [3] loss 0.26968, dsc 0.73032\n",
      "Batch train [4] loss 0.24574, dsc 0.75426\n",
      "Batch train [5] loss 0.28132, dsc 0.71868\n",
      "Batch train [6] loss 0.29010, dsc 0.70990\n",
      "Batch train [7] loss 0.28871, dsc 0.71129\n",
      "Batch train [8] loss 0.25150, dsc 0.74850\n",
      "Batch train [9] loss 0.25150, dsc 0.74850\n",
      "Batch train [10] loss 0.24412, dsc 0.75588\n",
      "Batch train [11] loss 0.23008, dsc 0.76992\n",
      "Batch train [12] loss 0.34917, dsc 0.65083\n",
      "Batch train [13] loss 0.24871, dsc 0.75129\n",
      "Batch train [14] loss 0.23131, dsc 0.76869\n",
      "Batch train [15] loss 0.24776, dsc 0.75224\n",
      "Batch train [16] loss 0.25419, dsc 0.74581\n",
      "Batch train [17] loss 0.33490, dsc 0.66510\n",
      "Batch train [18] loss 0.26120, dsc 0.73880\n",
      "Batch train [19] loss 0.25244, dsc 0.74756\n",
      "Batch train [20] loss 0.24471, dsc 0.75529\n",
      "Batch train [21] loss 0.27274, dsc 0.72726\n",
      "Batch train [22] loss 0.25810, dsc 0.74190\n",
      "Batch train [23] loss 0.20564, dsc 0.79436\n",
      "Batch train [24] loss 0.24129, dsc 0.75871\n",
      "Batch train [25] loss 0.24416, dsc 0.75584\n",
      "Batch train [26] loss 0.23202, dsc 0.76798\n",
      "Batch train [27] loss 0.26977, dsc 0.73023\n",
      "Batch train [28] loss 0.24353, dsc 0.75647\n",
      "Batch train [29] loss 0.23167, dsc 0.76833\n",
      "Batch train [30] loss 0.24255, dsc 0.75745\n",
      "Batch train [31] loss 0.22260, dsc 0.77740\n",
      "Batch train [32] loss 0.22860, dsc 0.77140\n",
      "Batch train [33] loss 0.23367, dsc 0.76633\n",
      "Batch train [34] loss 0.21058, dsc 0.78942\n",
      "Batch train [35] loss 0.22910, dsc 0.77090\n",
      "Batch train [36] loss 0.23282, dsc 0.76718\n",
      "Batch train [37] loss 0.22985, dsc 0.77015\n",
      "Batch train [38] loss 0.23291, dsc 0.76709\n",
      "Batch train [39] loss 0.19830, dsc 0.80170\n",
      "Batch train [40] loss 0.23169, dsc 0.76831\n",
      "Epoch [19] train done\n",
      "Batch eval [1] loss 0.24528, dsc 0.75472\n",
      "Batch eval [2] loss 0.26122, dsc 0.73878\n",
      "Batch eval [3] loss 0.28722, dsc 0.71278\n",
      "Batch eval [4] loss 0.25971, dsc 0.74029\n",
      "Batch eval [5] loss 0.24614, dsc 0.75386\n",
      "Epoch [19] valid done\n",
      "Epoch [19] T 146.04s, deltaT 7.47s, loss: train 0.25109, valid 0.25992, dsc: train 0.74891, valid 0.74008\n",
      "Batch train [1] loss 0.20944, dsc 0.79056\n",
      "Batch train [2] loss 0.21157, dsc 0.78843\n",
      "Batch train [3] loss 0.23589, dsc 0.76411\n",
      "Batch train [4] loss 0.33319, dsc 0.66681\n",
      "Batch train [5] loss 0.22782, dsc 0.77218\n",
      "Batch train [6] loss 0.24981, dsc 0.75019\n",
      "Batch train [7] loss 0.24070, dsc 0.75930\n",
      "Batch train [8] loss 0.20735, dsc 0.79265\n",
      "Batch train [9] loss 0.21762, dsc 0.78238\n",
      "Batch train [10] loss 0.26385, dsc 0.73615\n",
      "Batch train [11] loss 0.30944, dsc 0.69056\n",
      "Batch train [12] loss 0.23523, dsc 0.76477\n",
      "Batch train [13] loss 0.22100, dsc 0.77900\n",
      "Batch train [14] loss 0.23000, dsc 0.77000\n",
      "Batch train [15] loss 0.22596, dsc 0.77404\n",
      "Batch train [16] loss 0.22852, dsc 0.77148\n",
      "Batch train [17] loss 0.20913, dsc 0.79087\n",
      "Batch train [18] loss 0.18306, dsc 0.81694\n",
      "Batch train [19] loss 0.22389, dsc 0.77611\n",
      "Batch train [20] loss 0.23042, dsc 0.76958\n",
      "Batch train [21] loss 0.19744, dsc 0.80256\n",
      "Batch train [22] loss 0.20170, dsc 0.79830\n",
      "Batch train [23] loss 0.24483, dsc 0.75517\n",
      "Batch train [24] loss 0.18430, dsc 0.81570\n",
      "Batch train [25] loss 0.23218, dsc 0.76782\n",
      "Batch train [26] loss 0.22411, dsc 0.77589\n",
      "Batch train [27] loss 0.21872, dsc 0.78128\n",
      "Batch train [28] loss 0.24870, dsc 0.75130\n",
      "Batch train [29] loss 0.21005, dsc 0.78995\n",
      "Batch train [30] loss 0.20501, dsc 0.79499\n",
      "Batch train [31] loss 0.21892, dsc 0.78108\n",
      "Batch train [32] loss 0.24754, dsc 0.75246\n",
      "Batch train [33] loss 0.20021, dsc 0.79979\n",
      "Batch train [34] loss 0.24107, dsc 0.75893\n",
      "Batch train [35] loss 0.20947, dsc 0.79053\n",
      "Batch train [36] loss 0.22449, dsc 0.77551\n",
      "Batch train [37] loss 0.21540, dsc 0.78460\n",
      "Batch train [38] loss 0.20992, dsc 0.79008\n",
      "Batch train [39] loss 0.23128, dsc 0.76872\n",
      "Batch train [40] loss 0.21595, dsc 0.78405\n",
      "Epoch [20] train done\n",
      "Batch eval [1] loss 0.22988, dsc 0.77012\n",
      "Batch eval [2] loss 0.25637, dsc 0.74363\n",
      "Batch eval [3] loss 0.23331, dsc 0.76669\n",
      "Batch eval [4] loss 0.24162, dsc 0.75838\n",
      "Batch eval [5] loss 0.23086, dsc 0.76914\n",
      "Epoch [20] valid done\n",
      "Epoch [20] T 153.52s, deltaT 7.48s, loss: train 0.22688, valid 0.23841, dsc: train 0.77312, valid 0.76159\n",
      "Batch train [1] loss 0.19390, dsc 0.80610\n",
      "Batch train [2] loss 0.19751, dsc 0.80249\n",
      "Batch train [3] loss 0.17644, dsc 0.82356\n",
      "Batch train [4] loss 0.21395, dsc 0.78605\n",
      "Batch train [5] loss 0.21478, dsc 0.78522\n",
      "Batch train [6] loss 0.18473, dsc 0.81527\n",
      "Batch train [7] loss 0.22137, dsc 0.77863\n",
      "Batch train [8] loss 0.23506, dsc 0.76494\n",
      "Batch train [9] loss 0.21258, dsc 0.78742\n",
      "Batch train [10] loss 0.23695, dsc 0.76305\n",
      "Batch train [11] loss 0.30669, dsc 0.69331\n",
      "Batch train [12] loss 0.20231, dsc 0.79769\n",
      "Batch train [13] loss 0.28243, dsc 0.71757\n",
      "Batch train [14] loss 0.21286, dsc 0.78714\n",
      "Batch train [15] loss 0.20696, dsc 0.79304\n",
      "Batch train [16] loss 0.23251, dsc 0.76749\n",
      "Batch train [17] loss 0.18862, dsc 0.81138\n",
      "Batch train [18] loss 0.21888, dsc 0.78112\n",
      "Batch train [19] loss 0.21110, dsc 0.78890\n",
      "Batch train [20] loss 0.22214, dsc 0.77786\n",
      "Batch train [21] loss 0.22468, dsc 0.77532\n",
      "Batch train [22] loss 0.21734, dsc 0.78266\n",
      "Batch train [23] loss 0.24317, dsc 0.75683\n",
      "Batch train [24] loss 0.19630, dsc 0.80370\n",
      "Batch train [25] loss 0.24653, dsc 0.75347\n",
      "Batch train [26] loss 0.20880, dsc 0.79120\n",
      "Batch train [27] loss 0.19641, dsc 0.80359\n",
      "Batch train [28] loss 0.20431, dsc 0.79569\n",
      "Batch train [29] loss 0.24075, dsc 0.75925\n",
      "Batch train [30] loss 0.16942, dsc 0.83058\n",
      "Batch train [31] loss 0.20380, dsc 0.79620\n",
      "Batch train [32] loss 0.21348, dsc 0.78652\n",
      "Batch train [33] loss 0.19672, dsc 0.80328\n",
      "Batch train [34] loss 0.23393, dsc 0.76607\n",
      "Batch train [35] loss 0.16406, dsc 0.83594\n",
      "Batch train [36] loss 0.20238, dsc 0.79762\n",
      "Batch train [37] loss 0.19091, dsc 0.80909\n",
      "Batch train [38] loss 0.20261, dsc 0.79739\n",
      "Batch train [39] loss 0.20152, dsc 0.79848\n",
      "Batch train [40] loss 0.18255, dsc 0.81745\n",
      "Epoch [21] train done\n",
      "Batch eval [1] loss 0.25082, dsc 0.74918\n",
      "Batch eval [2] loss 0.22601, dsc 0.77399\n",
      "Batch eval [3] loss 0.27790, dsc 0.72210\n",
      "Batch eval [4] loss 0.21841, dsc 0.78159\n",
      "Batch eval [5] loss 0.23448, dsc 0.76552\n",
      "Epoch [21] valid done\n",
      "Epoch [21] T 161.10s, deltaT 7.58s, loss: train 0.21279, valid 0.24153, dsc: train 0.78721, valid 0.75847\n",
      "Batch train [1] loss 0.20027, dsc 0.79973\n",
      "Batch train [2] loss 0.19122, dsc 0.80878\n",
      "Batch train [3] loss 0.20090, dsc 0.79910\n",
      "Batch train [4] loss 0.18962, dsc 0.81038\n",
      "Batch train [5] loss 0.18494, dsc 0.81506\n",
      "Batch train [6] loss 0.19539, dsc 0.80461\n",
      "Batch train [7] loss 0.27118, dsc 0.72882\n",
      "Batch train [8] loss 0.18426, dsc 0.81574\n",
      "Batch train [9] loss 0.17994, dsc 0.82006\n",
      "Batch train [10] loss 0.20798, dsc 0.79202\n",
      "Batch train [11] loss 0.18369, dsc 0.81631\n",
      "Batch train [12] loss 0.19143, dsc 0.80857\n",
      "Batch train [13] loss 0.18815, dsc 0.81185\n",
      "Batch train [14] loss 0.19854, dsc 0.80146\n",
      "Batch train [15] loss 0.20217, dsc 0.79783\n",
      "Batch train [16] loss 0.23334, dsc 0.76666\n",
      "Batch train [17] loss 0.22583, dsc 0.77417\n",
      "Batch train [18] loss 0.19895, dsc 0.80105\n",
      "Batch train [19] loss 0.20210, dsc 0.79790\n",
      "Batch train [20] loss 0.18616, dsc 0.81384\n",
      "Batch train [21] loss 0.18125, dsc 0.81875\n",
      "Batch train [22] loss 0.27543, dsc 0.72457\n",
      "Batch train [23] loss 0.18036, dsc 0.81964\n",
      "Batch train [24] loss 0.18864, dsc 0.81136\n",
      "Batch train [25] loss 0.18894, dsc 0.81106\n",
      "Batch train [26] loss 0.20031, dsc 0.79969\n",
      "Batch train [27] loss 0.17037, dsc 0.82963\n",
      "Batch train [28] loss 0.18039, dsc 0.81961\n",
      "Batch train [29] loss 0.19579, dsc 0.80421\n",
      "Batch train [30] loss 0.16633, dsc 0.83367\n",
      "Batch train [31] loss 0.20860, dsc 0.79140\n",
      "Batch train [32] loss 0.17641, dsc 0.82359\n",
      "Batch train [33] loss 0.21004, dsc 0.78996\n",
      "Batch train [34] loss 0.19911, dsc 0.80089\n",
      "Batch train [35] loss 0.19712, dsc 0.80288\n",
      "Batch train [36] loss 0.23292, dsc 0.76708\n",
      "Batch train [37] loss 0.17171, dsc 0.82829\n",
      "Batch train [38] loss 0.20055, dsc 0.79945\n",
      "Batch train [39] loss 0.19460, dsc 0.80540\n",
      "Batch train [40] loss 0.21335, dsc 0.78665\n",
      "Epoch [22] train done\n",
      "Batch eval [1] loss 0.23677, dsc 0.76323\n",
      "Batch eval [2] loss 0.23363, dsc 0.76637\n",
      "Batch eval [3] loss 0.24261, dsc 0.75739\n",
      "Batch eval [4] loss 0.20857, dsc 0.79143\n",
      "Batch eval [5] loss 0.22475, dsc 0.77525\n",
      "Epoch [22] valid done\n",
      "Epoch [22] T 168.67s, deltaT 7.57s, loss: train 0.19871, valid 0.22927, dsc: train 0.80129, valid 0.77073\n",
      "Batch train [1] loss 0.17819, dsc 0.82181\n",
      "Batch train [2] loss 0.17330, dsc 0.82670\n",
      "Batch train [3] loss 0.18637, dsc 0.81363\n",
      "Batch train [4] loss 0.17725, dsc 0.82275\n",
      "Batch train [5] loss 0.17059, dsc 0.82941\n",
      "Batch train [6] loss 0.22333, dsc 0.77667\n",
      "Batch train [7] loss 0.20275, dsc 0.79725\n",
      "Batch train [8] loss 0.20491, dsc 0.79509\n",
      "Batch train [9] loss 0.18005, dsc 0.81995\n",
      "Batch train [10] loss 0.20707, dsc 0.79293\n",
      "Batch train [11] loss 0.21255, dsc 0.78745\n",
      "Batch train [12] loss 0.17665, dsc 0.82335\n",
      "Batch train [13] loss 0.18806, dsc 0.81194\n",
      "Batch train [14] loss 0.19545, dsc 0.80455\n",
      "Batch train [15] loss 0.16797, dsc 0.83203\n",
      "Batch train [16] loss 0.18140, dsc 0.81860\n",
      "Batch train [17] loss 0.20608, dsc 0.79392\n",
      "Batch train [18] loss 0.17246, dsc 0.82754\n",
      "Batch train [19] loss 0.17974, dsc 0.82026\n",
      "Batch train [20] loss 0.17354, dsc 0.82646\n",
      "Batch train [21] loss 0.19204, dsc 0.80796\n",
      "Batch train [22] loss 0.19033, dsc 0.80967\n",
      "Batch train [23] loss 0.15961, dsc 0.84039\n",
      "Batch train [24] loss 0.22575, dsc 0.77425\n",
      "Batch train [25] loss 0.22397, dsc 0.77603\n",
      "Batch train [26] loss 0.19230, dsc 0.80770\n",
      "Batch train [27] loss 0.17895, dsc 0.82105\n",
      "Batch train [28] loss 0.16360, dsc 0.83640\n",
      "Batch train [29] loss 0.26769, dsc 0.73231\n",
      "Batch train [30] loss 0.20250, dsc 0.79750\n",
      "Batch train [31] loss 0.18232, dsc 0.81768\n",
      "Batch train [32] loss 0.18112, dsc 0.81888\n",
      "Batch train [33] loss 0.18778, dsc 0.81222\n",
      "Batch train [34] loss 0.17121, dsc 0.82879\n",
      "Batch train [35] loss 0.20692, dsc 0.79308\n",
      "Batch train [36] loss 0.18775, dsc 0.81225\n",
      "Batch train [37] loss 0.16485, dsc 0.83515\n",
      "Batch train [38] loss 0.17555, dsc 0.82445\n",
      "Batch train [39] loss 0.26531, dsc 0.73469\n",
      "Batch train [40] loss 0.19871, dsc 0.80129\n",
      "Epoch [23] train done\n",
      "Batch eval [1] loss 0.19740, dsc 0.80260\n",
      "Batch eval [2] loss 0.23017, dsc 0.76983\n",
      "Batch eval [3] loss 0.21416, dsc 0.78584\n",
      "Batch eval [4] loss 0.20979, dsc 0.79021\n",
      "Batch eval [5] loss 0.18676, dsc 0.81324\n",
      "Epoch [23] valid done\n",
      "Epoch [23] T 176.30s, deltaT 7.63s, loss: train 0.19190, valid 0.20766, dsc: train 0.80810, valid 0.79234\n",
      "Batch train [1] loss 0.18686, dsc 0.81314\n",
      "Batch train [2] loss 0.17105, dsc 0.82895\n",
      "Batch train [3] loss 0.16603, dsc 0.83397\n",
      "Batch train [4] loss 0.18330, dsc 0.81670\n",
      "Batch train [5] loss 0.15524, dsc 0.84476\n",
      "Batch train [6] loss 0.16340, dsc 0.83660\n",
      "Batch train [7] loss 0.14852, dsc 0.85148\n",
      "Batch train [8] loss 0.20330, dsc 0.79670\n",
      "Batch train [9] loss 0.19165, dsc 0.80835\n",
      "Batch train [10] loss 0.20123, dsc 0.79877\n",
      "Batch train [11] loss 0.18665, dsc 0.81335\n",
      "Batch train [12] loss 0.16219, dsc 0.83781\n",
      "Batch train [13] loss 0.18527, dsc 0.81473\n",
      "Batch train [14] loss 0.18543, dsc 0.81457\n",
      "Batch train [15] loss 0.18405, dsc 0.81595\n",
      "Batch train [16] loss 0.15508, dsc 0.84492\n",
      "Batch train [17] loss 0.17220, dsc 0.82780\n",
      "Batch train [18] loss 0.16326, dsc 0.83674\n",
      "Batch train [19] loss 0.22364, dsc 0.77636\n",
      "Batch train [20] loss 0.19419, dsc 0.80581\n",
      "Batch train [21] loss 0.18021, dsc 0.81979\n",
      "Batch train [22] loss 0.17527, dsc 0.82473\n",
      "Batch train [23] loss 0.20129, dsc 0.79871\n",
      "Batch train [24] loss 0.18105, dsc 0.81895\n",
      "Batch train [25] loss 0.16118, dsc 0.83882\n",
      "Batch train [26] loss 0.18948, dsc 0.81052\n",
      "Batch train [27] loss 0.16384, dsc 0.83616\n",
      "Batch train [28] loss 0.17282, dsc 0.82718\n",
      "Batch train [29] loss 0.18475, dsc 0.81525\n",
      "Batch train [30] loss 0.16323, dsc 0.83677\n",
      "Batch train [31] loss 0.16848, dsc 0.83152\n",
      "Batch train [32] loss 0.16173, dsc 0.83827\n",
      "Batch train [33] loss 0.17425, dsc 0.82575\n",
      "Batch train [34] loss 0.18559, dsc 0.81441\n",
      "Batch train [35] loss 0.20344, dsc 0.79656\n",
      "Batch train [36] loss 0.15596, dsc 0.84404\n",
      "Batch train [37] loss 0.16696, dsc 0.83304\n",
      "Batch train [38] loss 0.25224, dsc 0.74776\n",
      "Batch train [39] loss 0.17823, dsc 0.82177\n",
      "Batch train [40] loss 0.17629, dsc 0.82371\n",
      "Epoch [24] train done\n",
      "Batch eval [1] loss 0.20994, dsc 0.79006\n",
      "Batch eval [2] loss 0.20342, dsc 0.79658\n",
      "Batch eval [3] loss 0.23113, dsc 0.76887\n",
      "Batch eval [4] loss 0.20067, dsc 0.79933\n",
      "Batch eval [5] loss 0.20685, dsc 0.79315\n",
      "Epoch [24] valid done\n",
      "Epoch [24] T 184.15s, deltaT 7.85s, loss: train 0.17947, valid 0.21040, dsc: train 0.82053, valid 0.78960\n",
      "Batch train [1] loss 0.16484, dsc 0.83516\n",
      "Batch train [2] loss 0.15528, dsc 0.84472\n",
      "Batch train [3] loss 0.24059, dsc 0.75941\n",
      "Batch train [4] loss 0.16046, dsc 0.83954\n",
      "Batch train [5] loss 0.15891, dsc 0.84109\n",
      "Batch train [6] loss 0.16562, dsc 0.83438\n",
      "Batch train [7] loss 0.19406, dsc 0.80594\n",
      "Batch train [8] loss 0.16063, dsc 0.83937\n",
      "Batch train [9] loss 0.15881, dsc 0.84119\n",
      "Batch train [10] loss 0.14580, dsc 0.85420\n",
      "Batch train [11] loss 0.18311, dsc 0.81689\n",
      "Batch train [12] loss 0.14166, dsc 0.85834\n",
      "Batch train [13] loss 0.16941, dsc 0.83059\n",
      "Batch train [14] loss 0.16517, dsc 0.83483\n",
      "Batch train [15] loss 0.19463, dsc 0.80537\n",
      "Batch train [16] loss 0.15176, dsc 0.84824\n",
      "Batch train [17] loss 0.17381, dsc 0.82619\n",
      "Batch train [18] loss 0.17363, dsc 0.82637\n",
      "Batch train [19] loss 0.17355, dsc 0.82645\n",
      "Batch train [20] loss 0.16664, dsc 0.83336\n",
      "Batch train [21] loss 0.16256, dsc 0.83744\n",
      "Batch train [22] loss 0.19279, dsc 0.80721\n",
      "Batch train [23] loss 0.17967, dsc 0.82033\n",
      "Batch train [24] loss 0.18401, dsc 0.81599\n",
      "Batch train [25] loss 0.17358, dsc 0.82642\n",
      "Batch train [26] loss 0.16568, dsc 0.83432\n",
      "Batch train [27] loss 0.17221, dsc 0.82779\n",
      "Batch train [28] loss 0.17595, dsc 0.82405\n",
      "Batch train [29] loss 0.16764, dsc 0.83236\n",
      "Batch train [30] loss 0.17154, dsc 0.82846\n",
      "Batch train [31] loss 0.21109, dsc 0.78891\n",
      "Batch train [32] loss 0.15600, dsc 0.84400\n",
      "Batch train [33] loss 0.17589, dsc 0.82411\n",
      "Batch train [34] loss 0.17157, dsc 0.82843\n",
      "Batch train [35] loss 0.15714, dsc 0.84286\n",
      "Batch train [36] loss 0.17214, dsc 0.82786\n",
      "Batch train [37] loss 0.15659, dsc 0.84341\n",
      "Batch train [38] loss 0.15382, dsc 0.84618\n",
      "Batch train [39] loss 0.17905, dsc 0.82095\n",
      "Batch train [40] loss 0.24095, dsc 0.75905\n",
      "Epoch [25] train done\n",
      "Batch eval [1] loss 0.22528, dsc 0.77472\n",
      "Batch eval [2] loss 0.23956, dsc 0.76044\n",
      "Batch eval [3] loss 0.26743, dsc 0.73257\n",
      "Batch eval [4] loss 0.20985, dsc 0.79015\n",
      "Batch eval [5] loss 0.21424, dsc 0.78576\n",
      "Epoch [25] valid done\n",
      "Epoch [25] T 191.98s, deltaT 7.83s, loss: train 0.17296, valid 0.23127, dsc: train 0.82704, valid 0.76873\n",
      "Batch train [1] loss 0.16126, dsc 0.83874\n",
      "Batch train [2] loss 0.15861, dsc 0.84139\n",
      "Batch train [3] loss 0.16400, dsc 0.83600\n",
      "Batch train [4] loss 0.16864, dsc 0.83136\n",
      "Batch train [5] loss 0.14805, dsc 0.85195\n",
      "Batch train [6] loss 0.14221, dsc 0.85779\n",
      "Batch train [7] loss 0.16999, dsc 0.83001\n",
      "Batch train [8] loss 0.16295, dsc 0.83705\n",
      "Batch train [9] loss 0.16353, dsc 0.83647\n",
      "Batch train [10] loss 0.13574, dsc 0.86426\n",
      "Batch train [11] loss 0.13470, dsc 0.86530\n",
      "Batch train [12] loss 0.14810, dsc 0.85190\n",
      "Batch train [13] loss 0.15773, dsc 0.84227\n",
      "Batch train [14] loss 0.15639, dsc 0.84361\n",
      "Batch train [15] loss 0.15960, dsc 0.84040\n",
      "Batch train [16] loss 0.15516, dsc 0.84484\n",
      "Batch train [17] loss 0.15278, dsc 0.84722\n",
      "Batch train [18] loss 0.14846, dsc 0.85154\n",
      "Batch train [19] loss 0.13978, dsc 0.86022\n",
      "Batch train [20] loss 0.15903, dsc 0.84097\n",
      "Batch train [21] loss 0.17709, dsc 0.82291\n",
      "Batch train [22] loss 0.17108, dsc 0.82892\n",
      "Batch train [23] loss 0.16160, dsc 0.83840\n",
      "Batch train [24] loss 0.15025, dsc 0.84975\n",
      "Batch train [25] loss 0.15260, dsc 0.84740\n",
      "Batch train [26] loss 0.13836, dsc 0.86164\n",
      "Batch train [27] loss 0.16171, dsc 0.83829\n",
      "Batch train [28] loss 0.21827, dsc 0.78173\n",
      "Batch train [29] loss 0.18813, dsc 0.81187\n",
      "Batch train [30] loss 0.16614, dsc 0.83386\n",
      "Batch train [31] loss 0.14669, dsc 0.85331\n",
      "Batch train [32] loss 0.17271, dsc 0.82729\n",
      "Batch train [33] loss 0.15377, dsc 0.84623\n",
      "Batch train [34] loss 0.19389, dsc 0.80611\n",
      "Batch train [35] loss 0.15910, dsc 0.84090\n",
      "Batch train [36] loss 0.14504, dsc 0.85496\n",
      "Batch train [37] loss 0.15831, dsc 0.84169\n",
      "Batch train [38] loss 0.16862, dsc 0.83138\n",
      "Batch train [39] loss 0.22631, dsc 0.77369\n",
      "Batch train [40] loss 0.18625, dsc 0.81375\n",
      "Epoch [26] train done\n",
      "Batch eval [1] loss 0.21661, dsc 0.78339\n",
      "Batch eval [2] loss 0.23000, dsc 0.77000\n",
      "Batch eval [3] loss 0.22256, dsc 0.77744\n",
      "Batch eval [4] loss 0.18733, dsc 0.81267\n",
      "Batch eval [5] loss 0.20810, dsc 0.79190\n",
      "Epoch [26] valid done\n",
      "Epoch [26] T 200.01s, deltaT 8.02s, loss: train 0.16207, valid 0.21292, dsc: train 0.83793, valid 0.78708\n",
      "Batch train [1] loss 0.15210, dsc 0.84790\n",
      "Batch train [2] loss 0.15812, dsc 0.84188\n",
      "Batch train [3] loss 0.15301, dsc 0.84699\n",
      "Batch train [4] loss 0.15233, dsc 0.84767\n",
      "Batch train [5] loss 0.13575, dsc 0.86425\n",
      "Batch train [6] loss 0.16361, dsc 0.83639\n",
      "Batch train [7] loss 0.14119, dsc 0.85881\n",
      "Batch train [8] loss 0.15939, dsc 0.84061\n",
      "Batch train [9] loss 0.14794, dsc 0.85206\n",
      "Batch train [10] loss 0.16134, dsc 0.83866\n",
      "Batch train [11] loss 0.14791, dsc 0.85209\n",
      "Batch train [12] loss 0.16406, dsc 0.83594\n",
      "Batch train [13] loss 0.13990, dsc 0.86010\n",
      "Batch train [14] loss 0.15764, dsc 0.84236\n",
      "Batch train [15] loss 0.16518, dsc 0.83482\n",
      "Batch train [16] loss 0.18218, dsc 0.81782\n",
      "Batch train [17] loss 0.14185, dsc 0.85815\n",
      "Batch train [18] loss 0.13048, dsc 0.86952\n",
      "Batch train [19] loss 0.14081, dsc 0.85919\n",
      "Batch train [20] loss 0.14100, dsc 0.85900\n",
      "Batch train [21] loss 0.13157, dsc 0.86843\n",
      "Batch train [22] loss 0.15029, dsc 0.84971\n",
      "Batch train [23] loss 0.12137, dsc 0.87863\n",
      "Batch train [24] loss 0.20107, dsc 0.79893\n",
      "Batch train [25] loss 0.14675, dsc 0.85325\n",
      "Batch train [26] loss 0.13894, dsc 0.86106\n",
      "Batch train [27] loss 0.14504, dsc 0.85496\n",
      "Batch train [28] loss 0.21301, dsc 0.78699\n",
      "Batch train [29] loss 0.16253, dsc 0.83747\n",
      "Batch train [30] loss 0.15935, dsc 0.84065\n",
      "Batch train [31] loss 0.15706, dsc 0.84294\n",
      "Batch train [32] loss 0.17717, dsc 0.82283\n",
      "Batch train [33] loss 0.16088, dsc 0.83912\n",
      "Batch train [34] loss 0.14750, dsc 0.85250\n",
      "Batch train [35] loss 0.13051, dsc 0.86949\n",
      "Batch train [36] loss 0.14877, dsc 0.85123\n",
      "Batch train [37] loss 0.15574, dsc 0.84426\n",
      "Batch train [38] loss 0.19088, dsc 0.80912\n",
      "Batch train [39] loss 0.17016, dsc 0.82984\n",
      "Batch train [40] loss 0.14372, dsc 0.85628\n",
      "Epoch [27] train done\n",
      "Batch eval [1] loss 0.19781, dsc 0.80219\n",
      "Batch eval [2] loss 0.20735, dsc 0.79265\n",
      "Batch eval [3] loss 0.20907, dsc 0.79093\n",
      "Batch eval [4] loss 0.18171, dsc 0.81829\n",
      "Batch eval [5] loss 0.17632, dsc 0.82368\n",
      "Epoch [27] valid done\n",
      "Epoch [27] T 207.95s, deltaT 7.95s, loss: train 0.15470, valid 0.19445, dsc: train 0.84530, valid 0.80555\n",
      "Batch train [1] loss 0.15231, dsc 0.84769\n",
      "Batch train [2] loss 0.14667, dsc 0.85333\n",
      "Batch train [3] loss 0.15831, dsc 0.84169\n",
      "Batch train [4] loss 0.15813, dsc 0.84187\n",
      "Batch train [5] loss 0.12853, dsc 0.87147\n",
      "Batch train [6] loss 0.14511, dsc 0.85489\n",
      "Batch train [7] loss 0.14161, dsc 0.85839\n",
      "Batch train [8] loss 0.16185, dsc 0.83815\n",
      "Batch train [9] loss 0.16308, dsc 0.83692\n",
      "Batch train [10] loss 0.14171, dsc 0.85829\n",
      "Batch train [11] loss 0.12690, dsc 0.87310\n",
      "Batch train [12] loss 0.14830, dsc 0.85170\n",
      "Batch train [13] loss 0.13610, dsc 0.86390\n",
      "Batch train [14] loss 0.13480, dsc 0.86520\n",
      "Batch train [15] loss 0.14349, dsc 0.85651\n",
      "Batch train [16] loss 0.14850, dsc 0.85150\n",
      "Batch train [17] loss 0.16063, dsc 0.83937\n",
      "Batch train [18] loss 0.16534, dsc 0.83466\n",
      "Batch train [19] loss 0.15531, dsc 0.84469\n",
      "Batch train [20] loss 0.19954, dsc 0.80046\n",
      "Batch train [21] loss 0.13961, dsc 0.86039\n",
      "Batch train [22] loss 0.14834, dsc 0.85166\n",
      "Batch train [23] loss 0.16356, dsc 0.83644\n",
      "Batch train [24] loss 0.14717, dsc 0.85283\n",
      "Batch train [25] loss 0.14803, dsc 0.85197\n",
      "Batch train [26] loss 0.16185, dsc 0.83815\n",
      "Batch train [27] loss 0.14142, dsc 0.85858\n",
      "Batch train [28] loss 0.15340, dsc 0.84660\n",
      "Batch train [29] loss 0.15124, dsc 0.84876\n",
      "Batch train [30] loss 0.17614, dsc 0.82386\n",
      "Batch train [31] loss 0.16279, dsc 0.83721\n",
      "Batch train [32] loss 0.14048, dsc 0.85952\n",
      "Batch train [33] loss 0.17069, dsc 0.82931\n",
      "Batch train [34] loss 0.20060, dsc 0.79940\n",
      "Batch train [35] loss 0.16305, dsc 0.83695\n",
      "Batch train [36] loss 0.15314, dsc 0.84686\n",
      "Batch train [37] loss 0.15287, dsc 0.84713\n",
      "Batch train [38] loss 0.13575, dsc 0.86425\n",
      "Batch train [39] loss 0.15399, dsc 0.84601\n",
      "Batch train [40] loss 0.13671, dsc 0.86329\n",
      "Epoch [28] train done\n",
      "Batch eval [1] loss 0.20083, dsc 0.79917\n",
      "Batch eval [2] loss 0.19804, dsc 0.80196\n",
      "Batch eval [3] loss 0.20091, dsc 0.79909\n",
      "Batch eval [4] loss 0.18582, dsc 0.81418\n",
      "Batch eval [5] loss 0.18214, dsc 0.81786\n",
      "Epoch [28] valid done\n",
      "Epoch [28] T 216.09s, deltaT 8.13s, loss: train 0.15293, valid 0.19355, dsc: train 0.84707, valid 0.80645\n",
      "Batch train [1] loss 0.14303, dsc 0.85697\n",
      "Batch train [2] loss 0.14021, dsc 0.85979\n",
      "Batch train [3] loss 0.13399, dsc 0.86601\n",
      "Batch train [4] loss 0.12194, dsc 0.87806\n",
      "Batch train [5] loss 0.14763, dsc 0.85237\n",
      "Batch train [6] loss 0.14856, dsc 0.85144\n",
      "Batch train [7] loss 0.18538, dsc 0.81462\n",
      "Batch train [8] loss 0.14682, dsc 0.85318\n",
      "Batch train [9] loss 0.14966, dsc 0.85034\n",
      "Batch train [10] loss 0.19486, dsc 0.80514\n",
      "Batch train [11] loss 0.14327, dsc 0.85673\n",
      "Batch train [12] loss 0.13877, dsc 0.86123\n",
      "Batch train [13] loss 0.14704, dsc 0.85296\n",
      "Batch train [14] loss 0.15037, dsc 0.84963\n",
      "Batch train [15] loss 0.17121, dsc 0.82879\n",
      "Batch train [16] loss 0.12625, dsc 0.87375\n",
      "Batch train [17] loss 0.13124, dsc 0.86876\n",
      "Batch train [18] loss 0.15603, dsc 0.84397\n",
      "Batch train [19] loss 0.13410, dsc 0.86590\n",
      "Batch train [20] loss 0.14473, dsc 0.85527\n",
      "Batch train [21] loss 0.14277, dsc 0.85723\n",
      "Batch train [22] loss 0.13858, dsc 0.86142\n",
      "Batch train [23] loss 0.12312, dsc 0.87688\n",
      "Batch train [24] loss 0.12981, dsc 0.87019\n",
      "Batch train [25] loss 0.13771, dsc 0.86229\n",
      "Batch train [26] loss 0.12466, dsc 0.87534\n",
      "Batch train [27] loss 0.14803, dsc 0.85197\n",
      "Batch train [28] loss 0.15670, dsc 0.84330\n",
      "Batch train [29] loss 0.13690, dsc 0.86310\n",
      "Batch train [30] loss 0.12120, dsc 0.87880\n",
      "Batch train [31] loss 0.12259, dsc 0.87741\n",
      "Batch train [32] loss 0.15716, dsc 0.84284\n",
      "Batch train [33] loss 0.15632, dsc 0.84368\n",
      "Batch train [34] loss 0.13388, dsc 0.86612\n",
      "Batch train [35] loss 0.13794, dsc 0.86206\n",
      "Batch train [36] loss 0.13168, dsc 0.86832\n",
      "Batch train [37] loss 0.13942, dsc 0.86058\n",
      "Batch train [38] loss 0.16825, dsc 0.83175\n",
      "Batch train [39] loss 0.15308, dsc 0.84692\n",
      "Batch train [40] loss 0.12141, dsc 0.87859\n",
      "Epoch [29] train done\n",
      "Batch eval [1] loss 0.18515, dsc 0.81485\n",
      "Batch eval [2] loss 0.20069, dsc 0.79931\n",
      "Batch eval [3] loss 0.21171, dsc 0.78829\n",
      "Batch eval [4] loss 0.17521, dsc 0.82479\n",
      "Batch eval [5] loss 0.16563, dsc 0.83437\n",
      "Epoch [29] valid done\n",
      "Epoch [29] T 224.07s, deltaT 7.98s, loss: train 0.14341, valid 0.18768, dsc: train 0.85659, valid 0.81232\n",
      "Batch train [1] loss 0.15498, dsc 0.84502\n",
      "Batch train [2] loss 0.14072, dsc 0.85928\n",
      "Batch train [3] loss 0.14987, dsc 0.85013\n",
      "Batch train [4] loss 0.14205, dsc 0.85795\n",
      "Batch train [5] loss 0.14426, dsc 0.85574\n",
      "Batch train [6] loss 0.14549, dsc 0.85451\n",
      "Batch train [7] loss 0.12295, dsc 0.87705\n",
      "Batch train [8] loss 0.12493, dsc 0.87507\n",
      "Batch train [9] loss 0.12860, dsc 0.87140\n",
      "Batch train [10] loss 0.13096, dsc 0.86904\n",
      "Batch train [11] loss 0.17213, dsc 0.82787\n",
      "Batch train [12] loss 0.12778, dsc 0.87222\n",
      "Batch train [13] loss 0.15386, dsc 0.84614\n",
      "Batch train [14] loss 0.13033, dsc 0.86967\n",
      "Batch train [15] loss 0.12214, dsc 0.87786\n",
      "Batch train [16] loss 0.11198, dsc 0.88802\n",
      "Batch train [17] loss 0.15614, dsc 0.84386\n",
      "Batch train [18] loss 0.13447, dsc 0.86553\n",
      "Batch train [19] loss 0.12156, dsc 0.87844\n",
      "Batch train [20] loss 0.16817, dsc 0.83183\n",
      "Batch train [21] loss 0.15707, dsc 0.84293\n",
      "Batch train [22] loss 0.13540, dsc 0.86460\n",
      "Batch train [23] loss 0.13332, dsc 0.86668\n",
      "Batch train [24] loss 0.21039, dsc 0.78961\n",
      "Batch train [25] loss 0.18012, dsc 0.81988\n",
      "Batch train [26] loss 0.13792, dsc 0.86208\n",
      "Batch train [27] loss 0.16028, dsc 0.83972\n",
      "Batch train [28] loss 0.13481, dsc 0.86519\n",
      "Batch train [29] loss 0.12970, dsc 0.87030\n",
      "Batch train [30] loss 0.15112, dsc 0.84888\n",
      "Batch train [31] loss 0.13665, dsc 0.86335\n",
      "Batch train [32] loss 0.13828, dsc 0.86172\n",
      "Batch train [33] loss 0.11677, dsc 0.88323\n",
      "Batch train [34] loss 0.12507, dsc 0.87493\n",
      "Batch train [35] loss 0.13428, dsc 0.86572\n",
      "Batch train [36] loss 0.14128, dsc 0.85872\n",
      "Batch train [37] loss 0.16011, dsc 0.83989\n",
      "Batch train [38] loss 0.12704, dsc 0.87296\n",
      "Batch train [39] loss 0.14518, dsc 0.85482\n",
      "Batch train [40] loss 0.15543, dsc 0.84457\n",
      "Epoch [30] train done\n",
      "Batch eval [1] loss 0.22664, dsc 0.77336\n",
      "Batch eval [2] loss 0.21698, dsc 0.78302\n",
      "Batch eval [3] loss 0.23022, dsc 0.76978\n",
      "Batch eval [4] loss 0.16131, dsc 0.83869\n",
      "Batch eval [5] loss 0.18413, dsc 0.81587\n",
      "Epoch [30] valid done\n",
      "Epoch [30] T 231.98s, deltaT 7.91s, loss: train 0.14234, valid 0.20386, dsc: train 0.85766, valid 0.79614\n",
      "Elapsed time 0:03:51\n"
     ]
    }
   ],
   "source": [
    "# preparing model loop params\n",
    "low_res_model_info = prepare_model(epochs=30, in_channels=8, train_dataset=train_low_res_dataset, valid_dataset=valid_low_res_dataset, test_dataset=test_low_res_dataset)\n",
    "show_model_info(low_res_model_info)\n",
    "\n",
    "# getting everything necessary for model training\n",
    "low_res_train_loop_params = {k:v for k,v in low_res_model_info.items() if k not in ['model_total_params', 'model_total_trainable_params']}\n",
    "# running training loop\n",
    "train_loop(**low_res_train_loop_params)\n",
    "\n",
    "low_res_model = itemgetter('model')(low_res_model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full resolution cutting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading high/full res dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 1x dataset\n",
      "normalizing dataset\n",
      "normalizing done\n",
      "filtering labels\n",
      "filtering labels done\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n",
      "data type: float64 int8\n",
      "data max 12.81577046544424, min -0.40489707167932215\n",
      "label max 22, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0b4c06ae854191a2e619f598882af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=79, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bbbf068586404ab0e2c948e50f6a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset data and label shapes (1, 160, 32, 32) (1, 160, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "full_res_dataset = get_dataset(dataset_size=50, shrink_factor=1, filter_labels=filter_labels, unify_labels=False)\n",
    "full_res_dataset.to_numpy()\n",
    "full_res_dataset.show_data_type()\n",
    "preview_dataset(full_res_dataset, preview_index=0, show_hist=False)\n",
    "\n",
    "print('dataset data and label shapes', low_res_dataset.data_list[0].shape, full_res_dataset.data_list[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing low res network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting bounding box cut in full res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "full_res_split_dataset_obj = copy_split_dataset(full_res_dataset, low_res_split_dataset_obj)\n",
    "get_dataset_info(full_res_dataset, full_res_split_dataset_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### debuging cut algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved model to cpu\n",
      "CUDA Memory Usage\n",
      "GPU:        GeForce RTX 2070\n",
      "Allocated:  0.0 GB\n",
      "Cached:     0.0 GB\n",
      "Max memory: 0.2 GB\n",
      "Max Cached: 0.3 GB\n"
     ]
    }
   ],
   "source": [
    "# moving model to cpu and setting to eval mode, preventing model params changes/training\n",
    "low_res_model = low_res_model.to('cpu')\n",
    "#low_res_model.to(low_res_model_info['device'])\n",
    "low_res_model.eval()\n",
    "\n",
    "low_res_model_info['model'] = low_res_model\n",
    "torch.cuda.empty_cache()\n",
    "print('moved model to cpu')\n",
    "\n",
    "show_cuda_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug removing 0 outlier pixels from 1586\n",
      "debug box delta [ 29 -16   8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1689537 1689537\n",
      "debug bounding box sizes (43, 208, 160) (72, 192, 168)\n",
      "debug bounding boxes (53, 95, 144, 351, 176, 335) (39, 110, 152, 343, 172, 339)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05f720630d74617a38bdb256bf3f4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=79, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db96cc3894564631a96bf2d23b03a069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52feaee5f5db4b83a613eff65431e4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afceb9786074d28a9e9ac31f39a6b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_index = 24 # 48, 111\n",
    "tmp = get_full_res_cut(low_res_model, low_res_dataset.data_list[dataset_index],\n",
    "                 full_res_dataset.data_list[dataset_index], full_res_dataset.label_list[dataset_index],\n",
    "                 low_res_mask_threshold=0.5,\n",
    "                 desire_bounding_box_size=DESIRE_BOUNDING_BOX_SIZE, \n",
    "                 show_debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Running cut algorithm, creating cut dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting cut index 0\n",
      "debug removing 0 outlier pixels from 1180\n",
      "debug box delta [22 48 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1223526 1223526\n",
      "getting cut index 1\n",
      "debug removing 0 outlier pixels from 1375\n",
      "debug box delta [23 16 -8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1326052 1326052\n",
      "getting cut index 2\n",
      "debug removing 15 outlier pixels from 1713\n",
      "debug box delta [ 20  16 -24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1890464 1890464\n",
      "getting cut index 3\n",
      "debug removing 0 outlier pixels from 1561\n",
      "debug box delta [17 16  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1560217 1560217\n",
      "getting cut index 4\n",
      "debug removing 5 outlier pixels from 1239\n",
      "debug box delta [23 48 -8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1451227 1451227\n",
      "getting cut index 5\n",
      "debug removing 20 outlier pixels from 1242\n",
      "debug box delta [23 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1262651 1262651\n",
      "getting cut index 6\n",
      "debug removing 0 outlier pixels from 1196\n",
      "debug box delta [23 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1566938 1566938\n",
      "getting cut index 7\n",
      "debug removing 0 outlier pixels from 1027\n",
      "debug box delta [20 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 869847 869847\n",
      "getting cut index 8\n",
      "debug removing 0 outlier pixels from 1385\n",
      "debug box delta [20 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1397249 1397249\n",
      "getting cut index 9\n",
      "debug removing 0 outlier pixels from 1463\n",
      "debug box delta [20 16  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1350330 1350330\n",
      "getting cut index 10\n",
      "debug removing 4 outlier pixels from 1466\n",
      "debug box delta [22 16 -8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1635868 1635868\n",
      "getting cut index 11\n",
      "debug removing 11 outlier pixels from 1221\n",
      "debug box delta [26 48 -8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1283062 1283062\n",
      "getting cut index 12\n",
      "debug removing 0 outlier pixels from 1370\n",
      "debug box delta [25 32 -8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1518406 1518406\n",
      "getting cut index 13\n",
      "debug removing 50 outlier pixels from 1383\n",
      "debug box delta [23 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1504194 1504194\n",
      "getting cut index 14\n",
      "debug removing 0 outlier pixels from 1121\n",
      "debug box delta [24 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1084254 1084254\n",
      "getting cut index 15\n",
      "debug removing 23 outlier pixels from 1214\n",
      "debug box delta [26 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1221257 1221257\n",
      "getting cut index 16\n",
      "debug removing 0 outlier pixels from 946\n",
      "debug box delta [ 6 64 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 945639 945639\n",
      "getting cut index 17\n",
      "debug removing 0 outlier pixels from 1488\n",
      "debug box delta [ 25  16 -24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1469035 1469035\n",
      "getting cut index 18\n",
      "debug removing 0 outlier pixels from 1280\n",
      "debug box delta [26 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1322571 1322571\n",
      "getting cut index 19\n",
      "debug removing 0 outlier pixels from 1550\n",
      "debug box delta [16 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1593516 1593516\n",
      "getting cut index 20\n",
      "debug removing 0 outlier pixels from 1330\n",
      "debug box delta [25 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1390348 1390348\n",
      "getting cut index 21\n",
      "debug removing 0 outlier pixels from 1375\n",
      "debug box delta [ 24  16 -24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1463017 1463017\n",
      "getting cut index 22\n",
      "debug removing 1 outlier pixels from 1233\n",
      "debug box delta [27 48 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1162215 1162215\n",
      "getting cut index 23\n",
      "debug removing 0 outlier pixels from 1227\n",
      "debug box delta [22 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1029805 1029805\n",
      "getting cut index 24\n",
      "debug removing 0 outlier pixels from 1586\n",
      "debug box delta [ 29 -16   8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1689537 1689537\n",
      "getting cut index 25\n",
      "debug removing 0 outlier pixels from 1259\n",
      "debug box delta [24 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1141739 1141739\n",
      "getting cut index 26\n",
      "debug removing 0 outlier pixels from 1317\n",
      "debug box delta [23 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1167835 1167835\n",
      "getting cut index 27\n",
      "debug removing 0 outlier pixels from 1397\n",
      "debug box delta [ 26 -16   8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1783264 1783264\n",
      "getting cut index 28\n",
      "debug removing 21 outlier pixels from 1733\n",
      "debug box delta [21 16 -8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1944758 1944758\n",
      "getting cut index 29\n",
      "debug removing 0 outlier pixels from 1264\n",
      "debug box delta [22 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1583396 1583396\n",
      "getting cut index 30\n",
      "debug removing 4 outlier pixels from 1235\n",
      "debug box delta [20 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1248609 1248609\n",
      "getting cut index 31\n",
      "debug removing 0 outlier pixels from 1035\n",
      "debug box delta [25 48 40]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 947124 947124\n",
      "getting cut index 32\n",
      "debug removing 0 outlier pixels from 1588\n",
      "debug box delta [17 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1648187 1648187\n",
      "getting cut index 33\n",
      "debug removing 0 outlier pixels from 1403\n",
      "debug box delta [20 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1214697 1214697\n",
      "getting cut index 34\n",
      "debug removing 0 outlier pixels from 1523\n",
      "debug box delta [24 16 -8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1445951 1445951\n",
      "getting cut index 35\n",
      "debug removing 0 outlier pixels from 1792\n",
      "debug box delta [ 15  16 -24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1963068 1963068\n",
      "getting cut index 36\n",
      "debug removing 0 outlier pixels from 1437\n",
      "debug box delta [26 16  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1241941 1241941\n",
      "getting cut index 37\n",
      "debug removing 0 outlier pixels from 1392\n",
      "debug box delta [19 32 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1298886 1298886\n",
      "getting cut index 38\n",
      "debug removing 0 outlier pixels from 1430\n",
      "debug box delta [25 16  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1731533 1731533\n",
      "getting cut index 39\n",
      "debug removing 23 outlier pixels from 1290\n",
      "debug box delta [21 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1067335 1067335\n",
      "getting cut index 40\n",
      "debug removing 0 outlier pixels from 1301\n",
      "debug box delta [25 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1311715 1311715\n",
      "getting cut index 41\n",
      "debug removing 23 outlier pixels from 1356\n",
      "debug box delta [21 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1411792 1411792\n",
      "getting cut index 42\n",
      "debug removing 0 outlier pixels from 930\n",
      "debug box delta [32 32 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 951804 951804\n",
      "getting cut index 43\n",
      "debug removing 0 outlier pixels from 1174\n",
      "debug box delta [30 48 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1024831 1024831\n",
      "getting cut index 44\n",
      "debug removing 0 outlier pixels from 1446\n",
      "debug box delta [16 48  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1763923 1763923\n",
      "getting cut index 45\n",
      "debug removing 0 outlier pixels from 1158\n",
      "debug box delta [28 32 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1115633 1115633\n",
      "getting cut index 46\n",
      "debug removing 0 outlier pixels from 1541\n",
      "debug box delta [23 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1670156 1670156\n",
      "getting cut index 47\n",
      "debug removing 0 outlier pixels from 1455\n",
      "debug box delta [21 32  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1413179 1413179\n",
      "getting cut index 48\n",
      "debug removing 0 outlier pixels from 1025\n",
      "debug box delta [17 64 24]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 781269 781269\n",
      "getting cut index 49\n",
      "debug removing 0 outlier pixels from 1711\n",
      "debug box delta [19 16  8]\n",
      "debug, Does cut and original label contain the same amount of pixels? True 1756965 1756965\n"
     ]
    }
   ],
   "source": [
    "cut_full_res_dataset = full_res_dataset.copy(copy_lists=False)\n",
    "cut_full_res_dataset = get_cut_lists(low_res_model, low_res_dataset, full_res_dataset, cut_full_res_dataset, low_res_mask_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 192, 168) (72, 192, 168)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cut_full_res_dataset.set_output_label(None)\n",
    "debug_data, debug_label = cut_full_res_dataset[48]\n",
    "debug_data = debug_data[0] # channel dimension\n",
    "slice_index = 70\n",
    "print(debug_data.shape, debug_label.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "plt.subplot(1, 2, 1).set_title('data')\n",
    "plt.imshow(debug_data[slice_index], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2).set_title('label')\n",
    "plt.imshow(debug_label[slice_index], cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### reviewing full res and cut dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: float64 int8\n",
      "\n",
      "full res shape (1, 160, 512, 512) (160, 512, 512)\n",
      "cut full res shape (1, 72, 192, 168) (72, 192, 168)\n",
      "\n",
      "dataset RAM sizes in GB 17.578125 0.9733200073242188\n",
      "single item RAM in GB 0.0390625 0.3125\n",
      "\n",
      "data max 11.780218856954171, min -0.42423961281850314\n",
      "label max 22, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef94c72750840dcba30ce22ac826c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19143ecc0b8c4dd2adbb96261fa0ca0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cut_full_res_dataset.show_data_type()\n",
    "print()\n",
    "print('full res shape', full_res_dataset.data_list[0].shape, full_res_dataset.label_list[0].shape)\n",
    "print('cut full res shape', cut_full_res_dataset.data_list[0].shape, cut_full_res_dataset.label_list[0].shape)\n",
    "print()\n",
    "print('dataset RAM sizes in GB', full_res_dataset.get_data_size() / 1024**3, cut_full_res_dataset.get_data_size() / 1024**3)\n",
    "print('single item RAM in GB', full_res_dataset.label_list[0].nbytes / 1024**3, full_res_dataset.data_list[0].nbytes / 1024**3)\n",
    "print()\n",
    "preview_dataset(cut_full_res_dataset, max_slices=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Full resolution cut model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing cut dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAJBCAYAAAA5l61JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5Sd9X3f+893LhppBJIQ4iIk2UggiI0v4BBC6tjBlziYuiZxWa593MROHWN3Oa1zVprGjs9qenp61snFrt2sJPjgmmI3LvEF306CL9j1JW1MzP1mSwYMBgkhhAS6a6SZ+Z0/ZmMGkIyYPaMtjV6vtWZp79++/R6eR6M3z/Psvau1FgDg6NbX6wkAAL0nCAAAQQAACAIAIIIAAIggAAAyg0FQVRdW1dqquruq3jtTrwMAdK9m4nMIqqo/yQ+T/HKSdUmuT/Lm1tr3p/3FAICuDczQ856X5O7W2o+SpKr+OsnFSfYbBHNqqM3N/BmaCgCQJNvz6COttRP2d9tMBcGyJA9Mur4uyc8f6M5zMz8/X6+aoakAAEny9fbZHx/otpkKgmdUVZcmuTRJ5ma4V9MAADJzJxWuT7Ji0vXlnbGfaK1d3lo7t7V27mCGZmgaAMDBmKkguD7J6qpaWVVzkrwpyZdm6LUAgC7NyCGD1tpoVf12kq8m6U9yRWvtzpl4LQCgezN2DkFr7Zok18zU8wMA08cnFQIAggAAEAQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAA6SIIqmpFVX2zqr5fVXdW1Xs64/++qtZX1S2dn4umb7oAwEwY6OKxo0l+t7V2U1Udm+TGqrq2c9uHWmsf6H56AMChMOUgaK1tSLKhc3l7Vf0gybLpmhgAcOhMyzkEVXVqknOS/ENn6Ler6raquqKqjjvAYy6tqhuq6oZ9GZmOaQAAU9R1EFTVMUmuTvI7rbVtSS5LclqSszOxB+GD+3tca+3y1tq5rbVzBzPU7TQAgC50FQRVNZiJGPhka+1zSdJa29haG2utjSf5aJLzup8mADCTunmXQSX5WJIftNb+06TxpZPu9mtJ7pj69ACAQ6Gbdxm8NMmvJ7m9qm7pjP1BkjdX1dlJWpL7kryzqxkCADOum3cZ/M8ktZ+brpn6dACAXvBJhQCAIAAABAEAEEEAAEQQAAARBABABAEAEEEAAEQQAAARBABABAEAkO6+3AiALtXAQNLfP/UnGG9po/uS1qZvUhyVBAFAjwycfFK2vGJltp3at/+vijsIQ4+2nPR3j2b8jjXTOzmOOoIAoEfGli7JY2/Ymcte8skpP8fHN700ax47KwvumMaJcVQSBAAzpIaG0jc8nPTv/3StPSfMy3OP35AL5o1P+TV+uPCe3LL4hTluyfFPGm8jezO+c1cyPjbl5+boIggAZkJff/a+7AVZf8GcjB5zgOP7S0by+0tv7uplfnbufRm8aFPWrl79pPGFaypL/+b+jK5b39Xzc/QQBAAzoPr7s+mcobz/kk/nguH79nufwSQL++YkmTPl13nRnP5c86Irs+uFT0THWEsuvvkdGbt+USIIOEiCALrQv2hh6rhFaQNTPEu8tWTrjoxt3mLX7izRN39++pYsTps/L3uObzljzsY8Z+CYGXu9werPkv75TxtfvnBrdqxYnmO2rrSNcVAEAUxRDQxkxwVn5oELk/4Fe6f0HG2ssuC7S7P0M3dlbNOmaZ4hvbDv587MvRfPSf/SXXnlqlvy3IHdSWYuCA7kbcv+Vz7wjtdk/ZZFtjEOiiCAqaq+bH7eQP781VfkFXO3TekpdrR9OX/8X+WULw8nflfPCltXDeXdv/zVvGvRmgxWfwbr0MdAkvzT+Y/m4rP/e7aO77WNcVAEARyE/gUL0p5zSsaOHfrJ2PhAX3YvHcvJ/dsy3DfFY8DjyXGLd2Tb2Sdn3smLfjLct3c0/esfyehDG7udOofA5O1jx3Mqy+dsnvo2MV1zqr70py/HVPvJNjZ/yYL0P/RoRtdvcPiApxEEcBDGfua5ueutw3nO6if+ge7vG89vnbg2qwZGM9WTwoZqIL9/5lfzV7/zC9k2Mvcn4w89dmwWX70yC67enDY62u30mWGTt4/XLbkt589dn14cJtifydvYuq0LU3+7Iif+1aMZ37mz11PjMCMI4CDsOXFeLjzv1vzlsuv2c+vwlJ+3v/ryxmO25o2rv/Kk8W/s7s97bnxnFpSvGzkSPH37ODxiIHnyNnbPvh35lbv+TU6aMycRBDyFIIAD6F+wIGPPPzW7T5qbR144kJXzDt0B2OP7dmXnafuy85+ckzmPjWbu2g0ZXf/gIXt9nlkvt4+pGq5kYMXOPHrhmZm7ZTTDdz2S0Xt/7HsQSCII4MBWLM1dvz7xf34r523KJcfemkP1f34rB8fzH3/pc/nuOafn79avyqKPLc9cQXB46eH2MVWL+4fyJ+dcnf9x2vNz65Zl2fTJU7L4/nUOS5FEEMABjR07lOes3tiT3cAL++blLcduzluO3Zy/mP9grjzhdZlb5f/kDiO93D6maqgG8/r5u/L6+TfkG4tuzntOfmcW9/cngoAIAniSvvnzs+/nzszWVUPZsaLyuiW393pKOW3Ow3nkvLG0vvMz/MhYjr1+ncMHdO3k/h3Z86Jd2fS2l2Tuoy0Lb9qYsbvv7fW06CFBAJP0LT4u9148J+/+5a/mlMFH84/mPZBe/5/fL8x9LJe9+uO57+VL8pc/fHnmbD05/YKALq0c6M8V51+Z75+9LJ/fcE62XbYs8wXBUU0QQJL09acGB9KOHU7/0l1516I1nfeR93438MK+eblweCQZXp+bT7kva4dfkCl+UDLToAYGkv7+jA30pb9v6t9S2GvDfXPy8rnJy+euz742kE8cuyJP/wBkjiaCgKNeDQ1l78tekE3nDGXP8S2vXHVLBss/uTxd/4IF2fHKn8nm5w1k98kTn0MBs4Ug4KjXNzyc9RfMyfsv+XTOmLMxzx3Y3bOPm+XwVosX5YELkz9/9RU5oX97Vg/sSzefQwGHE0EAfZXRY1ouGL6v8610h28MDPWNZu8x/RlecnzayN6M79zlI2gPoTbQn/4Fe/OKuY9/XPVgr6cE08bHoMER5NUL78yjl+zM2v9jdTa+5QUZOOXkXk8JmCXsIYAjyK8Mb835538kO8dbLr75HRm7flGybn2vpwXMAoKAo1b/ooWp4xZl7PhjM37M6BGxu2yoBnNi/2DSnxw7dyTpc1443Tu2f3f2HF/pX70qtXsk449szviePb2eFoeYIOCoVAMD2XHBmXngwmTu8bvzG2d8N4v6/HXg6PTzc+/L6tffldtfsix9P5qXVZ9ZkNz6g15Pi0PMb0COTtWXzc8byJ+/+oq8Yu62DFZ/BmvuMz8OZqHnzRnOVaddk7FVLe9a+erc//dnZujWXs+KQ00QcHTqq6SS+bW3c7Y4HEBffwaWLc3o0uOyfdlwlizanP6qXs9q2g3VYFLJvP59yexbPA6CIAD4KfrmD2fD61Ykr92S5Qs35a1L/z4DPiuSWUgQAPwUNWcwW89s+fqLP5aVg49/RsWRcAoqPDu2aoCD0G83OrOcIAAABAHAwRhrvZ4BzCxBAPBTtL37snBN5eKb35GL1l6UT+9YmLF25H7tMRyIIAD4KcZ37srSv7k/p/xffdnx4eX5wF2vyWh8oRSzj3cZcHQab6nxZNv43OwY35KhGsxgeSsZ+zE+ltF165N163PM1pV5cOvCjLXmvfrMOoKAo1IbG8viH4zmPdf+8wwu3pNLzrwlf3DC93JMn08rBI5ODhlwdBofyzHfXJPn//GGrPrjsVx143l5bHy017MC6Bl7CDhqjW3blmzblv4di9O344w4TYyj1b42lkfH92T7eMvG3QtSTpE4KgkCgKPczXvH8y/v+M1s/eHizF/Xl2X3Puy0yaOQIAA4yt2y57kZ//KSnPGpNWl792V89+5eT4keEARwBNk6vjt37+vP5rH52fTosVmwb198Xg7dGhkfzMDulrHNW3o9FXpIEMAR5Is7VuQPv/WGzL93ICfcO57asKHXUwJmCUEAR5Drtp+eFV9Jhv/2hqSNZ2zUOyOA6SEIYGwsQ5v68hebfzFnzH0o58+7N2fNmdfrWe3XWKv07Wtp+/b2eipHpRrZl/bQ3Hx4ywuzfM7mvGzefZO+EvnIsmt8b743Mje371mRL2x4cYa2eZ/N0U4QcNQb37k7z/na9nzr/l/Il0+s/O3Fd+Wq067JUA32emocZsa3PJpVXzwhX7jtldmxonLrr16XDy69qdfTmpJ7R8fyW9e9NYu+OTdzHxvPwps3xv6mo5sg4KjX9u1Nrr89i65Pjj99ZW7/2WUZW+WjaXm68Z070/ftm3Pct5Pjzn9RbnzZc5IjNAgeGjsmc2+flyX/7ca0kRExgCCAyWr3SPrumZdLT31NTh3enEsW3pCzh4Z6OqcNozvy2e1n5ZbtK/LNtWfk9Mf29XQ+TOjftif3rz0pb1/wizlteFP+2cIbc9qRePhg3PtUmCAIYJLxzVuy6rMLs+67q3Pnqudn468vyEdX/K+ezunv95ySP/v/LsqyvxvN6Y/ty8Ca+31ozGGgPbAhZ3xiKPd85Xm57sUvyuD/NprfW3xPr6cFUyYIYJLxPXuSW3+QoVuTE897Ye56/QkZWz6e/urd1348uO+4LFqbDP3t9UkiBg4T49u3J9ffnqEkS+q83PtrJyQ5woLAzgEmEQRwAP2P7cqDNyzNy8cvyRmLNuU9J319Rg8f7Brfm49tXZ3PPXh29o498VXMDz64OCvXO0xA9yZvY+sfWZQT7h1PmncXMEEQwAG0+9fn9CuT8c/Pz83nn5zP/9aWnH3CnTP2elvG9+ZDN7wqKz9eOXb7E28r/JmRHakHNtozQNcmb2Onbdmd2rDBZ1nwE10HQVXdl2R7JvZkjrbWzq2qxUk+leTUJPcleWNr7dFuXwsOpfE9e5IfTuwCXnTiz+X+3YuzY3zPk+4zWP1TenviWBvPSBvN+KTvWNwyPpD+jUMZunlNxh594q+LvbqHv2otu8cGp237mG772lj2tbEDbmOQTN8egle01h6ZdP29Sb7RWvujqnpv5/rvT9NrwSE3b92O/P21L8iLTz39J2PVl/zSaXflP57ylSwdeHZnl39mx/H5k7Wvydatwz8ZG98zkJNubWkjI9M2bw6N6d4+ptO+Npa/eOy0fHTNS7Nry7BtjAOaqUMGFye5oHP540m+FUHAEayt+VFO/8jxydCcJ8YGB/J3v/nC/PiN387SZ/k36cr1/yjHfGxhlt7+8BOD4+NpW7dnzDfNHXGme/uYTvvaWD665qU55cNzMueBjbYxDmg6NtOW5GtV1ZL8v621y5Oc1Fp7/FtXHkpy0lMfVFWXJrk0SeZm+Kk3w2GljYxkdP2DTxqrwTkZ2nxi7hxZlhP6735Wz7d+68IsW7czoz+6bxpnSa880/ZxUv/dWdTXl+P6Z/Z33Ujbl01jIxmZdJxp+/hgdm0ZzpwHNmb0vvtn9PU5sk1HEPxia219VZ2Y5NqqWjP5xtZa68RCnjJ+eZLLk2RBLXaYlCNOGxvLiTeN5E+PeUP+n2Oe3ZnaC9dW+jfe79PhZrHJ28f/ffxYfunc7+fDy7+WhX0z9z0ZX921ML930yUZW/dEeNRYTRwm2Lp9xl6X2aHrIGitre/8+XBVfT7JeUk2VtXS1tqGqlqa5OGf+iRwJBofy+D/vCOrbpw7ccD4WWh792Z0955nviNHrknbRy0+Lt/6N8/L1lO+nIUz+JEWX996VpZcPZyF16590ngbGXGYgGfUVRBU1fwkfa217Z3Lr0nyH5J8Kclbk/xR588vdjtROBy1kZGMOUGLA3h8++ivvszZvDTX7jw9KwY3z9jr3bJ5eYa27PMOAqak2z0EJyX5fFU9/lz/vbX2laq6Psmnq+rtSX6c5I1dvg7AEWt8164s/9be/OdH35DxOc98/6ka3tBywt3rHYpiSroKgtbaj5K8eD/jm5O8qpvnBpgt2shIBr55S075Tv8z37mrFxrP6JiPsGJqfFIhwKEwPpY27h9rDl+9+8YWAOCwIQgAAEEAAAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAABIMjDVB1bVmUk+NWloVZJ/l2RRknck2dQZ/4PW2jVTniEAMOOmHASttbVJzk6SqupPsj7J55P8ZpIPtdY+MC0zBABm3HQdMnhVkntaaz+epucDAA6h6QqCNyW5atL1366q26rqiqo6bn8PqKpLq+qGqrphX0amaRoAwFR0HQRVNSfJ65N8pjN0WZLTMnE4YUOSD+7vca21y1tr57bWzh3MULfTAAC6MB17CF6b5KbW2sYkaa1tbK2NtdbGk3w0yXnT8BoAwAyajiB4cyYdLqiqpZNu+7Ukd0zDawAAM2jK7zJIkqqan+SXk7xz0vCfVNXZSVqS+55yGwBwGOoqCFprO5Mc/5SxX+9qRgDAIeeTCgEAQQAACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAAAiCACACAIAIIIAAIggAABykEFQVVdU1cNVdcekscVVdW1V3dX587jOeFXVn1XV3VV1W1W9ZKYmDwBMj4PdQ3BlkgufMvbeJN9ora1O8o3O9SR5bZLVnZ9Lk1zW/TQBgJl0UEHQWvtOki1PGb44ycc7lz+e5FcnjX+iTbguyaKqWjodkwUAZkY35xCc1Frb0Ln8UJKTOpeXJXlg0v3WdcYAgMPUtJxU2FprSdqzeUxVXVpVN1TVDfsyMh3TAACmqJsg2Pj4oYDOnw93xtcnWTHpfss7Y0/SWru8tXZua+3cwQx1MQ0AoFvdBMGXkry1c/mtSb44afw3Ou82OD/J1kmHFgCAw9DAwdypqq5KckGSJVW1LskfJvmjJJ+uqrcn+XGSN3bufk2Si5LcnWRXkt+c5jkDANPsoIKgtfbmA9z0qv3ctyV5dzeTAgAOLZ9UCAAIAgBAEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAABEEAAAEQQAQAQBABBBAADkIIKgqq6oqoer6o5JY39aVWuq6raq+nxVLeqMn1pVu6vqls7PR2Zy8gDA9DiYPQRXJrnwKWPXJnlBa+1FSX6Y5H2TbruntXZ25+dd0zNNAGAmPWMQtNa+k2TLU8a+1lob7Vy9LsnyGZgbAHCITMc5BP8iyZcnXV9ZVTdX1ber6mXT8PwAwAwb6ObBVfX+JKNJPtkZ2pDkOa21zVX1s0m+UFVntda27eexlya5NEnmZribaQAAXZryHoKqeluS1yV5S2utJUlrbaS1trlz+cYk9yQ5Y3+Pb61d3lo7t7V27mCGpjoNAGAaTCkIqurCJP82yetba7smjZ9QVf2dy6uSrE7yo+mYKAAwc57xkEFVXZXkgiRLqmpdkj/MxLsKhpJcW1VJcl3nHQUvT/IfqmpfkvEk72qtbdnvEwMAh41nDILW2pv3M/yxA9z36iRXdzspAODQ8kmFAIAgAAAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAEAQAQQQAARBAAABEEAEAOIgiq6oqqeriq7pg09u+ran1V3dL5uWjSbe+rqruram1V/cpMTRwAmD4Hs4fgyiQX7mf8Q621szs/1yRJVT0/yZuSnNV5zF9WVf90TRYAmBnPGAStte8k2XKQz3dxkr9urY201u5NcneS87qYHwBwCHRzDsFvV9VtnUMKx3XGliV5YNJ91nXGnqaqLq2qG6rqhn0Z6WIaAEC3phoElyU5LcnZSTYk+eCzfYLW2uWttXNba+cOZmiK0wAApsOUgqC1trG1NtZaG0/y0TxxWGB9khWT7rq8MwYAHMamFARVtXTS1V9L8vg7EL6U5E1VNVRVK5OsTvK97qYIAMy0gWe6Q1VdleSCJEuqal2SP0xyQVWdnaQluS/JO5OktXZnVX06yfeTjCZ5d2ttbGamDgBMl2qt9XoOWVCL28/Xq3o9DQCY1b7ePntja+3c/d3mkwoBAEEAAAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgBxEEFTVFVX1cFXdMWnsU1V1S+fnvqq6pTN+alXtnnTbR2Zy8gDA9Bg4iPtcmeTPk3zi8YHW2j97/HJVfTDJ1kn3v6e1dvZ0TRAAmHnPGAStte9U1an7u62qKskbk7xyeqcFABxK3Z5D8LIkG1trd00aW1lVN1fVt6vqZQd6YFVdWlU3VNUN+zLS5TQAgG4czCGDn+bNSa6adH1Dkue01jZX1c8m+UJVndVa2/bUB7bWLk9yeZIsqMWty3kAAF2Y8h6CqhpI8oYkn3p8rLU20lrb3Ll8Y5J7kpzR7SQBgJnVzSGDVydZ01pb9/hAVZ1QVf2dy6uSrE7yo+6mCADMtIN52+FVSb6b5MyqWldVb+/c9KY8+XBBkrw8yW2dtyF+Nsm7WmtbpnPCAMD0O5h3Gbz5AONv28/Y1Umu7n5aAMCh5JMKAQBBAAAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAACIIAIAIAgAgggAAiCAAAJJUa63Xc0hVbUry4yRLkjzS4+nMpNm+fIllnA1m+/Ils38ZZ/vyJZZxqp7bWjthfzccFkHwuKq6obV2bq/nMVNm+/IllnE2mO3Ll8z+ZZzty5dYxpngkAEAIAgAgMMvCC7v9QRm2GxfvsQyzgazffmS2b+Ms335Ess47Q6rcwgAgN443PYQAAA9cFgEQVVdWFVrq+ruqnpvr+czHapqRVV9s6q+X1V3VtV7OuOLq+raqrqr8+dxvZ5rN6qqv6purqq/6VxfWVX/0FmXn6qqOb2eYzeqalFVfbaq1lTVD6rqF2bhOvzfO9voHVV1VVXNPdLXY1VdUVUPV9Udk8b2u95qwp91lvW2qnpJ72Z+cA6wfH/a2U5vq6rPV9WiSbe9r7N8a6vqV3oz62dnf8s46bbfrapWVUs612fFOuyM/6vOeryzqv5k0viMr8OeB0FV9Sf5iySvTfL8JG+uquf3dlbTYjTJ77bWnp/k/CTv7izXe5N8o7W2Osk3OtePZO9J8oNJ1/84yYdaa6cneTTJ23syq+nzn5N8pbX2M0lenIllnTXrsKqWJfnXSc5trb0gSX+SN+XIX49XJrnwKWMHWm+vTbK683NpkssO0Ry7cWWevnzXJnlBa+1FSX6Y5H1J0vm986YkZ3Ue85ed37uHuyvz9GVMVa1I8pok908anhXrsKpekeTiJC9urZ2V5AOd8UOyDnseBEnOS3J3a+1HrbW9Sf46E/9BjmittQ2ttZs6l7dn4h+SZZlYto937vbxJL/amxl2r6qWJ/nHSf5L53oleWWSz3bucqQv38IkL0/ysSRpre1trT2WWbQOOwaSzKuqgSTDSTbkCF+PrbXvJNnylOEDrbeLk3yiTbguyaKqWnpoZjo1+1u+1trXWmujnavXJVneubwQ68QAAAN6SURBVHxxkr9urY201u5Ncncmfu8e1g6wDpPkQ0n+bZLJJ8DNinWY5F8m+aPW2kjnPg93xg/JOjwcgmBZkgcmXV/XGZs1qurUJOck+YckJ7XWNnRueijJST2a1nT4cCb+Yo53rh+f5LFJv5SO9HW5MsmmJP+1c1jkv1TV/MyiddhaW5+J/wu5PxMhsDXJjZld6/FxB1pvs/F30L9I8uXO5VmzfFV1cZL1rbVbn3LTbFnGM5K8rHO47ttV9XOd8UOyfIdDEMxqVXVMkquT/E5rbdvk29rEWzyOyLd5VNXrkjzcWrux13OZQQNJXpLkstbaOUl25imHB47kdZgknePoF2cifk5JMj/72U072xzp6+2nqar3Z+KQ5Sd7PZfpVFXDSf4gyb/r9Vxm0ECSxZk4zPx7ST7d2fN6SBwOQbA+yYpJ15d3xo54VTWYiRj4ZGvtc53hjY/vyur8+fCBHn+Ye2mS11fVfZk4zPPKTBxvX9TZ9Zwc+etyXZJ1rbV/6Fz/bCYCYbaswyR5dZJ7W2ubWmv7knwuE+t2Nq3Hxx1ovc2a30FV9bYkr0vylvbEe8pny/KdlolwvbXze2d5kpuq6uTMnmVcl+RznUMf38vE3tclOUTLdzgEwfVJVnfOap6TiRMnvtTjOXWtU3UfS/KD1tp/mnTTl5K8tXP5rUm+eKjnNh1aa+9rrS1vrZ2aiXX2P1prb0nyzSSXdO52xC5fkrTWHkryQFWd2Rl6VZLvZ5asw477k5xfVcOdbfbxZZw163GSA623LyX5jc6Z6ucn2Trp0MIRo6ouzMQhvNe31nZNuulLSd5UVUNVtTITJ959rxdz7EZr7fbW2omttVM7v3fWJXlJ5+/prFiHSb6Q5BVJUlVnJJmTiS83OjTrsLXW858kF2XirNh7kry/1/OZpmX6xUzskrwtyS2dn4sycZz9G0nuSvL1JIt7PddpWNYLkvxN5/KqzoZ6d5LPJBnq9fy6XLazk9zQWY9fSHLcbFuHSf7PJGuS3JHkvyUZOtLXY5KrMnFOxL5M/MPx9gOttySViXc63ZPk9ky846LnyzCF5bs7E8eZH/9985FJ939/Z/nWJnltr+c/1WV8yu33JVkyy9bhnCR/1fm7eFOSVx7KdeiTCgGAw+KQAQDQY4IAABAEAIAgAAAiCACACAIAIIIAAIggAACS/P8Pf3zhfo9PqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "cut_full_res_dataset.set_output_label([OARS_LABELS.EYE_L, OARS_LABELS.EYE_R, OARS_LABELS.LENS_L, OARS_LABELS.LENS_R])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cut_full_res_dataset.__getitem__(0)[1][47])\n",
    "plt.show()\n",
    "\n",
    "cut_split_dataset_obj = copy_split_dataset(cut_full_res_dataset, low_res_split_dataset_obj)\n",
    "get_dataset_info(cut_full_res_dataset, cut_split_dataset_obj)\n",
    "\n",
    "cut_train_dataset, cut_valid_dataset, cut_test_dataset = itemgetter(\n",
    "    'train_dataset', 'valid_dataset', 'test_dataset')(cut_split_dataset_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Cut Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device running \"cuda\"\n",
      "max output channels 128\n",
      "Model number of params: 1193537, trainable 1193537\n",
      "Running training loop\n",
      "Batch train [1] loss 0.99691, dsc 0.00309\n",
      "Batch train [2] loss 0.99556, dsc 0.00444\n",
      "Batch train [3] loss 0.99433, dsc 0.00567\n",
      "Batch train [4] loss 0.99303, dsc 0.00697\n",
      "Batch train [5] loss 0.99537, dsc 0.00463\n",
      "Batch train [6] loss 0.99128, dsc 0.00872\n",
      "Batch train [7] loss 0.99275, dsc 0.00725\n",
      "Batch train [8] loss 0.99258, dsc 0.00742\n",
      "Batch train [9] loss 0.99226, dsc 0.00774\n",
      "Batch train [10] loss 0.99326, dsc 0.00674\n",
      "Batch train [11] loss 0.99157, dsc 0.00843\n",
      "Batch train [12] loss 0.99239, dsc 0.00761\n",
      "Batch train [13] loss 0.99144, dsc 0.00856\n",
      "Batch train [14] loss 0.98963, dsc 0.01037\n",
      "Batch train [15] loss 0.99201, dsc 0.00799\n",
      "Batch train [16] loss 0.99007, dsc 0.00993\n",
      "Batch train [17] loss 0.99136, dsc 0.00864\n",
      "Batch train [18] loss 0.99111, dsc 0.00889\n",
      "Batch train [19] loss 0.99051, dsc 0.00949\n",
      "Batch train [20] loss 0.99232, dsc 0.00768\n",
      "Epoch [1] train done\n",
      "Batch eval [1] loss 0.99468, dsc 0.00532\n",
      "Batch eval [2] loss 0.99490, dsc 0.00510\n",
      "Batch eval [3] loss 0.99371, dsc 0.00629\n",
      "Batch eval [4] loss 0.99349, dsc 0.00651\n",
      "Batch eval [5] loss 0.99233, dsc 0.00767\n",
      "Epoch [1] valid done\n",
      "Epoch [1] T 68.57s, deltaT 68.57s, loss: train 0.99249, valid 0.99382, dsc: train 0.00751, valid 0.00618\n",
      "Batch train [1] loss 0.98875, dsc 0.01125\n",
      "Batch train [2] loss 0.99151, dsc 0.00849\n",
      "Batch train [3] loss 0.99136, dsc 0.00864\n",
      "Batch train [4] loss 0.98939, dsc 0.01061\n",
      "Batch train [5] loss 0.99074, dsc 0.00926\n",
      "Batch train [6] loss 0.99249, dsc 0.00751\n",
      "Batch train [7] loss 0.99042, dsc 0.00958\n",
      "Batch train [8] loss 0.98881, dsc 0.01119\n",
      "Batch train [9] loss 0.99075, dsc 0.00925\n",
      "Batch train [10] loss 0.99006, dsc 0.00994\n",
      "Batch train [11] loss 0.98926, dsc 0.01074\n",
      "Batch train [12] loss 0.99061, dsc 0.00939\n",
      "Batch train [13] loss 0.99170, dsc 0.00830\n",
      "Batch train [14] loss 0.99148, dsc 0.00852\n",
      "Batch train [15] loss 0.99150, dsc 0.00850\n",
      "Batch train [16] loss 0.99216, dsc 0.00784\n",
      "Batch train [17] loss 0.99181, dsc 0.00819\n",
      "Batch train [18] loss 0.99065, dsc 0.00935\n",
      "Batch train [19] loss 0.99323, dsc 0.00677\n",
      "Batch train [20] loss 0.99116, dsc 0.00884\n",
      "Epoch [2] train done\n",
      "Batch eval [1] loss 0.99276, dsc 0.00724\n",
      "Batch eval [2] loss 0.99462, dsc 0.00538\n",
      "Batch eval [3] loss 0.99192, dsc 0.00808\n",
      "Batch eval [4] loss 0.99093, dsc 0.00907\n",
      "Batch eval [5] loss 0.98667, dsc 0.01333\n",
      "Epoch [2] valid done\n",
      "Epoch [2] T 133.34s, deltaT 64.77s, loss: train 0.99089, valid 0.99138, dsc: train 0.00911, valid 0.00862\n",
      "Batch train [1] loss 0.99056, dsc 0.00944\n",
      "Batch train [2] loss 0.99200, dsc 0.00800\n",
      "Batch train [3] loss 0.99062, dsc 0.00938\n",
      "Batch train [4] loss 0.99250, dsc 0.00750\n",
      "Batch train [5] loss 0.99018, dsc 0.00982\n",
      "Batch train [6] loss 0.99133, dsc 0.00867\n",
      "Batch train [7] loss 0.98921, dsc 0.01079\n",
      "Batch train [8] loss 0.98995, dsc 0.01005\n",
      "Batch train [9] loss 0.98972, dsc 0.01028\n",
      "Batch train [10] loss 0.99170, dsc 0.00830\n",
      "Batch train [11] loss 0.99038, dsc 0.00962\n",
      "Batch train [12] loss 0.98821, dsc 0.01179\n",
      "Batch train [13] loss 0.99333, dsc 0.00667\n",
      "Batch train [14] loss 0.98857, dsc 0.01143\n",
      "Batch train [15] loss 0.99102, dsc 0.00898\n",
      "Batch train [16] loss 0.99068, dsc 0.00932\n",
      "Batch train [17] loss 0.99172, dsc 0.00828\n",
      "Batch train [18] loss 0.98949, dsc 0.01051\n",
      "Batch train [19] loss 0.99051, dsc 0.00949\n",
      "Batch train [20] loss 0.99031, dsc 0.00969\n",
      "Epoch [3] train done\n",
      "Batch eval [1] loss 0.99158, dsc 0.00842\n",
      "Batch eval [2] loss 0.99307, dsc 0.00693\n",
      "Batch eval [3] loss 0.99112, dsc 0.00888\n",
      "Batch eval [4] loss 0.99010, dsc 0.00990\n",
      "Batch eval [5] loss 0.98516, dsc 0.01484\n",
      "Epoch [3] valid done\n",
      "Epoch [3] T 197.24s, deltaT 63.90s, loss: train 0.99060, valid 0.99021, dsc: train 0.00940, valid 0.00979\n",
      "Batch train [1] loss 0.98896, dsc 0.01104\n",
      "Batch train [2] loss 0.99157, dsc 0.00843\n",
      "Batch train [3] loss 0.99113, dsc 0.00887\n",
      "Batch train [4] loss 0.99054, dsc 0.00946\n",
      "Batch train [5] loss 0.99050, dsc 0.00950\n",
      "Batch train [6] loss 0.99157, dsc 0.00843\n",
      "Batch train [7] loss 0.99221, dsc 0.00779\n",
      "Batch train [8] loss 0.98988, dsc 0.01012\n",
      "Batch train [9] loss 0.98807, dsc 0.01193\n",
      "Batch train [10] loss 0.99085, dsc 0.00915\n",
      "Batch train [11] loss 0.99240, dsc 0.00760\n",
      "Batch train [12] loss 0.98918, dsc 0.01082\n",
      "Batch train [13] loss 0.98889, dsc 0.01111\n",
      "Batch train [14] loss 0.99069, dsc 0.00931\n",
      "Batch train [15] loss 0.99027, dsc 0.00973\n",
      "Batch train [16] loss 0.99214, dsc 0.00786\n",
      "Batch train [17] loss 0.99109, dsc 0.00891\n",
      "Batch train [18] loss 0.98876, dsc 0.01124\n",
      "Batch train [19] loss 0.98871, dsc 0.01129\n",
      "Batch train [20] loss 0.99007, dsc 0.00993\n",
      "Epoch [4] train done\n",
      "Batch eval [1] loss 0.99161, dsc 0.00839\n",
      "Batch eval [2] loss 0.99314, dsc 0.00686\n",
      "Batch eval [3] loss 0.99121, dsc 0.00879\n",
      "Batch eval [4] loss 0.99021, dsc 0.00979\n",
      "Batch eval [5] loss 0.98536, dsc 0.01464\n",
      "Epoch [4] valid done\n",
      "Epoch [4] T 261.73s, deltaT 64.49s, loss: train 0.99037, valid 0.99031, dsc: train 0.00963, valid 0.00969\n",
      "Batch train [1] loss 0.98828, dsc 0.01172\n",
      "Batch train [2] loss 0.99066, dsc 0.00934\n",
      "Batch train [3] loss 0.98954, dsc 0.01046\n",
      "Batch train [4] loss 0.99031, dsc 0.00969\n",
      "Batch train [5] loss 0.99020, dsc 0.00980\n",
      "Batch train [6] loss 0.99064, dsc 0.00936\n",
      "Batch train [7] loss 0.98881, dsc 0.01119\n",
      "Batch train [8] loss 0.98985, dsc 0.01015\n",
      "Batch train [9] loss 0.99060, dsc 0.00940\n",
      "Batch train [10] loss 0.98837, dsc 0.01163\n",
      "Batch train [11] loss 0.99110, dsc 0.00890\n",
      "Batch train [12] loss 0.99104, dsc 0.00896\n",
      "Batch train [13] loss 0.99064, dsc 0.00936\n",
      "Batch train [14] loss 0.99242, dsc 0.00758\n",
      "Batch train [15] loss 0.99121, dsc 0.00879\n",
      "Batch train [16] loss 0.98912, dsc 0.01088\n",
      "Batch train [17] loss 0.99163, dsc 0.00837\n",
      "Batch train [18] loss 0.98830, dsc 0.01170\n",
      "Batch train [19] loss 0.98839, dsc 0.01161\n",
      "Batch train [20] loss 0.99121, dsc 0.00879\n",
      "Epoch [5] train done\n",
      "Batch eval [1] loss 0.99136, dsc 0.00864\n",
      "Batch eval [2] loss 0.99290, dsc 0.00710\n",
      "Batch eval [3] loss 0.99090, dsc 0.00910\n",
      "Batch eval [4] loss 0.98982, dsc 0.01018\n",
      "Batch eval [5] loss 0.98481, dsc 0.01519\n",
      "Epoch [5] valid done\n",
      "Epoch [5] T 325.69s, deltaT 63.96s, loss: train 0.99012, valid 0.98996, dsc: train 0.00988, valid 0.01004\n",
      "Batch train [1] loss 0.98807, dsc 0.01193\n",
      "Batch train [2] loss 0.99071, dsc 0.00929\n",
      "Batch train [3] loss 0.99029, dsc 0.00971\n",
      "Batch train [4] loss 0.99023, dsc 0.00977\n",
      "Batch train [5] loss 0.99276, dsc 0.00724\n",
      "Batch train [6] loss 0.98887, dsc 0.01113\n",
      "Batch train [7] loss 0.99183, dsc 0.00817\n",
      "Batch train [8] loss 0.98760, dsc 0.01240\n",
      "Batch train [9] loss 0.99228, dsc 0.00772\n",
      "Batch train [10] loss 0.98999, dsc 0.01001\n",
      "Batch train [11] loss 0.98746, dsc 0.01254\n",
      "Batch train [12] loss 0.98915, dsc 0.01085\n",
      "Batch train [13] loss 0.98893, dsc 0.01107\n",
      "Batch train [14] loss 0.98980, dsc 0.01020\n",
      "Batch train [15] loss 0.99084, dsc 0.00916\n",
      "Batch train [16] loss 0.99222, dsc 0.00778\n",
      "Batch train [17] loss 0.99091, dsc 0.00909\n",
      "Batch train [18] loss 0.98810, dsc 0.01190\n",
      "Batch train [19] loss 0.98941, dsc 0.01059\n",
      "Batch train [20] loss 0.98778, dsc 0.01222\n",
      "Epoch [6] train done\n",
      "Batch eval [1] loss 0.99109, dsc 0.00891\n",
      "Batch eval [2] loss 0.99264, dsc 0.00736\n",
      "Batch eval [3] loss 0.99058, dsc 0.00942\n",
      "Batch eval [4] loss 0.98947, dsc 0.01053\n",
      "Batch eval [5] loss 0.98415, dsc 0.01585\n",
      "Epoch [6] valid done\n",
      "Epoch [6] T 389.44s, deltaT 63.74s, loss: train 0.98986, valid 0.98959, dsc: train 0.01014, valid 0.01041\n",
      "Batch train [1] loss 0.98693, dsc 0.01307\n",
      "Batch train [2] loss 0.99184, dsc 0.00816\n",
      "Batch train [3] loss 0.99029, dsc 0.00971\n",
      "Batch train [4] loss 0.99057, dsc 0.00943\n",
      "Batch train [5] loss 0.99055, dsc 0.00945\n",
      "Batch train [6] loss 0.99012, dsc 0.00988\n",
      "Batch train [7] loss 0.99084, dsc 0.00916\n",
      "Batch train [8] loss 0.99249, dsc 0.00751\n",
      "Batch train [9] loss 0.98778, dsc 0.01222\n",
      "Batch train [10] loss 0.98852, dsc 0.01148\n",
      "Batch train [11] loss 0.98937, dsc 0.01063\n",
      "Batch train [12] loss 0.98966, dsc 0.01034\n",
      "Batch train [13] loss 0.98833, dsc 0.01167\n",
      "Batch train [14] loss 0.98613, dsc 0.01387\n",
      "Batch train [15] loss 0.98963, dsc 0.01037\n",
      "Batch train [16] loss 0.99128, dsc 0.00872\n",
      "Batch train [17] loss 0.99012, dsc 0.00988\n",
      "Batch train [18] loss 0.99100, dsc 0.00900\n",
      "Batch train [19] loss 0.98735, dsc 0.01265\n",
      "Batch train [20] loss 0.98915, dsc 0.01085\n",
      "Epoch [7] train done\n",
      "Batch eval [1] loss 0.99091, dsc 0.00909\n",
      "Batch eval [2] loss 0.99248, dsc 0.00752\n",
      "Batch eval [3] loss 0.99038, dsc 0.00962\n",
      "Batch eval [4] loss 0.98925, dsc 0.01075\n",
      "Batch eval [5] loss 0.98382, dsc 0.01618\n",
      "Epoch [7] valid done\n",
      "Epoch [7] T 453.54s, deltaT 64.10s, loss: train 0.98960, valid 0.98937, dsc: train 0.01040, valid 0.01063\n",
      "Batch train [1] loss 0.98985, dsc 0.01015\n",
      "Batch train [2] loss 0.98604, dsc 0.01396\n",
      "Batch train [3] loss 0.99076, dsc 0.00924\n",
      "Batch train [4] loss 0.99144, dsc 0.00856\n",
      "Batch train [5] loss 0.99154, dsc 0.00846\n",
      "Batch train [6] loss 0.99038, dsc 0.00962\n",
      "Batch train [7] loss 0.99161, dsc 0.00839\n",
      "Batch train [8] loss 0.99050, dsc 0.00950\n",
      "Batch train [9] loss 0.98982, dsc 0.01018\n",
      "Batch train [10] loss 0.99094, dsc 0.00906\n",
      "Batch train [11] loss 0.99067, dsc 0.00933\n",
      "Batch train [12] loss 0.98868, dsc 0.01132\n",
      "Batch train [13] loss 0.98913, dsc 0.01087\n",
      "Batch train [14] loss 0.98714, dsc 0.01286\n",
      "Batch train [15] loss 0.98795, dsc 0.01205\n",
      "Batch train [16] loss 0.98813, dsc 0.01187\n",
      "Batch train [17] loss 0.98891, dsc 0.01109\n",
      "Batch train [18] loss 0.98655, dsc 0.01345\n",
      "Batch train [19] loss 0.98902, dsc 0.01098\n",
      "Batch train [20] loss 0.98741, dsc 0.01259\n",
      "Epoch [8] train done\n",
      "Batch eval [1] loss 0.99068, dsc 0.00932\n",
      "Batch eval [2] loss 0.99232, dsc 0.00768\n",
      "Batch eval [3] loss 0.99011, dsc 0.00989\n",
      "Batch eval [4] loss 0.98892, dsc 0.01108\n",
      "Batch eval [5] loss 0.98384, dsc 0.01616\n",
      "Epoch [8] valid done\n",
      "Epoch [8] T 517.49s, deltaT 63.95s, loss: train 0.98932, valid 0.98918, dsc: train 0.01068, valid 0.01082\n",
      "Batch train [1] loss 0.99016, dsc 0.00984\n",
      "Batch train [2] loss 0.98651, dsc 0.01349\n",
      "Batch train [3] loss 0.98695, dsc 0.01305\n",
      "Batch train [4] loss 0.99025, dsc 0.00975\n",
      "Batch train [5] loss 0.98846, dsc 0.01154\n",
      "Batch train [6] loss 0.99110, dsc 0.00890\n",
      "Batch train [7] loss 0.98634, dsc 0.01366\n",
      "Batch train [8] loss 0.98860, dsc 0.01140\n",
      "Batch train [9] loss 0.98575, dsc 0.01425\n",
      "Batch train [10] loss 0.99052, dsc 0.00948\n",
      "Batch train [11] loss 0.99055, dsc 0.00945\n",
      "Batch train [12] loss 0.98981, dsc 0.01019\n",
      "Batch train [13] loss 0.99109, dsc 0.00891\n",
      "Batch train [14] loss 0.98721, dsc 0.01279\n",
      "Batch train [15] loss 0.98776, dsc 0.01224\n",
      "Batch train [16] loss 0.99164, dsc 0.00836\n",
      "Batch train [17] loss 0.98961, dsc 0.01039\n",
      "Batch train [18] loss 0.98859, dsc 0.01141\n",
      "Batch train [19] loss 0.99093, dsc 0.00907\n",
      "Batch train [20] loss 0.98882, dsc 0.01118\n",
      "Epoch [9] train done\n",
      "Batch eval [1] loss 0.99048, dsc 0.00952\n",
      "Batch eval [2] loss 0.99209, dsc 0.00791\n",
      "Batch eval [3] loss 0.98990, dsc 0.01010\n",
      "Batch eval [4] loss 0.98869, dsc 0.01131\n",
      "Batch eval [5] loss 0.98298, dsc 0.01702\n",
      "Epoch [9] valid done\n",
      "Epoch [9] T 581.57s, deltaT 64.08s, loss: train 0.98903, valid 0.98883, dsc: train 0.01097, valid 0.01117\n",
      "Batch train [1] loss 0.98848, dsc 0.01152\n",
      "Batch train [2] loss 0.98858, dsc 0.01142\n",
      "Batch train [3] loss 0.98835, dsc 0.01165\n",
      "Batch train [4] loss 0.98815, dsc 0.01185\n",
      "Batch train [5] loss 0.99025, dsc 0.00975\n",
      "Batch train [6] loss 0.98957, dsc 0.01043\n",
      "Batch train [7] loss 0.98834, dsc 0.01166\n",
      "Batch train [8] loss 0.98955, dsc 0.01045\n",
      "Batch train [9] loss 0.98775, dsc 0.01225\n",
      "Batch train [10] loss 0.98977, dsc 0.01023\n",
      "Batch train [11] loss 0.98900, dsc 0.01100\n",
      "Batch train [12] loss 0.98774, dsc 0.01226\n",
      "Batch train [13] loss 0.98708, dsc 0.01292\n",
      "Batch train [14] loss 0.98820, dsc 0.01180\n",
      "Batch train [15] loss 0.99106, dsc 0.00894\n",
      "Batch train [16] loss 0.98899, dsc 0.01101\n",
      "Batch train [17] loss 0.98870, dsc 0.01130\n",
      "Batch train [18] loss 0.98750, dsc 0.01250\n",
      "Batch train [19] loss 0.99073, dsc 0.00927\n",
      "Batch train [20] loss 0.98624, dsc 0.01376\n",
      "Epoch [10] train done\n",
      "Batch eval [1] loss 0.99013, dsc 0.00987\n",
      "Batch eval [2] loss 0.99178, dsc 0.00822\n",
      "Batch eval [3] loss 0.98952, dsc 0.01048\n",
      "Batch eval [4] loss 0.98825, dsc 0.01175\n",
      "Batch eval [5] loss 0.98239, dsc 0.01761\n",
      "Epoch [10] valid done\n",
      "Epoch [10] T 645.97s, deltaT 64.40s, loss: train 0.98870, valid 0.98841, dsc: train 0.01130, valid 0.01159\n",
      "Batch train [1] loss 0.98832, dsc 0.01168\n",
      "Batch train [2] loss 0.98854, dsc 0.01146\n",
      "Batch train [3] loss 0.99001, dsc 0.00999\n",
      "Batch train [4] loss 0.98629, dsc 0.01371\n",
      "Batch train [5] loss 0.98784, dsc 0.01216\n",
      "Batch train [6] loss 0.98616, dsc 0.01384\n",
      "Batch train [7] loss 0.98565, dsc 0.01435\n",
      "Batch train [8] loss 0.98677, dsc 0.01323\n",
      "Batch train [9] loss 0.99154, dsc 0.00846\n",
      "Batch train [10] loss 0.98586, dsc 0.01414\n",
      "Batch train [11] loss 0.98778, dsc 0.01222\n",
      "Batch train [12] loss 0.99004, dsc 0.00996\n",
      "Batch train [13] loss 0.98749, dsc 0.01251\n",
      "Batch train [14] loss 0.98937, dsc 0.01063\n",
      "Batch train [15] loss 0.99086, dsc 0.00914\n",
      "Batch train [16] loss 0.98620, dsc 0.01380\n",
      "Batch train [17] loss 0.98989, dsc 0.01011\n",
      "Batch train [18] loss 0.98846, dsc 0.01154\n",
      "Batch train [19] loss 0.98780, dsc 0.01220\n",
      "Batch train [20] loss 0.99204, dsc 0.00796\n",
      "Epoch [11] train done\n",
      "Batch eval [1] loss 0.98988, dsc 0.01012\n",
      "Batch eval [2] loss 0.99153, dsc 0.00847\n",
      "Batch eval [3] loss 0.98919, dsc 0.01081\n",
      "Batch eval [4] loss 0.98785, dsc 0.01215\n",
      "Batch eval [5] loss 0.98170, dsc 0.01830\n",
      "Epoch [11] valid done\n",
      "Epoch [11] T 710.63s, deltaT 64.66s, loss: train 0.98835, valid 0.98803, dsc: train 0.01165, valid 0.01197\n",
      "Batch train [1] loss 0.98826, dsc 0.01174\n",
      "Batch train [2] loss 0.98991, dsc 0.01009\n",
      "Batch train [3] loss 0.99058, dsc 0.00942\n",
      "Batch train [4] loss 0.98784, dsc 0.01216\n",
      "Batch train [5] loss 0.98692, dsc 0.01308\n",
      "Batch train [6] loss 0.98683, dsc 0.01317\n",
      "Batch train [7] loss 0.98847, dsc 0.01153\n",
      "Batch train [8] loss 0.98540, dsc 0.01460\n",
      "Batch train [9] loss 0.98805, dsc 0.01195\n",
      "Batch train [10] loss 0.98800, dsc 0.01200\n",
      "Batch train [11] loss 0.98731, dsc 0.01269\n",
      "Batch train [12] loss 0.98830, dsc 0.01170\n",
      "Batch train [13] loss 0.99145, dsc 0.00855\n",
      "Batch train [14] loss 0.98389, dsc 0.01611\n",
      "Batch train [15] loss 0.98722, dsc 0.01278\n",
      "Batch train [16] loss 0.99098, dsc 0.00902\n",
      "Batch train [17] loss 0.98690, dsc 0.01310\n",
      "Batch train [18] loss 0.98877, dsc 0.01123\n",
      "Batch train [19] loss 0.98613, dsc 0.01387\n",
      "Batch train [20] loss 0.98798, dsc 0.01202\n",
      "Epoch [12] train done\n",
      "Batch eval [1] loss 0.98966, dsc 0.01034\n",
      "Batch eval [2] loss 0.99130, dsc 0.00870\n",
      "Batch eval [3] loss 0.98894, dsc 0.01106\n",
      "Batch eval [4] loss 0.98756, dsc 0.01244\n",
      "Batch eval [5] loss 0.98135, dsc 0.01865\n",
      "Epoch [12] valid done\n",
      "Epoch [12] T 775.17s, deltaT 64.54s, loss: train 0.98796, valid 0.98776, dsc: train 0.01204, valid 0.01224\n",
      "Batch train [1] loss 0.98950, dsc 0.01050\n",
      "Batch train [2] loss 0.98589, dsc 0.01411\n",
      "Batch train [3] loss 0.98517, dsc 0.01483\n",
      "Batch train [4] loss 0.98592, dsc 0.01408\n",
      "Batch train [5] loss 0.98765, dsc 0.01235\n",
      "Batch train [6] loss 0.98960, dsc 0.01040\n",
      "Batch train [7] loss 0.98921, dsc 0.01079\n",
      "Batch train [8] loss 0.98634, dsc 0.01366\n",
      "Batch train [9] loss 0.98690, dsc 0.01310\n",
      "Batch train [10] loss 0.99049, dsc 0.00951\n",
      "Batch train [11] loss 0.99038, dsc 0.00962\n",
      "Batch train [12] loss 0.98838, dsc 0.01162\n",
      "Batch train [13] loss 0.98777, dsc 0.01223\n",
      "Batch train [14] loss 0.98734, dsc 0.01266\n",
      "Batch train [15] loss 0.98600, dsc 0.01400\n",
      "Batch train [16] loss 0.98546, dsc 0.01454\n",
      "Batch train [17] loss 0.98928, dsc 0.01072\n",
      "Batch train [18] loss 0.98925, dsc 0.01075\n",
      "Batch train [19] loss 0.98498, dsc 0.01502\n",
      "Batch train [20] loss 0.98475, dsc 0.01525\n",
      "Epoch [13] train done\n",
      "Batch eval [1] loss 0.98976, dsc 0.01024\n",
      "Batch eval [2] loss 0.99146, dsc 0.00854\n",
      "Batch eval [3] loss 0.98907, dsc 0.01093\n",
      "Batch eval [4] loss 0.98786, dsc 0.01214\n",
      "Batch eval [5] loss 0.98173, dsc 0.01827\n",
      "Epoch [13] valid done\n",
      "Epoch [13] T 838.75s, deltaT 63.58s, loss: train 0.98751, valid 0.98798, dsc: train 0.01249, valid 0.01202\n",
      "Batch train [1] loss 0.98983, dsc 0.01017\n",
      "Batch train [2] loss 0.98717, dsc 0.01283\n",
      "Batch train [3] loss 0.98733, dsc 0.01267\n",
      "Batch train [4] loss 0.98412, dsc 0.01588\n",
      "Batch train [5] loss 0.98602, dsc 0.01398\n",
      "Batch train [6] loss 0.98777, dsc 0.01223\n",
      "Batch train [7] loss 0.98470, dsc 0.01530\n",
      "Batch train [8] loss 0.98969, dsc 0.01031\n",
      "Batch train [9] loss 0.98718, dsc 0.01282\n",
      "Batch train [10] loss 0.98769, dsc 0.01231\n",
      "Batch train [11] loss 0.98987, dsc 0.01013\n",
      "Batch train [12] loss 0.98655, dsc 0.01345\n",
      "Batch train [13] loss 0.98771, dsc 0.01229\n",
      "Batch train [14] loss 0.98927, dsc 0.01073\n",
      "Batch train [15] loss 0.98547, dsc 0.01453\n",
      "Batch train [16] loss 0.98579, dsc 0.01421\n",
      "Batch train [17] loss 0.98524, dsc 0.01476\n",
      "Batch train [18] loss 0.98628, dsc 0.01372\n",
      "Batch train [19] loss 0.98523, dsc 0.01477\n",
      "Batch train [20] loss 0.98694, dsc 0.01306\n",
      "Epoch [14] train done\n",
      "Batch eval [1] loss 0.98900, dsc 0.01100\n",
      "Batch eval [2] loss 0.99074, dsc 0.00926\n",
      "Batch eval [3] loss 0.98818, dsc 0.01182\n",
      "Batch eval [4] loss 0.98683, dsc 0.01317\n",
      "Batch eval [5] loss 0.98042, dsc 0.01958\n",
      "Epoch [14] valid done\n",
      "Epoch [14] T 899.59s, deltaT 60.84s, loss: train 0.98699, valid 0.98704, dsc: train 0.01301, valid 0.01296\n",
      "Batch train [1] loss 0.98684, dsc 0.01316\n",
      "Batch train [2] loss 0.98588, dsc 0.01412\n",
      "Batch train [3] loss 0.98874, dsc 0.01126\n",
      "Batch train [4] loss 0.98649, dsc 0.01351\n",
      "Batch train [5] loss 0.98710, dsc 0.01290\n",
      "Batch train [6] loss 0.98895, dsc 0.01105\n",
      "Batch train [7] loss 0.98188, dsc 0.01812\n",
      "Batch train [8] loss 0.98982, dsc 0.01018\n",
      "Batch train [9] loss 0.98617, dsc 0.01383\n",
      "Batch train [10] loss 0.98359, dsc 0.01641\n",
      "Batch train [11] loss 0.98602, dsc 0.01398\n",
      "Batch train [12] loss 0.98553, dsc 0.01447\n",
      "Batch train [13] loss 0.98534, dsc 0.01466\n",
      "Batch train [14] loss 0.98595, dsc 0.01405\n",
      "Batch train [15] loss 0.98596, dsc 0.01404\n",
      "Batch train [16] loss 0.98857, dsc 0.01143\n",
      "Batch train [17] loss 0.98498, dsc 0.01502\n",
      "Batch train [18] loss 0.98719, dsc 0.01281\n",
      "Batch train [19] loss 0.98296, dsc 0.01704\n",
      "Batch train [20] loss 0.99097, dsc 0.00903\n",
      "Epoch [15] train done\n",
      "Batch eval [1] loss 0.98805, dsc 0.01195\n",
      "Batch eval [2] loss 0.98995, dsc 0.01005\n",
      "Batch eval [3] loss 0.98715, dsc 0.01285\n",
      "Batch eval [4] loss 0.98587, dsc 0.01413\n",
      "Batch eval [5] loss 0.97887, dsc 0.02113\n",
      "Epoch [15] valid done\n",
      "Epoch [15] T 960.40s, deltaT 60.80s, loss: train 0.98645, valid 0.98598, dsc: train 0.01355, valid 0.01402\n",
      "Batch train [1] loss 0.98605, dsc 0.01395\n",
      "Batch train [2] loss 0.98639, dsc 0.01361\n",
      "Batch train [3] loss 0.98869, dsc 0.01131\n",
      "Batch train [4] loss 0.98864, dsc 0.01136\n",
      "Batch train [5] loss 0.98392, dsc 0.01608\n",
      "Batch train [6] loss 0.98456, dsc 0.01544\n",
      "Batch train [7] loss 0.98415, dsc 0.01585\n",
      "Batch train [8] loss 0.98491, dsc 0.01509\n",
      "Batch train [9] loss 0.98439, dsc 0.01561\n",
      "Batch train [10] loss 0.98664, dsc 0.01336\n",
      "Batch train [11] loss 0.98450, dsc 0.01550\n",
      "Batch train [12] loss 0.98689, dsc 0.01311\n",
      "Batch train [13] loss 0.98476, dsc 0.01524\n",
      "Batch train [14] loss 0.98782, dsc 0.01218\n",
      "Batch train [15] loss 0.98185, dsc 0.01815\n",
      "Batch train [16] loss 0.99088, dsc 0.00912\n",
      "Batch train [17] loss 0.98561, dsc 0.01439\n",
      "Batch train [18] loss 0.98481, dsc 0.01519\n",
      "Batch train [19] loss 0.98703, dsc 0.01297\n",
      "Batch train [20] loss 0.98394, dsc 0.01606\n",
      "Epoch [16] train done\n",
      "Batch eval [1] loss 0.98936, dsc 0.01064\n",
      "Batch eval [2] loss 0.99062, dsc 0.00938\n",
      "Batch eval [3] loss 0.98767, dsc 0.01233\n",
      "Batch eval [4] loss 0.98678, dsc 0.01322\n",
      "Batch eval [5] loss 0.98244, dsc 0.01756\n",
      "Epoch [16] valid done\n",
      "Epoch [16] T 1024.82s, deltaT 64.42s, loss: train 0.98582, valid 0.98737, dsc: train 0.01418, valid 0.01263\n",
      "Batch train [1] loss 0.98553, dsc 0.01447\n",
      "Batch train [2] loss 0.98057, dsc 0.01943\n",
      "Batch train [3] loss 0.98597, dsc 0.01403\n",
      "Batch train [4] loss 0.98682, dsc 0.01318\n",
      "Batch train [5] loss 0.98246, dsc 0.01754\n",
      "Batch train [6] loss 0.98481, dsc 0.01519\n",
      "Batch train [7] loss 0.98365, dsc 0.01635\n",
      "Batch train [8] loss 0.98506, dsc 0.01494\n",
      "Batch train [9] loss 0.98263, dsc 0.01737\n",
      "Batch train [10] loss 0.98539, dsc 0.01461\n",
      "Batch train [11] loss 0.98683, dsc 0.01317\n",
      "Batch train [12] loss 0.98748, dsc 0.01252\n",
      "Batch train [13] loss 0.98864, dsc 0.01136\n",
      "Batch train [14] loss 0.98429, dsc 0.01571\n",
      "Batch train [15] loss 0.98899, dsc 0.01101\n",
      "Batch train [16] loss 0.98541, dsc 0.01459\n",
      "Batch train [17] loss 0.98524, dsc 0.01476\n",
      "Batch train [18] loss 0.98770, dsc 0.01230\n",
      "Batch train [19] loss 0.98404, dsc 0.01596\n",
      "Batch train [20] loss 0.98287, dsc 0.01713\n",
      "Epoch [17] train done\n",
      "Batch eval [1] loss 0.98666, dsc 0.01334\n",
      "Batch eval [2] loss 0.98955, dsc 0.01045\n",
      "Batch eval [3] loss 0.98605, dsc 0.01395\n",
      "Batch eval [4] loss 0.98648, dsc 0.01352\n",
      "Batch eval [5] loss 0.97907, dsc 0.02093\n",
      "Epoch [17] valid done\n",
      "Epoch [17] T 1089.31s, deltaT 64.50s, loss: train 0.98522, valid 0.98556, dsc: train 0.01478, valid 0.01444\n",
      "Batch train [1] loss 0.98094, dsc 0.01906\n",
      "Batch train [2] loss 0.98406, dsc 0.01594\n",
      "Batch train [3] loss 0.98165, dsc 0.01835\n",
      "Batch train [4] loss 0.98382, dsc 0.01618\n",
      "Batch train [5] loss 0.98844, dsc 0.01156\n",
      "Batch train [6] loss 0.98767, dsc 0.01233\n",
      "Batch train [7] loss 0.98767, dsc 0.01233\n",
      "Batch train [8] loss 0.98540, dsc 0.01460\n",
      "Batch train [9] loss 0.98645, dsc 0.01355\n",
      "Batch train [10] loss 0.98497, dsc 0.01503\n",
      "Batch train [11] loss 0.98456, dsc 0.01544\n",
      "Batch train [12] loss 0.98612, dsc 0.01388\n",
      "Batch train [13] loss 0.98207, dsc 0.01793\n",
      "Batch train [14] loss 0.98378, dsc 0.01622\n",
      "Batch train [15] loss 0.98039, dsc 0.01961\n",
      "Batch train [16] loss 0.98616, dsc 0.01384\n",
      "Batch train [17] loss 0.98232, dsc 0.01768\n",
      "Batch train [18] loss 0.98696, dsc 0.01304\n",
      "Batch train [19] loss 0.98347, dsc 0.01653\n",
      "Batch train [20] loss 0.98216, dsc 0.01784\n",
      "Epoch [18] train done\n",
      "Batch eval [1] loss 0.98229, dsc 0.01771\n",
      "Batch eval [2] loss 0.98750, dsc 0.01250\n",
      "Batch eval [3] loss 0.98236, dsc 0.01764\n",
      "Batch eval [4] loss 0.98212, dsc 0.01788\n",
      "Batch eval [5] loss 0.97358, dsc 0.02642\n",
      "Epoch [18] valid done\n",
      "Epoch [18] T 1153.63s, deltaT 64.31s, loss: train 0.98445, valid 0.98157, dsc: train 0.01555, valid 0.01843\n",
      "Batch train [1] loss 0.98487, dsc 0.01513\n",
      "Batch train [2] loss 0.98462, dsc 0.01538\n",
      "Batch train [3] loss 0.98595, dsc 0.01404\n",
      "Batch train [4] loss 0.98300, dsc 0.01700\n",
      "Batch train [5] loss 0.98330, dsc 0.01670\n",
      "Batch train [6] loss 0.98418, dsc 0.01582\n",
      "Batch train [7] loss 0.98456, dsc 0.01544\n",
      "Batch train [8] loss 0.98349, dsc 0.01651\n",
      "Batch train [9] loss 0.98151, dsc 0.01849\n",
      "Batch train [10] loss 0.98470, dsc 0.01530\n",
      "Batch train [11] loss 0.98206, dsc 0.01794\n",
      "Batch train [12] loss 0.98655, dsc 0.01345\n",
      "Batch train [13] loss 0.98281, dsc 0.01719\n",
      "Batch train [14] loss 0.98438, dsc 0.01562\n",
      "Batch train [15] loss 0.98414, dsc 0.01586\n",
      "Batch train [16] loss 0.97829, dsc 0.02171\n",
      "Batch train [17] loss 0.97905, dsc 0.02095\n",
      "Batch train [18] loss 0.98576, dsc 0.01424\n",
      "Batch train [19] loss 0.98398, dsc 0.01602\n",
      "Batch train [20] loss 0.98358, dsc 0.01642\n",
      "Epoch [19] train done\n",
      "Batch eval [1] loss 0.98353, dsc 0.01647\n",
      "Batch eval [2] loss 0.98727, dsc 0.01273\n",
      "Batch eval [3] loss 0.98275, dsc 0.01725\n",
      "Batch eval [4] loss 0.98291, dsc 0.01709\n",
      "Batch eval [5] loss 0.97323, dsc 0.02677\n",
      "Epoch [19] valid done\n",
      "Epoch [19] T 1218.31s, deltaT 64.68s, loss: train 0.98354, valid 0.98194, dsc: train 0.01646, valid 0.01806\n",
      "Batch train [1] loss 0.98844, dsc 0.01156\n",
      "Batch train [2] loss 0.98320, dsc 0.01680\n",
      "Batch train [3] loss 0.98276, dsc 0.01724\n",
      "Batch train [4] loss 0.98608, dsc 0.01392\n",
      "Batch train [5] loss 0.98363, dsc 0.01637\n",
      "Batch train [6] loss 0.98567, dsc 0.01433\n",
      "Batch train [7] loss 0.98150, dsc 0.01850\n",
      "Batch train [8] loss 0.98188, dsc 0.01812\n",
      "Batch train [9] loss 0.98435, dsc 0.01565\n",
      "Batch train [10] loss 0.97934, dsc 0.02066\n",
      "Batch train [11] loss 0.98168, dsc 0.01832\n",
      "Batch train [12] loss 0.97909, dsc 0.02091\n",
      "Batch train [13] loss 0.98648, dsc 0.01352\n",
      "Batch train [14] loss 0.97946, dsc 0.02054\n",
      "Batch train [15] loss 0.98016, dsc 0.01984\n",
      "Batch train [16] loss 0.97913, dsc 0.02087\n",
      "Batch train [17] loss 0.98411, dsc 0.01589\n",
      "Batch train [18] loss 0.98586, dsc 0.01414\n",
      "Batch train [19] loss 0.97774, dsc 0.02226\n",
      "Batch train [20] loss 0.98076, dsc 0.01924\n",
      "Epoch [20] train done\n",
      "Batch eval [1] loss 0.98307, dsc 0.01693\n",
      "Batch eval [2] loss 0.98688, dsc 0.01312\n",
      "Batch eval [3] loss 0.98227, dsc 0.01773\n",
      "Batch eval [4] loss 0.98194, dsc 0.01806\n",
      "Batch eval [5] loss 0.97211, dsc 0.02789\n",
      "Epoch [20] valid done\n",
      "Epoch [20] T 1281.96s, deltaT 63.65s, loss: train 0.98257, valid 0.98125, dsc: train 0.01743, valid 0.01875\n",
      "Batch train [1] loss 0.98357, dsc 0.01643\n",
      "Batch train [2] loss 0.97585, dsc 0.02415\n",
      "Batch train [3] loss 0.98135, dsc 0.01865\n",
      "Batch train [4] loss 0.97883, dsc 0.02117\n",
      "Batch train [5] loss 0.98306, dsc 0.01694\n",
      "Batch train [6] loss 0.98842, dsc 0.01158\n",
      "Batch train [7] loss 0.97665, dsc 0.02335\n",
      "Batch train [8] loss 0.98388, dsc 0.01612\n",
      "Batch train [9] loss 0.98434, dsc 0.01566\n",
      "Batch train [10] loss 0.97827, dsc 0.02173\n",
      "Batch train [11] loss 0.98317, dsc 0.01683\n",
      "Batch train [12] loss 0.98099, dsc 0.01901\n",
      "Batch train [13] loss 0.97962, dsc 0.02038\n",
      "Batch train [14] loss 0.98478, dsc 0.01522\n",
      "Batch train [15] loss 0.98051, dsc 0.01949\n",
      "Batch train [16] loss 0.98342, dsc 0.01658\n",
      "Batch train [17] loss 0.98226, dsc 0.01774\n",
      "Batch train [18] loss 0.97969, dsc 0.02031\n",
      "Batch train [19] loss 0.98134, dsc 0.01866\n",
      "Batch train [20] loss 0.97957, dsc 0.02043\n",
      "Epoch [21] train done\n",
      "Batch eval [1] loss 0.97988, dsc 0.02012\n",
      "Batch eval [2] loss 0.98431, dsc 0.01569\n",
      "Batch eval [3] loss 0.97903, dsc 0.02097\n",
      "Batch eval [4] loss 0.97921, dsc 0.02079\n",
      "Batch eval [5] loss 0.96739, dsc 0.03261\n",
      "Epoch [21] valid done\n",
      "Epoch [21] T 1344.24s, deltaT 62.28s, loss: train 0.98148, valid 0.97796, dsc: train 0.01852, valid 0.02204\n",
      "Batch train [1] loss 0.97903, dsc 0.02097\n",
      "Batch train [2] loss 0.98193, dsc 0.01807\n",
      "Batch train [3] loss 0.98042, dsc 0.01958\n",
      "Batch train [4] loss 0.97577, dsc 0.02423\n",
      "Batch train [5] loss 0.97885, dsc 0.02115\n",
      "Batch train [6] loss 0.98250, dsc 0.01750\n",
      "Batch train [7] loss 0.97813, dsc 0.02187\n",
      "Batch train [8] loss 0.97979, dsc 0.02021\n",
      "Batch train [9] loss 0.98301, dsc 0.01699\n",
      "Batch train [10] loss 0.97856, dsc 0.02144\n",
      "Batch train [11] loss 0.98004, dsc 0.01996\n",
      "Batch train [12] loss 0.97772, dsc 0.02228\n",
      "Batch train [13] loss 0.97937, dsc 0.02063\n",
      "Batch train [14] loss 0.97913, dsc 0.02087\n",
      "Batch train [15] loss 0.98052, dsc 0.01948\n",
      "Batch train [16] loss 0.98559, dsc 0.01441\n",
      "Batch train [17] loss 0.97681, dsc 0.02319\n",
      "Batch train [18] loss 0.98368, dsc 0.01632\n",
      "Batch train [19] loss 0.98131, dsc 0.01869\n",
      "Batch train [20] loss 0.98256, dsc 0.01744\n",
      "Epoch [22] train done\n",
      "Batch eval [1] loss 0.97973, dsc 0.02027\n",
      "Batch eval [2] loss 0.98420, dsc 0.01580\n",
      "Batch eval [3] loss 0.97884, dsc 0.02116\n",
      "Batch eval [4] loss 0.97862, dsc 0.02138\n",
      "Batch eval [5] loss 0.96675, dsc 0.03325\n",
      "Epoch [22] valid done\n",
      "Epoch [22] T 1406.53s, deltaT 62.29s, loss: train 0.98024, valid 0.97763, dsc: train 0.01976, valid 0.02237\n",
      "Batch train [1] loss 0.97876, dsc 0.02124\n",
      "Batch train [2] loss 0.97788, dsc 0.02212\n",
      "Batch train [3] loss 0.97911, dsc 0.02089\n",
      "Batch train [4] loss 0.98439, dsc 0.01561\n",
      "Batch train [5] loss 0.98077, dsc 0.01923\n",
      "Batch train [6] loss 0.97395, dsc 0.02605\n",
      "Batch train [7] loss 0.97796, dsc 0.02204\n",
      "Batch train [8] loss 0.97669, dsc 0.02331\n",
      "Batch train [9] loss 0.98410, dsc 0.01590\n",
      "Batch train [10] loss 0.97820, dsc 0.02180\n",
      "Batch train [11] loss 0.97869, dsc 0.02131\n",
      "Batch train [12] loss 0.97777, dsc 0.02223\n",
      "Batch train [13] loss 0.98348, dsc 0.01652\n",
      "Batch train [14] loss 0.98094, dsc 0.01906\n",
      "Batch train [15] loss 0.97664, dsc 0.02336\n",
      "Batch train [16] loss 0.97888, dsc 0.02112\n",
      "Batch train [17] loss 0.97820, dsc 0.02180\n",
      "Batch train [18] loss 0.97955, dsc 0.02045\n",
      "Batch train [19] loss 0.97485, dsc 0.02515\n",
      "Batch train [20] loss 0.97527, dsc 0.02473\n",
      "Epoch [23] train done\n",
      "Batch eval [1] loss 0.97252, dsc 0.02748\n",
      "Batch eval [2] loss 0.97874, dsc 0.02126\n",
      "Batch eval [3] loss 0.97114, dsc 0.02886\n",
      "Batch eval [4] loss 0.97120, dsc 0.02880\n",
      "Batch eval [5] loss 0.95565, dsc 0.04435\n",
      "Epoch [23] valid done\n",
      "Epoch [23] T 1468.75s, deltaT 62.21s, loss: train 0.97880, valid 0.96985, dsc: train 0.02120, valid 0.03015\n",
      "Batch train [1] loss 0.97506, dsc 0.02494\n",
      "Batch train [2] loss 0.98265, dsc 0.01735\n",
      "Batch train [3] loss 0.97910, dsc 0.02090\n",
      "Batch train [4] loss 0.97729, dsc 0.02271\n",
      "Batch train [5] loss 0.97742, dsc 0.02258\n",
      "Batch train [6] loss 0.97585, dsc 0.02415\n",
      "Batch train [7] loss 0.97765, dsc 0.02235\n",
      "Batch train [8] loss 0.97159, dsc 0.02841\n",
      "Batch train [9] loss 0.97847, dsc 0.02153\n",
      "Batch train [10] loss 0.97855, dsc 0.02145\n",
      "Batch train [11] loss 0.98199, dsc 0.01801\n",
      "Batch train [12] loss 0.98061, dsc 0.01939\n",
      "Batch train [13] loss 0.97658, dsc 0.02342\n",
      "Batch train [14] loss 0.97587, dsc 0.02413\n",
      "Batch train [15] loss 0.97771, dsc 0.02229\n",
      "Batch train [16] loss 0.98007, dsc 0.01993\n",
      "Batch train [17] loss 0.97598, dsc 0.02402\n",
      "Batch train [18] loss 0.97017, dsc 0.02983\n",
      "Batch train [19] loss 0.97311, dsc 0.02689\n",
      "Batch train [20] loss 0.97851, dsc 0.02149\n",
      "Epoch [24] train done\n",
      "Batch eval [1] loss 0.97731, dsc 0.02269\n",
      "Batch eval [2] loss 0.98237, dsc 0.01763\n",
      "Batch eval [3] loss 0.97568, dsc 0.02432\n",
      "Batch eval [4] loss 0.97383, dsc 0.02617\n",
      "Batch eval [5] loss 0.96110, dsc 0.03890\n",
      "Epoch [24] valid done\n",
      "Epoch [24] T 1533.40s, deltaT 64.65s, loss: train 0.97721, valid 0.97406, dsc: train 0.02279, valid 0.02594\n",
      "Batch train [1] loss 0.97776, dsc 0.02224\n",
      "Batch train [2] loss 0.97878, dsc 0.02122\n",
      "Batch train [3] loss 0.97486, dsc 0.02514\n",
      "Batch train [4] loss 0.97433, dsc 0.02567\n",
      "Batch train [5] loss 0.97222, dsc 0.02778\n",
      "Batch train [6] loss 0.98013, dsc 0.01987\n",
      "Batch train [7] loss 0.97217, dsc 0.02783\n",
      "Batch train [8] loss 0.97579, dsc 0.02421\n",
      "Batch train [9] loss 0.97284, dsc 0.02716\n",
      "Batch train [10] loss 0.97571, dsc 0.02429\n",
      "Batch train [11] loss 0.97524, dsc 0.02476\n",
      "Batch train [12] loss 0.97587, dsc 0.02413\n",
      "Batch train [13] loss 0.97271, dsc 0.02729\n",
      "Batch train [14] loss 0.97972, dsc 0.02028\n",
      "Batch train [15] loss 0.97295, dsc 0.02705\n",
      "Batch train [16] loss 0.97431, dsc 0.02569\n",
      "Batch train [17] loss 0.97906, dsc 0.02094\n",
      "Batch train [18] loss 0.97351, dsc 0.02649\n",
      "Batch train [19] loss 0.97085, dsc 0.02915\n",
      "Batch train [20] loss 0.97666, dsc 0.02334\n",
      "Epoch [25] train done\n",
      "Batch eval [1] loss 0.97420, dsc 0.02580\n",
      "Batch eval [2] loss 0.97866, dsc 0.02134\n",
      "Batch eval [3] loss 0.97178, dsc 0.02822\n",
      "Batch eval [4] loss 0.96964, dsc 0.03036\n",
      "Batch eval [5] loss 0.95456, dsc 0.04544\n",
      "Epoch [25] valid done\n",
      "Epoch [25] T 1598.35s, deltaT 64.95s, loss: train 0.97527, valid 0.96977, dsc: train 0.02473, valid 0.03023\n",
      "Batch train [1] loss 0.97048, dsc 0.02952\n",
      "Batch train [2] loss 0.97910, dsc 0.02090\n",
      "Batch train [3] loss 0.96795, dsc 0.03205\n",
      "Batch train [4] loss 0.96672, dsc 0.03328\n",
      "Batch train [5] loss 0.97348, dsc 0.02652\n",
      "Batch train [6] loss 0.97450, dsc 0.02550\n",
      "Batch train [7] loss 0.97146, dsc 0.02854\n",
      "Batch train [8] loss 0.97410, dsc 0.02590\n",
      "Batch train [9] loss 0.97195, dsc 0.02805\n",
      "Batch train [10] loss 0.97901, dsc 0.02099\n",
      "Batch train [11] loss 0.97531, dsc 0.02469\n",
      "Batch train [12] loss 0.97386, dsc 0.02614\n",
      "Batch train [13] loss 0.96626, dsc 0.03374\n",
      "Batch train [14] loss 0.97748, dsc 0.02252\n",
      "Batch train [15] loss 0.97367, dsc 0.02633\n",
      "Batch train [16] loss 0.97618, dsc 0.02382\n",
      "Batch train [17] loss 0.96348, dsc 0.03652\n",
      "Batch train [18] loss 0.96282, dsc 0.03718\n",
      "Batch train [19] loss 0.97015, dsc 0.02985\n",
      "Batch train [20] loss 0.96970, dsc 0.03030\n",
      "Epoch [26] train done\n",
      "Batch eval [1] loss 0.97589, dsc 0.02411\n",
      "Batch eval [2] loss 0.98219, dsc 0.01781\n",
      "Batch eval [3] loss 0.97599, dsc 0.02401\n",
      "Batch eval [4] loss 0.96974, dsc 0.03026\n",
      "Batch eval [5] loss 0.96039, dsc 0.03961\n",
      "Epoch [26] valid done\n",
      "Epoch [26] T 1661.58s, deltaT 63.23s, loss: train 0.97188, valid 0.97284, dsc: train 0.02812, valid 0.02716\n",
      "Batch train [1] loss 0.96917, dsc 0.03083\n",
      "Batch train [2] loss 0.96473, dsc 0.03527\n",
      "Batch train [3] loss 0.97409, dsc 0.02591\n",
      "Batch train [4] loss 0.96506, dsc 0.03494\n",
      "Batch train [5] loss 0.96772, dsc 0.03228\n",
      "Batch train [6] loss 0.96453, dsc 0.03547\n",
      "Batch train [7] loss 0.97023, dsc 0.02977\n",
      "Batch train [8] loss 0.96587, dsc 0.03413\n",
      "Batch train [9] loss 0.96973, dsc 0.03027\n",
      "Batch train [10] loss 0.95460, dsc 0.04540\n",
      "Batch train [11] loss 0.95848, dsc 0.04152\n",
      "Batch train [12] loss 0.96517, dsc 0.03483\n",
      "Batch train [13] loss 0.97012, dsc 0.02988\n",
      "Batch train [14] loss 0.96226, dsc 0.03774\n",
      "Batch train [15] loss 0.96460, dsc 0.03540\n",
      "Batch train [16] loss 0.96100, dsc 0.03900\n",
      "Batch train [17] loss 0.95739, dsc 0.04261\n",
      "Batch train [18] loss 0.96910, dsc 0.03090\n",
      "Batch train [19] loss 0.96799, dsc 0.03201\n",
      "Batch train [20] loss 0.95059, dsc 0.04941\n",
      "Epoch [27] train done\n",
      "Batch eval [1] loss 0.96647, dsc 0.03353\n",
      "Batch eval [2] loss 0.97293, dsc 0.02707\n",
      "Batch eval [3] loss 0.96495, dsc 0.03505\n",
      "Batch eval [4] loss 0.96162, dsc 0.03838\n",
      "Batch eval [5] loss 0.94312, dsc 0.05688\n",
      "Epoch [27] valid done\n",
      "Epoch [27] T 1723.27s, deltaT 61.69s, loss: train 0.96462, valid 0.96182, dsc: train 0.03538, valid 0.03818\n",
      "Batch train [1] loss 0.96413, dsc 0.03587\n",
      "Batch train [2] loss 0.95033, dsc 0.04967\n",
      "Batch train [3] loss 0.95800, dsc 0.04200\n",
      "Batch train [4] loss 0.95653, dsc 0.04347\n",
      "Batch train [5] loss 0.97004, dsc 0.02996\n",
      "Batch train [6] loss 0.95646, dsc 0.04354\n",
      "Batch train [7] loss 0.95959, dsc 0.04041\n",
      "Batch train [8] loss 0.96357, dsc 0.03643\n",
      "Batch train [9] loss 0.94800, dsc 0.05200\n",
      "Batch train [10] loss 0.94905, dsc 0.05095\n",
      "Batch train [11] loss 0.95496, dsc 0.04504\n",
      "Batch train [12] loss 0.95823, dsc 0.04177\n",
      "Batch train [13] loss 0.95658, dsc 0.04342\n",
      "Batch train [14] loss 0.96282, dsc 0.03718\n",
      "Batch train [15] loss 0.95377, dsc 0.04623\n",
      "Batch train [16] loss 0.94494, dsc 0.05506\n",
      "Batch train [17] loss 0.94515, dsc 0.05485\n",
      "Batch train [18] loss 0.95426, dsc 0.04574\n",
      "Batch train [19] loss 0.95682, dsc 0.04318\n",
      "Batch train [20] loss 0.96177, dsc 0.03823\n",
      "Epoch [28] train done\n",
      "Batch eval [1] loss 0.96079, dsc 0.03921\n",
      "Batch eval [2] loss 0.97002, dsc 0.02998\n",
      "Batch eval [3] loss 0.95861, dsc 0.04139\n",
      "Batch eval [4] loss 0.95226, dsc 0.04774\n",
      "Batch eval [5] loss 0.93350, dsc 0.06650\n",
      "Epoch [28] valid done\n",
      "Epoch [28] T 1786.82s, deltaT 63.54s, loss: train 0.95625, valid 0.95504, dsc: train 0.04375, valid 0.04496\n",
      "Batch train [1] loss 0.94746, dsc 0.05254\n",
      "Batch train [2] loss 0.94808, dsc 0.05192\n",
      "Batch train [3] loss 0.95076, dsc 0.04924\n",
      "Batch train [4] loss 0.94325, dsc 0.05675\n",
      "Batch train [5] loss 0.94088, dsc 0.05912\n",
      "Batch train [6] loss 0.94729, dsc 0.05271\n",
      "Batch train [7] loss 0.95594, dsc 0.04406\n",
      "Batch train [8] loss 0.96247, dsc 0.03753\n",
      "Batch train [9] loss 0.95151, dsc 0.04849\n",
      "Batch train [10] loss 0.94797, dsc 0.05203\n",
      "Batch train [11] loss 0.94611, dsc 0.05389\n",
      "Batch train [12] loss 0.95899, dsc 0.04101\n",
      "Batch train [13] loss 0.94540, dsc 0.05460\n",
      "Batch train [14] loss 0.94611, dsc 0.05389\n",
      "Batch train [15] loss 0.94799, dsc 0.05201\n",
      "Batch train [16] loss 0.93963, dsc 0.06037\n",
      "Batch train [17] loss 0.92873, dsc 0.07127\n",
      "Batch train [18] loss 0.94633, dsc 0.05367\n",
      "Batch train [19] loss 0.94104, dsc 0.05896\n",
      "Batch train [20] loss 0.94475, dsc 0.05525\n",
      "Epoch [29] train done\n",
      "Batch eval [1] loss 0.94592, dsc 0.05408\n",
      "Batch eval [2] loss 0.95657, dsc 0.04343\n",
      "Batch eval [3] loss 0.94470, dsc 0.05530\n",
      "Batch eval [4] loss 0.93941, dsc 0.06059\n",
      "Batch eval [5] loss 0.91585, dsc 0.08415\n",
      "Epoch [29] valid done\n",
      "Epoch [29] T 1850.17s, deltaT 63.35s, loss: train 0.94703, valid 0.94049, dsc: train 0.05297, valid 0.05951\n",
      "Batch train [1] loss 0.93187, dsc 0.06813\n",
      "Batch train [2] loss 0.93820, dsc 0.06180\n",
      "Batch train [3] loss 0.94071, dsc 0.05929\n",
      "Batch train [4] loss 0.93850, dsc 0.06150\n",
      "Batch train [5] loss 0.93639, dsc 0.06361\n",
      "Batch train [6] loss 0.93301, dsc 0.06699\n",
      "Batch train [7] loss 0.93621, dsc 0.06379\n",
      "Batch train [8] loss 0.93937, dsc 0.06063\n",
      "Batch train [9] loss 0.94239, dsc 0.05761\n",
      "Batch train [10] loss 0.93410, dsc 0.06590\n",
      "Batch train [11] loss 0.93677, dsc 0.06323\n",
      "Batch train [12] loss 0.94190, dsc 0.05810\n",
      "Batch train [13] loss 0.92816, dsc 0.07184\n",
      "Batch train [14] loss 0.94735, dsc 0.05265\n",
      "Batch train [15] loss 0.94352, dsc 0.05648\n",
      "Batch train [16] loss 0.94299, dsc 0.05701\n",
      "Batch train [17] loss 0.91645, dsc 0.08355\n",
      "Batch train [18] loss 0.94634, dsc 0.05366\n",
      "Batch train [19] loss 0.91719, dsc 0.08281\n",
      "Batch train [20] loss 0.92544, dsc 0.07456\n",
      "Epoch [30] train done\n",
      "Batch eval [1] loss 0.94439, dsc 0.05561\n",
      "Batch eval [2] loss 0.96555, dsc 0.03445\n",
      "Batch eval [3] loss 0.96282, dsc 0.03718\n",
      "Batch eval [4] loss 0.95642, dsc 0.04358\n",
      "Batch eval [5] loss 0.95486, dsc 0.04514\n",
      "Epoch [30] valid done\n",
      "Epoch [30] T 1914.20s, deltaT 64.03s, loss: train 0.93584, valid 0.95681, dsc: train 0.06416, valid 0.04319\n",
      "Batch train [1] loss 0.93312, dsc 0.06688\n",
      "Batch train [2] loss 0.91096, dsc 0.08904\n",
      "Batch train [3] loss 0.93024, dsc 0.06976\n",
      "Batch train [4] loss 0.92747, dsc 0.07253\n",
      "Batch train [5] loss 0.91269, dsc 0.08731\n",
      "Batch train [6] loss 0.92263, dsc 0.07737\n",
      "Batch train [7] loss 0.94016, dsc 0.05984\n",
      "Batch train [8] loss 0.94711, dsc 0.05289\n",
      "Batch train [9] loss 0.92907, dsc 0.07093\n",
      "Batch train [10] loss 0.92395, dsc 0.07605\n",
      "Batch train [11] loss 0.90464, dsc 0.09536\n",
      "Batch train [12] loss 0.90989, dsc 0.09011\n",
      "Batch train [13] loss 0.91844, dsc 0.08156\n",
      "Batch train [14] loss 0.92681, dsc 0.07319\n",
      "Batch train [15] loss 0.91610, dsc 0.08390\n",
      "Batch train [16] loss 0.91127, dsc 0.08873\n",
      "Batch train [17] loss 0.93070, dsc 0.06930\n",
      "Batch train [18] loss 0.89545, dsc 0.10455\n",
      "Batch train [19] loss 0.91997, dsc 0.08003\n",
      "Batch train [20] loss 0.92304, dsc 0.07696\n",
      "Epoch [31] train done\n",
      "Batch eval [1] loss 0.91531, dsc 0.08469\n",
      "Batch eval [2] loss 0.93038, dsc 0.06962\n",
      "Batch eval [3] loss 0.91154, dsc 0.08846\n",
      "Batch eval [4] loss 0.90428, dsc 0.09572\n",
      "Batch eval [5] loss 0.86261, dsc 0.13739\n",
      "Epoch [31] valid done\n",
      "Epoch [31] T 1977.60s, deltaT 63.39s, loss: train 0.92169, valid 0.90482, dsc: train 0.07831, valid 0.09518\n",
      "Batch train [1] loss 0.92658, dsc 0.07342\n",
      "Batch train [2] loss 0.89253, dsc 0.10747\n",
      "Batch train [3] loss 0.91104, dsc 0.08896\n",
      "Batch train [4] loss 0.91716, dsc 0.08284\n",
      "Batch train [5] loss 0.90250, dsc 0.09750\n",
      "Batch train [6] loss 0.89491, dsc 0.10509\n",
      "Batch train [7] loss 0.89334, dsc 0.10666\n",
      "Batch train [8] loss 0.90659, dsc 0.09341\n",
      "Batch train [9] loss 0.92279, dsc 0.07721\n",
      "Batch train [10] loss 0.87331, dsc 0.12669\n",
      "Batch train [11] loss 0.90167, dsc 0.09833\n",
      "Batch train [12] loss 0.88383, dsc 0.11617\n",
      "Batch train [13] loss 0.90575, dsc 0.09425\n",
      "Batch train [14] loss 0.92355, dsc 0.07645\n",
      "Batch train [15] loss 0.91456, dsc 0.08544\n",
      "Batch train [16] loss 0.91603, dsc 0.08397\n",
      "Batch train [17] loss 0.88530, dsc 0.11470\n",
      "Batch train [18] loss 0.89999, dsc 0.10001\n",
      "Batch train [19] loss 0.90783, dsc 0.09217\n",
      "Batch train [20] loss 0.88285, dsc 0.11715\n",
      "Epoch [32] train done\n",
      "Batch eval [1] loss 0.89885, dsc 0.10115\n",
      "Batch eval [2] loss 0.91597, dsc 0.08403\n",
      "Batch eval [3] loss 0.89398, dsc 0.10602\n",
      "Batch eval [4] loss 0.88497, dsc 0.11503\n",
      "Batch eval [5] loss 0.83403, dsc 0.16597\n",
      "Epoch [32] valid done\n",
      "Epoch [32] T 2040.97s, deltaT 63.37s, loss: train 0.90311, valid 0.88556, dsc: train 0.09689, valid 0.11444\n",
      "Batch train [1] loss 0.90053, dsc 0.09947\n",
      "Batch train [2] loss 0.86987, dsc 0.13013\n",
      "Batch train [3] loss 0.88315, dsc 0.11685\n",
      "Batch train [4] loss 0.88429, dsc 0.11571\n",
      "Batch train [5] loss 0.90605, dsc 0.09395\n",
      "Batch train [6] loss 0.86809, dsc 0.13191\n",
      "Batch train [7] loss 0.89276, dsc 0.10724\n",
      "Batch train [8] loss 0.88582, dsc 0.11418\n",
      "Batch train [9] loss 0.90713, dsc 0.09287\n",
      "Batch train [10] loss 0.84710, dsc 0.15290\n",
      "Batch train [11] loss 0.88404, dsc 0.11596\n",
      "Batch train [12] loss 0.88712, dsc 0.11288\n",
      "Batch train [13] loss 0.87858, dsc 0.12142\n",
      "Batch train [14] loss 0.84677, dsc 0.15323\n",
      "Batch train [15] loss 0.89331, dsc 0.10669\n",
      "Batch train [16] loss 0.88234, dsc 0.11766\n",
      "Batch train [17] loss 0.88813, dsc 0.11187\n",
      "Batch train [18] loss 0.87318, dsc 0.12682\n",
      "Batch train [19] loss 0.85232, dsc 0.14768\n",
      "Batch train [20] loss 0.88098, dsc 0.11902\n",
      "Epoch [33] train done\n",
      "Batch eval [1] loss 0.87069, dsc 0.12931\n",
      "Batch eval [2] loss 0.89228, dsc 0.10772\n",
      "Batch eval [3] loss 0.86575, dsc 0.13425\n",
      "Batch eval [4] loss 0.85338, dsc 0.14662\n",
      "Batch eval [5] loss 0.79388, dsc 0.20612\n",
      "Epoch [33] valid done\n",
      "Epoch [33] T 2106.08s, deltaT 65.12s, loss: train 0.88058, valid 0.85520, dsc: train 0.11942, valid 0.14480\n",
      "Batch train [1] loss 0.90498, dsc 0.09502\n",
      "Batch train [2] loss 0.87587, dsc 0.12413\n",
      "Batch train [3] loss 0.87435, dsc 0.12565\n",
      "Batch train [4] loss 0.86248, dsc 0.13752\n",
      "Batch train [5] loss 0.87462, dsc 0.12538\n",
      "Batch train [6] loss 0.86532, dsc 0.13468\n",
      "Batch train [7] loss 0.84227, dsc 0.15773\n",
      "Batch train [8] loss 0.83888, dsc 0.16112\n",
      "Batch train [9] loss 0.84922, dsc 0.15078\n",
      "Batch train [10] loss 0.82985, dsc 0.17015\n",
      "Batch train [11] loss 0.84476, dsc 0.15524\n",
      "Batch train [12] loss 0.84491, dsc 0.15509\n",
      "Batch train [13] loss 0.87558, dsc 0.12442\n",
      "Batch train [14] loss 0.84173, dsc 0.15827\n",
      "Batch train [15] loss 0.84818, dsc 0.15182\n",
      "Batch train [16] loss 0.81388, dsc 0.18612\n",
      "Batch train [17] loss 0.83744, dsc 0.16256\n",
      "Batch train [18] loss 0.84092, dsc 0.15908\n",
      "Batch train [19] loss 0.82145, dsc 0.17855\n",
      "Batch train [20] loss 0.84602, dsc 0.15398\n",
      "Epoch [34] train done\n",
      "Batch eval [1] loss 0.86140, dsc 0.13860\n",
      "Batch eval [2] loss 0.88463, dsc 0.11537\n",
      "Batch eval [3] loss 0.86057, dsc 0.13943\n",
      "Batch eval [4] loss 0.84461, dsc 0.15539\n",
      "Batch eval [5] loss 0.78589, dsc 0.21411\n",
      "Epoch [34] valid done\n",
      "Epoch [34] T 2170.09s, deltaT 64.00s, loss: train 0.85164, valid 0.84742, dsc: train 0.14836, valid 0.15258\n",
      "Batch train [1] loss 0.83597, dsc 0.16403\n",
      "Batch train [2] loss 0.85747, dsc 0.14253\n",
      "Batch train [3] loss 0.80843, dsc 0.19157\n",
      "Batch train [4] loss 0.83086, dsc 0.16914\n",
      "Batch train [5] loss 0.78970, dsc 0.21030\n",
      "Batch train [6] loss 0.82774, dsc 0.17226\n",
      "Batch train [7] loss 0.87015, dsc 0.12985\n",
      "Batch train [8] loss 0.81181, dsc 0.18819\n",
      "Batch train [9] loss 0.86159, dsc 0.13841\n",
      "Batch train [10] loss 0.80268, dsc 0.19732\n",
      "Batch train [11] loss 0.81914, dsc 0.18086\n",
      "Batch train [12] loss 0.83778, dsc 0.16222\n",
      "Batch train [13] loss 0.80324, dsc 0.19676\n",
      "Batch train [14] loss 0.84032, dsc 0.15968\n",
      "Batch train [15] loss 0.80937, dsc 0.19063\n",
      "Batch train [16] loss 0.77776, dsc 0.22224\n",
      "Batch train [17] loss 0.78931, dsc 0.21069\n",
      "Batch train [18] loss 0.80463, dsc 0.19537\n",
      "Batch train [19] loss 0.78269, dsc 0.21731\n",
      "Batch train [20] loss 0.79418, dsc 0.20582\n",
      "Epoch [35] train done\n",
      "Batch eval [1] loss 0.81110, dsc 0.18890\n",
      "Batch eval [2] loss 0.83589, dsc 0.16411\n",
      "Batch eval [3] loss 0.80501, dsc 0.19499\n",
      "Batch eval [4] loss 0.78066, dsc 0.21934\n",
      "Batch eval [5] loss 0.69178, dsc 0.30822\n",
      "Epoch [35] valid done\n",
      "Epoch [35] T 2235.00s, deltaT 64.92s, loss: train 0.81774, valid 0.78489, dsc: train 0.18226, valid 0.21511\n",
      "Batch train [1] loss 0.77326, dsc 0.22674\n",
      "Batch train [2] loss 0.78062, dsc 0.21938\n",
      "Batch train [3] loss 0.78405, dsc 0.21595\n",
      "Batch train [4] loss 0.75720, dsc 0.24280\n",
      "Batch train [5] loss 0.80444, dsc 0.19556\n",
      "Batch train [6] loss 0.79698, dsc 0.20302\n",
      "Batch train [7] loss 0.77941, dsc 0.22059\n",
      "Batch train [8] loss 0.79551, dsc 0.20449\n",
      "Batch train [9] loss 0.84827, dsc 0.15173\n",
      "Batch train [10] loss 0.75984, dsc 0.24016\n",
      "Batch train [11] loss 0.76943, dsc 0.23057\n",
      "Batch train [12] loss 0.81399, dsc 0.18601\n",
      "Batch train [13] loss 0.77619, dsc 0.22381\n",
      "Batch train [14] loss 0.76200, dsc 0.23800\n",
      "Batch train [15] loss 0.76231, dsc 0.23769\n",
      "Batch train [16] loss 0.74266, dsc 0.25734\n",
      "Batch train [17] loss 0.75114, dsc 0.24886\n",
      "Batch train [18] loss 0.71682, dsc 0.28318\n",
      "Batch train [19] loss 0.75633, dsc 0.24367\n",
      "Batch train [20] loss 0.75773, dsc 0.24227\n",
      "Epoch [36] train done\n",
      "Batch eval [1] loss 0.76645, dsc 0.23355\n",
      "Batch eval [2] loss 0.80053, dsc 0.19947\n",
      "Batch eval [3] loss 0.75629, dsc 0.24371\n",
      "Batch eval [4] loss 0.73963, dsc 0.26037\n",
      "Batch eval [5] loss 0.64500, dsc 0.35500\n",
      "Epoch [36] valid done\n",
      "Epoch [36] T 2299.45s, deltaT 64.45s, loss: train 0.77441, valid 0.74158, dsc: train 0.22559, valid 0.25842\n",
      "Batch train [1] loss 0.77012, dsc 0.22988\n",
      "Batch train [2] loss 0.78047, dsc 0.21953\n",
      "Batch train [3] loss 0.73276, dsc 0.26724\n",
      "Batch train [4] loss 0.76466, dsc 0.23534\n",
      "Batch train [5] loss 0.71406, dsc 0.28594\n",
      "Batch train [6] loss 0.73074, dsc 0.26926\n",
      "Batch train [7] loss 0.70728, dsc 0.29272\n",
      "Batch train [8] loss 0.72834, dsc 0.27166\n",
      "Batch train [9] loss 0.76183, dsc 0.23817\n",
      "Batch train [10] loss 0.69340, dsc 0.30660\n",
      "Batch train [11] loss 0.80677, dsc 0.19323\n",
      "Batch train [12] loss 0.68656, dsc 0.31344\n",
      "Batch train [13] loss 0.70413, dsc 0.29587\n",
      "Batch train [14] loss 0.74474, dsc 0.25526\n",
      "Batch train [15] loss 0.70872, dsc 0.29128\n",
      "Batch train [16] loss 0.69671, dsc 0.30329\n",
      "Batch train [17] loss 0.70692, dsc 0.29308\n",
      "Batch train [18] loss 0.76073, dsc 0.23927\n",
      "Batch train [19] loss 0.70526, dsc 0.29474\n",
      "Batch train [20] loss 0.65274, dsc 0.34726\n",
      "Epoch [37] train done\n",
      "Batch eval [1] loss 0.69764, dsc 0.30236\n",
      "Batch eval [2] loss 0.75774, dsc 0.24226\n",
      "Batch eval [3] loss 0.70108, dsc 0.29892\n",
      "Batch eval [4] loss 0.66068, dsc 0.33932\n",
      "Batch eval [5] loss 0.60820, dsc 0.39180\n",
      "Epoch [37] valid done\n",
      "Epoch [37] T 2364.19s, deltaT 64.74s, loss: train 0.72785, valid 0.68507, dsc: train 0.27215, valid 0.31493\n",
      "Batch train [1] loss 0.71149, dsc 0.28851\n",
      "Batch train [2] loss 0.66700, dsc 0.33300\n",
      "Batch train [3] loss 0.65308, dsc 0.34692\n",
      "Batch train [4] loss 0.70335, dsc 0.29665\n",
      "Batch train [5] loss 0.73734, dsc 0.26266\n",
      "Batch train [6] loss 0.71377, dsc 0.28623\n",
      "Batch train [7] loss 0.68711, dsc 0.31289\n",
      "Batch train [8] loss 0.71833, dsc 0.28167\n",
      "Batch train [9] loss 0.60671, dsc 0.39329\n",
      "Batch train [10] loss 0.66792, dsc 0.33208\n",
      "Batch train [11] loss 0.67241, dsc 0.32759\n",
      "Batch train [12] loss 0.60593, dsc 0.39407\n",
      "Batch train [13] loss 0.65015, dsc 0.34985\n",
      "Batch train [14] loss 0.67120, dsc 0.32880\n",
      "Batch train [15] loss 0.68302, dsc 0.31698\n",
      "Batch train [16] loss 0.70579, dsc 0.29421\n",
      "Batch train [17] loss 0.68499, dsc 0.31501\n",
      "Batch train [18] loss 0.69430, dsc 0.30570\n",
      "Batch train [19] loss 0.58307, dsc 0.41693\n",
      "Batch train [20] loss 0.62461, dsc 0.37539\n",
      "Epoch [38] train done\n",
      "Batch eval [1] loss 0.62388, dsc 0.37612\n",
      "Batch eval [2] loss 0.69417, dsc 0.30583\n",
      "Batch eval [3] loss 0.64210, dsc 0.35790\n",
      "Batch eval [4] loss 0.58853, dsc 0.41147\n",
      "Batch eval [5] loss 0.56781, dsc 0.43219\n",
      "Epoch [38] valid done\n",
      "Epoch [38] T 2428.97s, deltaT 64.78s, loss: train 0.67208, valid 0.62330, dsc: train 0.32792, valid 0.37670\n",
      "Batch train [1] loss 0.61538, dsc 0.38462\n",
      "Batch train [2] loss 0.58250, dsc 0.41750\n",
      "Batch train [3] loss 0.55834, dsc 0.44166\n",
      "Batch train [4] loss 0.60798, dsc 0.39202\n",
      "Batch train [5] loss 0.59742, dsc 0.40258\n",
      "Batch train [6] loss 0.64518, dsc 0.35482\n",
      "Batch train [7] loss 0.62170, dsc 0.37830\n",
      "Batch train [8] loss 0.62756, dsc 0.37244\n",
      "Batch train [9] loss 0.61928, dsc 0.38072\n",
      "Batch train [10] loss 0.65897, dsc 0.34103\n",
      "Batch train [11] loss 0.59057, dsc 0.40943\n",
      "Batch train [12] loss 0.63597, dsc 0.36403\n",
      "Batch train [13] loss 0.65824, dsc 0.34176\n",
      "Batch train [14] loss 0.64491, dsc 0.35509\n",
      "Batch train [15] loss 0.62717, dsc 0.37283\n",
      "Batch train [16] loss 0.56802, dsc 0.43198\n",
      "Batch train [17] loss 0.65270, dsc 0.34730\n",
      "Batch train [18] loss 0.58717, dsc 0.41283\n",
      "Batch train [19] loss 0.55510, dsc 0.44490\n",
      "Batch train [20] loss 0.58153, dsc 0.41847\n",
      "Epoch [39] train done\n",
      "Batch eval [1] loss 0.78521, dsc 0.21479\n",
      "Batch eval [2] loss 0.90448, dsc 0.09552\n",
      "Batch eval [3] loss 0.84593, dsc 0.15407\n",
      "Batch eval [4] loss 0.68527, dsc 0.31473\n",
      "Batch eval [5] loss 0.70841, dsc 0.29159\n",
      "Epoch [39] valid done\n",
      "Epoch [39] T 2493.63s, deltaT 64.66s, loss: train 0.61179, valid 0.78586, dsc: train 0.38821, valid 0.21414\n",
      "Batch train [1] loss 0.62069, dsc 0.37931\n",
      "Batch train [2] loss 0.58367, dsc 0.41633\n",
      "Batch train [3] loss 0.53963, dsc 0.46037\n",
      "Batch train [4] loss 0.64370, dsc 0.35630\n",
      "Batch train [5] loss 0.56895, dsc 0.43105\n",
      "Batch train [6] loss 0.57006, dsc 0.42994\n",
      "Batch train [7] loss 0.56120, dsc 0.43880\n",
      "Batch train [8] loss 0.53333, dsc 0.46667\n",
      "Batch train [9] loss 0.54478, dsc 0.45522\n",
      "Batch train [10] loss 0.60264, dsc 0.39736\n",
      "Batch train [11] loss 0.49489, dsc 0.50511\n",
      "Batch train [12] loss 0.52064, dsc 0.47936\n",
      "Batch train [13] loss 0.52885, dsc 0.47115\n",
      "Batch train [14] loss 0.59400, dsc 0.40600\n",
      "Batch train [15] loss 0.55081, dsc 0.44919\n",
      "Batch train [16] loss 0.59356, dsc 0.40644\n",
      "Batch train [17] loss 0.54703, dsc 0.45297\n",
      "Batch train [18] loss 0.58060, dsc 0.41940\n",
      "Batch train [19] loss 0.53528, dsc 0.46472\n",
      "Batch train [20] loss 0.46972, dsc 0.53028\n",
      "Epoch [40] train done\n",
      "Batch eval [1] loss 0.57975, dsc 0.42025\n",
      "Batch eval [2] loss 0.61881, dsc 0.38119\n",
      "Batch eval [3] loss 0.53910, dsc 0.46090\n",
      "Batch eval [4] loss 0.51894, dsc 0.48106\n",
      "Batch eval [5] loss 0.43632, dsc 0.56368\n",
      "Epoch [40] valid done\n",
      "Epoch [40] T 2558.03s, deltaT 64.39s, loss: train 0.55920, valid 0.53858, dsc: train 0.44080, valid 0.46142\n",
      "Batch train [1] loss 0.53121, dsc 0.46879\n",
      "Batch train [2] loss 0.48259, dsc 0.51741\n",
      "Batch train [3] loss 0.55093, dsc 0.44907\n",
      "Batch train [4] loss 0.50504, dsc 0.49496\n",
      "Batch train [5] loss 0.47327, dsc 0.52673\n",
      "Batch train [6] loss 0.58263, dsc 0.41737\n",
      "Batch train [7] loss 0.50422, dsc 0.49578\n",
      "Batch train [8] loss 0.49177, dsc 0.50823\n",
      "Batch train [9] loss 0.45740, dsc 0.54260\n",
      "Batch train [10] loss 0.47769, dsc 0.52231\n",
      "Batch train [11] loss 0.49786, dsc 0.50214\n",
      "Batch train [12] loss 0.54157, dsc 0.45843\n",
      "Batch train [13] loss 0.48379, dsc 0.51621\n",
      "Batch train [14] loss 0.45658, dsc 0.54342\n",
      "Batch train [15] loss 0.46454, dsc 0.53546\n",
      "Batch train [16] loss 0.46209, dsc 0.53791\n",
      "Batch train [17] loss 0.50367, dsc 0.49633\n",
      "Batch train [18] loss 0.45510, dsc 0.54490\n",
      "Batch train [19] loss 0.52982, dsc 0.47018\n",
      "Batch train [20] loss 0.51718, dsc 0.48282\n",
      "Epoch [41] train done\n",
      "Batch eval [1] loss 0.52240, dsc 0.47760\n",
      "Batch eval [2] loss 0.56132, dsc 0.43868\n",
      "Batch eval [3] loss 0.48359, dsc 0.51641\n",
      "Batch eval [4] loss 0.45857, dsc 0.54143\n",
      "Batch eval [5] loss 0.35628, dsc 0.64372\n",
      "Epoch [41] valid done\n",
      "Epoch [41] T 2622.35s, deltaT 64.33s, loss: train 0.49845, valid 0.47643, dsc: train 0.50155, valid 0.52357\n",
      "Batch train [1] loss 0.49172, dsc 0.50828\n",
      "Batch train [2] loss 0.46232, dsc 0.53768\n",
      "Batch train [3] loss 0.47062, dsc 0.52938\n",
      "Batch train [4] loss 0.50149, dsc 0.49851\n",
      "Batch train [5] loss 0.41922, dsc 0.58078\n",
      "Batch train [6] loss 0.43820, dsc 0.56180\n",
      "Batch train [7] loss 0.46337, dsc 0.53663\n",
      "Batch train [8] loss 0.46165, dsc 0.53835\n",
      "Batch train [9] loss 0.45363, dsc 0.54637\n",
      "Batch train [10] loss 0.48242, dsc 0.51758\n",
      "Batch train [11] loss 0.49274, dsc 0.50726\n",
      "Batch train [12] loss 0.41525, dsc 0.58475\n",
      "Batch train [13] loss 0.41297, dsc 0.58703\n",
      "Batch train [14] loss 0.39889, dsc 0.60111\n",
      "Batch train [15] loss 0.46042, dsc 0.53958\n",
      "Batch train [16] loss 0.46380, dsc 0.53620\n",
      "Batch train [17] loss 0.47821, dsc 0.52179\n",
      "Batch train [18] loss 0.45035, dsc 0.54965\n",
      "Batch train [19] loss 0.40568, dsc 0.59432\n",
      "Batch train [20] loss 0.38549, dsc 0.61451\n",
      "Epoch [42] train done\n",
      "Batch eval [1] loss 0.69779, dsc 0.30221\n",
      "Batch eval [2] loss 0.80797, dsc 0.19203\n",
      "Batch eval [3] loss 0.82256, dsc 0.17744\n",
      "Batch eval [4] loss 0.58648, dsc 0.41352\n",
      "Batch eval [5] loss 0.70720, dsc 0.29280\n",
      "Epoch [42] valid done\n",
      "Epoch [42] T 2686.54s, deltaT 64.18s, loss: train 0.45042, valid 0.72440, dsc: train 0.54958, valid 0.27560\n",
      "Batch train [1] loss 0.42387, dsc 0.57613\n",
      "Batch train [2] loss 0.36914, dsc 0.63086\n",
      "Batch train [3] loss 0.35633, dsc 0.64367\n",
      "Batch train [4] loss 0.40722, dsc 0.59278\n",
      "Batch train [5] loss 0.36219, dsc 0.63781\n",
      "Batch train [6] loss 0.37559, dsc 0.62441\n",
      "Batch train [7] loss 0.43626, dsc 0.56374\n",
      "Batch train [8] loss 0.46121, dsc 0.53879\n",
      "Batch train [9] loss 0.41159, dsc 0.58841\n",
      "Batch train [10] loss 0.45283, dsc 0.54717\n",
      "Batch train [11] loss 0.39108, dsc 0.60892\n",
      "Batch train [12] loss 0.41677, dsc 0.58323\n",
      "Batch train [13] loss 0.40518, dsc 0.59482\n",
      "Batch train [14] loss 0.36122, dsc 0.63878\n",
      "Batch train [15] loss 0.37548, dsc 0.62452\n",
      "Batch train [16] loss 0.44341, dsc 0.55659\n",
      "Batch train [17] loss 0.38071, dsc 0.61929\n",
      "Batch train [18] loss 0.37554, dsc 0.62446\n",
      "Batch train [19] loss 0.37643, dsc 0.62357\n",
      "Batch train [20] loss 0.39957, dsc 0.60043\n",
      "Epoch [43] train done\n",
      "Batch eval [1] loss 0.38330, dsc 0.61670\n",
      "Batch eval [2] loss 0.41440, dsc 0.58560\n",
      "Batch eval [3] loss 0.37899, dsc 0.62101\n",
      "Batch eval [4] loss 0.35852, dsc 0.64148\n",
      "Batch eval [5] loss 0.35292, dsc 0.64708\n",
      "Epoch [43] valid done\n",
      "Epoch [43] T 2752.32s, deltaT 65.79s, loss: train 0.39908, valid 0.37762, dsc: train 0.60092, valid 0.62238\n",
      "Batch train [1] loss 0.34498, dsc 0.65502\n",
      "Batch train [2] loss 0.36923, dsc 0.63077\n",
      "Batch train [3] loss 0.35727, dsc 0.64273\n",
      "Batch train [4] loss 0.31771, dsc 0.68229\n",
      "Batch train [5] loss 0.35642, dsc 0.64358\n",
      "Batch train [6] loss 0.35936, dsc 0.64064\n",
      "Batch train [7] loss 0.39067, dsc 0.60933\n",
      "Batch train [8] loss 0.39681, dsc 0.60319\n",
      "Batch train [9] loss 0.30630, dsc 0.69370\n",
      "Batch train [10] loss 0.39737, dsc 0.60263\n",
      "Batch train [11] loss 0.32864, dsc 0.67136\n",
      "Batch train [12] loss 0.37207, dsc 0.62793\n",
      "Batch train [13] loss 0.35806, dsc 0.64194\n",
      "Batch train [14] loss 0.34994, dsc 0.65006\n",
      "Batch train [15] loss 0.35409, dsc 0.64591\n",
      "Batch train [16] loss 0.32128, dsc 0.67872\n",
      "Batch train [17] loss 0.43862, dsc 0.56138\n",
      "Batch train [18] loss 0.37335, dsc 0.62665\n",
      "Batch train [19] loss 0.36859, dsc 0.63141\n",
      "Batch train [20] loss 0.31375, dsc 0.68625\n",
      "Epoch [44] train done\n",
      "Batch eval [1] loss 0.36693, dsc 0.63307\n",
      "Batch eval [2] loss 0.39316, dsc 0.60684\n",
      "Batch eval [3] loss 0.34506, dsc 0.65494\n",
      "Batch eval [4] loss 0.33999, dsc 0.66001\n",
      "Batch eval [5] loss 0.32085, dsc 0.67915\n",
      "Epoch [44] valid done\n",
      "Epoch [44] T 2817.34s, deltaT 65.01s, loss: train 0.35873, valid 0.35320, dsc: train 0.64127, valid 0.64680\n",
      "Batch train [1] loss 0.27936, dsc 0.72064\n",
      "Batch train [2] loss 0.34225, dsc 0.65775\n",
      "Batch train [3] loss 0.31003, dsc 0.68997\n",
      "Batch train [4] loss 0.29081, dsc 0.70919\n",
      "Batch train [5] loss 0.34383, dsc 0.65617\n",
      "Batch train [6] loss 0.38568, dsc 0.61432\n",
      "Batch train [7] loss 0.31197, dsc 0.68803\n",
      "Batch train [8] loss 0.34223, dsc 0.65777\n",
      "Batch train [9] loss 0.32516, dsc 0.67484\n",
      "Batch train [10] loss 0.29369, dsc 0.70631\n",
      "Batch train [11] loss 0.33177, dsc 0.66823\n",
      "Batch train [12] loss 0.28580, dsc 0.71420\n",
      "Batch train [13] loss 0.35154, dsc 0.64846\n",
      "Batch train [14] loss 0.31792, dsc 0.68208\n",
      "Batch train [15] loss 0.30987, dsc 0.69013\n",
      "Batch train [16] loss 0.35352, dsc 0.64648\n",
      "Batch train [17] loss 0.35381, dsc 0.64619\n",
      "Batch train [18] loss 0.35093, dsc 0.64907\n",
      "Batch train [19] loss 0.28112, dsc 0.71888\n",
      "Batch train [20] loss 0.31727, dsc 0.68273\n",
      "Epoch [45] train done\n",
      "Batch eval [1] loss 0.30010, dsc 0.69990\n",
      "Batch eval [2] loss 0.35991, dsc 0.64009\n",
      "Batch eval [3] loss 0.35431, dsc 0.64569\n",
      "Batch eval [4] loss 0.27419, dsc 0.72581\n",
      "Batch eval [5] loss 0.30949, dsc 0.69051\n",
      "Epoch [45] valid done\n",
      "Epoch [45] T 2882.57s, deltaT 65.23s, loss: train 0.32393, valid 0.31960, dsc: train 0.67607, valid 0.68040\n",
      "Batch train [1] loss 0.34767, dsc 0.65233\n",
      "Batch train [2] loss 0.33356, dsc 0.66644\n",
      "Batch train [3] loss 0.30445, dsc 0.69555\n",
      "Batch train [4] loss 0.30333, dsc 0.69667\n",
      "Batch train [5] loss 0.29397, dsc 0.70603\n",
      "Batch train [6] loss 0.30501, dsc 0.69499\n",
      "Batch train [7] loss 0.25103, dsc 0.74897\n",
      "Batch train [8] loss 0.25833, dsc 0.74167\n",
      "Batch train [9] loss 0.27218, dsc 0.72782\n",
      "Batch train [10] loss 0.28108, dsc 0.71892\n",
      "Batch train [11] loss 0.24739, dsc 0.75261\n",
      "Batch train [12] loss 0.30709, dsc 0.69291\n",
      "Batch train [13] loss 0.31837, dsc 0.68163\n",
      "Batch train [14] loss 0.25741, dsc 0.74259\n",
      "Batch train [15] loss 0.29125, dsc 0.70875\n",
      "Batch train [16] loss 0.27878, dsc 0.72122\n",
      "Batch train [17] loss 0.29164, dsc 0.70836\n",
      "Batch train [18] loss 0.32865, dsc 0.67135\n",
      "Batch train [19] loss 0.34166, dsc 0.65834\n",
      "Batch train [20] loss 0.26312, dsc 0.73688\n",
      "Epoch [46] train done\n",
      "Batch eval [1] loss 0.32251, dsc 0.67749\n",
      "Batch eval [2] loss 0.36650, dsc 0.63350\n",
      "Batch eval [3] loss 0.37642, dsc 0.62358\n",
      "Batch eval [4] loss 0.33323, dsc 0.66677\n",
      "Batch eval [5] loss 0.38546, dsc 0.61454\n",
      "Epoch [46] valid done\n",
      "Epoch [46] T 2947.77s, deltaT 65.20s, loss: train 0.29380, valid 0.35682, dsc: train 0.70620, valid 0.64318\n",
      "Batch train [1] loss 0.25650, dsc 0.74350\n",
      "Batch train [2] loss 0.28140, dsc 0.71860\n",
      "Batch train [3] loss 0.24519, dsc 0.75481\n",
      "Batch train [4] loss 0.24730, dsc 0.75270\n",
      "Batch train [5] loss 0.26559, dsc 0.73441\n",
      "Batch train [6] loss 0.28835, dsc 0.71165\n",
      "Batch train [7] loss 0.32927, dsc 0.67073\n",
      "Batch train [8] loss 0.24950, dsc 0.75050\n",
      "Batch train [9] loss 0.30706, dsc 0.69294\n",
      "Batch train [10] loss 0.27884, dsc 0.72116\n",
      "Batch train [11] loss 0.28974, dsc 0.71026\n",
      "Batch train [12] loss 0.22908, dsc 0.77092\n",
      "Batch train [13] loss 0.27706, dsc 0.72294\n",
      "Batch train [14] loss 0.25669, dsc 0.74331\n",
      "Batch train [15] loss 0.28439, dsc 0.71561\n",
      "Batch train [16] loss 0.25977, dsc 0.74023\n",
      "Batch train [17] loss 0.25080, dsc 0.74920\n",
      "Batch train [18] loss 0.25188, dsc 0.74812\n",
      "Batch train [19] loss 0.22591, dsc 0.77409\n",
      "Batch train [20] loss 0.27720, dsc 0.72280\n",
      "Epoch [47] train done\n",
      "Batch eval [1] loss 0.28003, dsc 0.71997\n",
      "Batch eval [2] loss 0.30965, dsc 0.69035\n",
      "Batch eval [3] loss 0.28571, dsc 0.71429\n",
      "Batch eval [4] loss 0.26612, dsc 0.73388\n",
      "Batch eval [5] loss 0.32371, dsc 0.67629\n",
      "Epoch [47] valid done\n",
      "Epoch [47] T 3012.48s, deltaT 64.71s, loss: train 0.26758, valid 0.29304, dsc: train 0.73242, valid 0.70696\n",
      "Batch train [1] loss 0.27245, dsc 0.72755\n",
      "Batch train [2] loss 0.23483, dsc 0.76517\n",
      "Batch train [3] loss 0.24266, dsc 0.75734\n",
      "Batch train [4] loss 0.25533, dsc 0.74467\n",
      "Batch train [5] loss 0.24484, dsc 0.75516\n",
      "Batch train [6] loss 0.22584, dsc 0.77416\n",
      "Batch train [7] loss 0.27234, dsc 0.72766\n",
      "Batch train [8] loss 0.26599, dsc 0.73401\n",
      "Batch train [9] loss 0.24132, dsc 0.75868\n",
      "Batch train [10] loss 0.31512, dsc 0.68488\n",
      "Batch train [11] loss 0.24885, dsc 0.75115\n",
      "Batch train [12] loss 0.26560, dsc 0.73440\n",
      "Batch train [13] loss 0.24231, dsc 0.75769\n",
      "Batch train [14] loss 0.25173, dsc 0.74827\n",
      "Batch train [15] loss 0.25002, dsc 0.74998\n",
      "Batch train [16] loss 0.24392, dsc 0.75608\n",
      "Batch train [17] loss 0.19751, dsc 0.80249\n",
      "Batch train [18] loss 0.23607, dsc 0.76393\n",
      "Batch train [19] loss 0.26077, dsc 0.73923\n",
      "Batch train [20] loss 0.19428, dsc 0.80572\n",
      "Epoch [48] train done\n",
      "Batch eval [1] loss 0.30409, dsc 0.69591\n",
      "Batch eval [2] loss 0.33381, dsc 0.66619\n",
      "Batch eval [3] loss 0.24140, dsc 0.75860\n",
      "Batch eval [4] loss 0.24309, dsc 0.75691\n",
      "Batch eval [5] loss 0.17539, dsc 0.82461\n",
      "Epoch [48] valid done\n",
      "Epoch [48] T 3080.24s, deltaT 67.76s, loss: train 0.24809, valid 0.25956, dsc: train 0.75191, valid 0.74044\n",
      "Batch train [1] loss 0.23323, dsc 0.76677\n",
      "Batch train [2] loss 0.26990, dsc 0.73010\n",
      "Batch train [3] loss 0.21746, dsc 0.78254\n",
      "Batch train [4] loss 0.21682, dsc 0.78318\n",
      "Batch train [5] loss 0.25370, dsc 0.74630\n",
      "Batch train [6] loss 0.21166, dsc 0.78834\n",
      "Batch train [7] loss 0.22863, dsc 0.77137\n",
      "Batch train [8] loss 0.22362, dsc 0.77638\n",
      "Batch train [9] loss 0.19278, dsc 0.80722\n",
      "Batch train [10] loss 0.19974, dsc 0.80026\n",
      "Batch train [11] loss 0.27951, dsc 0.72049\n",
      "Batch train [12] loss 0.21707, dsc 0.78293\n",
      "Batch train [13] loss 0.25964, dsc 0.74036\n",
      "Batch train [14] loss 0.27825, dsc 0.72175\n",
      "Batch train [15] loss 0.19606, dsc 0.80394\n",
      "Batch train [16] loss 0.20300, dsc 0.79700\n",
      "Batch train [17] loss 0.20861, dsc 0.79139\n",
      "Batch train [18] loss 0.24678, dsc 0.75322\n",
      "Batch train [19] loss 0.22823, dsc 0.77177\n",
      "Batch train [20] loss 0.27692, dsc 0.72308\n",
      "Epoch [49] train done\n",
      "Batch eval [1] loss 0.27780, dsc 0.72220\n",
      "Batch eval [2] loss 0.29408, dsc 0.70592\n",
      "Batch eval [3] loss 0.24198, dsc 0.75802\n",
      "Batch eval [4] loss 0.21569, dsc 0.78431\n",
      "Batch eval [5] loss 0.22891, dsc 0.77109\n",
      "Epoch [49] valid done\n",
      "Epoch [49] T 3149.88s, deltaT 69.64s, loss: train 0.23208, valid 0.25169, dsc: train 0.76792, valid 0.74831\n",
      "Batch train [1] loss 0.20471, dsc 0.79529\n",
      "Batch train [2] loss 0.21947, dsc 0.78053\n",
      "Batch train [3] loss 0.19622, dsc 0.80378\n",
      "Batch train [4] loss 0.24194, dsc 0.75806\n",
      "Batch train [5] loss 0.19298, dsc 0.80702\n",
      "Batch train [6] loss 0.21169, dsc 0.78831\n",
      "Batch train [7] loss 0.19439, dsc 0.80561\n",
      "Batch train [8] loss 0.22888, dsc 0.77112\n",
      "Batch train [9] loss 0.22391, dsc 0.77609\n",
      "Batch train [10] loss 0.19979, dsc 0.80021\n",
      "Batch train [11] loss 0.24272, dsc 0.75728\n",
      "Batch train [12] loss 0.19165, dsc 0.80835\n",
      "Batch train [13] loss 0.17994, dsc 0.82006\n",
      "Batch train [14] loss 0.21834, dsc 0.78166\n",
      "Batch train [15] loss 0.21028, dsc 0.78972\n",
      "Batch train [16] loss 0.22876, dsc 0.77124\n",
      "Batch train [17] loss 0.20095, dsc 0.79905\n",
      "Batch train [18] loss 0.25132, dsc 0.74868\n",
      "Batch train [19] loss 0.21828, dsc 0.78172\n",
      "Batch train [20] loss 0.21163, dsc 0.78837\n",
      "Epoch [50] train done\n",
      "Batch eval [1] loss 0.22888, dsc 0.77112\n",
      "Batch eval [2] loss 0.25055, dsc 0.74945\n",
      "Batch eval [3] loss 0.27585, dsc 0.72415\n",
      "Batch eval [4] loss 0.23016, dsc 0.76984\n",
      "Batch eval [5] loss 0.33043, dsc 0.66957\n",
      "Epoch [50] valid done\n",
      "Epoch [50] T 3219.31s, deltaT 69.43s, loss: train 0.21339, valid 0.26317, dsc: train 0.78661, valid 0.73683\n",
      "Batch train [1] loss 0.19587, dsc 0.80413\n",
      "Batch train [2] loss 0.20426, dsc 0.79574\n",
      "Batch train [3] loss 0.18040, dsc 0.81960\n",
      "Batch train [4] loss 0.21037, dsc 0.78963\n",
      "Batch train [5] loss 0.20440, dsc 0.79560\n",
      "Batch train [6] loss 0.23205, dsc 0.76795\n",
      "Batch train [7] loss 0.18497, dsc 0.81503\n",
      "Batch train [8] loss 0.18907, dsc 0.81093\n",
      "Batch train [9] loss 0.19622, dsc 0.80378\n",
      "Batch train [10] loss 0.21689, dsc 0.78311\n",
      "Batch train [11] loss 0.17967, dsc 0.82033\n",
      "Batch train [12] loss 0.19790, dsc 0.80210\n",
      "Batch train [13] loss 0.21063, dsc 0.78937\n",
      "Batch train [14] loss 0.16339, dsc 0.83661\n",
      "Batch train [15] loss 0.19146, dsc 0.80854\n",
      "Batch train [16] loss 0.23871, dsc 0.76129\n",
      "Batch train [17] loss 0.19457, dsc 0.80543\n",
      "Batch train [18] loss 0.16310, dsc 0.83690\n",
      "Batch train [19] loss 0.19103, dsc 0.80897\n",
      "Batch train [20] loss 0.20589, dsc 0.79411\n",
      "Epoch [51] train done\n",
      "Batch eval [1] loss 0.25229, dsc 0.74771\n",
      "Batch eval [2] loss 0.27007, dsc 0.72993\n",
      "Batch eval [3] loss 0.20525, dsc 0.79475\n",
      "Batch eval [4] loss 0.19768, dsc 0.80232\n",
      "Batch eval [5] loss 0.16221, dsc 0.83779\n",
      "Epoch [51] valid done\n",
      "Epoch [51] T 3286.64s, deltaT 67.33s, loss: train 0.19754, valid 0.21750, dsc: train 0.80246, valid 0.78250\n",
      "Batch train [1] loss 0.15605, dsc 0.84395\n",
      "Batch train [2] loss 0.19192, dsc 0.80808\n",
      "Batch train [3] loss 0.17607, dsc 0.82393\n",
      "Batch train [4] loss 0.18818, dsc 0.81182\n",
      "Batch train [5] loss 0.18249, dsc 0.81751\n",
      "Batch train [6] loss 0.22949, dsc 0.77051\n",
      "Batch train [7] loss 0.18212, dsc 0.81788\n",
      "Batch train [8] loss 0.21871, dsc 0.78129\n",
      "Batch train [9] loss 0.19599, dsc 0.80401\n",
      "Batch train [10] loss 0.19305, dsc 0.80695\n",
      "Batch train [11] loss 0.20275, dsc 0.79725\n",
      "Batch train [12] loss 0.15989, dsc 0.84011\n",
      "Batch train [13] loss 0.24148, dsc 0.75852\n",
      "Batch train [14] loss 0.25312, dsc 0.74688\n",
      "Batch train [15] loss 0.17990, dsc 0.82010\n",
      "Batch train [16] loss 0.19358, dsc 0.80642\n",
      "Batch train [17] loss 0.17621, dsc 0.82379\n",
      "Batch train [18] loss 0.14887, dsc 0.85113\n",
      "Batch train [19] loss 0.15314, dsc 0.84686\n",
      "Batch train [20] loss 0.19524, dsc 0.80476\n",
      "Epoch [52] train done\n",
      "Batch eval [1] loss 0.21554, dsc 0.78446\n",
      "Batch eval [2] loss 0.21399, dsc 0.78601\n",
      "Batch eval [3] loss 0.23908, dsc 0.76092\n",
      "Batch eval [4] loss 0.21648, dsc 0.78352\n",
      "Batch eval [5] loss 0.27390, dsc 0.72610\n",
      "Epoch [52] valid done\n",
      "Epoch [52] T 3354.65s, deltaT 68.00s, loss: train 0.19091, valid 0.23180, dsc: train 0.80909, valid 0.76820\n",
      "Batch train [1] loss 0.17134, dsc 0.82866\n",
      "Batch train [2] loss 0.20268, dsc 0.79732\n",
      "Batch train [3] loss 0.19794, dsc 0.80206\n",
      "Batch train [4] loss 0.16816, dsc 0.83184\n",
      "Batch train [5] loss 0.18991, dsc 0.81009\n",
      "Batch train [6] loss 0.18539, dsc 0.81461\n",
      "Batch train [7] loss 0.20462, dsc 0.79538\n",
      "Batch train [8] loss 0.16426, dsc 0.83574\n",
      "Batch train [9] loss 0.23863, dsc 0.76137\n",
      "Batch train [10] loss 0.18747, dsc 0.81253\n",
      "Batch train [11] loss 0.16931, dsc 0.83069\n",
      "Batch train [12] loss 0.17489, dsc 0.82511\n",
      "Batch train [13] loss 0.16264, dsc 0.83736\n",
      "Batch train [14] loss 0.19171, dsc 0.80829\n",
      "Batch train [15] loss 0.15646, dsc 0.84354\n",
      "Batch train [16] loss 0.18920, dsc 0.81080\n",
      "Batch train [17] loss 0.15123, dsc 0.84877\n",
      "Batch train [18] loss 0.14898, dsc 0.85102\n",
      "Batch train [19] loss 0.18963, dsc 0.81037\n",
      "Batch train [20] loss 0.15877, dsc 0.84123\n",
      "Epoch [53] train done\n",
      "Batch eval [1] loss 0.21159, dsc 0.78841\n",
      "Batch eval [2] loss 0.22293, dsc 0.77707\n",
      "Batch eval [3] loss 0.17537, dsc 0.82463\n",
      "Batch eval [4] loss 0.17014, dsc 0.82986\n",
      "Batch eval [5] loss 0.19496, dsc 0.80504\n",
      "Epoch [53] valid done\n",
      "Epoch [53] T 3422.76s, deltaT 68.12s, loss: train 0.18016, valid 0.19500, dsc: train 0.81984, valid 0.80500\n",
      "Batch train [1] loss 0.14857, dsc 0.85143\n",
      "Batch train [2] loss 0.18412, dsc 0.81588\n",
      "Batch train [3] loss 0.19051, dsc 0.80949\n",
      "Batch train [4] loss 0.15687, dsc 0.84313\n",
      "Batch train [5] loss 0.14947, dsc 0.85053\n",
      "Batch train [6] loss 0.16106, dsc 0.83894\n",
      "Batch train [7] loss 0.15439, dsc 0.84561\n",
      "Batch train [8] loss 0.17953, dsc 0.82047\n",
      "Batch train [9] loss 0.16154, dsc 0.83846\n",
      "Batch train [10] loss 0.20231, dsc 0.79769\n",
      "Batch train [11] loss 0.14266, dsc 0.85734\n",
      "Batch train [12] loss 0.18339, dsc 0.81661\n",
      "Batch train [13] loss 0.15049, dsc 0.84951\n",
      "Batch train [14] loss 0.17917, dsc 0.82083\n",
      "Batch train [15] loss 0.20314, dsc 0.79686\n",
      "Batch train [16] loss 0.19027, dsc 0.80973\n",
      "Batch train [17] loss 0.15973, dsc 0.84027\n",
      "Batch train [18] loss 0.16685, dsc 0.83315\n",
      "Batch train [19] loss 0.15772, dsc 0.84228\n",
      "Batch train [20] loss 0.14929, dsc 0.85071\n",
      "Epoch [54] train done\n",
      "Batch eval [1] loss 0.24708, dsc 0.75292\n",
      "Batch eval [2] loss 0.26635, dsc 0.73365\n",
      "Batch eval [3] loss 0.17008, dsc 0.82992\n",
      "Batch eval [4] loss 0.16703, dsc 0.83297\n",
      "Batch eval [5] loss 0.16741, dsc 0.83259\n",
      "Epoch [54] valid done\n",
      "Epoch [54] T 3490.69s, deltaT 67.93s, loss: train 0.16855, valid 0.20359, dsc: train 0.83145, valid 0.79641\n",
      "Batch train [1] loss 0.16068, dsc 0.83932\n",
      "Batch train [2] loss 0.16558, dsc 0.83442\n",
      "Batch train [3] loss 0.16581, dsc 0.83419\n",
      "Batch train [4] loss 0.15842, dsc 0.84158\n",
      "Batch train [5] loss 0.15092, dsc 0.84908\n",
      "Batch train [6] loss 0.14330, dsc 0.85670\n",
      "Batch train [7] loss 0.18540, dsc 0.81460\n",
      "Batch train [8] loss 0.14055, dsc 0.85945\n",
      "Batch train [9] loss 0.17837, dsc 0.82163\n",
      "Batch train [10] loss 0.14061, dsc 0.85939\n",
      "Batch train [11] loss 0.15851, dsc 0.84149\n",
      "Batch train [12] loss 0.12817, dsc 0.87183\n",
      "Batch train [13] loss 0.14686, dsc 0.85314\n",
      "Batch train [14] loss 0.19088, dsc 0.80912\n",
      "Batch train [15] loss 0.13749, dsc 0.86251\n",
      "Batch train [16] loss 0.14715, dsc 0.85285\n",
      "Batch train [17] loss 0.14100, dsc 0.85900\n",
      "Batch train [18] loss 0.18301, dsc 0.81699\n",
      "Batch train [19] loss 0.20516, dsc 0.79484\n",
      "Batch train [20] loss 0.17274, dsc 0.82726\n",
      "Epoch [55] train done\n",
      "Batch eval [1] loss 0.18778, dsc 0.81222\n",
      "Batch eval [2] loss 0.18876, dsc 0.81124\n",
      "Batch eval [3] loss 0.23153, dsc 0.76847\n",
      "Batch eval [4] loss 0.18627, dsc 0.81373\n",
      "Batch eval [5] loss 0.26679, dsc 0.73321\n",
      "Epoch [55] valid done\n",
      "Epoch [55] T 3558.73s, deltaT 68.04s, loss: train 0.16003, valid 0.21223, dsc: train 0.83997, valid 0.78777\n",
      "Batch train [1] loss 0.14360, dsc 0.85640\n",
      "Batch train [2] loss 0.15032, dsc 0.84968\n",
      "Batch train [3] loss 0.21231, dsc 0.78769\n",
      "Batch train [4] loss 0.14922, dsc 0.85078\n",
      "Batch train [5] loss 0.14157, dsc 0.85843\n",
      "Batch train [6] loss 0.12685, dsc 0.87315\n",
      "Batch train [7] loss 0.16359, dsc 0.83641\n",
      "Batch train [8] loss 0.13263, dsc 0.86737\n",
      "Batch train [9] loss 0.13420, dsc 0.86580\n",
      "Batch train [10] loss 0.17870, dsc 0.82130\n",
      "Batch train [11] loss 0.13897, dsc 0.86103\n",
      "Batch train [12] loss 0.13910, dsc 0.86090\n",
      "Batch train [13] loss 0.14796, dsc 0.85204\n",
      "Batch train [14] loss 0.19989, dsc 0.80011\n",
      "Batch train [15] loss 0.14245, dsc 0.85755\n",
      "Batch train [16] loss 0.17556, dsc 0.82444\n",
      "Batch train [17] loss 0.14455, dsc 0.85545\n",
      "Batch train [18] loss 0.14178, dsc 0.85822\n",
      "Batch train [19] loss 0.14842, dsc 0.85158\n",
      "Batch train [20] loss 0.15518, dsc 0.84482\n",
      "Epoch [56] train done\n",
      "Batch eval [1] loss 0.19904, dsc 0.80096\n",
      "Batch eval [2] loss 0.21897, dsc 0.78103\n",
      "Batch eval [3] loss 0.17173, dsc 0.82827\n",
      "Batch eval [4] loss 0.15569, dsc 0.84431\n",
      "Batch eval [5] loss 0.17481, dsc 0.82519\n",
      "Epoch [56] valid done\n",
      "Epoch [56] T 3626.77s, deltaT 68.04s, loss: train 0.15334, valid 0.18405, dsc: train 0.84666, valid 0.81595\n",
      "Batch train [1] loss 0.16707, dsc 0.83293\n",
      "Batch train [2] loss 0.15894, dsc 0.84106\n",
      "Batch train [3] loss 0.12850, dsc 0.87150\n",
      "Batch train [4] loss 0.17985, dsc 0.82015\n",
      "Batch train [5] loss 0.12271, dsc 0.87729\n",
      "Batch train [6] loss 0.14401, dsc 0.85599\n",
      "Batch train [7] loss 0.14810, dsc 0.85190\n",
      "Batch train [8] loss 0.14248, dsc 0.85752\n",
      "Batch train [9] loss 0.13973, dsc 0.86027\n",
      "Batch train [10] loss 0.15557, dsc 0.84443\n",
      "Batch train [11] loss 0.16059, dsc 0.83941\n",
      "Batch train [12] loss 0.12182, dsc 0.87818\n",
      "Batch train [13] loss 0.16837, dsc 0.83163\n",
      "Batch train [14] loss 0.14281, dsc 0.85719\n",
      "Batch train [15] loss 0.11642, dsc 0.88358\n",
      "Batch train [16] loss 0.13742, dsc 0.86258\n",
      "Batch train [17] loss 0.13436, dsc 0.86564\n",
      "Batch train [18] loss 0.17915, dsc 0.82085\n",
      "Batch train [19] loss 0.12042, dsc 0.87958\n",
      "Batch train [20] loss 0.13545, dsc 0.86455\n",
      "Epoch [57] train done\n",
      "Batch eval [1] loss 0.17559, dsc 0.82441\n",
      "Batch eval [2] loss 0.20398, dsc 0.79602\n",
      "Batch eval [3] loss 0.15021, dsc 0.84979\n",
      "Batch eval [4] loss 0.13939, dsc 0.86061\n",
      "Batch eval [5] loss 0.19819, dsc 0.80181\n",
      "Epoch [57] valid done\n",
      "Epoch [57] T 3694.44s, deltaT 67.66s, loss: train 0.14519, valid 0.17347, dsc: train 0.85481, valid 0.82653\n",
      "Batch train [1] loss 0.14234, dsc 0.85766\n",
      "Batch train [2] loss 0.13544, dsc 0.86456\n",
      "Batch train [3] loss 0.14288, dsc 0.85712\n",
      "Batch train [4] loss 0.14641, dsc 0.85359\n",
      "Batch train [5] loss 0.11368, dsc 0.88632\n",
      "Batch train [6] loss 0.13327, dsc 0.86673\n",
      "Batch train [7] loss 0.12325, dsc 0.87675\n",
      "Batch train [8] loss 0.15243, dsc 0.84757\n",
      "Batch train [9] loss 0.13348, dsc 0.86652\n",
      "Batch train [10] loss 0.12756, dsc 0.87244\n",
      "Batch train [11] loss 0.17160, dsc 0.82840\n",
      "Batch train [12] loss 0.14977, dsc 0.85023\n",
      "Batch train [13] loss 0.16174, dsc 0.83826\n",
      "Batch train [14] loss 0.11276, dsc 0.88724\n",
      "Batch train [15] loss 0.12638, dsc 0.87362\n",
      "Batch train [16] loss 0.16805, dsc 0.83195\n",
      "Batch train [17] loss 0.12590, dsc 0.87410\n",
      "Batch train [18] loss 0.13584, dsc 0.86416\n",
      "Batch train [19] loss 0.13726, dsc 0.86274\n",
      "Batch train [20] loss 0.13562, dsc 0.86438\n",
      "Epoch [58] train done\n",
      "Batch eval [1] loss 0.18395, dsc 0.81605\n",
      "Batch eval [2] loss 0.19537, dsc 0.80463\n",
      "Batch eval [3] loss 0.15975, dsc 0.84025\n",
      "Batch eval [4] loss 0.13804, dsc 0.86196\n",
      "Batch eval [5] loss 0.17909, dsc 0.82091\n",
      "Epoch [58] valid done\n",
      "Epoch [58] T 3763.26s, deltaT 68.82s, loss: train 0.13878, valid 0.17124, dsc: train 0.86122, valid 0.82876\n",
      "Batch train [1] loss 0.10666, dsc 0.89334\n",
      "Batch train [2] loss 0.12723, dsc 0.87277\n",
      "Batch train [3] loss 0.12849, dsc 0.87151\n",
      "Batch train [4] loss 0.13560, dsc 0.86440\n",
      "Batch train [5] loss 0.12988, dsc 0.87012\n",
      "Batch train [6] loss 0.12250, dsc 0.87750\n",
      "Batch train [7] loss 0.16938, dsc 0.83062\n",
      "Batch train [8] loss 0.12865, dsc 0.87135\n",
      "Batch train [9] loss 0.12642, dsc 0.87358\n",
      "Batch train [10] loss 0.13084, dsc 0.86916\n",
      "Batch train [11] loss 0.14072, dsc 0.85928\n",
      "Batch train [12] loss 0.16578, dsc 0.83422\n",
      "Batch train [13] loss 0.14945, dsc 0.85055\n",
      "Batch train [14] loss 0.16826, dsc 0.83174\n",
      "Batch train [15] loss 0.12920, dsc 0.87080\n",
      "Batch train [16] loss 0.17159, dsc 0.82841\n",
      "Batch train [17] loss 0.13280, dsc 0.86720\n",
      "Batch train [18] loss 0.13345, dsc 0.86655\n",
      "Batch train [19] loss 0.15904, dsc 0.84096\n",
      "Batch train [20] loss 0.12262, dsc 0.87738\n",
      "Epoch [59] train done\n",
      "Batch eval [1] loss 0.17352, dsc 0.82648\n",
      "Batch eval [2] loss 0.17008, dsc 0.82992\n",
      "Batch eval [3] loss 0.19199, dsc 0.80801\n",
      "Batch eval [4] loss 0.15302, dsc 0.84698\n",
      "Batch eval [5] loss 0.23361, dsc 0.76639\n",
      "Epoch [59] valid done\n",
      "Epoch [59] T 3832.11s, deltaT 68.85s, loss: train 0.13893, valid 0.18445, dsc: train 0.86107, valid 0.81555\n",
      "Batch train [1] loss 0.12040, dsc 0.87960\n",
      "Batch train [2] loss 0.15587, dsc 0.84413\n",
      "Batch train [3] loss 0.15195, dsc 0.84805\n",
      "Batch train [4] loss 0.12774, dsc 0.87226\n",
      "Batch train [5] loss 0.12132, dsc 0.87868\n",
      "Batch train [6] loss 0.12444, dsc 0.87556\n",
      "Batch train [7] loss 0.14977, dsc 0.85023\n",
      "Batch train [8] loss 0.11628, dsc 0.88372\n",
      "Batch train [9] loss 0.12289, dsc 0.87711\n",
      "Batch train [10] loss 0.18350, dsc 0.81650\n",
      "Batch train [11] loss 0.11657, dsc 0.88343\n",
      "Batch train [12] loss 0.15490, dsc 0.84510\n",
      "Batch train [13] loss 0.14558, dsc 0.85442\n",
      "Batch train [14] loss 0.13963, dsc 0.86037\n",
      "Batch train [15] loss 0.14069, dsc 0.85931\n",
      "Batch train [16] loss 0.13967, dsc 0.86033\n",
      "Batch train [17] loss 0.10891, dsc 0.89109\n",
      "Batch train [18] loss 0.11227, dsc 0.88773\n",
      "Batch train [19] loss 0.14443, dsc 0.85557\n",
      "Batch train [20] loss 0.13948, dsc 0.86052\n",
      "Epoch [60] train done\n",
      "Batch eval [1] loss 0.15748, dsc 0.84252\n",
      "Batch eval [2] loss 0.18347, dsc 0.81653\n",
      "Batch eval [3] loss 0.17017, dsc 0.82983\n",
      "Batch eval [4] loss 0.13702, dsc 0.86298\n",
      "Batch eval [5] loss 0.19663, dsc 0.80337\n",
      "Epoch [60] valid done\n",
      "Epoch [60] T 3899.63s, deltaT 67.53s, loss: train 0.13581, valid 0.16895, dsc: train 0.86419, valid 0.83105\n",
      "Elapsed time 1:04:59\n"
     ]
    }
   ],
   "source": [
    "cut_model_info = prepare_model(epochs=60,\n",
    "                               learning_rate=5e-4,\n",
    "                               in_channels=8,\n",
    "                               batch_size=2,\n",
    "                               train_dataset=cut_train_dataset, valid_dataset=cut_valid_dataset, test_dataset=cut_test_dataset)\n",
    "show_model_info(cut_model_info)\n",
    "\n",
    "cut_train_loop_params = {k:v for k,v in cut_model_info.items() if k not in ['model_total_params', 'model_total_trainable_params']}\n",
    "train_loop(**cut_train_loop_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Usage\n",
      "GPU:        GeForce RTX 2070\n",
      "Allocated:  0.0 GB\n",
      "Cached:     0.9 GB\n",
      "Max memory: 5.1 GB\n",
      "Max Cached: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "show_cuda_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "160x128x128 = 2_621_440 \\\n",
    "72x198x168 = 2_395_008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<IPython.core.display.Markdown object>,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing number 31\n",
      "loss 0.14042633771896362, dsc 0.8595736622810364, inputs_len 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45842f930d6415b88680df3498fb66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=49, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4b466e72484adc814552c00fc3542f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG shapes torch.Size([1, 72, 192, 168]) torch.Size([1, 72, 192, 168]) torch.Size([1, 1, 72, 192, 168])\n",
      "DEBUG prediction max 1.0, min 2.3276585125131533e-05\n",
      "DEBUG intersection 3550.24609375\n",
      "DEBUG label sum 3871.0\n",
      "DEBUG prediction sum 4389.48388671875\n",
      "DEBUG intersection2 3550.24609375\n",
      "DEBUG dsc 0.8595733642578125\n",
      "DEBUG MSE 0.00020352425053715706\n"
     ]
    }
   ],
   "source": [
    "max_slices = cut_train_dataset.__getitem__(0)[1].shape[0]\n",
    "\n",
    "display(Markdown(\"### Train Eval\"))\n",
    "show_model_dataset_pred_preview(cut_model_info, cut_train_dataset, max_slices=max_slices, default_slice=49)\n",
    "\n",
    "# display(Markdown(\"### Valid Eval\"))\n",
    "# show_model_dataset_pred_preview(cut_model_info, cut_valid_dataset, max_slices=max_slices, default_slice=53)\n",
    "\n",
    "# display(Markdown(\"### Test Eval\"))\n",
    "# eval_image_dataset(test_dataset, 78, 'test_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing label prediction comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, rescaled_preds = get_rescaled_preds(cut_model_info[\"model\"], cut_full_res_dataset, cut_model_info[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521bf026ccce47c9ae55edc4b2cad340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=49, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f125c88d5a47fca225dfa83d2b4594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_prediction_with_ground_true(cut_full_res_dataset, rescaled_preds, dataset_index=6, default_slice=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
