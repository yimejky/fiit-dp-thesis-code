{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Found Google Colab')\n",
    "    !pip3 install torch torchvision torchsummary\n",
    "    !pip3 install simpleitk\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import src.helpers.oars_labels_consts as OARS_LABELS\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "from importlib import reload\n",
    "\n",
    "from src.training_helpers import loss_batch, show_model_info\n",
    "from src.helpers.prepare_model import prepare_model\n",
    "from src.helpers.train_loop import train_loop\n",
    "from src.helpers.get_dataset import get_dataset, get_dataloaders\n",
    "from src.helpers.get_dataset_info import get_dataset_info\n",
    "from src.helpers.preview_dataset import preview_dataset\n",
    "from src.helpers.get_bounding_box import get_bounding_box, get_bounding_box_3D, get_bounding_box_3D_size, get_dividable_bounding_box, get_final_bounding_box_slice\n",
    "\n",
    "MAX_PADDING_SLICES = 160\n",
    "torch.manual_seed(20)\n",
    "\n",
    "# [56 177 156] is bounding box size without spinal cord in dataset, so we get bounding box which can be divided by pooling/unpooling layers and in the end still persist size\n",
    "dataset_max_bounding_box = [56, 177, 156]\n",
    "desire_bounding_box_size = get_dividable_bounding_box(dataset_max_bounding_box, pooling_layers=3, offset=12)\n",
    "print('Dataset biggest bounding box wihtout spinal cord', dataset_max_bounding_box)\n",
    "print('Cut target size', desire_bounding_box_size)\n",
    "\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading low res dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 16x dataset\n",
      "normalizing dataset\n",
      "parsing dataset to numpy\n",
      "train 40, valid_size 5, test 5, full 50\n",
      "train indeces [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indeces [6, 13, 19, 25, 38]\n",
      "test indeces [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "\n",
    "low_res_dataset = get_dataset(dataset_size=50, shrink_factor=16, filter_labels=filter_labels)\n",
    "low_res_dataset.dilatate_labels(repeat=1)\n",
    "low_res_dataset.to_numpy()\n",
    "low_res_dataloaders_obj = get_dataloaders(low_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "\n",
    "get_dataset_info(low_res_dataset, low_res_dataloaders_obj)\n",
    "train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset = itemgetter('train_dataset', 'valid_dataset', 'test_dataset')(low_res_dataloaders_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 12.505709639268096, min -0.40698009878688973\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de787eca90b44e293568d85a2f1d7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=101, max=159),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabb78b0bf314659ab3341b461d779f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(low_res_dataset, preview_index=0, show_hist=False, max_padding_slices=MAX_PADDING_SLICES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training low res model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device running \"cuda\"\n",
      "max output channels 128\n",
      "Model number of params: 1193537, trainable 1193537\n",
      "Running training loop\n",
      "Batch eval [1] loss 0.95115, dsc 0.04885\n",
      "Batch eval [2] loss 0.96262, dsc 0.03738\n",
      "Batch eval [3] loss 0.96249, dsc 0.03751\n",
      "Batch eval [4] loss 0.96250, dsc 0.03750\n",
      "Batch eval [5] loss 0.95840, dsc 0.04160\n",
      "Epoch [1] T 6.97s, deltaT 6.97s, loss: train 0.96122, valid 0.95943, dsc: train 0.03878, valid 0.04057\n",
      "Batch eval [1] loss 0.94273, dsc 0.05727\n",
      "Batch eval [2] loss 0.95209, dsc 0.04791\n",
      "Batch eval [3] loss 0.94611, dsc 0.05389\n",
      "Batch eval [4] loss 0.95591, dsc 0.04409\n",
      "Batch eval [5] loss 0.94411, dsc 0.05589\n",
      "Epoch [2] T 13.98s, deltaT 7.01s, loss: train 0.95455, valid 0.94819, dsc: train 0.04545, valid 0.05181\n",
      "Batch eval [1] loss 0.94189, dsc 0.05811\n",
      "Batch eval [2] loss 0.95095, dsc 0.04905\n",
      "Batch eval [3] loss 0.94386, dsc 0.05614\n",
      "Batch eval [4] loss 0.95524, dsc 0.04476\n",
      "Batch eval [5] loss 0.94215, dsc 0.05785\n",
      "Epoch [3] T 20.97s, deltaT 6.99s, loss: train 0.95045, valid 0.94682, dsc: train 0.04955, valid 0.05318\n",
      "Batch eval [1] loss 0.93101, dsc 0.06899\n",
      "Batch eval [2] loss 0.94291, dsc 0.05709\n",
      "Batch eval [3] loss 0.93634, dsc 0.06366\n",
      "Batch eval [4] loss 0.94832, dsc 0.05168\n",
      "Batch eval [5] loss 0.93415, dsc 0.06585\n",
      "Epoch [4] T 28.05s, deltaT 7.07s, loss: train 0.94596, valid 0.93855, dsc: train 0.05404, valid 0.06145\n",
      "Batch eval [1] loss 0.92171, dsc 0.07829\n",
      "Batch eval [2] loss 0.93422, dsc 0.06578\n",
      "Batch eval [3] loss 0.92556, dsc 0.07444\n",
      "Batch eval [4] loss 0.93999, dsc 0.06001\n",
      "Batch eval [5] loss 0.92376, dsc 0.07624\n",
      "Epoch [5] T 35.17s, deltaT 7.12s, loss: train 0.94041, valid 0.92905, dsc: train 0.05959, valid 0.07095\n",
      "Batch eval [1] loss 0.91586, dsc 0.08414\n",
      "Batch eval [2] loss 0.92885, dsc 0.07115\n",
      "Batch eval [3] loss 0.91883, dsc 0.08117\n",
      "Batch eval [4] loss 0.93562, dsc 0.06438\n",
      "Batch eval [5] loss 0.91819, dsc 0.08181\n",
      "Epoch [6] T 42.37s, deltaT 7.20s, loss: train 0.93388, valid 0.92347, dsc: train 0.06612, valid 0.07653\n",
      "Batch eval [1] loss 0.91070, dsc 0.08930\n",
      "Batch eval [2] loss 0.92280, dsc 0.07720\n",
      "Batch eval [3] loss 0.91239, dsc 0.08761\n",
      "Batch eval [4] loss 0.93150, dsc 0.06850\n",
      "Batch eval [5] loss 0.91173, dsc 0.08827\n",
      "Epoch [7] T 49.66s, deltaT 7.28s, loss: train 0.92527, valid 0.91782, dsc: train 0.07473, valid 0.08218\n",
      "Batch eval [1] loss 0.89488, dsc 0.10512\n",
      "Batch eval [2] loss 0.90584, dsc 0.09416\n",
      "Batch eval [3] loss 0.89315, dsc 0.10685\n",
      "Batch eval [4] loss 0.91520, dsc 0.08480\n",
      "Batch eval [5] loss 0.89401, dsc 0.10599\n",
      "Epoch [8] T 57.46s, deltaT 7.81s, loss: train 0.91365, valid 0.90062, dsc: train 0.08635, valid 0.09938\n",
      "Batch eval [1] loss 0.88391, dsc 0.11609\n",
      "Batch eval [2] loss 0.89896, dsc 0.10104\n",
      "Batch eval [3] loss 0.88896, dsc 0.11104\n",
      "Batch eval [4] loss 0.91127, dsc 0.08873\n",
      "Batch eval [5] loss 0.88687, dsc 0.11313\n",
      "Epoch [9] T 64.70s, deltaT 7.24s, loss: train 0.89505, valid 0.89400, dsc: train 0.10495, valid 0.10600\n",
      "Batch eval [1] loss 0.79401, dsc 0.20599\n",
      "Batch eval [2] loss 0.81627, dsc 0.18373\n",
      "Batch eval [3] loss 0.79822, dsc 0.20178\n",
      "Batch eval [4] loss 0.84555, dsc 0.15445\n",
      "Batch eval [5] loss 0.80159, dsc 0.19841\n",
      "Epoch [10] T 71.87s, deltaT 7.17s, loss: train 0.85484, valid 0.81113, dsc: train 0.14516, valid 0.18887\n",
      "Batch eval [1] loss 0.79838, dsc 0.20162\n",
      "Batch eval [2] loss 0.82240, dsc 0.17760\n",
      "Batch eval [3] loss 0.83091, dsc 0.16909\n",
      "Batch eval [4] loss 0.82594, dsc 0.17406\n",
      "Batch eval [5] loss 0.77772, dsc 0.22228\n",
      "Epoch [11] T 79.08s, deltaT 7.21s, loss: train 0.80219, valid 0.81107, dsc: train 0.19781, valid 0.18893\n",
      "Batch eval [1] loss 0.63265, dsc 0.36735\n",
      "Batch eval [2] loss 0.67084, dsc 0.32916\n",
      "Batch eval [3] loss 0.64057, dsc 0.35943\n",
      "Batch eval [4] loss 0.69541, dsc 0.30459\n",
      "Batch eval [5] loss 0.63573, dsc 0.36427\n",
      "Epoch [12] T 86.43s, deltaT 7.34s, loss: train 0.72204, valid 0.65504, dsc: train 0.27796, valid 0.34496\n",
      "Batch eval [1] loss 0.55849, dsc 0.44151\n",
      "Batch eval [2] loss 0.59775, dsc 0.40225\n",
      "Batch eval [3] loss 0.56563, dsc 0.43437\n",
      "Batch eval [4] loss 0.63570, dsc 0.36430\n",
      "Batch eval [5] loss 0.56259, dsc 0.43741\n",
      "Epoch [13] T 93.65s, deltaT 7.22s, loss: train 0.62581, valid 0.58403, dsc: train 0.37419, valid 0.41597\n",
      "Batch eval [1] loss 0.45671, dsc 0.54329\n",
      "Batch eval [2] loss 0.49933, dsc 0.50067\n",
      "Batch eval [3] loss 0.47036, dsc 0.52964\n",
      "Batch eval [4] loss 0.53288, dsc 0.46712\n",
      "Batch eval [5] loss 0.47031, dsc 0.52969\n",
      "Epoch [14] T 100.80s, deltaT 7.15s, loss: train 0.52975, valid 0.48592, dsc: train 0.47025, valid 0.51408\n",
      "Batch eval [1] loss 0.38043, dsc 0.61957\n",
      "Batch eval [2] loss 0.41744, dsc 0.58256\n",
      "Batch eval [3] loss 0.39987, dsc 0.60013\n",
      "Batch eval [4] loss 0.43045, dsc 0.56955\n",
      "Batch eval [5] loss 0.38746, dsc 0.61254\n",
      "Epoch [15] T 107.94s, deltaT 7.13s, loss: train 0.44435, valid 0.40313, dsc: train 0.55565, valid 0.59687\n",
      "Batch eval [1] loss 0.35572, dsc 0.64428\n",
      "Batch eval [2] loss 0.40131, dsc 0.59869\n",
      "Batch eval [3] loss 0.38262, dsc 0.61738\n",
      "Batch eval [4] loss 0.40968, dsc 0.59032\n",
      "Batch eval [5] loss 0.35826, dsc 0.64174\n",
      "Epoch [16] T 115.14s, deltaT 7.20s, loss: train 0.37133, valid 0.38152, dsc: train 0.62867, valid 0.61848\n",
      "Batch eval [1] loss 0.32644, dsc 0.67356\n",
      "Batch eval [2] loss 0.33635, dsc 0.66365\n",
      "Batch eval [3] loss 0.35214, dsc 0.64786\n",
      "Batch eval [4] loss 0.34491, dsc 0.65509\n",
      "Batch eval [5] loss 0.34034, dsc 0.65966\n",
      "Epoch [17] T 122.36s, deltaT 7.22s, loss: train 0.31988, valid 0.34004, dsc: train 0.68012, valid 0.65996\n",
      "Batch eval [1] loss 0.25263, dsc 0.74737\n",
      "Batch eval [2] loss 0.29195, dsc 0.70805\n",
      "Batch eval [3] loss 0.28123, dsc 0.71877\n",
      "Batch eval [4] loss 0.29470, dsc 0.70530\n",
      "Batch eval [5] loss 0.26067, dsc 0.73933\n",
      "Epoch [18] T 130.07s, deltaT 7.71s, loss: train 0.27815, valid 0.27623, dsc: train 0.72185, valid 0.72377\n",
      "Batch eval [1] loss 0.24421, dsc 0.75579\n",
      "Batch eval [2] loss 0.26630, dsc 0.73370\n",
      "Batch eval [3] loss 0.27061, dsc 0.72939\n",
      "Batch eval [4] loss 0.28206, dsc 0.71794\n",
      "Batch eval [5] loss 0.25664, dsc 0.74336\n",
      "Epoch [19] T 137.69s, deltaT 7.62s, loss: train 0.24466, valid 0.26396, dsc: train 0.75534, valid 0.73604\n",
      "Batch eval [1] loss 0.21599, dsc 0.78401\n",
      "Batch eval [2] loss 0.26785, dsc 0.73215\n",
      "Batch eval [3] loss 0.22570, dsc 0.77430\n",
      "Batch eval [4] loss 0.27141, dsc 0.72859\n",
      "Batch eval [5] loss 0.24155, dsc 0.75845\n",
      "Epoch [20] T 145.07s, deltaT 7.38s, loss: train 0.22674, valid 0.24450, dsc: train 0.77326, valid 0.75550\n",
      "Batch eval [1] loss 0.24801, dsc 0.75199\n",
      "Batch eval [2] loss 0.25539, dsc 0.74461\n",
      "Batch eval [3] loss 0.31551, dsc 0.68449\n",
      "Batch eval [4] loss 0.22537, dsc 0.77463\n",
      "Batch eval [5] loss 0.25625, dsc 0.74375\n",
      "Epoch [21] T 152.51s, deltaT 7.44s, loss: train 0.20881, valid 0.26011, dsc: train 0.79119, valid 0.73989\n",
      "Batch eval [1] loss 0.19571, dsc 0.80429\n",
      "Batch eval [2] loss 0.25364, dsc 0.74636\n",
      "Batch eval [3] loss 0.23188, dsc 0.76812\n",
      "Batch eval [4] loss 0.21215, dsc 0.78785\n",
      "Batch eval [5] loss 0.23819, dsc 0.76181\n",
      "Epoch [22] T 159.58s, deltaT 7.07s, loss: train 0.19175, valid 0.22632, dsc: train 0.80825, valid 0.77368\n",
      "Batch eval [1] loss 0.18696, dsc 0.81304\n",
      "Batch eval [2] loss 0.24734, dsc 0.75266\n",
      "Batch eval [3] loss 0.21800, dsc 0.78200\n",
      "Batch eval [4] loss 0.22259, dsc 0.77741\n",
      "Batch eval [5] loss 0.21954, dsc 0.78046\n",
      "Epoch [23] T 166.78s, deltaT 7.20s, loss: train 0.18974, valid 0.21889, dsc: train 0.81026, valid 0.78111\n",
      "Batch eval [1] loss 0.18501, dsc 0.81499\n",
      "Batch eval [2] loss 0.23809, dsc 0.76191\n",
      "Batch eval [3] loss 0.24244, dsc 0.75756\n",
      "Batch eval [4] loss 0.21317, dsc 0.78683\n",
      "Batch eval [5] loss 0.20345, dsc 0.79655\n",
      "Epoch [24] T 174.16s, deltaT 7.37s, loss: train 0.17303, valid 0.21643, dsc: train 0.82697, valid 0.78357\n",
      "Batch eval [1] loss 0.18677, dsc 0.81323\n",
      "Batch eval [2] loss 0.21477, dsc 0.78523\n",
      "Batch eval [3] loss 0.20752, dsc 0.79248\n",
      "Batch eval [4] loss 0.19525, dsc 0.80475\n",
      "Batch eval [5] loss 0.20252, dsc 0.79748\n",
      "Epoch [25] T 181.82s, deltaT 7.66s, loss: train 0.17022, valid 0.20136, dsc: train 0.82978, valid 0.79864\n",
      "Batch eval [1] loss 0.18337, dsc 0.81663\n",
      "Batch eval [2] loss 0.22919, dsc 0.77081\n",
      "Batch eval [3] loss 0.19987, dsc 0.80013\n",
      "Batch eval [4] loss 0.20802, dsc 0.79198\n",
      "Batch eval [5] loss 0.19907, dsc 0.80093\n",
      "Epoch [26] T 189.55s, deltaT 7.73s, loss: train 0.15719, valid 0.20390, dsc: train 0.84281, valid 0.79610\n",
      "Batch eval [1] loss 0.20782, dsc 0.79218\n",
      "Batch eval [2] loss 0.22440, dsc 0.77560\n",
      "Batch eval [3] loss 0.23887, dsc 0.76113\n",
      "Batch eval [4] loss 0.19766, dsc 0.80234\n",
      "Batch eval [5] loss 0.19645, dsc 0.80355\n",
      "Epoch [27] T 197.20s, deltaT 7.65s, loss: train 0.14829, valid 0.21304, dsc: train 0.85171, valid 0.78696\n",
      "Batch eval [1] loss 0.18365, dsc 0.81635\n",
      "Batch eval [2] loss 0.20630, dsc 0.79370\n",
      "Batch eval [3] loss 0.19883, dsc 0.80117\n",
      "Batch eval [4] loss 0.18830, dsc 0.81170\n",
      "Batch eval [5] loss 0.19612, dsc 0.80388\n",
      "Epoch [28] T 204.98s, deltaT 7.78s, loss: train 0.14605, valid 0.19464, dsc: train 0.85395, valid 0.80536\n",
      "Batch eval [1] loss 0.19040, dsc 0.80960\n",
      "Batch eval [2] loss 0.21337, dsc 0.78663\n",
      "Batch eval [3] loss 0.19718, dsc 0.80282\n",
      "Batch eval [4] loss 0.19656, dsc 0.80344\n",
      "Batch eval [5] loss 0.18146, dsc 0.81854\n",
      "Epoch [29] T 213.08s, deltaT 8.09s, loss: train 0.14038, valid 0.19580, dsc: train 0.85962, valid 0.80420\n",
      "Batch eval [1] loss 0.18787, dsc 0.81213\n",
      "Batch eval [2] loss 0.21075, dsc 0.78925\n",
      "Batch eval [3] loss 0.20138, dsc 0.79862\n",
      "Batch eval [4] loss 0.19925, dsc 0.80075\n",
      "Batch eval [5] loss 0.17600, dsc 0.82400\n",
      "Epoch [30] T 220.72s, deltaT 7.64s, loss: train 0.13644, valid 0.19505, dsc: train 0.86356, valid 0.80495\n",
      "Elapsed time 0:03:40\n"
     ]
    }
   ],
   "source": [
    "# preparing model loop params\n",
    "low_res_model_info = prepare_model(epochs=30, in_channels=8, train_dataset=train_low_res_dataset, valid_dataset=valid_low_res_dataset, test_dataset=test_low_res_dataset)\n",
    "show_model_info(low_res_model_info, MAX_PADDING_SLICES)\n",
    "\n",
    "# getting everything necessary for model training\n",
    "low_res_train_loop_params = {k:v for k,v in low_res_model_info.items() if k not in ['model_total_params', 'model_total_trainable_params']}\n",
    "# running training loop\n",
    "train_loop(**low_res_train_loop_params)\n",
    "\n",
    "low_res_model = itemgetter('model')(low_res_model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading high/full res dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 1x dataset\n",
      "normalizing dataset\n",
      "parsing dataset to numpy\n",
      "dataset data and label shapes (1, 160, 32, 32) (1, 160, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "full_res_dataset = get_dataset(dataset_size=5, shrink_factor=1)\n",
    "full_res_dataset.to_numpy()\n",
    "\n",
    "print('dataset data and label shapes', low_res_dataset.data_list[0].shape, full_res_dataset.data_list[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing precoarse network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved model to cpu\n"
     ]
    }
   ],
   "source": [
    "# moving model to cpu and setting to eval mode, preventing model params changes/training\n",
    "low_res_model.to('cpu')\n",
    "low_res_model.eval()\n",
    "print('moved model to cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_image(input_img, expand_factor=16): # input numpy shape (1, 1, MAX_PADDING_SLICES, x, x)\n",
    "    # expanded_input_img = np.resize(tmp_output.copy(), (1, 1, 160, 512, 512))\n",
    "    # for i in range(MAX_PADDING_SLICES):\n",
    "    #    expanded_input_img[0, 0, i] = scipy.ndimage.zoom(tmp_output[0, 0, i], expand_factor, order=0) # TODO: zoom is using some interpolation, thus its not exact\n",
    "\n",
    "    expanded_input_img = np.repeat(np.repeat(input_img, expand_factor, axis=3), expand_factor, axis=4)\n",
    "        \n",
    "    return expanded_input_img\n",
    "\n",
    "\n",
    "def debug_preview_low_expand(model_output_img, exp_model_output_img, img_slice=100):\n",
    "    # preview of 32x32 segmentation and his expanded 512x512 version\n",
    "    model_output_img_percents = model_output_img[0, 0, img_slice].sum() / model_output_img[0, 0, img_slice].size\n",
    "    exp_model_output_img_percents = exp_model_output_img[0, 0, img_slice].sum() / exp_model_output_img[0, 0, img_slice].size\n",
    "    print(model_output_img_percents, exp_model_output_img_percents)\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(model_output_img[0, 0, img_slice], cmap=\"gray\", vmin=0, vmax=1)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(exp_model_output_img[0, 0, img_slice], cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def debug_preview_cuts(exp_model_output_img, new_bounding_box, data_cut, label_cut):\n",
    "    def f(slice_index):\n",
    "        tmp_cut = exp_model_output_img[0, 0, new_bounding_box[0]:new_bounding_box[1] + 1, new_bounding_box[2]:new_bounding_box[3] + 1, new_bounding_box[4]:new_bounding_box[5] + 1]\n",
    "        \n",
    "        plt.figure(figsize=(18, 12))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(tmp_cut[slice_index], cmap=\"gray\", vmin=0, vmax=1)\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(data_cut[slice_index], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(label_cut[slice_index])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    slices_count = label_cut.shape[0]-1\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=slices_count, step=1, value=slices_count // 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)\n",
    "\n",
    "\n",
    "def get_high_res_cut(low_res_model, low_res_data_img, full_res_data_img, full_res_label_img, low_res_mask_threshold, desire_bounding_box_size):\n",
    "    # getting low res segmentation\n",
    "    exp_low_res_data_img = np.expand_dims(low_res_data_img, axis=0)\n",
    "    model_output_img = low_res_model(torch.from_numpy(exp_low_res_data_img).float())\n",
    "    model_output_img = model_output_img.cpu().detach().numpy()\n",
    "    \n",
    "    # parsing low res float to int mask\n",
    "    model_output_img = (model_output_img > low_res_mask_threshold) * 1 # shape (1, 1, 160, 32, 32)\n",
    "\n",
    "    # expanding low res int mask to high res\n",
    "    exp_model_output_img = expand_image(model_output_img, expand_factor=16) # shape (1, 1, 160, 512, 512)\n",
    "\n",
    "    # getting bounding box\n",
    "    bounding_box = get_bounding_box_3D(exp_model_output_img[0][0])\n",
    "    new_bounding_box = get_final_bounding_box_slice(bounding_box, desire_bounding_box_size)\n",
    "\n",
    "    # getting bounding box cut\n",
    "    data_cut = full_res_data_img[0, new_bounding_box[0]:new_bounding_box[1] + 1, new_bounding_box[2]:new_bounding_box[3] + 1, new_bounding_box[4]:new_bounding_box[5] + 1]\n",
    "    label_cut = full_res_label_img[new_bounding_box[0]:new_bounding_box[1] + 1, new_bounding_box[2]:new_bounding_box[3] + 1, new_bounding_box[4]:new_bounding_box[5] + 1]\n",
    "    print('debug, does cut and original label contain the same amount of pixels?', label_cut.sum(), full_res_label_img.sum())\n",
    "\n",
    "    # debug\n",
    "    # debug_preview_low_expand(model_output_img, exp_model_output_img)\n",
    "    print('debug bounding box sizes', get_bounding_box_3D_size(*bounding_box), get_bounding_box_3D_size(*new_bounding_box))\n",
    "    debug_preview_cuts(exp_model_output_img, new_bounding_box, data_cut, label_cut)\n",
    "    \n",
    "    return data_cut, label_cut, new_bounding_box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting bounding box cut in high res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug box delta [21 32 -8]\n",
      "debug, does cut and original label contain the same amount of pixels? 1494767 1560867\n",
      "debug bounding box sizes (51, 160, 176) (72, 192, 168)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee8c09a19604f9099c1d0845deb55fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5e56dad67b49ddb1b4116154bbbe9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_index = 4\n",
    "low_res_mask_threshold = 0.5\n",
    "low_res_data_img = low_res_dataset.data_list[dataset_index]\n",
    "full_res_data_img = full_res_dataset.data_list[dataset_index]\n",
    "full_res_label_img = full_res_dataset.label_list[dataset_index]\n",
    "\n",
    "data_cut, label_cut, new_bounding_box = get_high_res_cut(low_res_model, low_res_data_img, full_res_data_img, full_res_label_img, low_res_mask_threshold, desire_bounding_box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 116, 144, 335, 164, 331), (72, 192, 168))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_bounding_box, get_bounding_box_3D_size(*new_bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
