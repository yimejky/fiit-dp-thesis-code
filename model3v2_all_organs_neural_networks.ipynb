{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset biggest bounding box wihtout spinal cord [56, 177, 156]\n",
      "Cut target size [72, 192, 168]\n",
      "Done Init\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/dp_tomastik/code')\n",
    "    !bash \"/content/drive/My Drive/dp_tomastik/code/scripts/install_libs.sh\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "from torchio import RandomAffine, Compose, ZNormalization\n",
    "\n",
    "from src.helpers import show_cuda_usage, preview_model_dataset_pred, preview_dataset\n",
    "from src.helpers import get_threshold_info_df, get_rescaled_preds\n",
    "from src.helpers import compare_prediction_with_ground_true, compare_one_prediction_with_ground_true\n",
    "from src.helpers import get_img_outliers_pixels, get_raw_with_prediction\n",
    "from src.helpers import get_rescaled_pred\n",
    "\n",
    "from src.dataset import transform_input_with_registration, get_norm_transform\n",
    "from src.dataset import get_full_res_cut, get_cut_lists, OARS_LABELS, get_dataset, get_dataset_info, get_dataset_transform\n",
    "from src.dataset import split_dataset, copy_split_dataset\n",
    "from src.consts import DATASET_MAX_BOUNDING_BOX, DESIRE_BOUNDING_BOX_SIZE\n",
    "from src.model_and_training import prepare_model, train_loop, show_model_info, load_checkpoint_model_info\n",
    "from src.model_and_training import iterate_model_v3v2\n",
    "from src.model_and_training.getters.get_device import get_device\n",
    "from src.model_and_training.architectures.unet_architecture_v3v2 import UNetV3v2\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import widgets\n",
    "\n",
    "torch.manual_seed(20)\n",
    "logging.basicConfig(filename='logs/all_organs_jupyter.log', level=logging.DEBUG)\n",
    "\n",
    "print('Dataset biggest bounding box wihtout spinal cord', DATASET_MAX_BOUNDING_BOX)\n",
    "print('Cut target size', DESIRE_BOUNDING_BOX_SIZE)\n",
    "print('Done Init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_models(oar_key):\n",
    "    possible_models = [folder_name for folder_name in os.listdir('./models') if oar_key in folder_name]    \n",
    "    \n",
    "    return possible_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading precourse neural network with datasets:\n",
    "- loading fullres dataset (512x512)\n",
    "- loading lowres dataset (32x32)\n",
    "- loading precourse model\n",
    "- parsing dataset to create cut dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA using 16x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "dilatating 1x dataset\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n",
      "CUDA using 1x dataset\n",
      "filtering labels\n",
      "filtering labels done\n",
      "parsing dataset to numpy\n",
      "numpy parsing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolas/fiit-dp-thesis-code/venv/lib/python3.8/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'src.losses.dice_loss.DiceLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model number of params: 298881, trainable 298881\n",
      "get_cut_lists: Cutting index 0\n",
      "get_full_res_cut: Removing 10/1335 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1223526 1223526\n",
      "get_cut_lists: Cutting index 1\n",
      "get_full_res_cut: Removing 0/1416 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1326052 1326052\n",
      "get_cut_lists: Cutting index 2\n",
      "get_full_res_cut: Removing 0/1873 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 20   0 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1890464 1890464\n",
      "get_cut_lists: Cutting index 3\n",
      "get_full_res_cut: Removing 0/1545 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [17 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1560217 1560217\n",
      "get_cut_lists: Cutting index 4\n",
      "get_full_res_cut: Removing 9/1510 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 48 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1451227 1451227\n",
      "get_cut_lists: Cutting index 5\n",
      "get_full_res_cut: Removing 0/1390 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1262651 1262651\n",
      "get_cut_lists: Cutting index 6\n",
      "get_full_res_cut: Removing 0/1451 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1566938 1566938\n",
      "get_cut_lists: Cutting index 7\n",
      "get_full_res_cut: Removing 0/958 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [29 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 869847 869847\n",
      "get_cut_lists: Cutting index 8\n",
      "get_full_res_cut: Removing 0/1489 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1397249 1397249\n",
      "get_cut_lists: Cutting index 9\n",
      "get_full_res_cut: Removing 0/1465 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1350330 1350330\n",
      "get_cut_lists: Cutting index 10\n",
      "get_full_res_cut: Removing 0/1650 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20  0 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1635868 1635868\n",
      "get_cut_lists: Cutting index 11\n",
      "get_full_res_cut: Removing 16/1371 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1283062 1283062\n",
      "get_cut_lists: Cutting index 12\n",
      "get_full_res_cut: Removing 0/1594 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1518406 1518406\n",
      "get_cut_lists: Cutting index 13\n",
      "get_full_res_cut: Removing 0/1482 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1504194 1504194\n",
      "get_cut_lists: Cutting index 14\n",
      "get_full_res_cut: Removing 0/1191 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1084254 1084254\n",
      "get_cut_lists: Cutting index 15\n",
      "get_full_res_cut: Removing 0/1267 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1221257 1221257\n",
      "get_cut_lists: Cutting index 16\n",
      "get_full_res_cut: Removing 2/1009 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 64 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 945639 945639\n",
      "get_cut_lists: Cutting index 17\n",
      "get_full_res_cut: Removing 0/1498 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1469035 1469035\n",
      "get_cut_lists: Cutting index 18\n",
      "get_full_res_cut: Removing 7/1371 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1322571 1322571\n",
      "get_cut_lists: Cutting index 19\n",
      "get_full_res_cut: Removing 0/1608 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [17 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1593516 1593516\n",
      "get_cut_lists: Cutting index 20\n",
      "get_full_res_cut: Removing 0/1359 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1390348 1390348\n",
      "get_cut_lists: Cutting index 21\n",
      "get_full_res_cut: Removing 0/1536 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 22  16 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1463017 1463017\n",
      "get_cut_lists: Cutting index 22\n",
      "get_full_res_cut: Removing 0/1231 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [26 32 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1162215 1162215\n",
      "get_cut_lists: Cutting index 23\n",
      "get_full_res_cut: Removing 0/1154 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1029805 1029805\n",
      "get_cut_lists: Cutting index 24\n",
      "get_full_res_cut: Removing 0/1669 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 29 -16   8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1689537 1689537\n",
      "get_cut_lists: Cutting index 25\n",
      "get_full_res_cut: Removing 0/1267 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1141739 1141739\n",
      "get_cut_lists: Cutting index 26\n",
      "get_full_res_cut: Removing 9/1289 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [18 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1167835 1167835\n",
      "get_cut_lists: Cutting index 27\n",
      "get_full_res_cut: Removing 15/1780 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [23  0  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1783264 1783264\n",
      "get_cut_lists: Cutting index 28\n",
      "get_full_res_cut: Removing 25/1916 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 22  16 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1944758 1944758\n",
      "get_cut_lists: Cutting index 29\n",
      "get_full_res_cut: Removing 0/1369 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [22 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1583396 1583396\n",
      "get_cut_lists: Cutting index 30\n",
      "get_full_res_cut: Removing 11/1390 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1248609 1248609\n",
      "get_cut_lists: Cutting index 31\n",
      "get_full_res_cut: Removing 0/1087 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [25 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 947124 947124\n",
      "get_cut_lists: Cutting index 32\n",
      "get_full_res_cut: Removing 39/1798 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [16 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1648187 1648187\n",
      "get_cut_lists: Cutting index 33\n",
      "get_full_res_cut: Removing 0/1327 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1214697 1214697\n",
      "get_cut_lists: Cutting index 34\n",
      "get_full_res_cut: Removing 0/1528 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 16 -8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1445951 1445951\n",
      "get_cut_lists: Cutting index 35\n",
      "get_full_res_cut: Removing 0/1981 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [ 14  32 -24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1963068 1963068\n",
      "get_cut_lists: Cutting index 36\n",
      "get_full_res_cut: Removing 0/1403 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [26 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1241941 1241941\n",
      "get_cut_lists: Cutting index 37\n",
      "get_full_res_cut: Removing 0/1417 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [19 32 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1298886 1298886\n",
      "get_cut_lists: Cutting index 38\n",
      "get_full_res_cut: Removing 0/1567 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1731533 1731533\n",
      "get_cut_lists: Cutting index 39\n",
      "get_full_res_cut: Removing 15/1286 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [24 48  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1067335 1067335\n",
      "get_cut_lists: Cutting index 40\n",
      "get_full_res_cut: Removing 0/1328 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1311715 1311715\n",
      "get_cut_lists: Cutting index 41\n",
      "get_full_res_cut: Removing 0/1559 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [18 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1411792 1411792\n",
      "get_cut_lists: Cutting index 42\n",
      "get_full_res_cut: Removing 10/1102 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 951804 951804\n",
      "get_cut_lists: Cutting index 43\n",
      "get_full_res_cut: Removing 0/1143 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [32 48 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1024831 1024831\n",
      "get_cut_lists: Cutting index 44\n",
      "get_full_res_cut: Removing 0/1734 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [13 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1763923 1763923\n",
      "get_cut_lists: Cutting index 45\n",
      "get_full_res_cut: Removing 0/1156 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [27 16 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1115633 1115633\n",
      "get_cut_lists: Cutting index 46\n",
      "get_full_res_cut: Removing 0/1657 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [21 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1670156 1670156\n",
      "get_cut_lists: Cutting index 47\n",
      "get_full_res_cut: Removing 0/1436 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 32  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1413179 1413179\n",
      "get_cut_lists: Cutting index 48\n",
      "get_full_res_cut: Removing 0/1002 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [28 64 24]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 781269 781269\n",
      "get_cut_lists: Cutting index 49\n",
      "get_full_res_cut: Removing 0/1705 outlier pixels\n",
      "get_final_bounding_box_slice: box delta [20 16  8]\n",
      "get_full_res_cut: Does cut and original label contain the same amount of pixels? True 1756965 1756965\n"
     ]
    }
   ],
   "source": [
    "datasets_params = ['train_dataset', 'valid_dataset', 'test_dataset']\n",
    "filter_labels = OARS_LABELS.OARS_LABELS_LIST\n",
    "if OARS_LABELS.SPINAL_CORD in filter_labels:\n",
    "    filter_labels.remove(OARS_LABELS.SPINAL_CORD)\n",
    "\n",
    "# low res\n",
    "low_res_dataset = get_dataset(dataset_size=50, shrink_factor=16, filter_labels=filter_labels, unify_labels=True)\n",
    "low_res_dataset.dilatate_labels(repeat=1)\n",
    "low_res_dataset.to_numpy()\n",
    "low_res_split_dataset_obj = split_dataset(low_res_dataset, train_size=40, valid_size=5, test_size=5)\n",
    "train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset = itemgetter(*datasets_params)(low_res_split_dataset_obj)\n",
    "\n",
    "# full res\n",
    "full_res_dataset = get_dataset(dataset_size=50, shrink_factor=1, filter_labels=filter_labels, unify_labels=False)\n",
    "full_res_dataset.to_numpy()\n",
    "full_res_split_dataset_obj = copy_split_dataset(full_res_dataset, low_res_split_dataset_obj)\n",
    "\n",
    "# low res model - precourse model\n",
    "epoch = 500\n",
    "log_date = datetime.datetime(year=2020, month=10, day=27, hour=11, minute=45, second=30).strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f'{log_date}_3d_unet_PRECOURSE'\n",
    "\n",
    "low_res_model_info = load_checkpoint_model_info(model_name, epoch, train_low_res_dataset, valid_low_res_dataset, test_low_res_dataset)\n",
    "show_model_info(low_res_model_info)\n",
    "\n",
    "# moving low res to gpu\n",
    "low_res_model_info['device'] = get_device()\n",
    "# low_res_model_info['device'] = 'cpu'\n",
    "low_res_model_info['model'] = low_res_model_info['model'].to(low_res_model_info['device'])\n",
    "low_res_model_info['model'].eval()\n",
    "\n",
    "# cut res\n",
    "cut_full_res_dataset = full_res_dataset.copy(copy_lists=False)\n",
    "cut_full_res_dataset = get_cut_lists(low_res_model_info['model'],\n",
    "                                     low_res_model_info['device'],\n",
    "                                     low_res_dataset, \n",
    "                                     full_res_dataset, \n",
    "                                     cut_full_res_dataset, \n",
    "                                     low_res_mask_threshold=0.5)\n",
    "cut_full_res_dataset.set_output_label(None)\n",
    "cut_split_dataset_obj = copy_split_dataset(cut_full_res_dataset, low_res_split_dataset_obj)\n",
    "cut_train_dataset, cut_valid_dataset, cut_test_dataset = itemgetter(*datasets_params)(cut_split_dataset_obj)\n",
    "\n",
    "# moving low res model to cpu\n",
    "low_res_model_info['device'] = 'cpu'\n",
    "low_res_model_info['model'] = low_res_model_info['model'].to(low_res_model_info['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 40, valid_size 5, test 5, full 50\n",
      "train indices [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "valid indices [6, 13, 19, 25, 38]\n",
      "test indices [16, 26, 27, 29, 39]\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(low_res_dataset, low_res_split_dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071, min -1024\n",
      "label max 22, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817162efbbd34f55b6a565cf133b408b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=0, max=0))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643ef3b7f551482b9b7c5101bdcc0b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_dataset(cut_full_res_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding registration to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "from src.helpers import get_registration_transform_np, preview_3d_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 120, 219), (136, 120, 219), (136, 120, 219), (136, 120, 219))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_ri = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/RI.mhd'))\n",
    "atlas_brainstem_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/brain_stem_map.mhd'))\n",
    "atlas_left_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/left_parotid_map.mhd'))\n",
    "atlas_right_parotid_map = sitk.GetArrayFromImage(sitk.ReadImage('./data/PDDCA-1.2-atlas/probabilistic_atlas/right_parotid_map.mhd'))\n",
    "\n",
    "atlas_ri.shape, atlas_brainstem_map.shape, atlas_left_parotid_map.shape, atlas_right_parotid_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_input = (atlas_ri[70:], atlas_left_parotid_map[70:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8111652a0cec48dea27bcd1d221fa0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74b6e55f7e94adaa2886e884454d208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_input = cut_full_res_dataset.get_raw_item_with_label_filter(0)\n",
    "tmp = get_registration_transform_np(atlas_input, dataset_input, numberOfIterations=500, show=False, preview=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_registration_list(dataset, atlas_input):\n",
    "    merged_list = list()\n",
    "\n",
    "    for dataset_index in range(len(dataset)):\n",
    "        dataset_input = dataset.get_raw_item_with_label_filter(dataset_index)\n",
    "\n",
    "        reg_output = get_registration_transform_np(atlas_input, dataset_input, numberOfIterations=500, show=False, preview=False)\n",
    "        reg_output = reg_output.astype(np.float32)\n",
    "        print(f'Registration done for index: {dataset_index}')\n",
    "        merged_output = np.array([dataset.data_list[dataset_index][0], reg_output])\n",
    "\n",
    "        merged_list.append(merged_output)\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration done for index: 0\n",
      "Registration done for index: 1\n",
      "Registration done for index: 2\n",
      "Registration done for index: 3\n",
      "Registration done for index: 4\n",
      "Registration done for index: 5\n",
      "Registration done for index: 6\n",
      "Registration done for index: 7\n",
      "Registration done for index: 8\n",
      "Registration done for index: 9\n",
      "Registration done for index: 10\n",
      "Registration done for index: 11\n",
      "Registration done for index: 12\n",
      "Registration done for index: 13\n",
      "Registration done for index: 14\n",
      "Registration done for index: 15\n",
      "Registration done for index: 16\n",
      "Registration done for index: 17\n",
      "Registration done for index: 18\n",
      "Registration done for index: 19\n",
      "Registration done for index: 20\n",
      "Registration done for index: 21\n",
      "Registration done for index: 22\n",
      "Registration done for index: 23\n",
      "Registration done for index: 24\n",
      "Registration done for index: 25\n",
      "Registration done for index: 26\n",
      "Registration done for index: 27\n",
      "Registration done for index: 28\n",
      "Registration done for index: 29\n",
      "Registration done for index: 30\n",
      "Registration done for index: 31\n",
      "Registration done for index: 32\n",
      "Registration done for index: 33\n",
      "Registration done for index: 34\n",
      "Registration done for index: 35\n",
      "Registration done for index: 36\n",
      "Registration done for index: 37\n",
      "Registration done for index: 38\n",
      "Registration done for index: 39\n",
      "Registration done for index: 40\n",
      "Registration done for index: 41\n",
      "Registration done for index: 42\n",
      "Registration done for index: 43\n",
      "Registration done for index: 44\n",
      "Registration done for index: 45\n",
      "Registration done for index: 46\n",
      "Registration done for index: 47\n",
      "Registration done for index: 48\n",
      "Registration done for index: 49\n"
     ]
    }
   ],
   "source": [
    "registration_list = create_registration_list(cut_full_res_dataset, atlas_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_full_res_dataset.data_list = registration_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c1eeea11764493b8e881ff802b2093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a94e78c493486887dd5e990bd7f100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0201472ce27f44279fd067d38f9526c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59522e2973dc4dc58c6405895880c639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7397b727e3194bd791d72dd29ba5c545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233e2914d35a434e90b834fb15a566b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_3d_image(registration_list[0][0], figsize=(10, 10))\n",
    "preview_3d_image(registration_list[0][1], figsize=(10, 10))\n",
    "\n",
    "preview_3d_image(cut_full_res_dataset.label_list[1][0] == OARS_LABELS.PAROTID_GLAND_R, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training all organs models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking list used for training single models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAROTID_GLAND_R, 13\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = [tmp_list[12]]\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with dataset label 'PAROTID_GLAND_R', value '13'\n",
      "folder '20210323-133350_3d_unet_lowres_model3v2_PAROTID_GLAND_R'\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolas/fiit-dp-thesis-code/src/model_and_training/architectures/unet_architecture_v3v2.py:301: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  img_np = layer_output.data[0].detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Model number of params: 1221609, trainable 1221609\n",
      "\n",
      "\n",
      "\n",
      "Running training loop\n",
      "DEBUG: Writing to tensorboard before epoch True, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  0, step 0\n",
      "Batch train [1] loss 0.99217, dsc 0.00783\n",
      "Batch train [1] loss 0.98972, dsc 0.01028\n",
      "Batch train [1] loss 0.99292, dsc 0.00708\n",
      "Batch train [1] loss 0.99553, dsc 0.00447\n",
      "Batch train [1] loss 0.99459, dsc 0.00541\n",
      "Batch train [1] loss 0.99471, dsc 0.00529\n",
      "Batch train [1] loss 0.98770, dsc 0.01230\n",
      "Batch train [1] loss 0.99008, dsc 0.00992\n",
      "Batch train [1] loss 0.99102, dsc 0.00898\n",
      "Batch train [1] loss 0.99146, dsc 0.00854\n",
      "Batch train [1] loss 0.98614, dsc 0.01386\n",
      "Batch train [1] loss 0.98858, dsc 0.01142\n",
      "Batch train [1] loss 0.99255, dsc 0.00745\n",
      "Batch train [1] loss 0.98736, dsc 0.01264\n",
      "Batch train [1] loss 0.99477, dsc 0.00523\n",
      "Batch train [1] loss 0.99430, dsc 0.00570\n",
      "Batch train [1] loss 0.99107, dsc 0.00893\n",
      "Batch train [1] loss 0.98652, dsc 0.01348\n",
      "Batch train [1] loss 0.98934, dsc 0.01066\n",
      "Batch train [1] loss 0.99172, dsc 0.00828\n",
      "Batch train [1] loss 0.98978, dsc 0.01022\n",
      "Batch train [1] loss 0.99376, dsc 0.00624\n",
      "Batch train [1] loss 0.99435, dsc 0.00565\n",
      "Batch train [1] loss 0.98920, dsc 0.01080\n",
      "Batch train [1] loss 0.98609, dsc 0.01391\n",
      "Batch train [1] loss 0.98689, dsc 0.01311\n",
      "Batch train [1] loss 0.98644, dsc 0.01356\n",
      "Batch train [1] loss 0.98450, dsc 0.01550\n",
      "Batch train [1] loss 0.99401, dsc 0.00599\n",
      "Batch train [1] loss 0.99204, dsc 0.00796\n",
      "Batch train [1] loss 0.98839, dsc 0.01161\n",
      "Batch train [1] loss 0.98922, dsc 0.01078\n",
      "Batch train [1] loss 0.99105, dsc 0.00895\n",
      "Batch train [1] loss 0.99170, dsc 0.00830\n",
      "Batch train [1] loss 0.99367, dsc 0.00633\n",
      "Batch train [1] loss 0.99289, dsc 0.00711\n",
      "Batch train [1] loss 0.99214, dsc 0.00786\n",
      "Batch train [1] loss 0.98573, dsc 0.01427\n",
      "Batch train [1] loss 0.98473, dsc 0.01527\n",
      "Batch train [1] loss 0.98702, dsc 0.01298\n",
      "Epoch [1] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 0, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  0, step 0\n",
      "Batch eval [1] loss 0.98396, dsc 0.01604\n",
      "Batch eval [1] loss 0.98853, dsc 0.01147\n",
      "Batch eval [1] loss 0.98267, dsc 0.01733\n",
      "Batch eval [1] loss 0.98887, dsc 0.01113\n",
      "Batch eval [1] loss 0.99137, dsc 0.00863\n",
      "Epoch [1] valid done\n",
      "Epoch [1] T 122.92s, deltaT 122.92s, loss: train 0.99040, valid 0.98708, dsc: train 0.00960, valid 0.01292\n",
      "DEBUG: Writing to tensorboard before epoch True, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  1, step 0\n",
      "Batch train [1] loss 0.98609, dsc 0.01391\n",
      "Batch train [1] loss 0.98578, dsc 0.01422\n",
      "Batch train [1] loss 0.99054, dsc 0.00946\n",
      "Batch train [1] loss 0.98228, dsc 0.01772\n",
      "Batch train [1] loss 0.98574, dsc 0.01426\n",
      "Batch train [1] loss 0.98584, dsc 0.01416\n",
      "Batch train [1] loss 0.99141, dsc 0.00859\n",
      "Batch train [1] loss 0.98649, dsc 0.01351\n",
      "Batch train [1] loss 0.98878, dsc 0.01122\n",
      "Batch train [1] loss 0.99146, dsc 0.00854\n",
      "Batch train [1] loss 0.99343, dsc 0.00657\n",
      "Batch train [1] loss 0.98052, dsc 0.01948\n",
      "Batch train [1] loss 0.99138, dsc 0.00862\n",
      "Batch train [1] loss 0.99257, dsc 0.00743\n",
      "Batch train [1] loss 0.99174, dsc 0.00826\n",
      "Batch train [1] loss 0.98438, dsc 0.01562\n",
      "Batch train [1] loss 0.97802, dsc 0.02198\n",
      "Batch train [1] loss 0.98609, dsc 0.01391\n",
      "Batch train [1] loss 0.98302, dsc 0.01698\n",
      "Batch train [1] loss 0.98103, dsc 0.01897\n",
      "Batch train [1] loss 0.98000, dsc 0.02000\n",
      "Batch train [1] loss 0.98692, dsc 0.01308\n",
      "Batch train [1] loss 0.99310, dsc 0.00690\n",
      "Batch train [1] loss 0.98638, dsc 0.01362\n",
      "Batch train [1] loss 0.98807, dsc 0.01193\n",
      "Batch train [1] loss 0.98761, dsc 0.01239\n",
      "Batch train [1] loss 0.99039, dsc 0.00961\n",
      "Batch train [1] loss 0.99020, dsc 0.00980\n",
      "Batch train [1] loss 0.99133, dsc 0.00867\n",
      "Batch train [1] loss 0.98499, dsc 0.01501\n",
      "Batch train [1] loss 0.98972, dsc 0.01028\n",
      "Batch train [1] loss 0.99200, dsc 0.00800\n",
      "Batch train [1] loss 0.97979, dsc 0.02021\n",
      "Batch train [1] loss 0.98237, dsc 0.01763\n",
      "Batch train [1] loss 0.99259, dsc 0.00741\n",
      "Batch train [1] loss 0.98340, dsc 0.01660\n",
      "Batch train [1] loss 0.98436, dsc 0.01564\n",
      "Batch train [1] loss 0.97742, dsc 0.02258\n",
      "Batch train [1] loss 0.98834, dsc 0.01166\n",
      "Batch train [1] loss 0.98577, dsc 0.01423\n",
      "Epoch [2] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 1, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  1, step 0\n",
      "Batch eval [1] loss 0.98103, dsc 0.01897\n",
      "Batch eval [1] loss 0.98637, dsc 0.01363\n",
      "Batch eval [1] loss 0.97961, dsc 0.02039\n",
      "Batch eval [1] loss 0.98668, dsc 0.01332\n",
      "Batch eval [1] loss 0.98974, dsc 0.01026\n",
      "Epoch [2] valid done\n",
      "Epoch [2] T 245.41s, deltaT 122.49s, loss: train 0.98678, valid 0.98468, dsc: train 0.01322, valid 0.01532\n",
      "DEBUG: Writing to tensorboard before epoch True, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  2, step 0\n",
      "Batch train [1] loss 0.99317, dsc 0.00683\n",
      "Batch train [1] loss 0.99143, dsc 0.00857\n",
      "Batch train [1] loss 0.98085, dsc 0.01915\n",
      "Batch train [1] loss 0.98471, dsc 0.01529\n",
      "Batch train [1] loss 0.97919, dsc 0.02081\n",
      "Batch train [1] loss 0.98571, dsc 0.01429\n",
      "Batch train [1] loss 0.97875, dsc 0.02125\n",
      "Batch train [1] loss 0.99286, dsc 0.00714\n",
      "Batch train [1] loss 0.98725, dsc 0.01275\n",
      "Batch train [1] loss 0.98419, dsc 0.01581\n",
      "Batch train [1] loss 0.99229, dsc 0.00771\n",
      "Batch train [1] loss 0.98940, dsc 0.01060\n",
      "Batch train [1] loss 0.98406, dsc 0.01594\n",
      "Batch train [1] loss 0.98347, dsc 0.01653\n",
      "Batch train [1] loss 0.99111, dsc 0.00889\n",
      "Batch train [1] loss 0.99245, dsc 0.00755\n",
      "Batch train [1] loss 0.99182, dsc 0.00818\n",
      "Batch train [1] loss 0.99107, dsc 0.00893\n",
      "Batch train [1] loss 0.98761, dsc 0.01239\n",
      "Batch train [1] loss 0.99007, dsc 0.00993\n",
      "Batch train [1] loss 0.98448, dsc 0.01552\n",
      "Batch train [1] loss 0.98005, dsc 0.01995\n",
      "Batch train [1] loss 0.98553, dsc 0.01447\n",
      "Batch train [1] loss 0.97909, dsc 0.02091\n",
      "Batch train [1] loss 0.99075, dsc 0.00925\n",
      "Batch train [1] loss 0.98977, dsc 0.01023\n",
      "Batch train [1] loss 0.98937, dsc 0.01063\n",
      "Batch train [1] loss 0.98429, dsc 0.01571\n",
      "Batch train [1] loss 0.97641, dsc 0.02359\n",
      "Batch train [1] loss 0.98276, dsc 0.01724\n",
      "Batch train [1] loss 0.98786, dsc 0.01214\n",
      "Batch train [1] loss 0.98606, dsc 0.01394\n",
      "Batch train [1] loss 0.98524, dsc 0.01476\n",
      "Batch train [1] loss 0.98200, dsc 0.01800\n",
      "Batch train [1] loss 0.98448, dsc 0.01552\n",
      "Batch train [1] loss 0.98797, dsc 0.01203\n",
      "Batch train [1] loss 0.98157, dsc 0.01843\n",
      "Batch train [1] loss 0.98540, dsc 0.01460\n",
      "Batch train [1] loss 0.99062, dsc 0.00938\n",
      "Batch train [1] loss 0.97623, dsc 0.02377\n",
      "Epoch [3] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 2, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  2, step 0\n",
      "Batch eval [1] loss 0.98028, dsc 0.01972\n",
      "Batch eval [1] loss 0.98570, dsc 0.01430\n",
      "Batch eval [1] loss 0.97955, dsc 0.02045\n",
      "Batch eval [1] loss 0.98604, dsc 0.01396\n",
      "Batch eval [1] loss 0.98915, dsc 0.01085\n",
      "Epoch [3] valid done\n",
      "Epoch [3] T 367.61s, deltaT 122.19s, loss: train 0.98603, valid 0.98415, dsc: train 0.01397, valid 0.01585\n",
      "DEBUG: Writing to tensorboard before epoch True, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  3, step 0\n",
      "Batch train [1] loss 0.97871, dsc 0.02129\n",
      "Batch train [1] loss 0.98908, dsc 0.01092\n",
      "Batch train [1] loss 0.99285, dsc 0.00715\n",
      "Batch train [1] loss 0.97608, dsc 0.02392\n",
      "Batch train [1] loss 0.97798, dsc 0.02202\n",
      "Batch train [1] loss 0.98756, dsc 0.01244\n",
      "Batch train [1] loss 0.97988, dsc 0.02012\n",
      "Batch train [1] loss 0.98259, dsc 0.01741\n",
      "Batch train [1] loss 0.99255, dsc 0.00745\n",
      "Batch train [1] loss 0.97595, dsc 0.02405\n",
      "Batch train [1] loss 0.98402, dsc 0.01598\n",
      "Batch train [1] loss 0.98114, dsc 0.01886\n",
      "Batch train [1] loss 0.98234, dsc 0.01766\n",
      "Batch train [1] loss 0.99186, dsc 0.00814\n",
      "Batch train [1] loss 0.99213, dsc 0.00787\n",
      "Batch train [1] loss 0.98485, dsc 0.01515\n",
      "Batch train [1] loss 0.98954, dsc 0.01046\n",
      "Batch train [1] loss 0.99091, dsc 0.00909\n",
      "Batch train [1] loss 0.99040, dsc 0.00960\n",
      "Batch train [1] loss 0.98686, dsc 0.01314\n",
      "Batch train [1] loss 0.98762, dsc 0.01238\n",
      "Batch train [1] loss 0.97915, dsc 0.02085\n",
      "Batch train [1] loss 0.99050, dsc 0.00950\n",
      "Batch train [1] loss 0.98553, dsc 0.01447\n",
      "Batch train [1] loss 0.98123, dsc 0.01877\n",
      "Batch train [1] loss 0.98645, dsc 0.01355\n",
      "Batch train [1] loss 0.98882, dsc 0.01118\n",
      "Batch train [1] loss 0.98484, dsc 0.01516\n",
      "Batch train [1] loss 0.98380, dsc 0.01620\n",
      "Batch train [1] loss 0.98301, dsc 0.01699\n",
      "Batch train [1] loss 0.99021, dsc 0.00979\n",
      "Batch train [1] loss 0.97760, dsc 0.02240\n",
      "Batch train [1] loss 0.98462, dsc 0.01538\n",
      "Batch train [1] loss 0.98299, dsc 0.01701\n",
      "Batch train [1] loss 0.99060, dsc 0.00940\n",
      "Batch train [1] loss 0.98333, dsc 0.01667\n",
      "Batch train [1] loss 0.98439, dsc 0.01561\n",
      "Batch train [1] loss 0.98322, dsc 0.01678\n",
      "Batch train [1] loss 0.99117, dsc 0.00883\n",
      "Batch train [1] loss 0.98909, dsc 0.01091\n",
      "Epoch [4] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 3, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  3, step 0\n",
      "Batch eval [1] loss 0.97965, dsc 0.02035\n",
      "Batch eval [1] loss 0.98517, dsc 0.01483\n",
      "Batch eval [1] loss 0.97838, dsc 0.02162\n",
      "Batch eval [1] loss 0.98550, dsc 0.01450\n",
      "Batch eval [1] loss 0.98871, dsc 0.01129\n",
      "Epoch [4] valid done\n",
      "Epoch [4] T 489.76s, deltaT 122.15s, loss: train 0.98539, valid 0.98348, dsc: train 0.01461, valid 0.01652\n",
      "DEBUG: Writing to tensorboard before epoch True, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  4, step 0\n",
      "Batch train [1] loss 0.98173, dsc 0.01827\n",
      "Batch train [1] loss 0.99028, dsc 0.00972\n",
      "Batch train [1] loss 0.99065, dsc 0.00935\n",
      "Batch train [1] loss 0.98724, dsc 0.01276\n",
      "Batch train [1] loss 0.98350, dsc 0.01650\n",
      "Batch train [1] loss 0.98036, dsc 0.01964\n",
      "Batch train [1] loss 0.97719, dsc 0.02281\n",
      "Batch train [1] loss 0.98899, dsc 0.01101\n",
      "Batch train [1] loss 0.98151, dsc 0.01849\n",
      "Batch train [1] loss 0.98067, dsc 0.01933\n",
      "Batch train [1] loss 0.98256, dsc 0.01744\n",
      "Batch train [1] loss 0.98437, dsc 0.01563\n",
      "Batch train [1] loss 0.99018, dsc 0.00982\n",
      "Batch train [1] loss 0.98249, dsc 0.01751\n",
      "Batch train [1] loss 0.97441, dsc 0.02559\n",
      "Batch train [1] loss 0.98290, dsc 0.01710\n",
      "Batch train [1] loss 0.98411, dsc 0.01589\n",
      "Batch train [1] loss 0.98902, dsc 0.01098\n",
      "Batch train [1] loss 0.97854, dsc 0.02146\n",
      "Batch train [1] loss 0.99135, dsc 0.00865\n",
      "Batch train [1] loss 0.98269, dsc 0.01731\n",
      "Batch train [1] loss 0.99089, dsc 0.00911\n",
      "Batch train [1] loss 0.98482, dsc 0.01518\n",
      "Batch train [1] loss 0.98984, dsc 0.01016\n",
      "Batch train [1] loss 0.98289, dsc 0.01711\n",
      "Batch train [1] loss 0.98604, dsc 0.01396\n",
      "Batch train [1] loss 0.97607, dsc 0.02393\n",
      "Batch train [1] loss 0.99153, dsc 0.00847\n",
      "Batch train [1] loss 0.98372, dsc 0.01628\n",
      "Batch train [1] loss 0.99217, dsc 0.00783\n",
      "Batch train [1] loss 0.98812, dsc 0.01188\n",
      "Batch train [1] loss 0.98557, dsc 0.01443\n",
      "Batch train [1] loss 0.98811, dsc 0.01189\n",
      "Batch train [1] loss 0.98637, dsc 0.01363\n",
      "Batch train [1] loss 0.99187, dsc 0.00813\n",
      "Batch train [1] loss 0.98963, dsc 0.01037\n",
      "Batch train [1] loss 0.98334, dsc 0.01666\n",
      "Batch train [1] loss 0.97378, dsc 0.02622\n",
      "Batch train [1] loss 0.97754, dsc 0.02246\n",
      "Batch train [1] loss 0.97653, dsc 0.02347\n",
      "Epoch [5] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 4, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  4, step 0\n",
      "Batch eval [1] loss 0.97895, dsc 0.02105\n",
      "Batch eval [1] loss 0.98442, dsc 0.01558\n",
      "Batch eval [1] loss 0.97801, dsc 0.02199\n",
      "Batch eval [1] loss 0.98477, dsc 0.01523\n",
      "Batch eval [1] loss 0.98810, dsc 0.01190\n",
      "Epoch [5] valid done\n",
      "Epoch [5] T 611.87s, deltaT 122.10s, loss: train 0.98459, valid 0.98285, dsc: train 0.01541, valid 0.01715\n",
      "DEBUG: Writing to tensorboard before epoch True, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  5, step 0\n",
      "Batch train [1] loss 0.99064, dsc 0.00936\n",
      "Batch train [1] loss 0.99209, dsc 0.00791\n",
      "Batch train [1] loss 0.98355, dsc 0.01645\n",
      "Batch train [1] loss 0.97630, dsc 0.02370\n",
      "Batch train [1] loss 0.98263, dsc 0.01737\n",
      "Batch train [1] loss 0.97779, dsc 0.02221\n",
      "Batch train [1] loss 0.99002, dsc 0.00998\n",
      "Batch train [1] loss 0.97316, dsc 0.02684\n",
      "Batch train [1] loss 0.98054, dsc 0.01946\n",
      "Batch train [1] loss 0.98421, dsc 0.01579\n",
      "Batch train [1] loss 0.98210, dsc 0.01790\n",
      "Batch train [1] loss 0.98850, dsc 0.01150\n",
      "Batch train [1] loss 0.98515, dsc 0.01485\n",
      "Batch train [1] loss 0.97533, dsc 0.02467\n",
      "Batch train [1] loss 0.98548, dsc 0.01452\n",
      "Batch train [1] loss 0.98949, dsc 0.01051\n",
      "Batch train [1] loss 0.97565, dsc 0.02435\n",
      "Batch train [1] loss 0.98616, dsc 0.01384\n",
      "Batch train [1] loss 0.98293, dsc 0.01707\n",
      "Batch train [1] loss 0.98137, dsc 0.01863\n",
      "Batch train [1] loss 0.98749, dsc 0.01251\n",
      "Batch train [1] loss 0.97894, dsc 0.02106\n",
      "Batch train [1] loss 0.98190, dsc 0.01810\n",
      "Batch train [1] loss 0.98321, dsc 0.01679\n",
      "Batch train [1] loss 0.98917, dsc 0.01083\n",
      "Batch train [1] loss 0.98117, dsc 0.01883\n",
      "Batch train [1] loss 0.99073, dsc 0.00927\n",
      "Batch train [1] loss 0.98801, dsc 0.01199\n",
      "Batch train [1] loss 0.99099, dsc 0.00901\n",
      "Batch train [1] loss 0.99142, dsc 0.00858\n",
      "Batch train [1] loss 0.97984, dsc 0.02016\n",
      "Batch train [1] loss 0.98754, dsc 0.01246\n",
      "Batch train [1] loss 0.98281, dsc 0.01719\n",
      "Batch train [1] loss 0.98554, dsc 0.01446\n",
      "Batch train [1] loss 0.97618, dsc 0.02382\n",
      "Batch train [1] loss 0.98116, dsc 0.01884\n",
      "Batch train [1] loss 0.97241, dsc 0.02759\n",
      "Batch train [1] loss 0.98895, dsc 0.01105\n",
      "Batch train [1] loss 0.98920, dsc 0.01080\n",
      "Batch train [1] loss 0.97850, dsc 0.02150\n",
      "Epoch [6] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 5, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  5, step 0\n",
      "Batch eval [1] loss 0.97827, dsc 0.02173\n",
      "Batch eval [1] loss 0.98393, dsc 0.01607\n",
      "Batch eval [1] loss 0.97716, dsc 0.02284\n",
      "Batch eval [1] loss 0.98424, dsc 0.01576\n",
      "Batch eval [1] loss 0.98771, dsc 0.01229\n",
      "Epoch [6] valid done\n",
      "Epoch [6] T 734.10s, deltaT 122.22s, loss: train 0.98371, valid 0.98226, dsc: train 0.01629, valid 0.01774\n",
      "DEBUG: Writing to tensorboard before epoch True, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  6, step 0\n",
      "Batch train [1] loss 0.98483, dsc 0.01517\n",
      "Batch train [1] loss 0.98119, dsc 0.01881\n",
      "Batch train [1] loss 0.98056, dsc 0.01944\n",
      "Batch train [1] loss 0.97573, dsc 0.02427\n",
      "Batch train [1] loss 0.97483, dsc 0.02517\n",
      "Batch train [1] loss 0.97936, dsc 0.02064\n",
      "Batch train [1] loss 0.98421, dsc 0.01579\n",
      "Batch train [1] loss 0.98775, dsc 0.01225\n",
      "Batch train [1] loss 0.99108, dsc 0.00892\n",
      "Batch train [1] loss 0.98685, dsc 0.01315\n",
      "Batch train [1] loss 0.98887, dsc 0.01113\n",
      "Batch train [1] loss 0.99055, dsc 0.00945\n",
      "Batch train [1] loss 0.98742, dsc 0.01258\n",
      "Batch train [1] loss 0.98866, dsc 0.01134\n",
      "Batch train [1] loss 0.98110, dsc 0.01890\n",
      "Batch train [1] loss 0.98973, dsc 0.01027\n",
      "Batch train [1] loss 0.97595, dsc 0.02405\n",
      "Batch train [1] loss 0.99019, dsc 0.00981\n",
      "Batch train [1] loss 0.98291, dsc 0.01709\n",
      "Batch train [1] loss 0.97126, dsc 0.02874\n",
      "Batch train [1] loss 0.98206, dsc 0.01794\n",
      "Batch train [1] loss 0.98909, dsc 0.01091\n",
      "Batch train [1] loss 0.98182, dsc 0.01818\n",
      "Batch train [1] loss 0.98510, dsc 0.01490\n",
      "Batch train [1] loss 0.98661, dsc 0.01339\n",
      "Batch train [1] loss 0.98836, dsc 0.01164\n",
      "Batch train [1] loss 0.98142, dsc 0.01858\n",
      "Batch train [1] loss 0.97851, dsc 0.02149\n",
      "Batch train [1] loss 0.98032, dsc 0.01968\n",
      "Batch train [1] loss 0.98163, dsc 0.01837\n",
      "Batch train [1] loss 0.97977, dsc 0.02023\n",
      "Batch train [1] loss 0.97386, dsc 0.02614\n",
      "Batch train [1] loss 0.97757, dsc 0.02243\n",
      "Batch train [1] loss 0.98444, dsc 0.01556\n",
      "Batch train [1] loss 0.97982, dsc 0.02018\n",
      "Batch train [1] loss 0.97705, dsc 0.02295\n",
      "Batch train [1] loss 0.99095, dsc 0.00905\n",
      "Batch train [1] loss 0.97044, dsc 0.02956\n",
      "Batch train [1] loss 0.98821, dsc 0.01179\n",
      "Batch train [1] loss 0.97263, dsc 0.02737\n",
      "Epoch [7] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 6, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  6, step 0\n",
      "Batch eval [1] loss 0.97661, dsc 0.02339\n",
      "Batch eval [1] loss 0.98250, dsc 0.01750\n",
      "Batch eval [1] loss 0.97575, dsc 0.02425\n",
      "Batch eval [1] loss 0.98284, dsc 0.01716\n",
      "Batch eval [1] loss 0.98658, dsc 0.01342\n",
      "Epoch [7] valid done\n",
      "Epoch [7] T 856.28s, deltaT 122.17s, loss: train 0.98257, valid 0.98086, dsc: train 0.01743, valid 0.01914\n",
      "DEBUG: Writing to tensorboard before epoch True, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  7, step 0\n",
      "Batch train [1] loss 0.98972, dsc 0.01028\n",
      "Batch train [1] loss 0.97720, dsc 0.02280\n",
      "Batch train [1] loss 0.97314, dsc 0.02686\n",
      "Batch train [1] loss 0.96988, dsc 0.03012\n",
      "Batch train [1] loss 0.98672, dsc 0.01328\n",
      "Batch train [1] loss 0.99077, dsc 0.00923\n",
      "Batch train [1] loss 0.98117, dsc 0.01883\n",
      "Batch train [1] loss 0.98587, dsc 0.01413\n",
      "Batch train [1] loss 0.97904, dsc 0.02096\n",
      "Batch train [1] loss 0.98805, dsc 0.01195\n",
      "Batch train [1] loss 0.97918, dsc 0.02082\n",
      "Batch train [1] loss 0.98192, dsc 0.01808\n",
      "Batch train [1] loss 0.97887, dsc 0.02113\n",
      "Batch train [1] loss 0.98059, dsc 0.01941\n",
      "Batch train [1] loss 0.98271, dsc 0.01729\n",
      "Batch train [1] loss 0.98781, dsc 0.01219\n",
      "Batch train [1] loss 0.97919, dsc 0.02081\n",
      "Batch train [1] loss 0.97163, dsc 0.02837\n",
      "Batch train [1] loss 0.97722, dsc 0.02278\n",
      "Batch train [1] loss 0.98352, dsc 0.01648\n",
      "Batch train [1] loss 0.98578, dsc 0.01422\n",
      "Batch train [1] loss 0.96833, dsc 0.03167\n",
      "Batch train [1] loss 0.98295, dsc 0.01705\n",
      "Batch train [1] loss 0.98955, dsc 0.01045\n",
      "Batch train [1] loss 0.97572, dsc 0.02428\n",
      "Batch train [1] loss 0.98747, dsc 0.01253\n",
      "Batch train [1] loss 0.97271, dsc 0.02729\n",
      "Batch train [1] loss 0.97973, dsc 0.02027\n",
      "Batch train [1] loss 0.98861, dsc 0.01139\n",
      "Batch train [1] loss 0.97913, dsc 0.02087\n",
      "Batch train [1] loss 0.98723, dsc 0.01277\n",
      "Batch train [1] loss 0.97863, dsc 0.02137\n",
      "Batch train [1] loss 0.98353, dsc 0.01647\n",
      "Batch train [1] loss 0.98616, dsc 0.01384\n",
      "Batch train [1] loss 0.98782, dsc 0.01218\n",
      "Batch train [1] loss 0.97621, dsc 0.02379\n",
      "Batch train [1] loss 0.97972, dsc 0.02028\n",
      "Batch train [1] loss 0.98981, dsc 0.01019\n",
      "Batch train [1] loss 0.97308, dsc 0.02692\n",
      "Batch train [1] loss 0.97103, dsc 0.02897\n",
      "Epoch [8] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 7, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  7, step 0\n",
      "Batch eval [1] loss 0.97461, dsc 0.02539\n",
      "Batch eval [1] loss 0.98054, dsc 0.01946\n",
      "Batch eval [1] loss 0.97256, dsc 0.02744\n",
      "Batch eval [1] loss 0.98090, dsc 0.01910\n",
      "Batch eval [1] loss 0.98511, dsc 0.01489\n",
      "Epoch [8] valid done\n",
      "Epoch [8] T 978.44s, deltaT 122.16s, loss: train 0.98118, valid 0.97874, dsc: train 0.01882, valid 0.02126\n",
      "DEBUG: Writing to tensorboard before epoch True, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  8, step 0\n",
      "Batch train [1] loss 0.97474, dsc 0.02526\n",
      "Batch train [1] loss 0.98712, dsc 0.01288\n",
      "Batch train [1] loss 0.98826, dsc 0.01174\n",
      "Batch train [1] loss 0.98885, dsc 0.01115\n",
      "Batch train [1] loss 0.97931, dsc 0.02069\n",
      "Batch train [1] loss 0.97748, dsc 0.02252\n",
      "Batch train [1] loss 0.98574, dsc 0.01426\n",
      "Batch train [1] loss 0.97051, dsc 0.02949\n",
      "Batch train [1] loss 0.97929, dsc 0.02071\n",
      "Batch train [1] loss 0.98292, dsc 0.01708\n",
      "Batch train [1] loss 0.98189, dsc 0.01811\n",
      "Batch train [1] loss 0.96617, dsc 0.03383\n",
      "Batch train [1] loss 0.97111, dsc 0.02889\n",
      "Batch train [1] loss 0.98890, dsc 0.01110\n",
      "Batch train [1] loss 0.98671, dsc 0.01329\n",
      "Batch train [1] loss 0.97749, dsc 0.02251\n",
      "Batch train [1] loss 0.98643, dsc 0.01357\n",
      "Batch train [1] loss 0.97681, dsc 0.02319\n",
      "Batch train [1] loss 0.98004, dsc 0.01996\n",
      "Batch train [1] loss 0.97389, dsc 0.02611\n",
      "Batch train [1] loss 0.97837, dsc 0.02163\n",
      "Batch train [1] loss 0.96958, dsc 0.03042\n",
      "Batch train [1] loss 0.97875, dsc 0.02125\n",
      "Batch train [1] loss 0.97129, dsc 0.02871\n",
      "Batch train [1] loss 0.98959, dsc 0.01041\n",
      "Batch train [1] loss 0.98413, dsc 0.01587\n",
      "Batch train [1] loss 0.98401, dsc 0.01599\n",
      "Batch train [1] loss 0.97712, dsc 0.02288\n",
      "Batch train [1] loss 0.96560, dsc 0.03440\n",
      "Batch train [1] loss 0.98910, dsc 0.01090\n",
      "Batch train [1] loss 0.97602, dsc 0.02398\n",
      "Batch train [1] loss 0.97660, dsc 0.02340\n",
      "Batch train [1] loss 0.98042, dsc 0.01958\n",
      "Batch train [1] loss 0.97432, dsc 0.02568\n",
      "Batch train [1] loss 0.98150, dsc 0.01850\n",
      "Batch train [1] loss 0.98668, dsc 0.01332\n",
      "Batch train [1] loss 0.98615, dsc 0.01385\n",
      "Batch train [1] loss 0.98445, dsc 0.01555\n",
      "Batch train [1] loss 0.96788, dsc 0.03212\n",
      "Batch train [1] loss 0.97415, dsc 0.02585\n",
      "Epoch [9] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 8, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  8, step 0\n",
      "Batch eval [1] loss 0.97469, dsc 0.02531\n",
      "Batch eval [1] loss 0.97991, dsc 0.02009\n",
      "Batch eval [1] loss 0.97109, dsc 0.02891\n",
      "Batch eval [1] loss 0.98006, dsc 0.01994\n",
      "Batch eval [1] loss 0.98466, dsc 0.01534\n",
      "Epoch [9] valid done\n",
      "Epoch [9] T 1100.79s, deltaT 122.34s, loss: train 0.97948, valid 0.97808, dsc: train 0.02052, valid 0.02192\n",
      "DEBUG: Writing to tensorboard before epoch True, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  9, step 0\n",
      "Batch train [1] loss 0.98602, dsc 0.01398\n",
      "Batch train [1] loss 0.98786, dsc 0.01214\n",
      "Batch train [1] loss 0.96821, dsc 0.03179\n",
      "Batch train [1] loss 0.98922, dsc 0.01078\n",
      "Batch train [1] loss 0.96746, dsc 0.03254\n",
      "Batch train [1] loss 0.96399, dsc 0.03601\n",
      "Batch train [1] loss 0.97508, dsc 0.02492\n",
      "Batch train [1] loss 0.97723, dsc 0.02277\n",
      "Batch train [1] loss 0.97731, dsc 0.02269\n",
      "Batch train [1] loss 0.97527, dsc 0.02473\n",
      "Batch train [1] loss 0.98310, dsc 0.01690\n",
      "Batch train [1] loss 0.97320, dsc 0.02680\n",
      "Batch train [1] loss 0.96346, dsc 0.03654\n",
      "Batch train [1] loss 0.98848, dsc 0.01152\n",
      "Batch train [1] loss 0.98058, dsc 0.01942\n",
      "Batch train [1] loss 0.97521, dsc 0.02479\n",
      "Batch train [1] loss 0.98527, dsc 0.01473\n",
      "Batch train [1] loss 0.98510, dsc 0.01490\n",
      "Batch train [1] loss 0.97805, dsc 0.02195\n",
      "Batch train [1] loss 0.97106, dsc 0.02894\n",
      "Batch train [1] loss 0.98075, dsc 0.01925\n",
      "Batch train [1] loss 0.97533, dsc 0.02467\n",
      "Batch train [1] loss 0.98368, dsc 0.01632\n",
      "Batch train [1] loss 0.98346, dsc 0.01654\n",
      "Batch train [1] loss 0.96521, dsc 0.03479\n",
      "Batch train [1] loss 0.97642, dsc 0.02358\n",
      "Batch train [1] loss 0.98559, dsc 0.01441\n",
      "Batch train [1] loss 0.96801, dsc 0.03199\n",
      "Batch train [1] loss 0.97356, dsc 0.02644\n",
      "Batch train [1] loss 0.97627, dsc 0.02373\n",
      "Batch train [1] loss 0.98731, dsc 0.01269\n",
      "Batch train [1] loss 0.97420, dsc 0.02580\n",
      "Batch train [1] loss 0.98487, dsc 0.01513\n",
      "Batch train [1] loss 0.98240, dsc 0.01760\n",
      "Batch train [1] loss 0.98617, dsc 0.01383\n",
      "Batch train [1] loss 0.97008, dsc 0.02992\n",
      "Batch train [1] loss 0.96657, dsc 0.03343\n",
      "Batch train [1] loss 0.97150, dsc 0.02850\n",
      "Batch train [1] loss 0.97811, dsc 0.02189\n",
      "Batch train [1] loss 0.97874, dsc 0.02126\n",
      "Epoch [10] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 9, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  9, step 0\n",
      "Batch eval [1] loss 0.96777, dsc 0.03223\n",
      "Batch eval [1] loss 0.97612, dsc 0.02388\n",
      "Batch eval [1] loss 0.96421, dsc 0.03579\n",
      "Batch eval [1] loss 0.97593, dsc 0.02407\n",
      "Batch eval [1] loss 0.98202, dsc 0.01798\n",
      "Epoch [10] valid done\n",
      "Epoch [10] T 1223.05s, deltaT 122.26s, loss: train 0.97748, valid 0.97321, dsc: train 0.02252, valid 0.02679\n",
      "DEBUG: Writing to tensorboard before epoch True, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  10, step 0\n",
      "Batch train [1] loss 0.98309, dsc 0.01691\n",
      "Batch train [1] loss 0.97350, dsc 0.02650\n",
      "Batch train [1] loss 0.97850, dsc 0.02150\n",
      "Batch train [1] loss 0.98678, dsc 0.01322\n",
      "Batch train [1] loss 0.97506, dsc 0.02494\n",
      "Batch train [1] loss 0.97277, dsc 0.02723\n",
      "Batch train [1] loss 0.96584, dsc 0.03416\n",
      "Batch train [1] loss 0.98483, dsc 0.01517\n",
      "Batch train [1] loss 0.98426, dsc 0.01574\n",
      "Batch train [1] loss 0.97264, dsc 0.02736\n",
      "Batch train [1] loss 0.97057, dsc 0.02944\n",
      "Batch train [1] loss 0.98130, dsc 0.01870\n",
      "Batch train [1] loss 0.98378, dsc 0.01622\n",
      "Batch train [1] loss 0.96412, dsc 0.03588\n",
      "Batch train [1] loss 0.96875, dsc 0.03125\n",
      "Batch train [1] loss 0.97324, dsc 0.02676\n",
      "Batch train [1] loss 0.97392, dsc 0.02608\n",
      "Batch train [1] loss 0.98382, dsc 0.01618\n",
      "Batch train [1] loss 0.97894, dsc 0.02106\n",
      "Batch train [1] loss 0.97260, dsc 0.02740\n",
      "Batch train [1] loss 0.96542, dsc 0.03458\n",
      "Batch train [1] loss 0.98736, dsc 0.01264\n",
      "Batch train [1] loss 0.98514, dsc 0.01486\n",
      "Batch train [1] loss 0.97126, dsc 0.02874\n",
      "Batch train [1] loss 0.96153, dsc 0.03847\n",
      "Batch train [1] loss 0.96248, dsc 0.03752\n",
      "Batch train [1] loss 0.95797, dsc 0.04203\n",
      "Batch train [1] loss 0.98565, dsc 0.01435\n",
      "Batch train [1] loss 0.96734, dsc 0.03266\n",
      "Batch train [1] loss 0.98070, dsc 0.01930\n",
      "Batch train [1] loss 0.97505, dsc 0.02495\n",
      "Batch train [1] loss 0.98154, dsc 0.01846\n",
      "Batch train [1] loss 0.95722, dsc 0.04278\n",
      "Batch train [1] loss 0.97643, dsc 0.02357\n",
      "Batch train [1] loss 0.98324, dsc 0.01676\n",
      "Batch train [1] loss 0.97368, dsc 0.02632\n",
      "Batch train [1] loss 0.97329, dsc 0.02671\n",
      "Batch train [1] loss 0.98651, dsc 0.01349\n",
      "Batch train [1] loss 0.97738, dsc 0.02262\n",
      "Batch train [1] loss 0.96868, dsc 0.03132\n",
      "Epoch [11] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 10, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  10, step 0\n",
      "Batch eval [1] loss 0.96766, dsc 0.03234\n",
      "Batch eval [1] loss 0.97523, dsc 0.02477\n",
      "Batch eval [1] loss 0.96350, dsc 0.03650\n",
      "Batch eval [1] loss 0.97497, dsc 0.02503\n",
      "Batch eval [1] loss 0.98171, dsc 0.01829\n",
      "Epoch [11] valid done\n",
      "Epoch [11] T 1345.40s, deltaT 122.34s, loss: train 0.97515, valid 0.97261, dsc: train 0.02485, valid 0.02739\n",
      "DEBUG: Writing to tensorboard before epoch True, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  11, step 0\n",
      "Batch train [1] loss 0.98294, dsc 0.01706\n",
      "Batch train [1] loss 0.97092, dsc 0.02908\n",
      "Batch train [1] loss 0.95659, dsc 0.04341\n",
      "Batch train [1] loss 0.98439, dsc 0.01561\n",
      "Batch train [1] loss 0.97634, dsc 0.02366\n",
      "Batch train [1] loss 0.96341, dsc 0.03659\n",
      "Batch train [1] loss 0.96781, dsc 0.03219\n",
      "Batch train [1] loss 0.98284, dsc 0.01716\n",
      "Batch train [1] loss 0.95642, dsc 0.04358\n",
      "Batch train [1] loss 0.97693, dsc 0.02307\n",
      "Batch train [1] loss 0.96795, dsc 0.03205\n",
      "Batch train [1] loss 0.96334, dsc 0.03666\n",
      "Batch train [1] loss 0.98316, dsc 0.01684\n",
      "Batch train [1] loss 0.97932, dsc 0.02068\n",
      "Batch train [1] loss 0.98474, dsc 0.01526\n",
      "Batch train [1] loss 0.97483, dsc 0.02517\n",
      "Batch train [1] loss 0.97929, dsc 0.02071\n",
      "Batch train [1] loss 0.97307, dsc 0.02693\n",
      "Batch train [1] loss 0.95967, dsc 0.04033\n",
      "Batch train [1] loss 0.95944, dsc 0.04056\n",
      "Batch train [1] loss 0.97150, dsc 0.02850\n",
      "Batch train [1] loss 0.96499, dsc 0.03501\n",
      "Batch train [1] loss 0.97996, dsc 0.02004\n",
      "Batch train [1] loss 0.98605, dsc 0.01395\n",
      "Batch train [1] loss 0.97162, dsc 0.02838\n",
      "Batch train [1] loss 0.96939, dsc 0.03061\n",
      "Batch train [1] loss 0.95726, dsc 0.04274\n",
      "Batch train [1] loss 0.96943, dsc 0.03057\n",
      "Batch train [1] loss 0.97050, dsc 0.02950\n",
      "Batch train [1] loss 0.96751, dsc 0.03249\n",
      "Batch train [1] loss 0.96761, dsc 0.03239\n",
      "Batch train [1] loss 0.96315, dsc 0.03685\n",
      "Batch train [1] loss 0.96907, dsc 0.03093\n",
      "Batch train [1] loss 0.98139, dsc 0.01861\n",
      "Batch train [1] loss 0.98099, dsc 0.01901\n",
      "Batch train [1] loss 0.97577, dsc 0.02423\n",
      "Batch train [1] loss 0.97945, dsc 0.02055\n",
      "Batch train [1] loss 0.97032, dsc 0.02968\n",
      "Batch train [1] loss 0.98451, dsc 0.01549\n",
      "Batch train [1] loss 0.98499, dsc 0.01501\n",
      "Epoch [12] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 11, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  11, step 0\n",
      "Batch eval [1] loss 0.96617, dsc 0.03383\n",
      "Batch eval [1] loss 0.97410, dsc 0.02590\n",
      "Batch eval [1] loss 0.96352, dsc 0.03648\n",
      "Batch eval [1] loss 0.97364, dsc 0.02636\n",
      "Batch eval [1] loss 0.98041, dsc 0.01959\n",
      "Epoch [12] valid done\n",
      "Epoch [12] T 1467.75s, deltaT 122.35s, loss: train 0.97272, valid 0.97157, dsc: train 0.02728, valid 0.02843\n",
      "DEBUG: Writing to tensorboard before epoch True, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  12, step 0\n",
      "Batch train [1] loss 0.96700, dsc 0.03300\n",
      "Batch train [1] loss 0.97772, dsc 0.02228\n",
      "Batch train [1] loss 0.96820, dsc 0.03180\n",
      "Batch train [1] loss 0.97766, dsc 0.02234\n",
      "Batch train [1] loss 0.96962, dsc 0.03038\n",
      "Batch train [1] loss 0.98156, dsc 0.01844\n",
      "Batch train [1] loss 0.97861, dsc 0.02139\n",
      "Batch train [1] loss 0.96918, dsc 0.03082\n",
      "Batch train [1] loss 0.96405, dsc 0.03595\n",
      "Batch train [1] loss 0.95641, dsc 0.04359\n",
      "Batch train [1] loss 0.95132, dsc 0.04868\n",
      "Batch train [1] loss 0.96884, dsc 0.03116\n",
      "Batch train [1] loss 0.98492, dsc 0.01508\n",
      "Batch train [1] loss 0.97408, dsc 0.02592\n",
      "Batch train [1] loss 0.98073, dsc 0.01927\n",
      "Batch train [1] loss 0.96655, dsc 0.03345\n",
      "Batch train [1] loss 0.98350, dsc 0.01650\n",
      "Batch train [1] loss 0.98023, dsc 0.01977\n",
      "Batch train [1] loss 0.96185, dsc 0.03815\n",
      "Batch train [1] loss 0.95715, dsc 0.04285\n",
      "Batch train [1] loss 0.98419, dsc 0.01581\n",
      "Batch train [1] loss 0.97169, dsc 0.02831\n",
      "Batch train [1] loss 0.97816, dsc 0.02184\n",
      "Batch train [1] loss 0.98173, dsc 0.01827\n",
      "Batch train [1] loss 0.98262, dsc 0.01738\n",
      "Batch train [1] loss 0.97958, dsc 0.02042\n",
      "Batch train [1] loss 0.96637, dsc 0.03363\n",
      "Batch train [1] loss 0.95271, dsc 0.04729\n",
      "Batch train [1] loss 0.96582, dsc 0.03418\n",
      "Batch train [1] loss 0.96035, dsc 0.03965\n",
      "Batch train [1] loss 0.96799, dsc 0.03201\n",
      "Batch train [1] loss 0.96226, dsc 0.03774\n",
      "Batch train [1] loss 0.97337, dsc 0.02663\n",
      "Batch train [1] loss 0.96905, dsc 0.03095\n",
      "Batch train [1] loss 0.96397, dsc 0.03603\n",
      "Batch train [1] loss 0.94805, dsc 0.05195\n",
      "Batch train [1] loss 0.95250, dsc 0.04750\n",
      "Batch train [1] loss 0.95594, dsc 0.04406\n",
      "Batch train [1] loss 0.97215, dsc 0.02785\n",
      "Batch train [1] loss 0.97910, dsc 0.02090\n",
      "Epoch [13] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 12, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  12, step 0\n",
      "Batch eval [1] loss 0.96110, dsc 0.03890\n",
      "Batch eval [1] loss 0.96943, dsc 0.03057\n",
      "Batch eval [1] loss 0.95612, dsc 0.04388\n",
      "Batch eval [1] loss 0.96867, dsc 0.03133\n",
      "Batch eval [1] loss 0.97708, dsc 0.02292\n",
      "Epoch [13] valid done\n",
      "Epoch [13] T 1590.02s, deltaT 122.26s, loss: train 0.96967, valid 0.96648, dsc: train 0.03033, valid 0.03352\n",
      "DEBUG: Writing to tensorboard before epoch True, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  13, step 0\n",
      "Batch train [1] loss 0.97555, dsc 0.02445\n",
      "Batch train [1] loss 0.96704, dsc 0.03296\n",
      "Batch train [1] loss 0.96107, dsc 0.03893\n",
      "Batch train [1] loss 0.96329, dsc 0.03671\n",
      "Batch train [1] loss 0.98218, dsc 0.01782\n",
      "Batch train [1] loss 0.97841, dsc 0.02159\n",
      "Batch train [1] loss 0.97864, dsc 0.02136\n",
      "Batch train [1] loss 0.97950, dsc 0.02050\n",
      "Batch train [1] loss 0.98053, dsc 0.01947\n",
      "Batch train [1] loss 0.96364, dsc 0.03636\n",
      "Batch train [1] loss 0.95841, dsc 0.04159\n",
      "Batch train [1] loss 0.96930, dsc 0.03070\n",
      "Batch train [1] loss 0.98324, dsc 0.01676\n",
      "Batch train [1] loss 0.97847, dsc 0.02153\n",
      "Batch train [1] loss 0.97206, dsc 0.02794\n",
      "Batch train [1] loss 0.97627, dsc 0.02373\n",
      "Batch train [1] loss 0.98262, dsc 0.01738\n",
      "Batch train [1] loss 0.96249, dsc 0.03751\n",
      "Batch train [1] loss 0.95096, dsc 0.04904\n",
      "Batch train [1] loss 0.96498, dsc 0.03502\n",
      "Batch train [1] loss 0.96340, dsc 0.03660\n",
      "Batch train [1] loss 0.96455, dsc 0.03545\n",
      "Batch train [1] loss 0.98089, dsc 0.01911\n",
      "Batch train [1] loss 0.94338, dsc 0.05662\n",
      "Batch train [1] loss 0.94797, dsc 0.05203\n",
      "Batch train [1] loss 0.95270, dsc 0.04730\n",
      "Batch train [1] loss 0.97513, dsc 0.02487\n",
      "Batch train [1] loss 0.95537, dsc 0.04463\n",
      "Batch train [1] loss 0.97348, dsc 0.02652\n",
      "Batch train [1] loss 0.96452, dsc 0.03548\n",
      "Batch train [1] loss 0.95079, dsc 0.04921\n",
      "Batch train [1] loss 0.96565, dsc 0.03435\n",
      "Batch train [1] loss 0.94332, dsc 0.05668\n",
      "Batch train [1] loss 0.96038, dsc 0.03962\n",
      "Batch train [1] loss 0.96951, dsc 0.03049\n",
      "Batch train [1] loss 0.97687, dsc 0.02313\n",
      "Batch train [1] loss 0.95772, dsc 0.04228\n",
      "Batch train [1] loss 0.96073, dsc 0.03927\n",
      "Batch train [1] loss 0.96798, dsc 0.03202\n",
      "Batch train [1] loss 0.94713, dsc 0.05287\n",
      "Epoch [14] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 13, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  13, step 0\n",
      "Batch eval [1] loss 0.96074, dsc 0.03926\n",
      "Batch eval [1] loss 0.97033, dsc 0.02967\n",
      "Batch eval [1] loss 0.95583, dsc 0.04417\n",
      "Batch eval [1] loss 0.96860, dsc 0.03140\n",
      "Batch eval [1] loss 0.97712, dsc 0.02288\n",
      "Epoch [14] valid done\n",
      "Epoch [14] T 1712.43s, deltaT 122.40s, loss: train 0.96625, valid 0.96653, dsc: train 0.03375, valid 0.03347\n",
      "DEBUG: Writing to tensorboard before epoch True, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  14, step 0\n",
      "Batch train [1] loss 0.97745, dsc 0.02255\n",
      "Batch train [1] loss 0.95660, dsc 0.04340\n",
      "Batch train [1] loss 0.96758, dsc 0.03242\n",
      "Batch train [1] loss 0.95327, dsc 0.04673\n",
      "Batch train [1] loss 0.95025, dsc 0.04975\n",
      "Batch train [1] loss 0.96942, dsc 0.03058\n",
      "Batch train [1] loss 0.97595, dsc 0.02405\n",
      "Batch train [1] loss 0.97256, dsc 0.02744\n",
      "Batch train [1] loss 0.96047, dsc 0.03953\n",
      "Batch train [1] loss 0.95809, dsc 0.04191\n",
      "Batch train [1] loss 0.97609, dsc 0.02391\n",
      "Batch train [1] loss 0.97538, dsc 0.02462\n",
      "Batch train [1] loss 0.96220, dsc 0.03780\n",
      "Batch train [1] loss 0.97947, dsc 0.02053\n",
      "Batch train [1] loss 0.96393, dsc 0.03607\n",
      "Batch train [1] loss 0.96132, dsc 0.03868\n",
      "Batch train [1] loss 0.94385, dsc 0.05615\n",
      "Batch train [1] loss 0.96729, dsc 0.03271\n",
      "Batch train [1] loss 0.97179, dsc 0.02821\n",
      "Batch train [1] loss 0.98090, dsc 0.01910\n",
      "Batch train [1] loss 0.94647, dsc 0.05353\n",
      "Batch train [1] loss 0.95800, dsc 0.04200\n",
      "Batch train [1] loss 0.94193, dsc 0.05807\n",
      "Batch train [1] loss 0.98006, dsc 0.01994\n",
      "Batch train [1] loss 0.93778, dsc 0.06222\n",
      "Batch train [1] loss 0.95694, dsc 0.04306\n",
      "Batch train [1] loss 0.95104, dsc 0.04896\n",
      "Batch train [1] loss 0.93670, dsc 0.06330\n",
      "Batch train [1] loss 0.97819, dsc 0.02181\n",
      "Batch train [1] loss 0.97702, dsc 0.02298\n",
      "Batch train [1] loss 0.95977, dsc 0.04023\n",
      "Batch train [1] loss 0.96495, dsc 0.03505\n",
      "Batch train [1] loss 0.95679, dsc 0.04321\n",
      "Batch train [1] loss 0.97427, dsc 0.02573\n",
      "Batch train [1] loss 0.95907, dsc 0.04093\n",
      "Batch train [1] loss 0.95513, dsc 0.04487\n",
      "Batch train [1] loss 0.97130, dsc 0.02870\n",
      "Batch train [1] loss 0.95187, dsc 0.04813\n",
      "Batch train [1] loss 0.94158, dsc 0.05842\n",
      "Batch train [1] loss 0.97128, dsc 0.02872\n",
      "Epoch [15] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 14, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  14, step 0\n",
      "Batch eval [1] loss 0.94540, dsc 0.05460\n",
      "Batch eval [1] loss 0.95974, dsc 0.04026\n",
      "Batch eval [1] loss 0.94067, dsc 0.05933\n",
      "Batch eval [1] loss 0.95858, dsc 0.04142\n",
      "Batch eval [1] loss 0.97081, dsc 0.02919\n",
      "Epoch [15] valid done\n",
      "Epoch [15] T 1834.74s, deltaT 122.31s, loss: train 0.96235, valid 0.95504, dsc: train 0.03765, valid 0.04496\n",
      "DEBUG: Writing to tensorboard before epoch True, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  15, step 0\n",
      "Batch train [1] loss 0.97118, dsc 0.02882\n",
      "Batch train [1] loss 0.95413, dsc 0.04587\n",
      "Batch train [1] loss 0.94878, dsc 0.05122\n",
      "Batch train [1] loss 0.94428, dsc 0.05572\n",
      "Batch train [1] loss 0.96240, dsc 0.03760\n",
      "Batch train [1] loss 0.97695, dsc 0.02305\n",
      "Batch train [1] loss 0.95981, dsc 0.04019\n",
      "Batch train [1] loss 0.93230, dsc 0.06770\n",
      "Batch train [1] loss 0.97852, dsc 0.02148\n",
      "Batch train [1] loss 0.97305, dsc 0.02695\n",
      "Batch train [1] loss 0.95704, dsc 0.04296\n",
      "Batch train [1] loss 0.97320, dsc 0.02680\n",
      "Batch train [1] loss 0.97290, dsc 0.02710\n",
      "Batch train [1] loss 0.93903, dsc 0.06097\n",
      "Batch train [1] loss 0.93770, dsc 0.06230\n",
      "Batch train [1] loss 0.95738, dsc 0.04262\n",
      "Batch train [1] loss 0.96770, dsc 0.03230\n",
      "Batch train [1] loss 0.97191, dsc 0.02809\n",
      "Batch train [1] loss 0.93089, dsc 0.06911\n",
      "Batch train [1] loss 0.96932, dsc 0.03068\n",
      "Batch train [1] loss 0.97852, dsc 0.02148\n",
      "Batch train [1] loss 0.95292, dsc 0.04708\n",
      "Batch train [1] loss 0.94018, dsc 0.05982\n",
      "Batch train [1] loss 0.96380, dsc 0.03620\n",
      "Batch train [1] loss 0.96765, dsc 0.03235\n",
      "Batch train [1] loss 0.95346, dsc 0.04654\n",
      "Batch train [1] loss 0.94424, dsc 0.05576\n",
      "Batch train [1] loss 0.95463, dsc 0.04537\n",
      "Batch train [1] loss 0.95036, dsc 0.04964\n",
      "Batch train [1] loss 0.96223, dsc 0.03777\n",
      "Batch train [1] loss 0.94717, dsc 0.05283\n",
      "Batch train [1] loss 0.97252, dsc 0.02748\n",
      "Batch train [1] loss 0.97382, dsc 0.02618\n",
      "Batch train [1] loss 0.96049, dsc 0.03951\n",
      "Batch train [1] loss 0.95495, dsc 0.04505\n",
      "Batch train [1] loss 0.95122, dsc 0.04878\n",
      "Batch train [1] loss 0.94633, dsc 0.05367\n",
      "Batch train [1] loss 0.93216, dsc 0.06784\n",
      "Batch train [1] loss 0.97531, dsc 0.02469\n",
      "Batch train [1] loss 0.95054, dsc 0.04946\n",
      "Epoch [16] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 15, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  15, step 0\n",
      "Batch eval [1] loss 0.94651, dsc 0.05349\n",
      "Batch eval [1] loss 0.95960, dsc 0.04040\n",
      "Batch eval [1] loss 0.94320, dsc 0.05680\n",
      "Batch eval [1] loss 0.95795, dsc 0.04205\n",
      "Batch eval [1] loss 0.97039, dsc 0.02961\n",
      "Epoch [16] valid done\n",
      "Epoch [16] T 1957.18s, deltaT 122.43s, loss: train 0.95777, valid 0.95553, dsc: train 0.04223, valid 0.04447\n",
      "DEBUG: Writing to tensorboard before epoch True, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  16, step 0\n",
      "Batch train [1] loss 0.95614, dsc 0.04386\n",
      "Batch train [1] loss 0.96584, dsc 0.03416\n",
      "Batch train [1] loss 0.93887, dsc 0.06113\n",
      "Batch train [1] loss 0.94619, dsc 0.05381\n",
      "Batch train [1] loss 0.97014, dsc 0.02986\n",
      "Batch train [1] loss 0.96755, dsc 0.03245\n",
      "Batch train [1] loss 0.95833, dsc 0.04167\n",
      "Batch train [1] loss 0.96760, dsc 0.03240\n",
      "Batch train [1] loss 0.94221, dsc 0.05779\n",
      "Batch train [1] loss 0.97612, dsc 0.02388\n",
      "Batch train [1] loss 0.95307, dsc 0.04693\n",
      "Batch train [1] loss 0.97461, dsc 0.02539\n",
      "Batch train [1] loss 0.93482, dsc 0.06518\n",
      "Batch train [1] loss 0.96961, dsc 0.03039\n",
      "Batch train [1] loss 0.97049, dsc 0.02951\n",
      "Batch train [1] loss 0.93060, dsc 0.06940\n",
      "Batch train [1] loss 0.97208, dsc 0.02792\n",
      "Batch train [1] loss 0.94363, dsc 0.05637\n",
      "Batch train [1] loss 0.95162, dsc 0.04838\n",
      "Batch train [1] loss 0.94809, dsc 0.05191\n",
      "Batch train [1] loss 0.93909, dsc 0.06091\n",
      "Batch train [1] loss 0.92940, dsc 0.07060\n",
      "Batch train [1] loss 0.94568, dsc 0.05432\n",
      "Batch train [1] loss 0.97588, dsc 0.02412\n",
      "Batch train [1] loss 0.92298, dsc 0.07702\n",
      "Batch train [1] loss 0.96297, dsc 0.03703\n",
      "Batch train [1] loss 0.96890, dsc 0.03110\n",
      "Batch train [1] loss 0.93105, dsc 0.06895\n",
      "Batch train [1] loss 0.94614, dsc 0.05386\n",
      "Batch train [1] loss 0.94992, dsc 0.05008\n",
      "Batch train [1] loss 0.94728, dsc 0.05272\n",
      "Batch train [1] loss 0.95814, dsc 0.04186\n",
      "Batch train [1] loss 0.95600, dsc 0.04400\n",
      "Batch train [1] loss 0.94570, dsc 0.05430\n",
      "Batch train [1] loss 0.91925, dsc 0.08075\n",
      "Batch train [1] loss 0.97187, dsc 0.02813\n",
      "Batch train [1] loss 0.94932, dsc 0.05068\n",
      "Batch train [1] loss 0.94365, dsc 0.05635\n",
      "Batch train [1] loss 0.96652, dsc 0.03348\n",
      "Batch train [1] loss 0.95774, dsc 0.04226\n",
      "Epoch [17] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 16, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  16, step 0\n",
      "Batch eval [1] loss 0.94691, dsc 0.05309\n",
      "Batch eval [1] loss 0.95987, dsc 0.04013\n",
      "Batch eval [1] loss 0.94190, dsc 0.05810\n",
      "Batch eval [1] loss 0.95789, dsc 0.04211\n",
      "Batch eval [1] loss 0.96955, dsc 0.03045\n",
      "Epoch [17] valid done\n",
      "Epoch [17] T 2079.51s, deltaT 122.32s, loss: train 0.95313, valid 0.95522, dsc: train 0.04687, valid 0.04478\n",
      "DEBUG: Writing to tensorboard before epoch True, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  17, step 0\n",
      "Batch train [1] loss 0.92938, dsc 0.07062\n",
      "Batch train [1] loss 0.93632, dsc 0.06368\n",
      "Batch train [1] loss 0.96721, dsc 0.03279\n",
      "Batch train [1] loss 0.95437, dsc 0.04563\n",
      "Batch train [1] loss 0.94752, dsc 0.05248\n",
      "Batch train [1] loss 0.94531, dsc 0.05469\n",
      "Batch train [1] loss 0.95637, dsc 0.04363\n",
      "Batch train [1] loss 0.93773, dsc 0.06227\n",
      "Batch train [1] loss 0.94218, dsc 0.05782\n",
      "Batch train [1] loss 0.92182, dsc 0.07818\n",
      "Batch train [1] loss 0.96706, dsc 0.03294\n",
      "Batch train [1] loss 0.92258, dsc 0.07742\n",
      "Batch train [1] loss 0.92565, dsc 0.07435\n",
      "Batch train [1] loss 0.96736, dsc 0.03264\n",
      "Batch train [1] loss 0.93942, dsc 0.06058\n",
      "Batch train [1] loss 0.97142, dsc 0.02858\n",
      "Batch train [1] loss 0.97209, dsc 0.02791\n",
      "Batch train [1] loss 0.97335, dsc 0.02665\n",
      "Batch train [1] loss 0.96561, dsc 0.03439\n",
      "Batch train [1] loss 0.96110, dsc 0.03890\n",
      "Batch train [1] loss 0.93812, dsc 0.06188\n",
      "Batch train [1] loss 0.95003, dsc 0.04997\n",
      "Batch train [1] loss 0.92315, dsc 0.07685\n",
      "Batch train [1] loss 0.91662, dsc 0.08338\n",
      "Batch train [1] loss 0.96325, dsc 0.03675\n",
      "Batch train [1] loss 0.94785, dsc 0.05215\n",
      "Batch train [1] loss 0.96027, dsc 0.03973\n",
      "Batch train [1] loss 0.96851, dsc 0.03149\n",
      "Batch train [1] loss 0.96523, dsc 0.03477\n",
      "Batch train [1] loss 0.94559, dsc 0.05441\n",
      "Batch train [1] loss 0.96096, dsc 0.03904\n",
      "Batch train [1] loss 0.94005, dsc 0.05995\n",
      "Batch train [1] loss 0.95312, dsc 0.04688\n",
      "Batch train [1] loss 0.94936, dsc 0.05064\n",
      "Batch train [1] loss 0.97214, dsc 0.02786\n",
      "Batch train [1] loss 0.94075, dsc 0.05925\n",
      "Batch train [1] loss 0.94303, dsc 0.05697\n",
      "Batch train [1] loss 0.93913, dsc 0.06087\n",
      "Batch train [1] loss 0.93671, dsc 0.06329\n",
      "Batch train [1] loss 0.92472, dsc 0.07528\n",
      "Epoch [18] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 17, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  17, step 0\n",
      "Batch eval [1] loss 0.90868, dsc 0.09132\n",
      "Batch eval [1] loss 0.93003, dsc 0.06997\n",
      "Batch eval [1] loss 0.90311, dsc 0.09689\n",
      "Batch eval [1] loss 0.92908, dsc 0.07092\n",
      "Batch eval [1] loss 0.94421, dsc 0.05579\n",
      "Epoch [18] valid done\n",
      "Epoch [18] T 2201.63s, deltaT 122.12s, loss: train 0.94856, valid 0.92302, dsc: train 0.05144, valid 0.07698\n",
      "DEBUG: Writing to tensorboard before epoch True, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  18, step 0\n",
      "Batch train [1] loss 0.94563, dsc 0.05437\n",
      "Batch train [1] loss 0.96509, dsc 0.03491\n",
      "Batch train [1] loss 0.93790, dsc 0.06210\n",
      "Batch train [1] loss 0.92726, dsc 0.07274\n",
      "Batch train [1] loss 0.92859, dsc 0.07141\n",
      "Batch train [1] loss 0.96180, dsc 0.03820\n",
      "Batch train [1] loss 0.95028, dsc 0.04972\n",
      "Batch train [1] loss 0.93460, dsc 0.06540\n",
      "Batch train [1] loss 0.93226, dsc 0.06774\n",
      "Batch train [1] loss 0.96575, dsc 0.03425\n",
      "Batch train [1] loss 0.90655, dsc 0.09345\n",
      "Batch train [1] loss 0.96977, dsc 0.03023\n",
      "Batch train [1] loss 0.93968, dsc 0.06032\n",
      "Batch train [1] loss 0.95774, dsc 0.04226\n",
      "Batch train [1] loss 0.93391, dsc 0.06609\n",
      "Batch train [1] loss 0.93526, dsc 0.06474\n",
      "Batch train [1] loss 0.94527, dsc 0.05473\n",
      "Batch train [1] loss 0.96979, dsc 0.03021\n",
      "Batch train [1] loss 0.96721, dsc 0.03279\n",
      "Batch train [1] loss 0.96590, dsc 0.03410\n",
      "Batch train [1] loss 0.91242, dsc 0.08758\n",
      "Batch train [1] loss 0.95517, dsc 0.04483\n",
      "Batch train [1] loss 0.93756, dsc 0.06244\n",
      "Batch train [1] loss 0.93362, dsc 0.06638\n",
      "Batch train [1] loss 0.94895, dsc 0.05105\n",
      "Batch train [1] loss 0.96043, dsc 0.03957\n",
      "Batch train [1] loss 0.95367, dsc 0.04633\n",
      "Batch train [1] loss 0.96164, dsc 0.03836\n",
      "Batch train [1] loss 0.93692, dsc 0.06308\n",
      "Batch train [1] loss 0.90892, dsc 0.09108\n",
      "Batch train [1] loss 0.91425, dsc 0.08575\n",
      "Batch train [1] loss 0.92570, dsc 0.07430\n",
      "Batch train [1] loss 0.91590, dsc 0.08410\n",
      "Batch train [1] loss 0.93306, dsc 0.06694\n",
      "Batch train [1] loss 0.95885, dsc 0.04115\n",
      "Batch train [1] loss 0.93637, dsc 0.06363\n",
      "Batch train [1] loss 0.95470, dsc 0.04530\n",
      "Batch train [1] loss 0.90869, dsc 0.09131\n",
      "Batch train [1] loss 0.89937, dsc 0.10063\n",
      "Batch train [1] loss 0.94286, dsc 0.05714\n",
      "Epoch [19] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 18, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  18, step 0\n",
      "Batch eval [1] loss 0.89757, dsc 0.10243\n",
      "Batch eval [1] loss 0.91793, dsc 0.08207\n",
      "Batch eval [1] loss 0.89074, dsc 0.10926\n",
      "Batch eval [1] loss 0.91515, dsc 0.08485\n",
      "Batch eval [1] loss 0.93571, dsc 0.06429\n",
      "Epoch [19] valid done\n",
      "Epoch [19] T 2323.79s, deltaT 122.15s, loss: train 0.94098, valid 0.91142, dsc: train 0.05902, valid 0.08858\n",
      "DEBUG: Writing to tensorboard before epoch True, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  19, step 0\n",
      "Batch train [1] loss 0.93381, dsc 0.06619\n",
      "Batch train [1] loss 0.96757, dsc 0.03243\n",
      "Batch train [1] loss 0.95823, dsc 0.04177\n",
      "Batch train [1] loss 0.95402, dsc 0.04598\n",
      "Batch train [1] loss 0.92832, dsc 0.07168\n",
      "Batch train [1] loss 0.93026, dsc 0.06974\n",
      "Batch train [1] loss 0.93442, dsc 0.06558\n",
      "Batch train [1] loss 0.91932, dsc 0.08068\n",
      "Batch train [1] loss 0.92605, dsc 0.07395\n",
      "Batch train [1] loss 0.95279, dsc 0.04721\n",
      "Batch train [1] loss 0.95706, dsc 0.04294\n",
      "Batch train [1] loss 0.92701, dsc 0.07299\n",
      "Batch train [1] loss 0.90174, dsc 0.09826\n",
      "Batch train [1] loss 0.89969, dsc 0.10031\n",
      "Batch train [1] loss 0.89352, dsc 0.10648\n",
      "Batch train [1] loss 0.90237, dsc 0.09763\n",
      "Batch train [1] loss 0.91936, dsc 0.08064\n",
      "Batch train [1] loss 0.91933, dsc 0.08067\n",
      "Batch train [1] loss 0.91372, dsc 0.08628\n",
      "Batch train [1] loss 0.90516, dsc 0.09484\n",
      "Batch train [1] loss 0.89052, dsc 0.10948\n",
      "Batch train [1] loss 0.92932, dsc 0.07068\n",
      "Batch train [1] loss 0.92900, dsc 0.07100\n",
      "Batch train [1] loss 0.93257, dsc 0.06743\n",
      "Batch train [1] loss 0.95835, dsc 0.04165\n",
      "Batch train [1] loss 0.96308, dsc 0.03692\n",
      "Batch train [1] loss 0.92056, dsc 0.07944\n",
      "Batch train [1] loss 0.95305, dsc 0.04695\n",
      "Batch train [1] loss 0.94873, dsc 0.05127\n",
      "Batch train [1] loss 0.94572, dsc 0.05428\n",
      "Batch train [1] loss 0.95954, dsc 0.04046\n",
      "Batch train [1] loss 0.93839, dsc 0.06161\n",
      "Batch train [1] loss 0.93608, dsc 0.06392\n",
      "Batch train [1] loss 0.95269, dsc 0.04731\n",
      "Batch train [1] loss 0.95474, dsc 0.04526\n",
      "Batch train [1] loss 0.93327, dsc 0.06673\n",
      "Batch train [1] loss 0.95953, dsc 0.04047\n",
      "Batch train [1] loss 0.93891, dsc 0.06109\n",
      "Batch train [1] loss 0.90248, dsc 0.09752\n",
      "Batch train [1] loss 0.92056, dsc 0.07944\n",
      "Epoch [20] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 19, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  19, step 0\n",
      "Batch eval [1] loss 0.83370, dsc 0.16630\n",
      "Batch eval [1] loss 0.87678, dsc 0.12322\n",
      "Batch eval [1] loss 0.83578, dsc 0.16422\n",
      "Batch eval [1] loss 0.87116, dsc 0.12884\n",
      "Batch eval [1] loss 0.90075, dsc 0.09925\n",
      "Epoch [20] valid done\n",
      "Epoch [20] T 2445.95s, deltaT 122.15s, loss: train 0.93277, valid 0.86364, dsc: train 0.06723, valid 0.13636\n",
      "DEBUG: Writing to tensorboard before epoch True, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  20, step 0\n",
      "Batch train [1] loss 0.95333, dsc 0.04667\n",
      "Batch train [1] loss 0.94719, dsc 0.05281\n",
      "Batch train [1] loss 0.93406, dsc 0.06594\n",
      "Batch train [1] loss 0.90014, dsc 0.09986\n",
      "Batch train [1] loss 0.91664, dsc 0.08336\n",
      "Batch train [1] loss 0.94269, dsc 0.05731\n",
      "Batch train [1] loss 0.95071, dsc 0.04929\n",
      "Batch train [1] loss 0.95827, dsc 0.04173\n",
      "Batch train [1] loss 0.93651, dsc 0.06349\n",
      "Batch train [1] loss 0.91507, dsc 0.08493\n",
      "Batch train [1] loss 0.95458, dsc 0.04542\n",
      "Batch train [1] loss 0.94518, dsc 0.05482\n",
      "Batch train [1] loss 0.95629, dsc 0.04371\n",
      "Batch train [1] loss 0.91631, dsc 0.08369\n",
      "Batch train [1] loss 0.95904, dsc 0.04096\n",
      "Batch train [1] loss 0.89399, dsc 0.10601\n",
      "Batch train [1] loss 0.94100, dsc 0.05900\n",
      "Batch train [1] loss 0.88994, dsc 0.11006\n",
      "Batch train [1] loss 0.92884, dsc 0.07116\n",
      "Batch train [1] loss 0.91747, dsc 0.08253\n",
      "Batch train [1] loss 0.92008, dsc 0.07992\n",
      "Batch train [1] loss 0.90722, dsc 0.09278\n",
      "Batch train [1] loss 0.91235, dsc 0.08765\n",
      "Batch train [1] loss 0.88385, dsc 0.11615\n",
      "Batch train [1] loss 0.87541, dsc 0.12459\n",
      "Batch train [1] loss 0.91818, dsc 0.08182\n",
      "Batch train [1] loss 0.91812, dsc 0.08188\n",
      "Batch train [1] loss 0.91844, dsc 0.08156\n",
      "Batch train [1] loss 0.94958, dsc 0.05042\n",
      "Batch train [1] loss 0.89742, dsc 0.10258\n",
      "Batch train [1] loss 0.88510, dsc 0.11490\n",
      "Batch train [1] loss 0.94777, dsc 0.05223\n",
      "Batch train [1] loss 0.93085, dsc 0.06915\n",
      "Batch train [1] loss 0.90812, dsc 0.09188\n",
      "Batch train [1] loss 0.87638, dsc 0.12362\n",
      "Batch train [1] loss 0.94680, dsc 0.05320\n",
      "Batch train [1] loss 0.95919, dsc 0.04081\n",
      "Batch train [1] loss 0.91264, dsc 0.08736\n",
      "Batch train [1] loss 0.92333, dsc 0.07667\n",
      "Batch train [1] loss 0.89940, dsc 0.10060\n",
      "Epoch [21] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 20, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  20, step 0\n",
      "Batch eval [1] loss 0.90104, dsc 0.09896\n",
      "Batch eval [1] loss 0.92092, dsc 0.07908\n",
      "Batch eval [1] loss 0.91938, dsc 0.08062\n",
      "Batch eval [1] loss 0.91633, dsc 0.08367\n",
      "Batch eval [1] loss 0.94039, dsc 0.05960\n",
      "Epoch [21] valid done\n",
      "Epoch [21] T 2568.93s, deltaT 122.98s, loss: train 0.92369, valid 0.91961, dsc: train 0.07631, valid 0.08039\n",
      "DEBUG: Writing to tensorboard before epoch True, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  21, step 0\n",
      "Batch train [1] loss 0.92400, dsc 0.07600\n",
      "Batch train [1] loss 0.93606, dsc 0.06394\n",
      "Batch train [1] loss 0.90577, dsc 0.09423\n",
      "Batch train [1] loss 0.94825, dsc 0.05175\n",
      "Batch train [1] loss 0.94379, dsc 0.05621\n",
      "Batch train [1] loss 0.87781, dsc 0.12219\n",
      "Batch train [1] loss 0.91005, dsc 0.08995\n",
      "Batch train [1] loss 0.87973, dsc 0.12027\n",
      "Batch train [1] loss 0.90901, dsc 0.09099\n",
      "Batch train [1] loss 0.94594, dsc 0.05406\n",
      "Batch train [1] loss 0.89348, dsc 0.10652\n",
      "Batch train [1] loss 0.91205, dsc 0.08795\n",
      "Batch train [1] loss 0.92506, dsc 0.07494\n",
      "Batch train [1] loss 0.92688, dsc 0.07312\n",
      "Batch train [1] loss 0.91118, dsc 0.08882\n",
      "Batch train [1] loss 0.88824, dsc 0.11176\n",
      "Batch train [1] loss 0.92109, dsc 0.07891\n",
      "Batch train [1] loss 0.94639, dsc 0.05361\n",
      "Batch train [1] loss 0.90670, dsc 0.09330\n",
      "Batch train [1] loss 0.90721, dsc 0.09279\n",
      "Batch train [1] loss 0.89403, dsc 0.10597\n",
      "Batch train [1] loss 0.87780, dsc 0.12220\n",
      "Batch train [1] loss 0.86751, dsc 0.13249\n",
      "Batch train [1] loss 0.95422, dsc 0.04578\n",
      "Batch train [1] loss 0.90175, dsc 0.09825\n",
      "Batch train [1] loss 0.94106, dsc 0.05894\n",
      "Batch train [1] loss 0.94828, dsc 0.05172\n",
      "Batch train [1] loss 0.85439, dsc 0.14561\n",
      "Batch train [1] loss 0.89671, dsc 0.10329\n",
      "Batch train [1] loss 0.94851, dsc 0.05149\n",
      "Batch train [1] loss 0.90970, dsc 0.09030\n",
      "Batch train [1] loss 0.90383, dsc 0.09617\n",
      "Batch train [1] loss 0.93204, dsc 0.06796\n",
      "Batch train [1] loss 0.87547, dsc 0.12453\n",
      "Batch train [1] loss 0.93054, dsc 0.06946\n",
      "Batch train [1] loss 0.88859, dsc 0.11141\n",
      "Batch train [1] loss 0.85040, dsc 0.14960\n",
      "Batch train [1] loss 0.93725, dsc 0.06275\n",
      "Batch train [1] loss 0.93213, dsc 0.06787\n",
      "Batch train [1] loss 0.95002, dsc 0.04998\n",
      "Epoch [22] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 21, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  21, step 0\n",
      "Batch eval [1] loss 0.86571, dsc 0.13429\n",
      "Batch eval [1] loss 0.88628, dsc 0.11372\n",
      "Batch eval [1] loss 0.83576, dsc 0.16424\n",
      "Batch eval [1] loss 0.88484, dsc 0.11516\n",
      "Batch eval [1] loss 0.90967, dsc 0.09033\n",
      "Epoch [22] valid done\n",
      "Epoch [22] T 2691.24s, deltaT 122.30s, loss: train 0.91282, valid 0.87645, dsc: train 0.08718, valid 0.12355\n",
      "DEBUG: Writing to tensorboard before epoch True, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  22, step 0\n",
      "Batch train [1] loss 0.92636, dsc 0.07364\n",
      "Batch train [1] loss 0.89179, dsc 0.10821\n",
      "Batch train [1] loss 0.91367, dsc 0.08633\n",
      "Batch train [1] loss 0.94963, dsc 0.05037\n",
      "Batch train [1] loss 0.84961, dsc 0.15039\n",
      "Batch train [1] loss 0.92897, dsc 0.07103\n",
      "Batch train [1] loss 0.86921, dsc 0.13079\n",
      "Batch train [1] loss 0.85955, dsc 0.14045\n",
      "Batch train [1] loss 0.90846, dsc 0.09154\n",
      "Batch train [1] loss 0.89850, dsc 0.10150\n",
      "Batch train [1] loss 0.89135, dsc 0.10865\n",
      "Batch train [1] loss 0.89414, dsc 0.10586\n",
      "Batch train [1] loss 0.93958, dsc 0.06042\n",
      "Batch train [1] loss 0.87544, dsc 0.12456\n",
      "Batch train [1] loss 0.93115, dsc 0.06885\n",
      "Batch train [1] loss 0.93367, dsc 0.06633\n",
      "Batch train [1] loss 0.93225, dsc 0.06775\n",
      "Batch train [1] loss 0.89490, dsc 0.10510\n",
      "Batch train [1] loss 0.88779, dsc 0.11221\n",
      "Batch train [1] loss 0.86870, dsc 0.13130\n",
      "Batch train [1] loss 0.94149, dsc 0.05851\n",
      "Batch train [1] loss 0.93502, dsc 0.06498\n",
      "Batch train [1] loss 0.91166, dsc 0.08834\n",
      "Batch train [1] loss 0.93111, dsc 0.06889\n",
      "Batch train [1] loss 0.87621, dsc 0.12379\n",
      "Batch train [1] loss 0.91888, dsc 0.08112\n",
      "Batch train [1] loss 0.88208, dsc 0.11792\n",
      "Batch train [1] loss 0.90671, dsc 0.09329\n",
      "Batch train [1] loss 0.84981, dsc 0.15019\n",
      "Batch train [1] loss 0.88225, dsc 0.11775\n",
      "Batch train [1] loss 0.92158, dsc 0.07842\n",
      "Batch train [1] loss 0.94210, dsc 0.05790\n",
      "Batch train [1] loss 0.88976, dsc 0.11024\n",
      "Batch train [1] loss 0.83199, dsc 0.16801\n",
      "Batch train [1] loss 0.84227, dsc 0.15773\n",
      "Batch train [1] loss 0.89371, dsc 0.10629\n",
      "Batch train [1] loss 0.86906, dsc 0.13094\n",
      "Batch train [1] loss 0.84808, dsc 0.15192\n",
      "Batch train [1] loss 0.88952, dsc 0.11048\n",
      "Batch train [1] loss 0.93533, dsc 0.06467\n",
      "Epoch [23] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 22, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  22, step 0\n",
      "Batch eval [1] loss 0.80025, dsc 0.19975\n",
      "Batch eval [1] loss 0.85674, dsc 0.14326\n",
      "Batch eval [1] loss 0.79569, dsc 0.20431\n",
      "Batch eval [1] loss 0.84299, dsc 0.15701\n",
      "Batch eval [1] loss 0.88711, dsc 0.11289\n",
      "Epoch [23] valid done\n",
      "Epoch [23] T 2813.29s, deltaT 122.04s, loss: train 0.89858, valid 0.83656, dsc: train 0.10142, valid 0.16344\n",
      "DEBUG: Writing to tensorboard before epoch True, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  23, step 0\n",
      "Batch train [1] loss 0.87608, dsc 0.12392\n",
      "Batch train [1] loss 0.86667, dsc 0.13333\n",
      "Batch train [1] loss 0.93492, dsc 0.06508\n",
      "Batch train [1] loss 0.89976, dsc 0.10024\n",
      "Batch train [1] loss 0.82022, dsc 0.17978\n",
      "Batch train [1] loss 0.87608, dsc 0.12392\n",
      "Batch train [1] loss 0.83222, dsc 0.16778\n",
      "Batch train [1] loss 0.92343, dsc 0.07657\n",
      "Batch train [1] loss 0.88577, dsc 0.11423\n",
      "Batch train [1] loss 0.87163, dsc 0.12837\n",
      "Batch train [1] loss 0.81712, dsc 0.18288\n",
      "Batch train [1] loss 0.89974, dsc 0.10026\n",
      "Batch train [1] loss 0.92773, dsc 0.07227\n",
      "Batch train [1] loss 0.87827, dsc 0.12173\n",
      "Batch train [1] loss 0.90780, dsc 0.09220\n",
      "Batch train [1] loss 0.87969, dsc 0.12031\n",
      "Batch train [1] loss 0.84242, dsc 0.15758\n",
      "Batch train [1] loss 0.91859, dsc 0.08141\n",
      "Batch train [1] loss 0.86883, dsc 0.13117\n",
      "Batch train [1] loss 0.91204, dsc 0.08796\n",
      "Batch train [1] loss 0.86116, dsc 0.13884\n",
      "Batch train [1] loss 0.87378, dsc 0.12622\n",
      "Batch train [1] loss 0.83503, dsc 0.16497\n",
      "Batch train [1] loss 0.90988, dsc 0.09012\n",
      "Batch train [1] loss 0.82661, dsc 0.17339\n",
      "Batch train [1] loss 0.90197, dsc 0.09803\n",
      "Batch train [1] loss 0.85128, dsc 0.14872\n",
      "Batch train [1] loss 0.93197, dsc 0.06803\n",
      "Batch train [1] loss 0.93513, dsc 0.06487\n",
      "Batch train [1] loss 0.84305, dsc 0.15695\n",
      "Batch train [1] loss 0.87498, dsc 0.12502\n",
      "Batch train [1] loss 0.92611, dsc 0.07389\n",
      "Batch train [1] loss 0.88152, dsc 0.11848\n",
      "Batch train [1] loss 0.88577, dsc 0.11423\n",
      "Batch train [1] loss 0.91685, dsc 0.08315\n",
      "Batch train [1] loss 0.91815, dsc 0.08185\n",
      "Batch train [1] loss 0.84494, dsc 0.15506\n",
      "Batch train [1] loss 0.81730, dsc 0.18270\n",
      "Batch train [1] loss 0.85386, dsc 0.14614\n",
      "Batch train [1] loss 0.91609, dsc 0.08391\n",
      "Epoch [24] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 23, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  23, step 0\n",
      "Batch eval [1] loss 0.82789, dsc 0.17211\n",
      "Batch eval [1] loss 0.87574, dsc 0.12426\n",
      "Batch eval [1] loss 0.83609, dsc 0.16391\n",
      "Batch eval [1] loss 0.86972, dsc 0.13028\n",
      "Batch eval [1] loss 0.90188, dsc 0.09812\n",
      "Epoch [24] valid done\n",
      "Epoch [24] T 2935.63s, deltaT 122.33s, loss: train 0.88111, valid 0.86226, dsc: train 0.11889, valid 0.13774\n",
      "DEBUG: Writing to tensorboard before epoch True, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  24, step 0\n",
      "Batch train [1] loss 0.86473, dsc 0.13527\n",
      "Batch train [1] loss 0.82745, dsc 0.17255\n",
      "Batch train [1] loss 0.86639, dsc 0.13361\n",
      "Batch train [1] loss 0.84110, dsc 0.15890\n",
      "Batch train [1] loss 0.87097, dsc 0.12903\n",
      "Batch train [1] loss 0.84090, dsc 0.15910\n",
      "Batch train [1] loss 0.88006, dsc 0.11994\n",
      "Batch train [1] loss 0.88730, dsc 0.11270\n",
      "Batch train [1] loss 0.84855, dsc 0.15145\n",
      "Batch train [1] loss 0.79790, dsc 0.20210\n",
      "Batch train [1] loss 0.92355, dsc 0.07645\n",
      "Batch train [1] loss 0.92884, dsc 0.07116\n",
      "Batch train [1] loss 0.90058, dsc 0.09942\n",
      "Batch train [1] loss 0.89613, dsc 0.10387\n",
      "Batch train [1] loss 0.92482, dsc 0.07518\n",
      "Batch train [1] loss 0.84765, dsc 0.15235\n",
      "Batch train [1] loss 0.87421, dsc 0.12579\n",
      "Batch train [1] loss 0.89716, dsc 0.10284\n",
      "Batch train [1] loss 0.80546, dsc 0.19454\n",
      "Batch train [1] loss 0.91659, dsc 0.08341\n",
      "Batch train [1] loss 0.83475, dsc 0.16525\n",
      "Batch train [1] loss 0.88961, dsc 0.11039\n",
      "Batch train [1] loss 0.85598, dsc 0.14402\n",
      "Batch train [1] loss 0.84039, dsc 0.15961\n",
      "Batch train [1] loss 0.86498, dsc 0.13502\n",
      "Batch train [1] loss 0.90197, dsc 0.09803\n",
      "Batch train [1] loss 0.79186, dsc 0.20814\n",
      "Batch train [1] loss 0.90113, dsc 0.09887\n",
      "Batch train [1] loss 0.87292, dsc 0.12708\n",
      "Batch train [1] loss 0.89504, dsc 0.10496\n",
      "Batch train [1] loss 0.84989, dsc 0.15011\n",
      "Batch train [1] loss 0.81504, dsc 0.18496\n",
      "Batch train [1] loss 0.90243, dsc 0.09757\n",
      "Batch train [1] loss 0.90344, dsc 0.09656\n",
      "Batch train [1] loss 0.89909, dsc 0.10091\n",
      "Batch train [1] loss 0.75975, dsc 0.24025\n",
      "Batch train [1] loss 0.83042, dsc 0.16958\n",
      "Batch train [1] loss 0.77368, dsc 0.22632\n",
      "Batch train [1] loss 0.82419, dsc 0.17581\n",
      "Batch train [1] loss 0.81765, dsc 0.18235\n",
      "Epoch [25] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 24, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  24, step 0\n",
      "Batch eval [1] loss 0.75217, dsc 0.24783\n",
      "Batch eval [1] loss 0.79443, dsc 0.20557\n",
      "Batch eval [1] loss 0.73950, dsc 0.26050\n",
      "Batch eval [1] loss 0.78325, dsc 0.21675\n",
      "Batch eval [1] loss 0.83469, dsc 0.16531\n",
      "Epoch [25] valid done\n",
      "Epoch [25] T 3057.91s, deltaT 122.28s, loss: train 0.86161, valid 0.78081, dsc: train 0.13839, valid 0.21919\n",
      "DEBUG: Writing to tensorboard before epoch True, 25, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  25, step 0\n",
      "Batch train [1] loss 0.84289, dsc 0.15711\n",
      "Batch train [1] loss 0.87983, dsc 0.12017\n",
      "Batch train [1] loss 0.79767, dsc 0.20233\n",
      "Batch train [1] loss 0.80023, dsc 0.19977\n",
      "Batch train [1] loss 0.90176, dsc 0.09824\n",
      "Batch train [1] loss 0.89090, dsc 0.10910\n",
      "Batch train [1] loss 0.80398, dsc 0.19602\n",
      "Batch train [1] loss 0.80346, dsc 0.19654\n",
      "Batch train [1] loss 0.80427, dsc 0.19573\n",
      "Batch train [1] loss 0.70835, dsc 0.29165\n",
      "Batch train [1] loss 0.77857, dsc 0.22143\n",
      "Batch train [1] loss 0.72835, dsc 0.27165\n",
      "Batch train [1] loss 0.75596, dsc 0.24404\n",
      "Batch train [1] loss 0.86497, dsc 0.13503\n",
      "Batch train [1] loss 0.87194, dsc 0.12806\n",
      "Batch train [1] loss 0.77357, dsc 0.22643\n",
      "Batch train [1] loss 0.75567, dsc 0.24433\n",
      "Batch train [1] loss 0.76368, dsc 0.23632\n",
      "Batch train [1] loss 0.71867, dsc 0.28133\n",
      "Batch train [1] loss 0.67180, dsc 0.32820\n",
      "Batch train [1] loss 0.68816, dsc 0.31184\n",
      "Batch train [1] loss 0.81758, dsc 0.18242\n",
      "Batch train [1] loss 0.78523, dsc 0.21477\n",
      "Batch train [1] loss 0.85242, dsc 0.14758\n",
      "Batch train [1] loss 0.73104, dsc 0.26896\n",
      "Batch train [1] loss 0.83078, dsc 0.16922\n",
      "Batch train [1] loss 0.83719, dsc 0.16281\n",
      "Batch train [1] loss 0.70855, dsc 0.29145\n",
      "Batch train [1] loss 0.78221, dsc 0.21779\n",
      "Batch train [1] loss 0.75963, dsc 0.24037\n",
      "Batch train [1] loss 0.79680, dsc 0.20320\n",
      "Batch train [1] loss 0.72878, dsc 0.27122\n",
      "Batch train [1] loss 0.67094, dsc 0.32906\n",
      "Batch train [1] loss 0.71065, dsc 0.28935\n",
      "Batch train [1] loss 0.78990, dsc 0.21010\n",
      "Batch train [1] loss 0.64222, dsc 0.35778\n",
      "Batch train [1] loss 0.75624, dsc 0.24376\n",
      "Batch train [1] loss 0.80391, dsc 0.19609\n",
      "Batch train [1] loss 0.78043, dsc 0.21957\n",
      "Batch train [1] loss 0.79709, dsc 0.20291\n",
      "Epoch [26] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 25, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  25, step 0\n",
      "Batch eval [1] loss 0.49323, dsc 0.50677\n",
      "Batch eval [1] loss 0.56630, dsc 0.43370\n",
      "Batch eval [1] loss 0.58847, dsc 0.41153\n",
      "Batch eval [1] loss 0.54032, dsc 0.45968\n",
      "Batch eval [1] loss 0.64760, dsc 0.35240\n",
      "Epoch [26] valid done\n",
      "Epoch [26] T 3180.05s, deltaT 122.13s, loss: train 0.77966, valid 0.56718, dsc: train 0.22034, valid 0.43282\n",
      "DEBUG: Writing to tensorboard before epoch True, 26, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  26, step 0\n",
      "Batch train [1] loss 0.77820, dsc 0.22180\n",
      "Batch train [1] loss 0.67070, dsc 0.32930\n",
      "Batch train [1] loss 0.63706, dsc 0.36294\n",
      "Batch train [1] loss 0.70189, dsc 0.29811\n",
      "Batch train [1] loss 0.78430, dsc 0.21570\n",
      "Batch train [1] loss 0.63165, dsc 0.36835\n",
      "Batch train [1] loss 0.82800, dsc 0.17200\n",
      "Batch train [1] loss 0.71529, dsc 0.28471\n",
      "Batch train [1] loss 0.80913, dsc 0.19087\n",
      "Batch train [1] loss 0.64955, dsc 0.35045\n",
      "Batch train [1] loss 0.63715, dsc 0.36285\n",
      "Batch train [1] loss 0.65080, dsc 0.34920\n",
      "Batch train [1] loss 0.69689, dsc 0.30311\n",
      "Batch train [1] loss 0.64590, dsc 0.35410\n",
      "Batch train [1] loss 0.64871, dsc 0.35129\n",
      "Batch train [1] loss 0.72578, dsc 0.27422\n",
      "Batch train [1] loss 0.77050, dsc 0.22950\n",
      "Batch train [1] loss 0.59047, dsc 0.40953\n",
      "Batch train [1] loss 0.56153, dsc 0.43847\n",
      "Batch train [1] loss 0.63670, dsc 0.36330\n",
      "Batch train [1] loss 0.65287, dsc 0.34713\n",
      "Batch train [1] loss 0.65636, dsc 0.34364\n",
      "Batch train [1] loss 0.59227, dsc 0.40773\n",
      "Batch train [1] loss 0.71992, dsc 0.28008\n",
      "Batch train [1] loss 0.57123, dsc 0.42877\n",
      "Batch train [1] loss 0.65259, dsc 0.34741\n",
      "Batch train [1] loss 0.61433, dsc 0.38567\n",
      "Batch train [1] loss 0.54885, dsc 0.45115\n",
      "Batch train [1] loss 0.75607, dsc 0.24393\n",
      "Batch train [1] loss 0.67188, dsc 0.32812\n",
      "Batch train [1] loss 0.71338, dsc 0.28662\n",
      "Batch train [1] loss 0.74702, dsc 0.25298\n",
      "Batch train [1] loss 0.62356, dsc 0.37644\n",
      "Batch train [1] loss 0.65579, dsc 0.34421\n",
      "Batch train [1] loss 0.76419, dsc 0.23581\n",
      "Batch train [1] loss 0.60998, dsc 0.39002\n",
      "Batch train [1] loss 0.70429, dsc 0.29571\n",
      "Batch train [1] loss 0.69566, dsc 0.30434\n",
      "Batch train [1] loss 0.60602, dsc 0.39398\n",
      "Batch train [1] loss 0.72164, dsc 0.27836\n",
      "Epoch [27] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 26, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  26, step 0\n",
      "Batch eval [1] loss 0.63074, dsc 0.36926\n",
      "Batch eval [1] loss 0.64848, dsc 0.35152\n",
      "Batch eval [1] loss 0.63108, dsc 0.36892\n",
      "Batch eval [1] loss 0.63745, dsc 0.36255\n",
      "Batch eval [1] loss 0.72097, dsc 0.27903\n",
      "Epoch [27] valid done\n",
      "Epoch [27] T 3302.20s, deltaT 122.14s, loss: train 0.67620, valid 0.65375, dsc: train 0.32380, valid 0.34625\n",
      "DEBUG: Writing to tensorboard before epoch True, 27, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  27, step 0\n",
      "Batch train [1] loss 0.56139, dsc 0.43861\n",
      "Batch train [1] loss 0.64216, dsc 0.35784\n",
      "Batch train [1] loss 0.55693, dsc 0.44307\n",
      "Batch train [1] loss 0.51404, dsc 0.48596\n",
      "Batch train [1] loss 0.57897, dsc 0.42103\n",
      "Batch train [1] loss 0.71443, dsc 0.28557\n",
      "Batch train [1] loss 0.67925, dsc 0.32075\n",
      "Batch train [1] loss 0.57358, dsc 0.42642\n",
      "Batch train [1] loss 0.50445, dsc 0.49555\n",
      "Batch train [1] loss 0.60477, dsc 0.39523\n",
      "Batch train [1] loss 0.59326, dsc 0.40674\n",
      "Batch train [1] loss 0.70974, dsc 0.29026\n",
      "Batch train [1] loss 0.61454, dsc 0.38546\n",
      "Batch train [1] loss 0.68221, dsc 0.31779\n",
      "Batch train [1] loss 0.55690, dsc 0.44310\n",
      "Batch train [1] loss 0.46408, dsc 0.53592\n",
      "Batch train [1] loss 0.47961, dsc 0.52039\n",
      "Batch train [1] loss 0.47161, dsc 0.52839\n",
      "Batch train [1] loss 0.70711, dsc 0.29289\n",
      "Batch train [1] loss 0.67101, dsc 0.32899\n",
      "Batch train [1] loss 0.70906, dsc 0.29094\n",
      "Batch train [1] loss 0.56085, dsc 0.43915\n",
      "Batch train [1] loss 0.64574, dsc 0.35426\n",
      "Batch train [1] loss 0.66414, dsc 0.33586\n",
      "Batch train [1] loss 0.65970, dsc 0.34030\n",
      "Batch train [1] loss 0.53467, dsc 0.46533\n",
      "Batch train [1] loss 0.59122, dsc 0.40878\n",
      "Batch train [1] loss 0.53149, dsc 0.46851\n",
      "Batch train [1] loss 0.66483, dsc 0.33517\n",
      "Batch train [1] loss 0.50532, dsc 0.49468\n",
      "Batch train [1] loss 0.62434, dsc 0.37566\n",
      "Batch train [1] loss 0.48571, dsc 0.51429\n",
      "Batch train [1] loss 0.48759, dsc 0.51241\n",
      "Batch train [1] loss 0.63426, dsc 0.36574\n",
      "Batch train [1] loss 0.52358, dsc 0.47642\n",
      "Batch train [1] loss 0.53667, dsc 0.46333\n",
      "Batch train [1] loss 0.70480, dsc 0.29520\n",
      "Batch train [1] loss 0.50544, dsc 0.49456\n",
      "Batch train [1] loss 0.56954, dsc 0.43046\n",
      "Batch train [1] loss 0.46197, dsc 0.53803\n",
      "Epoch [28] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 27, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  27, step 0\n",
      "Batch eval [1] loss 0.60145, dsc 0.39855\n",
      "Batch eval [1] loss 0.64708, dsc 0.35292\n",
      "Batch eval [1] loss 0.58906, dsc 0.41094\n",
      "Batch eval [1] loss 0.65580, dsc 0.34420\n",
      "Batch eval [1] loss 0.75880, dsc 0.24120\n",
      "Epoch [28] valid done\n",
      "Epoch [28] T 3424.16s, deltaT 121.96s, loss: train 0.58702, valid 0.65044, dsc: train 0.41298, valid 0.34956\n",
      "DEBUG: Writing to tensorboard before epoch True, 28, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  28, step 0\n",
      "Batch train [1] loss 0.61491, dsc 0.38509\n",
      "Batch train [1] loss 0.67771, dsc 0.32229\n",
      "Batch train [1] loss 0.41099, dsc 0.58901\n",
      "Batch train [1] loss 0.45253, dsc 0.54747\n",
      "Batch train [1] loss 0.46950, dsc 0.53050\n",
      "Batch train [1] loss 0.47546, dsc 0.52454\n",
      "Batch train [1] loss 0.49781, dsc 0.50219\n",
      "Batch train [1] loss 0.50467, dsc 0.49533\n",
      "Batch train [1] loss 0.62439, dsc 0.37561\n",
      "Batch train [1] loss 0.51684, dsc 0.48316\n",
      "Batch train [1] loss 0.60243, dsc 0.39757\n",
      "Batch train [1] loss 0.40664, dsc 0.59336\n",
      "Batch train [1] loss 0.53605, dsc 0.46395\n",
      "Batch train [1] loss 0.43296, dsc 0.56704\n",
      "Batch train [1] loss 0.45813, dsc 0.54187\n",
      "Batch train [1] loss 0.57804, dsc 0.42196\n",
      "Batch train [1] loss 0.41215, dsc 0.58785\n",
      "Batch train [1] loss 0.50351, dsc 0.49649\n",
      "Batch train [1] loss 0.61504, dsc 0.38496\n",
      "Batch train [1] loss 0.49459, dsc 0.50541\n",
      "Batch train [1] loss 0.50533, dsc 0.49467\n",
      "Batch train [1] loss 0.42928, dsc 0.57072\n",
      "Batch train [1] loss 0.44486, dsc 0.55514\n",
      "Batch train [1] loss 0.57333, dsc 0.42667\n",
      "Batch train [1] loss 0.39575, dsc 0.60425\n",
      "Batch train [1] loss 0.60191, dsc 0.39809\n",
      "Batch train [1] loss 0.39354, dsc 0.60646\n",
      "Batch train [1] loss 0.38725, dsc 0.61275\n",
      "Batch train [1] loss 0.55234, dsc 0.44766\n",
      "Batch train [1] loss 0.42432, dsc 0.57568\n",
      "Batch train [1] loss 0.42619, dsc 0.57381\n",
      "Batch train [1] loss 0.43427, dsc 0.56573\n",
      "Batch train [1] loss 0.42998, dsc 0.57002\n",
      "Batch train [1] loss 0.57988, dsc 0.42012\n",
      "Batch train [1] loss 0.49066, dsc 0.50934\n",
      "Batch train [1] loss 0.46759, dsc 0.53241\n",
      "Batch train [1] loss 0.54049, dsc 0.45951\n",
      "Batch train [1] loss 0.60413, dsc 0.39587\n",
      "Batch train [1] loss 0.59988, dsc 0.40012\n",
      "Batch train [1] loss 0.53261, dsc 0.46739\n",
      "Epoch [29] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 28, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  28, step 0\n",
      "Batch eval [1] loss 0.64877, dsc 0.35123\n",
      "Batch eval [1] loss 0.65540, dsc 0.34460\n",
      "Batch eval [1] loss 0.66502, dsc 0.33498\n",
      "Batch eval [1] loss 0.66266, dsc 0.33734\n",
      "Batch eval [1] loss 0.73884, dsc 0.26116\n",
      "Epoch [29] valid done\n",
      "Epoch [29] T 3546.21s, deltaT 122.04s, loss: train 0.50245, valid 0.67414, dsc: train 0.49755, valid 0.32586\n",
      "DEBUG: Writing to tensorboard before epoch True, 29, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  29, step 0\n",
      "Batch train [1] loss 0.46864, dsc 0.53136\n",
      "Batch train [1] loss 0.40828, dsc 0.59172\n",
      "Batch train [1] loss 0.42428, dsc 0.57572\n",
      "Batch train [1] loss 0.35707, dsc 0.64293\n",
      "Batch train [1] loss 0.59646, dsc 0.40354\n",
      "Batch train [1] loss 0.39007, dsc 0.60993\n",
      "Batch train [1] loss 0.46025, dsc 0.53975\n",
      "Batch train [1] loss 0.31934, dsc 0.68066\n",
      "Batch train [1] loss 0.32745, dsc 0.67255\n",
      "Batch train [1] loss 0.44298, dsc 0.55702\n",
      "Batch train [1] loss 0.52047, dsc 0.47953\n",
      "Batch train [1] loss 0.57527, dsc 0.42473\n",
      "Batch train [1] loss 0.54947, dsc 0.45053\n",
      "Batch train [1] loss 0.35756, dsc 0.64244\n",
      "Batch train [1] loss 0.42005, dsc 0.57995\n",
      "Batch train [1] loss 0.54806, dsc 0.45194\n",
      "Batch train [1] loss 0.38463, dsc 0.61537\n",
      "Batch train [1] loss 0.50273, dsc 0.49727\n",
      "Batch train [1] loss 0.44003, dsc 0.55997\n",
      "Batch train [1] loss 0.37985, dsc 0.62015\n",
      "Batch train [1] loss 0.47986, dsc 0.52014\n",
      "Batch train [1] loss 0.51011, dsc 0.48989\n",
      "Batch train [1] loss 0.36853, dsc 0.63147\n",
      "Batch train [1] loss 0.50634, dsc 0.49366\n",
      "Batch train [1] loss 0.49843, dsc 0.50157\n",
      "Batch train [1] loss 0.51686, dsc 0.48314\n",
      "Batch train [1] loss 0.40344, dsc 0.59656\n",
      "Batch train [1] loss 0.54622, dsc 0.45378\n",
      "Batch train [1] loss 0.39928, dsc 0.60072\n",
      "Batch train [1] loss 0.39678, dsc 0.60322\n",
      "Batch train [1] loss 0.31933, dsc 0.68067\n",
      "Batch train [1] loss 0.39778, dsc 0.60222\n",
      "Batch train [1] loss 0.49900, dsc 0.50100\n",
      "Batch train [1] loss 0.38497, dsc 0.61503\n",
      "Batch train [1] loss 0.42455, dsc 0.57545\n",
      "Batch train [1] loss 0.36961, dsc 0.63039\n",
      "Batch train [1] loss 0.51028, dsc 0.48972\n",
      "Batch train [1] loss 0.36336, dsc 0.63664\n",
      "Batch train [1] loss 0.40838, dsc 0.59162\n",
      "Batch train [1] loss 0.39035, dsc 0.60965\n",
      "Epoch [30] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 29, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  29, step 0\n",
      "Batch eval [1] loss 0.39666, dsc 0.60334\n",
      "Batch eval [1] loss 0.40958, dsc 0.59042\n",
      "Batch eval [1] loss 0.42564, dsc 0.57436\n",
      "Batch eval [1] loss 0.40513, dsc 0.59487\n",
      "Batch eval [1] loss 0.51153, dsc 0.48847\n",
      "Epoch [30] valid done\n",
      "Epoch [30] T 3668.17s, deltaT 121.96s, loss: train 0.43916, valid 0.42971, dsc: train 0.56084, valid 0.57029\n",
      "DEBUG: Writing to tensorboard before epoch True, 30, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  30, step 0\n",
      "Batch train [1] loss 0.40560, dsc 0.59440\n",
      "Batch train [1] loss 0.48923, dsc 0.51077\n",
      "Batch train [1] loss 0.36303, dsc 0.63697\n",
      "Batch train [1] loss 0.39865, dsc 0.60135\n",
      "Batch train [1] loss 0.39508, dsc 0.60492\n",
      "Batch train [1] loss 0.32139, dsc 0.67861\n",
      "Batch train [1] loss 0.36881, dsc 0.63119\n",
      "Batch train [1] loss 0.34359, dsc 0.65641\n",
      "Batch train [1] loss 0.44969, dsc 0.55031\n",
      "Batch train [1] loss 0.34312, dsc 0.65688\n",
      "Batch train [1] loss 0.33602, dsc 0.66398\n",
      "Batch train [1] loss 0.29034, dsc 0.70966\n",
      "Batch train [1] loss 0.30032, dsc 0.69968\n",
      "Batch train [1] loss 0.30489, dsc 0.69511\n",
      "Batch train [1] loss 0.43996, dsc 0.56004\n",
      "Batch train [1] loss 0.35743, dsc 0.64257\n",
      "Batch train [1] loss 0.35459, dsc 0.64541\n",
      "Batch train [1] loss 0.32985, dsc 0.67015\n",
      "Batch train [1] loss 0.48102, dsc 0.51898\n",
      "Batch train [1] loss 0.43163, dsc 0.56837\n",
      "Batch train [1] loss 0.49159, dsc 0.50841\n",
      "Batch train [1] loss 0.34981, dsc 0.65019\n",
      "Batch train [1] loss 0.44622, dsc 0.55378\n",
      "Batch train [1] loss 0.33303, dsc 0.66697\n",
      "Batch train [1] loss 0.46742, dsc 0.53258\n",
      "Batch train [1] loss 0.34740, dsc 0.65260\n",
      "Batch train [1] loss 0.45743, dsc 0.54257\n",
      "Batch train [1] loss 0.34166, dsc 0.65834\n",
      "Batch train [1] loss 0.46959, dsc 0.53041\n",
      "Batch train [1] loss 0.32867, dsc 0.67133\n",
      "Batch train [1] loss 0.28590, dsc 0.71410\n",
      "Batch train [1] loss 0.51686, dsc 0.48314\n",
      "Batch train [1] loss 0.40945, dsc 0.59055\n",
      "Batch train [1] loss 0.34413, dsc 0.65587\n",
      "Batch train [1] loss 0.37812, dsc 0.62188\n",
      "Batch train [1] loss 0.44036, dsc 0.55964\n",
      "Batch train [1] loss 0.44333, dsc 0.55667\n",
      "Batch train [1] loss 0.26825, dsc 0.73175\n",
      "Batch train [1] loss 0.41526, dsc 0.58474\n",
      "Batch train [1] loss 0.32292, dsc 0.67708\n",
      "Epoch [31] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 30, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  30, step 0\n",
      "Batch eval [1] loss 0.55275, dsc 0.44725\n",
      "Batch eval [1] loss 0.62763, dsc 0.37237\n",
      "Batch eval [1] loss 0.58026, dsc 0.41974\n",
      "Batch eval [1] loss 0.63271, dsc 0.36729\n",
      "Batch eval [1] loss 0.72818, dsc 0.27182\n",
      "Epoch [31] valid done\n",
      "Epoch [31] T 3790.16s, deltaT 121.98s, loss: train 0.38404, valid 0.62431, dsc: train 0.61596, valid 0.37569\n",
      "DEBUG: Writing to tensorboard before epoch True, 31, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  31, step 0\n",
      "Batch train [1] loss 0.38027, dsc 0.61973\n",
      "Batch train [1] loss 0.41145, dsc 0.58855\n",
      "Batch train [1] loss 0.40279, dsc 0.59721\n",
      "Batch train [1] loss 0.36146, dsc 0.63854\n",
      "Batch train [1] loss 0.33074, dsc 0.66926\n",
      "Batch train [1] loss 0.32791, dsc 0.67209\n",
      "Batch train [1] loss 0.42530, dsc 0.57470\n",
      "Batch train [1] loss 0.36552, dsc 0.63448\n",
      "Batch train [1] loss 0.28045, dsc 0.71955\n",
      "Batch train [1] loss 0.35746, dsc 0.64254\n",
      "Batch train [1] loss 0.43358, dsc 0.56642\n",
      "Batch train [1] loss 0.35370, dsc 0.64630\n",
      "Batch train [1] loss 0.40412, dsc 0.59588\n",
      "Batch train [1] loss 0.31128, dsc 0.68872\n",
      "Batch train [1] loss 0.30961, dsc 0.69039\n",
      "Batch train [1] loss 0.28273, dsc 0.71727\n",
      "Batch train [1] loss 0.28056, dsc 0.71944\n",
      "Batch train [1] loss 0.42623, dsc 0.57377\n",
      "Batch train [1] loss 0.41849, dsc 0.58151\n",
      "Batch train [1] loss 0.28861, dsc 0.71139\n",
      "Batch train [1] loss 0.43456, dsc 0.56544\n",
      "Batch train [1] loss 0.30673, dsc 0.69327\n",
      "Batch train [1] loss 0.28921, dsc 0.71079\n",
      "Batch train [1] loss 0.43275, dsc 0.56725\n",
      "Batch train [1] loss 0.32138, dsc 0.67862\n",
      "Batch train [1] loss 0.42345, dsc 0.57655\n",
      "Batch train [1] loss 0.27856, dsc 0.72144\n",
      "Batch train [1] loss 0.29513, dsc 0.70487\n",
      "Batch train [1] loss 0.27368, dsc 0.72632\n",
      "Batch train [1] loss 0.43120, dsc 0.56880\n",
      "Batch train [1] loss 0.24863, dsc 0.75137\n",
      "Batch train [1] loss 0.30452, dsc 0.69548\n",
      "Batch train [1] loss 0.39432, dsc 0.60568\n",
      "Batch train [1] loss 0.43063, dsc 0.56937\n",
      "Batch train [1] loss 0.31701, dsc 0.68299\n",
      "Batch train [1] loss 0.28388, dsc 0.71612\n",
      "Batch train [1] loss 0.31680, dsc 0.68320\n",
      "Batch train [1] loss 0.43029, dsc 0.56971\n",
      "Batch train [1] loss 0.27290, dsc 0.72710\n",
      "Batch train [1] loss 0.29458, dsc 0.70542\n",
      "Epoch [32] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 31, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  31, step 0\n",
      "Batch eval [1] loss 0.54956, dsc 0.45044\n",
      "Batch eval [1] loss 0.50848, dsc 0.49152\n",
      "Batch eval [1] loss 0.56462, dsc 0.43538\n",
      "Batch eval [1] loss 0.50874, dsc 0.49126\n",
      "Batch eval [1] loss 0.61228, dsc 0.38772\n",
      "Epoch [32] valid done\n",
      "Epoch [32] T 3912.09s, deltaT 121.93s, loss: train 0.34831, valid 0.54874, dsc: train 0.65169, valid 0.45126\n",
      "DEBUG: Writing to tensorboard before epoch True, 32, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  32, step 0\n",
      "Batch train [1] loss 0.29099, dsc 0.70901\n",
      "Batch train [1] loss 0.35016, dsc 0.64984\n",
      "Batch train [1] loss 0.40470, dsc 0.59530\n",
      "Batch train [1] loss 0.29412, dsc 0.70588\n",
      "Batch train [1] loss 0.27504, dsc 0.72496\n",
      "Batch train [1] loss 0.41612, dsc 0.58388\n",
      "Batch train [1] loss 0.42316, dsc 0.57684\n",
      "Batch train [1] loss 0.27759, dsc 0.72241\n",
      "Batch train [1] loss 0.30892, dsc 0.69108\n",
      "Batch train [1] loss 0.40603, dsc 0.59397\n",
      "Batch train [1] loss 0.27597, dsc 0.72403\n",
      "Batch train [1] loss 0.40380, dsc 0.59620\n",
      "Batch train [1] loss 0.22278, dsc 0.77722\n",
      "Batch train [1] loss 0.28767, dsc 0.71233\n",
      "Batch train [1] loss 0.39863, dsc 0.60137\n",
      "Batch train [1] loss 0.36412, dsc 0.63588\n",
      "Batch train [1] loss 0.34536, dsc 0.65464\n",
      "Batch train [1] loss 0.38934, dsc 0.61066\n",
      "Batch train [1] loss 0.28857, dsc 0.71143\n",
      "Batch train [1] loss 0.23863, dsc 0.76137\n",
      "Batch train [1] loss 0.31590, dsc 0.68410\n",
      "Batch train [1] loss 0.24190, dsc 0.75810\n",
      "Batch train [1] loss 0.26121, dsc 0.73879\n",
      "Batch train [1] loss 0.30152, dsc 0.69848\n",
      "Batch train [1] loss 0.37723, dsc 0.62277\n",
      "Batch train [1] loss 0.25785, dsc 0.74215\n",
      "Batch train [1] loss 0.30508, dsc 0.69492\n",
      "Batch train [1] loss 0.22802, dsc 0.77198\n",
      "Batch train [1] loss 0.28143, dsc 0.71857\n",
      "Batch train [1] loss 0.22667, dsc 0.77333\n",
      "Batch train [1] loss 0.28335, dsc 0.71665\n",
      "Batch train [1] loss 0.22036, dsc 0.77964\n",
      "Batch train [1] loss 0.35122, dsc 0.64878\n",
      "Batch train [1] loss 0.27096, dsc 0.72904\n",
      "Batch train [1] loss 0.30222, dsc 0.69778\n",
      "Batch train [1] loss 0.34709, dsc 0.65291\n",
      "Batch train [1] loss 0.27404, dsc 0.72596\n",
      "Batch train [1] loss 0.26668, dsc 0.73332\n",
      "Batch train [1] loss 0.36666, dsc 0.63334\n",
      "Batch train [1] loss 0.36721, dsc 0.63279\n",
      "Epoch [33] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 32, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  32, step 0\n",
      "Batch eval [1] loss 0.38030, dsc 0.61970\n",
      "Batch eval [1] loss 0.44341, dsc 0.55659\n",
      "Batch eval [1] loss 0.43103, dsc 0.56897\n",
      "Batch eval [1] loss 0.44368, dsc 0.55632\n",
      "Batch eval [1] loss 0.55081, dsc 0.44919\n",
      "Epoch [33] valid done\n",
      "Epoch [33] T 4034.00s, deltaT 121.90s, loss: train 0.31271, valid 0.44985, dsc: train 0.68729, valid 0.55015\n",
      "DEBUG: Writing to tensorboard before epoch True, 33, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  33, step 0\n",
      "Batch train [1] loss 0.22688, dsc 0.77312\n",
      "Batch train [1] loss 0.25061, dsc 0.74939\n",
      "Batch train [1] loss 0.33520, dsc 0.66480\n",
      "Batch train [1] loss 0.20466, dsc 0.79534\n",
      "Batch train [1] loss 0.31449, dsc 0.68551\n",
      "Batch train [1] loss 0.25160, dsc 0.74840\n",
      "Batch train [1] loss 0.30489, dsc 0.69511\n",
      "Batch train [1] loss 0.28295, dsc 0.71705\n",
      "Batch train [1] loss 0.38619, dsc 0.61381\n",
      "Batch train [1] loss 0.31694, dsc 0.68306\n",
      "Batch train [1] loss 0.19693, dsc 0.80307\n",
      "Batch train [1] loss 0.24910, dsc 0.75090\n",
      "Batch train [1] loss 0.28736, dsc 0.71264\n",
      "Batch train [1] loss 0.38992, dsc 0.61008\n",
      "Batch train [1] loss 0.21132, dsc 0.78868\n",
      "Batch train [1] loss 0.29132, dsc 0.70868\n",
      "Batch train [1] loss 0.25904, dsc 0.74096\n",
      "Batch train [1] loss 0.29370, dsc 0.70630\n",
      "Batch train [1] loss 0.24988, dsc 0.75012\n",
      "Batch train [1] loss 0.33277, dsc 0.66723\n",
      "Batch train [1] loss 0.28568, dsc 0.71432\n",
      "Batch train [1] loss 0.24828, dsc 0.75172\n",
      "Batch train [1] loss 0.25001, dsc 0.74999\n",
      "Batch train [1] loss 0.22189, dsc 0.77811\n",
      "Batch train [1] loss 0.33429, dsc 0.66571\n",
      "Batch train [1] loss 0.22247, dsc 0.77753\n",
      "Batch train [1] loss 0.31036, dsc 0.68964\n",
      "Batch train [1] loss 0.33482, dsc 0.66518\n",
      "Batch train [1] loss 0.36945, dsc 0.63055\n",
      "Batch train [1] loss 0.27953, dsc 0.72047\n",
      "Batch train [1] loss 0.35876, dsc 0.64124\n",
      "Batch train [1] loss 0.33088, dsc 0.66912\n",
      "Batch train [1] loss 0.34333, dsc 0.65667\n",
      "Batch train [1] loss 0.26555, dsc 0.73445\n",
      "Batch train [1] loss 0.25429, dsc 0.74571\n",
      "Batch train [1] loss 0.19803, dsc 0.80197\n",
      "Batch train [1] loss 0.24493, dsc 0.75507\n",
      "Batch train [1] loss 0.34654, dsc 0.65346\n",
      "Batch train [1] loss 0.26433, dsc 0.73567\n",
      "Batch train [1] loss 0.24115, dsc 0.75885\n",
      "Epoch [34] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 33, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  33, step 0\n",
      "Batch eval [1] loss 0.55674, dsc 0.44326\n",
      "Batch eval [1] loss 0.54631, dsc 0.45369\n",
      "Batch eval [1] loss 0.52518, dsc 0.47482\n",
      "Batch eval [1] loss 0.56254, dsc 0.43746\n",
      "Batch eval [1] loss 0.64037, dsc 0.35963\n",
      "Epoch [34] valid done\n",
      "Epoch [34] T 4155.90s, deltaT 121.89s, loss: train 0.28351, valid 0.56623, dsc: train 0.71649, valid 0.43377\n",
      "DEBUG: Writing to tensorboard before epoch True, 34, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  34, step 0\n",
      "Batch train [1] loss 0.24389, dsc 0.75611\n",
      "Batch train [1] loss 0.24694, dsc 0.75306\n",
      "Batch train [1] loss 0.33798, dsc 0.66202\n",
      "Batch train [1] loss 0.27222, dsc 0.72778\n",
      "Batch train [1] loss 0.28291, dsc 0.71709\n",
      "Batch train [1] loss 0.33154, dsc 0.66846\n",
      "Batch train [1] loss 0.27893, dsc 0.72107\n",
      "Batch train [1] loss 0.18932, dsc 0.81068\n",
      "Batch train [1] loss 0.28203, dsc 0.71797\n",
      "Batch train [1] loss 0.21053, dsc 0.78947\n",
      "Batch train [1] loss 0.27295, dsc 0.72705\n",
      "Batch train [1] loss 0.26054, dsc 0.73946\n",
      "Batch train [1] loss 0.35999, dsc 0.64001\n",
      "Batch train [1] loss 0.32688, dsc 0.67312\n",
      "Batch train [1] loss 0.24008, dsc 0.75992\n",
      "Batch train [1] loss 0.31168, dsc 0.68832\n",
      "Batch train [1] loss 0.25636, dsc 0.74364\n",
      "Batch train [1] loss 0.23990, dsc 0.76010\n",
      "Batch train [1] loss 0.26864, dsc 0.73136\n",
      "Batch train [1] loss 0.29791, dsc 0.70209\n",
      "Batch train [1] loss 0.20906, dsc 0.79094\n",
      "Batch train [1] loss 0.20003, dsc 0.79997\n",
      "Batch train [1] loss 0.24724, dsc 0.75276\n",
      "Batch train [1] loss 0.24160, dsc 0.75840\n",
      "Batch train [1] loss 0.31603, dsc 0.68397\n",
      "Batch train [1] loss 0.35268, dsc 0.64732\n",
      "Batch train [1] loss 0.22673, dsc 0.77327\n",
      "Batch train [1] loss 0.22724, dsc 0.77276\n",
      "Batch train [1] loss 0.20448, dsc 0.79552\n",
      "Batch train [1] loss 0.31678, dsc 0.68322\n",
      "Batch train [1] loss 0.28651, dsc 0.71349\n",
      "Batch train [1] loss 0.18549, dsc 0.81451\n",
      "Batch train [1] loss 0.26016, dsc 0.73984\n",
      "Batch train [1] loss 0.28354, dsc 0.71646\n",
      "Batch train [1] loss 0.19241, dsc 0.80759\n",
      "Batch train [1] loss 0.22910, dsc 0.77090\n",
      "Batch train [1] loss 0.30660, dsc 0.69340\n",
      "Batch train [1] loss 0.29251, dsc 0.70749\n",
      "Batch train [1] loss 0.20117, dsc 0.79883\n",
      "Batch train [1] loss 0.22638, dsc 0.77362\n",
      "Epoch [35] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 34, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  34, step 0\n",
      "Batch eval [1] loss 0.36758, dsc 0.63242\n",
      "Batch eval [1] loss 0.45023, dsc 0.54977\n",
      "Batch eval [1] loss 0.43660, dsc 0.56340\n",
      "Batch eval [1] loss 0.46319, dsc 0.53681\n",
      "Batch eval [1] loss 0.56721, dsc 0.43279\n",
      "Epoch [35] valid done\n",
      "Epoch [35] T 4277.79s, deltaT 121.89s, loss: train 0.26292, valid 0.45696, dsc: train 0.73708, valid 0.54304\n",
      "DEBUG: Writing to tensorboard before epoch True, 35, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  35, step 0\n",
      "Batch train [1] loss 0.32845, dsc 0.67155\n",
      "Batch train [1] loss 0.22538, dsc 0.77462\n",
      "Batch train [1] loss 0.20899, dsc 0.79101\n",
      "Batch train [1] loss 0.21965, dsc 0.78035\n",
      "Batch train [1] loss 0.31266, dsc 0.68734\n",
      "Batch train [1] loss 0.20584, dsc 0.79416\n",
      "Batch train [1] loss 0.21926, dsc 0.78074\n",
      "Batch train [1] loss 0.21142, dsc 0.78858\n",
      "Batch train [1] loss 0.29867, dsc 0.70133\n",
      "Batch train [1] loss 0.24992, dsc 0.75008\n",
      "Batch train [1] loss 0.25761, dsc 0.74239\n",
      "Batch train [1] loss 0.24125, dsc 0.75875\n",
      "Batch train [1] loss 0.20964, dsc 0.79036\n",
      "Batch train [1] loss 0.20814, dsc 0.79186\n",
      "Batch train [1] loss 0.31146, dsc 0.68854\n",
      "Batch train [1] loss 0.22459, dsc 0.77541\n",
      "Batch train [1] loss 0.28477, dsc 0.71523\n",
      "Batch train [1] loss 0.30073, dsc 0.69927\n",
      "Batch train [1] loss 0.26465, dsc 0.73535\n",
      "Batch train [1] loss 0.28159, dsc 0.71841\n",
      "Batch train [1] loss 0.18346, dsc 0.81654\n",
      "Batch train [1] loss 0.18737, dsc 0.81263\n",
      "Batch train [1] loss 0.15939, dsc 0.84061\n",
      "Batch train [1] loss 0.24597, dsc 0.75403\n",
      "Batch train [1] loss 0.21832, dsc 0.78168\n",
      "Batch train [1] loss 0.17171, dsc 0.82829\n",
      "Batch train [1] loss 0.18328, dsc 0.81672\n",
      "Batch train [1] loss 0.20676, dsc 0.79324\n",
      "Batch train [1] loss 0.23654, dsc 0.76346\n",
      "Batch train [1] loss 0.34017, dsc 0.65983\n",
      "Batch train [1] loss 0.20594, dsc 0.79406\n",
      "Batch train [1] loss 0.30579, dsc 0.69421\n",
      "Batch train [1] loss 0.21208, dsc 0.78792\n",
      "Batch train [1] loss 0.21430, dsc 0.78570\n",
      "Batch train [1] loss 0.32635, dsc 0.67365\n",
      "Batch train [1] loss 0.28246, dsc 0.71754\n",
      "Batch train [1] loss 0.32734, dsc 0.67266\n",
      "Batch train [1] loss 0.25533, dsc 0.74467\n",
      "Batch train [1] loss 0.21587, dsc 0.78413\n",
      "Batch train [1] loss 0.22833, dsc 0.77167\n",
      "Epoch [36] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 35, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  35, step 0\n",
      "Batch eval [1] loss 0.53952, dsc 0.46048\n",
      "Batch eval [1] loss 0.50053, dsc 0.49947\n",
      "Batch eval [1] loss 0.52028, dsc 0.47972\n",
      "Batch eval [1] loss 0.51768, dsc 0.48232\n",
      "Batch eval [1] loss 0.60443, dsc 0.39557\n",
      "Epoch [36] valid done\n",
      "Epoch [36] T 4399.62s, deltaT 121.82s, loss: train 0.24429, valid 0.53649, dsc: train 0.75571, valid 0.46351\n",
      "DEBUG: Writing to tensorboard before epoch True, 36, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  36, step 0\n",
      "Batch train [1] loss 0.22540, dsc 0.77460\n",
      "Batch train [1] loss 0.18817, dsc 0.81183\n",
      "Batch train [1] loss 0.17683, dsc 0.82317\n",
      "Batch train [1] loss 0.19836, dsc 0.80164\n",
      "Batch train [1] loss 0.16582, dsc 0.83418\n",
      "Batch train [1] loss 0.22624, dsc 0.77376\n",
      "Batch train [1] loss 0.22481, dsc 0.77519\n",
      "Batch train [1] loss 0.22573, dsc 0.77427\n",
      "Batch train [1] loss 0.19990, dsc 0.80010\n",
      "Batch train [1] loss 0.29042, dsc 0.70958\n",
      "Batch train [1] loss 0.26697, dsc 0.73303\n",
      "Batch train [1] loss 0.27475, dsc 0.72525\n",
      "Batch train [1] loss 0.20216, dsc 0.79784\n",
      "Batch train [1] loss 0.25872, dsc 0.74128\n",
      "Batch train [1] loss 0.32377, dsc 0.67623\n",
      "Batch train [1] loss 0.27578, dsc 0.72422\n",
      "Batch train [1] loss 0.29561, dsc 0.70439\n",
      "Batch train [1] loss 0.29638, dsc 0.70362\n",
      "Batch train [1] loss 0.21050, dsc 0.78950\n",
      "Batch train [1] loss 0.21656, dsc 0.78344\n",
      "Batch train [1] loss 0.18131, dsc 0.81869\n",
      "Batch train [1] loss 0.22306, dsc 0.77694\n",
      "Batch train [1] loss 0.19345, dsc 0.80655\n",
      "Batch train [1] loss 0.16815, dsc 0.83185\n",
      "Batch train [1] loss 0.19568, dsc 0.80432\n",
      "Batch train [1] loss 0.17339, dsc 0.82661\n",
      "Batch train [1] loss 0.27152, dsc 0.72848\n",
      "Batch train [1] loss 0.25550, dsc 0.74450\n",
      "Batch train [1] loss 0.28122, dsc 0.71878\n",
      "Batch train [1] loss 0.21937, dsc 0.78063\n",
      "Batch train [1] loss 0.28773, dsc 0.71227\n",
      "Batch train [1] loss 0.27503, dsc 0.72497\n",
      "Batch train [1] loss 0.22581, dsc 0.77419\n",
      "Batch train [1] loss 0.19302, dsc 0.80698\n",
      "Batch train [1] loss 0.22283, dsc 0.77717\n",
      "Batch train [1] loss 0.17811, dsc 0.82189\n",
      "Batch train [1] loss 0.31700, dsc 0.68300\n",
      "Batch train [1] loss 0.19716, dsc 0.80284\n",
      "Batch train [1] loss 0.18772, dsc 0.81228\n",
      "Batch train [1] loss 0.20770, dsc 0.79230\n",
      "Epoch [37] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 36, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  36, step 0\n",
      "Batch eval [1] loss 0.26151, dsc 0.73849\n",
      "Batch eval [1] loss 0.25181, dsc 0.74819\n",
      "Batch eval [1] loss 0.28749, dsc 0.71251\n",
      "Batch eval [1] loss 0.26266, dsc 0.73734\n",
      "Batch eval [1] loss 0.38176, dsc 0.61824\n",
      "Epoch [37] valid done\n",
      "Epoch [37] T 4521.35s, deltaT 121.72s, loss: train 0.22994, valid 0.28904, dsc: train 0.77006, valid 0.71096\n",
      "DEBUG: Writing to tensorboard before epoch True, 37, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  37, step 0\n",
      "Batch train [1] loss 0.27166, dsc 0.72834\n",
      "Batch train [1] loss 0.19008, dsc 0.80992\n",
      "Batch train [1] loss 0.29686, dsc 0.70314\n",
      "Batch train [1] loss 0.25066, dsc 0.74934\n",
      "Batch train [1] loss 0.23116, dsc 0.76884\n",
      "Batch train [1] loss 0.20261, dsc 0.79739\n",
      "Batch train [1] loss 0.17059, dsc 0.82941\n",
      "Batch train [1] loss 0.17377, dsc 0.82623\n",
      "Batch train [1] loss 0.26200, dsc 0.73800\n",
      "Batch train [1] loss 0.17222, dsc 0.82778\n",
      "Batch train [1] loss 0.19731, dsc 0.80269\n",
      "Batch train [1] loss 0.22158, dsc 0.77842\n",
      "Batch train [1] loss 0.26834, dsc 0.73166\n",
      "Batch train [1] loss 0.19099, dsc 0.80901\n",
      "Batch train [1] loss 0.23111, dsc 0.76889\n",
      "Batch train [1] loss 0.21812, dsc 0.78188\n",
      "Batch train [1] loss 0.19205, dsc 0.80795\n",
      "Batch train [1] loss 0.28904, dsc 0.71096\n",
      "Batch train [1] loss 0.17014, dsc 0.82986\n",
      "Batch train [1] loss 0.18363, dsc 0.81637\n",
      "Batch train [1] loss 0.21752, dsc 0.78248\n",
      "Batch train [1] loss 0.15959, dsc 0.84041\n",
      "Batch train [1] loss 0.16780, dsc 0.83220\n",
      "Batch train [1] loss 0.19729, dsc 0.80271\n",
      "Batch train [1] loss 0.22556, dsc 0.77444\n",
      "Batch train [1] loss 0.18216, dsc 0.81784\n",
      "Batch train [1] loss 0.18853, dsc 0.81147\n",
      "Batch train [1] loss 0.18013, dsc 0.81987\n",
      "Batch train [1] loss 0.25567, dsc 0.74433\n",
      "Batch train [1] loss 0.19318, dsc 0.80682\n",
      "Batch train [1] loss 0.26072, dsc 0.73928\n",
      "Batch train [1] loss 0.14191, dsc 0.85809\n",
      "Batch train [1] loss 0.22061, dsc 0.77939\n",
      "Batch train [1] loss 0.27900, dsc 0.72100\n",
      "Batch train [1] loss 0.17195, dsc 0.82805\n",
      "Batch train [1] loss 0.23568, dsc 0.76432\n",
      "Batch train [1] loss 0.22188, dsc 0.77812\n",
      "Batch train [1] loss 0.25586, dsc 0.74414\n",
      "Batch train [1] loss 0.28257, dsc 0.71743\n",
      "Batch train [1] loss 0.20433, dsc 0.79567\n",
      "Epoch [38] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 37, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  37, step 0\n",
      "Batch eval [1] loss 0.47624, dsc 0.52376\n",
      "Batch eval [1] loss 0.38416, dsc 0.61584\n",
      "Batch eval [1] loss 0.43512, dsc 0.56488\n",
      "Batch eval [1] loss 0.41303, dsc 0.58697\n",
      "Batch eval [1] loss 0.49862, dsc 0.50138\n",
      "Epoch [38] valid done\n",
      "Epoch [38] T 4643.24s, deltaT 121.88s, loss: train 0.21565, valid 0.44144, dsc: train 0.78435, valid 0.55856\n",
      "DEBUG: Writing to tensorboard before epoch True, 38, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  38, step 0\n",
      "Batch train [1] loss 0.18249, dsc 0.81751\n",
      "Batch train [1] loss 0.17542, dsc 0.82458\n",
      "Batch train [1] loss 0.28341, dsc 0.71659\n",
      "Batch train [1] loss 0.16979, dsc 0.83021\n",
      "Batch train [1] loss 0.19012, dsc 0.80988\n",
      "Batch train [1] loss 0.25929, dsc 0.74071\n",
      "Batch train [1] loss 0.16429, dsc 0.83571\n",
      "Batch train [1] loss 0.22660, dsc 0.77340\n",
      "Batch train [1] loss 0.22892, dsc 0.77108\n",
      "Batch train [1] loss 0.17954, dsc 0.82046\n",
      "Batch train [1] loss 0.23713, dsc 0.76287\n",
      "Batch train [1] loss 0.19477, dsc 0.80523\n",
      "Batch train [1] loss 0.20693, dsc 0.79307\n",
      "Batch train [1] loss 0.24444, dsc 0.75556\n",
      "Batch train [1] loss 0.18834, dsc 0.81166\n",
      "Batch train [1] loss 0.29794, dsc 0.70206\n",
      "Batch train [1] loss 0.27860, dsc 0.72140\n",
      "Batch train [1] loss 0.17130, dsc 0.82870\n",
      "Batch train [1] loss 0.18196, dsc 0.81804\n",
      "Batch train [1] loss 0.24761, dsc 0.75239\n",
      "Batch train [1] loss 0.18769, dsc 0.81231\n",
      "Batch train [1] loss 0.17791, dsc 0.82209\n",
      "Batch train [1] loss 0.23016, dsc 0.76984\n",
      "Batch train [1] loss 0.18169, dsc 0.81831\n",
      "Batch train [1] loss 0.25637, dsc 0.74363\n",
      "Batch train [1] loss 0.18248, dsc 0.81752\n",
      "Batch train [1] loss 0.19321, dsc 0.80679\n",
      "Batch train [1] loss 0.21235, dsc 0.78765\n",
      "Batch train [1] loss 0.17099, dsc 0.82901\n",
      "Batch train [1] loss 0.17562, dsc 0.82438\n",
      "Batch train [1] loss 0.20437, dsc 0.79563\n",
      "Batch train [1] loss 0.15686, dsc 0.84314\n",
      "Batch train [1] loss 0.21691, dsc 0.78309\n",
      "Batch train [1] loss 0.21818, dsc 0.78182\n",
      "Batch train [1] loss 0.22857, dsc 0.77143\n",
      "Batch train [1] loss 0.15300, dsc 0.84700\n",
      "Batch train [1] loss 0.24826, dsc 0.75174\n",
      "Batch train [1] loss 0.17285, dsc 0.82715\n",
      "Batch train [1] loss 0.15789, dsc 0.84211\n",
      "Batch train [1] loss 0.23479, dsc 0.76521\n",
      "Epoch [39] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 38, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  38, step 0\n",
      "Batch eval [1] loss 0.27557, dsc 0.72443\n",
      "Batch eval [1] loss 0.27795, dsc 0.72205\n",
      "Batch eval [1] loss 0.30319, dsc 0.69681\n",
      "Batch eval [1] loss 0.28580, dsc 0.71420\n",
      "Batch eval [1] loss 0.39754, dsc 0.60246\n",
      "Epoch [39] valid done\n",
      "Epoch [39] T 4764.97s, deltaT 121.73s, loss: train 0.20673, valid 0.30801, dsc: train 0.79327, valid 0.69199\n",
      "DEBUG: Writing to tensorboard before epoch True, 39, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  39, step 0\n",
      "Batch train [1] loss 0.13607, dsc 0.86393\n",
      "Batch train [1] loss 0.17722, dsc 0.82278\n",
      "Batch train [1] loss 0.20313, dsc 0.79687\n",
      "Batch train [1] loss 0.17339, dsc 0.82661\n",
      "Batch train [1] loss 0.19182, dsc 0.80818\n",
      "Batch train [1] loss 0.18715, dsc 0.81285\n",
      "Batch train [1] loss 0.26338, dsc 0.73662\n",
      "Batch train [1] loss 0.20638, dsc 0.79362\n",
      "Batch train [1] loss 0.18699, dsc 0.81301\n",
      "Batch train [1] loss 0.25848, dsc 0.74152\n",
      "Batch train [1] loss 0.23981, dsc 0.76019\n",
      "Batch train [1] loss 0.14761, dsc 0.85239\n",
      "Batch train [1] loss 0.19594, dsc 0.80406\n",
      "Batch train [1] loss 0.20881, dsc 0.79119\n",
      "Batch train [1] loss 0.15558, dsc 0.84442\n",
      "Batch train [1] loss 0.22496, dsc 0.77504\n",
      "Batch train [1] loss 0.17830, dsc 0.82170\n",
      "Batch train [1] loss 0.24771, dsc 0.75229\n",
      "Batch train [1] loss 0.17499, dsc 0.82501\n",
      "Batch train [1] loss 0.15929, dsc 0.84071\n",
      "Batch train [1] loss 0.23990, dsc 0.76010\n",
      "Batch train [1] loss 0.21960, dsc 0.78040\n",
      "Batch train [1] loss 0.16736, dsc 0.83264\n",
      "Batch train [1] loss 0.16254, dsc 0.83746\n",
      "Batch train [1] loss 0.19918, dsc 0.80082\n",
      "Batch train [1] loss 0.18603, dsc 0.81397\n",
      "Batch train [1] loss 0.15513, dsc 0.84487\n",
      "Batch train [1] loss 0.22392, dsc 0.77608\n",
      "Batch train [1] loss 0.27587, dsc 0.72413\n",
      "Batch train [1] loss 0.17608, dsc 0.82392\n",
      "Batch train [1] loss 0.17178, dsc 0.82822\n",
      "Batch train [1] loss 0.20814, dsc 0.79186\n",
      "Batch train [1] loss 0.18230, dsc 0.81770\n",
      "Batch train [1] loss 0.21654, dsc 0.78346\n",
      "Batch train [1] loss 0.15889, dsc 0.84111\n",
      "Batch train [1] loss 0.21263, dsc 0.78737\n",
      "Batch train [1] loss 0.21135, dsc 0.78865\n",
      "Batch train [1] loss 0.27640, dsc 0.72360\n",
      "Batch train [1] loss 0.28515, dsc 0.71485\n",
      "Batch train [1] loss 0.17423, dsc 0.82577\n",
      "Epoch [40] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 39, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  39, step 0\n",
      "Batch eval [1] loss 0.19502, dsc 0.80498\n",
      "Batch eval [1] loss 0.26720, dsc 0.73280\n",
      "Batch eval [1] loss 0.28686, dsc 0.71314\n",
      "Batch eval [1] loss 0.29369, dsc 0.70631\n",
      "Batch eval [1] loss 0.39231, dsc 0.60769\n",
      "Epoch [40] valid done\n",
      "Epoch [40] T 4886.64s, deltaT 121.66s, loss: train 0.20050, valid 0.28702, dsc: train 0.79950, valid 0.71298\n",
      "DEBUG: Writing to tensorboard before epoch True, 40, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  40, step 0\n",
      "Batch train [1] loss 0.16720, dsc 0.83280\n",
      "Batch train [1] loss 0.16944, dsc 0.83056\n",
      "Batch train [1] loss 0.20887, dsc 0.79113\n",
      "Batch train [1] loss 0.17458, dsc 0.82542\n",
      "Batch train [1] loss 0.21454, dsc 0.78546\n",
      "Batch train [1] loss 0.14911, dsc 0.85089\n",
      "Batch train [1] loss 0.23776, dsc 0.76224\n",
      "Batch train [1] loss 0.18505, dsc 0.81495\n",
      "Batch train [1] loss 0.26160, dsc 0.73840\n",
      "Batch train [1] loss 0.17835, dsc 0.82165\n",
      "Batch train [1] loss 0.20486, dsc 0.79514\n",
      "Batch train [1] loss 0.24359, dsc 0.75641\n",
      "Batch train [1] loss 0.21766, dsc 0.78234\n",
      "Batch train [1] loss 0.17584, dsc 0.82416\n",
      "Batch train [1] loss 0.16747, dsc 0.83253\n",
      "Batch train [1] loss 0.16189, dsc 0.83811\n",
      "Batch train [1] loss 0.17180, dsc 0.82820\n",
      "Batch train [1] loss 0.16098, dsc 0.83902\n",
      "Batch train [1] loss 0.18218, dsc 0.81782\n",
      "Batch train [1] loss 0.21401, dsc 0.78599\n",
      "Batch train [1] loss 0.15651, dsc 0.84349\n",
      "Batch train [1] loss 0.18522, dsc 0.81478\n",
      "Batch train [1] loss 0.23787, dsc 0.76213\n",
      "Batch train [1] loss 0.16951, dsc 0.83049\n",
      "Batch train [1] loss 0.16823, dsc 0.83177\n",
      "Batch train [1] loss 0.23464, dsc 0.76536\n",
      "Batch train [1] loss 0.14383, dsc 0.85617\n",
      "Batch train [1] loss 0.19866, dsc 0.80134\n",
      "Batch train [1] loss 0.24201, dsc 0.75799\n",
      "Batch train [1] loss 0.21895, dsc 0.78105\n",
      "Batch train [1] loss 0.11411, dsc 0.88589\n",
      "Batch train [1] loss 0.20599, dsc 0.79401\n",
      "Batch train [1] loss 0.16626, dsc 0.83374\n",
      "Batch train [1] loss 0.24953, dsc 0.75047\n",
      "Batch train [1] loss 0.24761, dsc 0.75239\n",
      "Batch train [1] loss 0.15415, dsc 0.84585\n",
      "Batch train [1] loss 0.19817, dsc 0.80183\n",
      "Batch train [1] loss 0.16138, dsc 0.83862\n",
      "Batch train [1] loss 0.14676, dsc 0.85324\n",
      "Batch train [1] loss 0.21465, dsc 0.78535\n",
      "Epoch [41] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 40, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  40, step 0\n",
      "Batch eval [1] loss 0.22329, dsc 0.77671\n",
      "Batch eval [1] loss 0.22090, dsc 0.77910\n",
      "Batch eval [1] loss 0.34051, dsc 0.65949\n",
      "Batch eval [1] loss 0.24970, dsc 0.75030\n",
      "Batch eval [1] loss 0.37538, dsc 0.62462\n",
      "Epoch [41] valid done\n",
      "Epoch [41] T 5008.36s, deltaT 121.72s, loss: train 0.19152, valid 0.28195, dsc: train 0.80848, valid 0.71805\n",
      "DEBUG: Writing to tensorboard before epoch True, 41, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  41, step 0\n",
      "Batch train [1] loss 0.15620, dsc 0.84380\n",
      "Batch train [1] loss 0.14904, dsc 0.85096\n",
      "Batch train [1] loss 0.19090, dsc 0.80910\n",
      "Batch train [1] loss 0.14342, dsc 0.85658\n",
      "Batch train [1] loss 0.23577, dsc 0.76423\n",
      "Batch train [1] loss 0.22234, dsc 0.77766\n",
      "Batch train [1] loss 0.16459, dsc 0.83541\n",
      "Batch train [1] loss 0.13913, dsc 0.86087\n",
      "Batch train [1] loss 0.14811, dsc 0.85189\n",
      "Batch train [1] loss 0.15942, dsc 0.84058\n",
      "Batch train [1] loss 0.19459, dsc 0.80541\n",
      "Batch train [1] loss 0.13820, dsc 0.86180\n",
      "Batch train [1] loss 0.19266, dsc 0.80734\n",
      "Batch train [1] loss 0.20795, dsc 0.79205\n",
      "Batch train [1] loss 0.13780, dsc 0.86220\n",
      "Batch train [1] loss 0.14576, dsc 0.85424\n",
      "Batch train [1] loss 0.18348, dsc 0.81652\n",
      "Batch train [1] loss 0.16845, dsc 0.83155\n",
      "Batch train [1] loss 0.22029, dsc 0.77971\n",
      "Batch train [1] loss 0.21258, dsc 0.78742\n",
      "Batch train [1] loss 0.14986, dsc 0.85014\n",
      "Batch train [1] loss 0.19767, dsc 0.80233\n",
      "Batch train [1] loss 0.15517, dsc 0.84483\n",
      "Batch train [1] loss 0.19174, dsc 0.80826\n",
      "Batch train [1] loss 0.17392, dsc 0.82608\n",
      "Batch train [1] loss 0.22085, dsc 0.77915\n",
      "Batch train [1] loss 0.17030, dsc 0.82970\n",
      "Batch train [1] loss 0.24732, dsc 0.75268\n",
      "Batch train [1] loss 0.19605, dsc 0.80395\n",
      "Batch train [1] loss 0.17016, dsc 0.82984\n",
      "Batch train [1] loss 0.18673, dsc 0.81327\n",
      "Batch train [1] loss 0.14309, dsc 0.85691\n",
      "Batch train [1] loss 0.21534, dsc 0.78466\n",
      "Batch train [1] loss 0.17694, dsc 0.82306\n",
      "Batch train [1] loss 0.13306, dsc 0.86694\n",
      "Batch train [1] loss 0.22798, dsc 0.77202\n",
      "Batch train [1] loss 0.21158, dsc 0.78842\n",
      "Batch train [1] loss 0.14704, dsc 0.85296\n",
      "Batch train [1] loss 0.17735, dsc 0.82265\n",
      "Batch train [1] loss 0.22124, dsc 0.77876\n",
      "Epoch [42] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 41, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  41, step 0\n",
      "Batch eval [1] loss 0.17024, dsc 0.82976\n",
      "Batch eval [1] loss 0.17073, dsc 0.82927\n",
      "Batch eval [1] loss 0.23542, dsc 0.76458\n",
      "Batch eval [1] loss 0.17551, dsc 0.82449\n",
      "Batch eval [1] loss 0.28305, dsc 0.71695\n",
      "Epoch [42] valid done\n",
      "Epoch [42] T 5129.99s, deltaT 121.62s, loss: train 0.18060, valid 0.20699, dsc: train 0.81940, valid 0.79301\n",
      "DEBUG: Writing to tensorboard before epoch True, 42, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  42, step 0\n",
      "Batch train [1] loss 0.15382, dsc 0.84618\n",
      "Batch train [1] loss 0.18737, dsc 0.81263\n",
      "Batch train [1] loss 0.15985, dsc 0.84015\n",
      "Batch train [1] loss 0.24597, dsc 0.75403\n",
      "Batch train [1] loss 0.20272, dsc 0.79728\n",
      "Batch train [1] loss 0.16400, dsc 0.83600\n",
      "Batch train [1] loss 0.14771, dsc 0.85229\n",
      "Batch train [1] loss 0.20020, dsc 0.79980\n",
      "Batch train [1] loss 0.15359, dsc 0.84641\n",
      "Batch train [1] loss 0.14816, dsc 0.85184\n",
      "Batch train [1] loss 0.22750, dsc 0.77250\n",
      "Batch train [1] loss 0.12343, dsc 0.87657\n",
      "Batch train [1] loss 0.18519, dsc 0.81481\n",
      "Batch train [1] loss 0.13675, dsc 0.86325\n",
      "Batch train [1] loss 0.13968, dsc 0.86032\n",
      "Batch train [1] loss 0.22398, dsc 0.77602\n",
      "Batch train [1] loss 0.17555, dsc 0.82445\n",
      "Batch train [1] loss 0.13284, dsc 0.86716\n",
      "Batch train [1] loss 0.14968, dsc 0.85032\n",
      "Batch train [1] loss 0.14547, dsc 0.85453\n",
      "Batch train [1] loss 0.22002, dsc 0.77998\n",
      "Batch train [1] loss 0.16002, dsc 0.83998\n",
      "Batch train [1] loss 0.14158, dsc 0.85842\n",
      "Batch train [1] loss 0.23046, dsc 0.76954\n",
      "Batch train [1] loss 0.21555, dsc 0.78445\n",
      "Batch train [1] loss 0.14311, dsc 0.85689\n",
      "Batch train [1] loss 0.15335, dsc 0.84665\n",
      "Batch train [1] loss 0.20779, dsc 0.79221\n",
      "Batch train [1] loss 0.18570, dsc 0.81430\n",
      "Batch train [1] loss 0.15367, dsc 0.84633\n",
      "Batch train [1] loss 0.17528, dsc 0.82472\n",
      "Batch train [1] loss 0.14762, dsc 0.85238\n",
      "Batch train [1] loss 0.16285, dsc 0.83715\n",
      "Batch train [1] loss 0.14410, dsc 0.85590\n",
      "Batch train [1] loss 0.19729, dsc 0.80271\n",
      "Batch train [1] loss 0.16507, dsc 0.83493\n",
      "Batch train [1] loss 0.17112, dsc 0.82888\n",
      "Batch train [1] loss 0.15604, dsc 0.84396\n",
      "Batch train [1] loss 0.17732, dsc 0.82268\n",
      "Batch train [1] loss 0.18099, dsc 0.81901\n",
      "Epoch [43] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 42, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  42, step 0\n",
      "Batch eval [1] loss 0.23268, dsc 0.76732\n",
      "Batch eval [1] loss 0.17919, dsc 0.82081\n",
      "Batch eval [1] loss 0.24913, dsc 0.75087\n",
      "Batch eval [1] loss 0.19399, dsc 0.80601\n",
      "Batch eval [1] loss 0.29694, dsc 0.70306\n",
      "Epoch [43] valid done\n",
      "Epoch [43] T 5251.69s, deltaT 121.69s, loss: train 0.17231, valid 0.23039, dsc: train 0.82769, valid 0.76961\n",
      "DEBUG: Writing to tensorboard before epoch True, 43, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  43, step 0\n",
      "Batch train [1] loss 0.21263, dsc 0.78737\n",
      "Batch train [1] loss 0.16012, dsc 0.83988\n",
      "Batch train [1] loss 0.19519, dsc 0.80481\n",
      "Batch train [1] loss 0.15622, dsc 0.84378\n",
      "Batch train [1] loss 0.22909, dsc 0.77091\n",
      "Batch train [1] loss 0.16459, dsc 0.83541\n",
      "Batch train [1] loss 0.13202, dsc 0.86798\n",
      "Batch train [1] loss 0.20113, dsc 0.79887\n",
      "Batch train [1] loss 0.13232, dsc 0.86768\n",
      "Batch train [1] loss 0.17316, dsc 0.82684\n",
      "Batch train [1] loss 0.20247, dsc 0.79753\n",
      "Batch train [1] loss 0.14996, dsc 0.85004\n",
      "Batch train [1] loss 0.17626, dsc 0.82374\n",
      "Batch train [1] loss 0.19827, dsc 0.80173\n",
      "Batch train [1] loss 0.16372, dsc 0.83628\n",
      "Batch train [1] loss 0.18917, dsc 0.81083\n",
      "Batch train [1] loss 0.17967, dsc 0.82033\n",
      "Batch train [1] loss 0.20521, dsc 0.79479\n",
      "Batch train [1] loss 0.17315, dsc 0.82685\n",
      "Batch train [1] loss 0.16138, dsc 0.83862\n",
      "Batch train [1] loss 0.13788, dsc 0.86212\n",
      "Batch train [1] loss 0.12190, dsc 0.87810\n",
      "Batch train [1] loss 0.17020, dsc 0.82980\n",
      "Batch train [1] loss 0.14357, dsc 0.85643\n",
      "Batch train [1] loss 0.16913, dsc 0.83087\n",
      "Batch train [1] loss 0.15061, dsc 0.84939\n",
      "Batch train [1] loss 0.20405, dsc 0.79595\n",
      "Batch train [1] loss 0.14045, dsc 0.85955\n",
      "Batch train [1] loss 0.12707, dsc 0.87293\n",
      "Batch train [1] loss 0.20842, dsc 0.79158\n",
      "Batch train [1] loss 0.24944, dsc 0.75056\n",
      "Batch train [1] loss 0.19119, dsc 0.80881\n",
      "Batch train [1] loss 0.16618, dsc 0.83382\n",
      "Batch train [1] loss 0.14835, dsc 0.85165\n",
      "Batch train [1] loss 0.15157, dsc 0.84843\n",
      "Batch train [1] loss 0.18378, dsc 0.81622\n",
      "Batch train [1] loss 0.15942, dsc 0.84058\n",
      "Batch train [1] loss 0.12334, dsc 0.87666\n",
      "Batch train [1] loss 0.15266, dsc 0.84734\n",
      "Batch train [1] loss 0.13792, dsc 0.86208\n",
      "Epoch [44] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 43, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  43, step 0\n",
      "Batch eval [1] loss 0.16550, dsc 0.83450\n",
      "Batch eval [1] loss 0.17707, dsc 0.82293\n",
      "Batch eval [1] loss 0.23386, dsc 0.76614\n",
      "Batch eval [1] loss 0.17597, dsc 0.82403\n",
      "Batch eval [1] loss 0.31887, dsc 0.68113\n",
      "Epoch [44] valid done\n",
      "Epoch [44] T 5373.45s, deltaT 121.75s, loss: train 0.16982, valid 0.21425, dsc: train 0.83018, valid 0.78575\n",
      "DEBUG: Writing to tensorboard before epoch True, 44, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  44, step 0\n",
      "Batch train [1] loss 0.17956, dsc 0.82044\n",
      "Batch train [1] loss 0.19181, dsc 0.80819\n",
      "Batch train [1] loss 0.19098, dsc 0.80902\n",
      "Batch train [1] loss 0.14229, dsc 0.85771\n",
      "Batch train [1] loss 0.21256, dsc 0.78744\n",
      "Batch train [1] loss 0.18523, dsc 0.81477\n",
      "Batch train [1] loss 0.17452, dsc 0.82548\n",
      "Batch train [1] loss 0.15206, dsc 0.84794\n",
      "Batch train [1] loss 0.18399, dsc 0.81601\n",
      "Batch train [1] loss 0.20828, dsc 0.79172\n",
      "Batch train [1] loss 0.14418, dsc 0.85582\n",
      "Batch train [1] loss 0.14927, dsc 0.85073\n",
      "Batch train [1] loss 0.13521, dsc 0.86479\n",
      "Batch train [1] loss 0.17114, dsc 0.82886\n",
      "Batch train [1] loss 0.19281, dsc 0.80719\n",
      "Batch train [1] loss 0.16928, dsc 0.83072\n",
      "Batch train [1] loss 0.14385, dsc 0.85615\n",
      "Batch train [1] loss 0.13145, dsc 0.86855\n",
      "Batch train [1] loss 0.12456, dsc 0.87544\n",
      "Batch train [1] loss 0.19183, dsc 0.80817\n",
      "Batch train [1] loss 0.23675, dsc 0.76325\n",
      "Batch train [1] loss 0.15944, dsc 0.84056\n",
      "Batch train [1] loss 0.21310, dsc 0.78690\n",
      "Batch train [1] loss 0.14129, dsc 0.85871\n",
      "Batch train [1] loss 0.19154, dsc 0.80846\n",
      "Batch train [1] loss 0.12800, dsc 0.87200\n",
      "Batch train [1] loss 0.13844, dsc 0.86156\n",
      "Batch train [1] loss 0.19376, dsc 0.80624\n",
      "Batch train [1] loss 0.15201, dsc 0.84799\n",
      "Batch train [1] loss 0.15197, dsc 0.84803\n",
      "Batch train [1] loss 0.15365, dsc 0.84635\n",
      "Batch train [1] loss 0.15396, dsc 0.84604\n",
      "Batch train [1] loss 0.16900, dsc 0.83100\n",
      "Batch train [1] loss 0.14929, dsc 0.85071\n",
      "Batch train [1] loss 0.12802, dsc 0.87198\n",
      "Batch train [1] loss 0.17775, dsc 0.82225\n",
      "Batch train [1] loss 0.14102, dsc 0.85898\n",
      "Batch train [1] loss 0.13042, dsc 0.86958\n",
      "Batch train [1] loss 0.11556, dsc 0.88444\n",
      "Batch train [1] loss 0.18514, dsc 0.81486\n",
      "Epoch [45] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 44, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  44, step 0\n",
      "Batch eval [1] loss 0.34316, dsc 0.65684\n",
      "Batch eval [1] loss 0.15189, dsc 0.84811\n",
      "Batch eval [1] loss 0.32561, dsc 0.67439\n",
      "Batch eval [1] loss 0.19822, dsc 0.80178\n",
      "Batch eval [1] loss 0.26611, dsc 0.73389\n",
      "Epoch [45] valid done\n",
      "Epoch [45] T 5495.05s, deltaT 121.60s, loss: train 0.16462, valid 0.25700, dsc: train 0.83538, valid 0.74300\n",
      "DEBUG: Writing to tensorboard before epoch True, 45, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  45, step 0\n",
      "Batch train [1] loss 0.14452, dsc 0.85548\n",
      "Batch train [1] loss 0.14439, dsc 0.85561\n",
      "Batch train [1] loss 0.16262, dsc 0.83738\n",
      "Batch train [1] loss 0.13526, dsc 0.86474\n",
      "Batch train [1] loss 0.17982, dsc 0.82018\n",
      "Batch train [1] loss 0.13187, dsc 0.86813\n",
      "Batch train [1] loss 0.18025, dsc 0.81975\n",
      "Batch train [1] loss 0.20624, dsc 0.79376\n",
      "Batch train [1] loss 0.16623, dsc 0.83377\n",
      "Batch train [1] loss 0.14573, dsc 0.85427\n",
      "Batch train [1] loss 0.19927, dsc 0.80073\n",
      "Batch train [1] loss 0.16395, dsc 0.83605\n",
      "Batch train [1] loss 0.13683, dsc 0.86317\n",
      "Batch train [1] loss 0.14568, dsc 0.85432\n",
      "Batch train [1] loss 0.11094, dsc 0.88906\n",
      "Batch train [1] loss 0.15384, dsc 0.84616\n",
      "Batch train [1] loss 0.17802, dsc 0.82198\n",
      "Batch train [1] loss 0.13841, dsc 0.86159\n",
      "Batch train [1] loss 0.18088, dsc 0.81912\n",
      "Batch train [1] loss 0.16271, dsc 0.83729\n",
      "Batch train [1] loss 0.17562, dsc 0.82438\n",
      "Batch train [1] loss 0.19075, dsc 0.80925\n",
      "Batch train [1] loss 0.16025, dsc 0.83975\n",
      "Batch train [1] loss 0.14206, dsc 0.85794\n",
      "Batch train [1] loss 0.14023, dsc 0.85977\n",
      "Batch train [1] loss 0.12789, dsc 0.87211\n",
      "Batch train [1] loss 0.16163, dsc 0.83837\n",
      "Batch train [1] loss 0.21071, dsc 0.78929\n",
      "Batch train [1] loss 0.18392, dsc 0.81608\n",
      "Batch train [1] loss 0.13365, dsc 0.86635\n",
      "Batch train [1] loss 0.12891, dsc 0.87109\n",
      "Batch train [1] loss 0.14666, dsc 0.85334\n",
      "Batch train [1] loss 0.18710, dsc 0.81290\n",
      "Batch train [1] loss 0.12116, dsc 0.87884\n",
      "Batch train [1] loss 0.14194, dsc 0.85806\n",
      "Batch train [1] loss 0.12328, dsc 0.87672\n",
      "Batch train [1] loss 0.15110, dsc 0.84890\n",
      "Batch train [1] loss 0.13933, dsc 0.86067\n",
      "Batch train [1] loss 0.12588, dsc 0.87412\n",
      "Batch train [1] loss 0.22883, dsc 0.77117\n",
      "Epoch [46] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 45, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  45, step 0\n",
      "Batch eval [1] loss 0.16770, dsc 0.83230\n",
      "Batch eval [1] loss 0.14511, dsc 0.85489\n",
      "Batch eval [1] loss 0.21493, dsc 0.78507\n",
      "Batch eval [1] loss 0.14179, dsc 0.85821\n",
      "Batch eval [1] loss 0.28294, dsc 0.71706\n",
      "Epoch [46] valid done\n",
      "Epoch [46] T 5616.71s, deltaT 121.66s, loss: train 0.15721, valid 0.19049, dsc: train 0.84279, valid 0.80951\n",
      "DEBUG: Writing to tensorboard before epoch True, 46, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  46, step 0\n",
      "Batch train [1] loss 0.18866, dsc 0.81134\n",
      "Batch train [1] loss 0.17736, dsc 0.82264\n",
      "Batch train [1] loss 0.13677, dsc 0.86323\n",
      "Batch train [1] loss 0.16845, dsc 0.83155\n",
      "Batch train [1] loss 0.16999, dsc 0.83001\n",
      "Batch train [1] loss 0.20090, dsc 0.79910\n",
      "Batch train [1] loss 0.18958, dsc 0.81042\n",
      "Batch train [1] loss 0.15669, dsc 0.84331\n",
      "Batch train [1] loss 0.15091, dsc 0.84909\n",
      "Batch train [1] loss 0.14885, dsc 0.85115\n",
      "Batch train [1] loss 0.18219, dsc 0.81781\n",
      "Batch train [1] loss 0.14533, dsc 0.85467\n",
      "Batch train [1] loss 0.16229, dsc 0.83771\n",
      "Batch train [1] loss 0.13011, dsc 0.86989\n",
      "Batch train [1] loss 0.16027, dsc 0.83973\n",
      "Batch train [1] loss 0.23367, dsc 0.76633\n",
      "Batch train [1] loss 0.16772, dsc 0.83228\n",
      "Batch train [1] loss 0.20461, dsc 0.79539\n",
      "Batch train [1] loss 0.16126, dsc 0.83874\n",
      "Batch train [1] loss 0.14591, dsc 0.85409\n",
      "Batch train [1] loss 0.14616, dsc 0.85384\n",
      "Batch train [1] loss 0.13810, dsc 0.86190\n",
      "Batch train [1] loss 0.15443, dsc 0.84557\n",
      "Batch train [1] loss 0.12538, dsc 0.87462\n",
      "Batch train [1] loss 0.14224, dsc 0.85776\n",
      "Batch train [1] loss 0.21727, dsc 0.78273\n",
      "Batch train [1] loss 0.11002, dsc 0.88998\n",
      "Batch train [1] loss 0.14390, dsc 0.85610\n",
      "Batch train [1] loss 0.12765, dsc 0.87235\n",
      "Batch train [1] loss 0.17869, dsc 0.82131\n",
      "Batch train [1] loss 0.13421, dsc 0.86579\n",
      "Batch train [1] loss 0.13452, dsc 0.86548\n",
      "Batch train [1] loss 0.19182, dsc 0.80818\n",
      "Batch train [1] loss 0.13615, dsc 0.86385\n",
      "Batch train [1] loss 0.15353, dsc 0.84647\n",
      "Batch train [1] loss 0.20961, dsc 0.79039\n",
      "Batch train [1] loss 0.15037, dsc 0.84963\n",
      "Batch train [1] loss 0.19133, dsc 0.80867\n",
      "Batch train [1] loss 0.16406, dsc 0.83594\n",
      "Batch train [1] loss 0.12319, dsc 0.87681\n",
      "Epoch [47] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 46, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  46, step 0\n",
      "Batch eval [1] loss 0.19642, dsc 0.80358\n",
      "Batch eval [1] loss 0.13425, dsc 0.86575\n",
      "Batch eval [1] loss 0.27071, dsc 0.72929\n",
      "Batch eval [1] loss 0.16362, dsc 0.83638\n",
      "Batch eval [1] loss 0.26113, dsc 0.73887\n",
      "Epoch [47] valid done\n",
      "Epoch [47] T 5738.41s, deltaT 121.69s, loss: train 0.16135, valid 0.20523, dsc: train 0.83865, valid 0.79477\n",
      "DEBUG: Writing to tensorboard before epoch True, 47, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  47, step 0\n",
      "Batch train [1] loss 0.16182, dsc 0.83818\n",
      "Batch train [1] loss 0.21554, dsc 0.78446\n",
      "Batch train [1] loss 0.18505, dsc 0.81495\n",
      "Batch train [1] loss 0.12831, dsc 0.87169\n",
      "Batch train [1] loss 0.14173, dsc 0.85827\n",
      "Batch train [1] loss 0.13453, dsc 0.86547\n",
      "Batch train [1] loss 0.13682, dsc 0.86318\n",
      "Batch train [1] loss 0.15310, dsc 0.84690\n",
      "Batch train [1] loss 0.12432, dsc 0.87568\n",
      "Batch train [1] loss 0.12638, dsc 0.87362\n",
      "Batch train [1] loss 0.11603, dsc 0.88397\n",
      "Batch train [1] loss 0.13516, dsc 0.86484\n",
      "Batch train [1] loss 0.10398, dsc 0.89602\n",
      "Batch train [1] loss 0.14650, dsc 0.85350\n",
      "Batch train [1] loss 0.15025, dsc 0.84975\n",
      "Batch train [1] loss 0.11937, dsc 0.88063\n",
      "Batch train [1] loss 0.17743, dsc 0.82257\n",
      "Batch train [1] loss 0.18315, dsc 0.81685\n",
      "Batch train [1] loss 0.13541, dsc 0.86459\n",
      "Batch train [1] loss 0.12799, dsc 0.87201\n",
      "Batch train [1] loss 0.18293, dsc 0.81707\n",
      "Batch train [1] loss 0.13599, dsc 0.86401\n",
      "Batch train [1] loss 0.17977, dsc 0.82023\n",
      "Batch train [1] loss 0.12151, dsc 0.87849\n",
      "Batch train [1] loss 0.17276, dsc 0.82724\n",
      "Batch train [1] loss 0.15664, dsc 0.84336\n",
      "Batch train [1] loss 0.15178, dsc 0.84822\n",
      "Batch train [1] loss 0.20575, dsc 0.79425\n",
      "Batch train [1] loss 0.14439, dsc 0.85561\n",
      "Batch train [1] loss 0.12434, dsc 0.87566\n",
      "Batch train [1] loss 0.13487, dsc 0.86513\n",
      "Batch train [1] loss 0.18797, dsc 0.81203\n",
      "Batch train [1] loss 0.15333, dsc 0.84667\n",
      "Batch train [1] loss 0.13204, dsc 0.86796\n",
      "Batch train [1] loss 0.17885, dsc 0.82115\n",
      "Batch train [1] loss 0.12481, dsc 0.87519\n",
      "Batch train [1] loss 0.18194, dsc 0.81806\n",
      "Batch train [1] loss 0.16475, dsc 0.83525\n",
      "Batch train [1] loss 0.17266, dsc 0.82734\n",
      "Batch train [1] loss 0.14166, dsc 0.85834\n",
      "Epoch [48] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 47, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  47, step 0\n",
      "Batch eval [1] loss 0.20715, dsc 0.79285\n",
      "Batch eval [1] loss 0.17166, dsc 0.82834\n",
      "Batch eval [1] loss 0.30343, dsc 0.69657\n",
      "Batch eval [1] loss 0.18209, dsc 0.81791\n",
      "Batch eval [1] loss 0.30461, dsc 0.69539\n",
      "Epoch [48] valid done\n",
      "Epoch [48] T 5860.55s, deltaT 122.13s, loss: train 0.15129, valid 0.23379, dsc: train 0.84871, valid 0.76621\n",
      "DEBUG: Writing to tensorboard before epoch True, 48, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  48, step 0\n",
      "Batch train [1] loss 0.15520, dsc 0.84480\n",
      "Batch train [1] loss 0.12492, dsc 0.87508\n",
      "Batch train [1] loss 0.15170, dsc 0.84830\n",
      "Batch train [1] loss 0.14396, dsc 0.85604\n",
      "Batch train [1] loss 0.16239, dsc 0.83761\n",
      "Batch train [1] loss 0.13190, dsc 0.86810\n",
      "Batch train [1] loss 0.10014, dsc 0.89986\n",
      "Batch train [1] loss 0.19227, dsc 0.80773\n",
      "Batch train [1] loss 0.10735, dsc 0.89265\n",
      "Batch train [1] loss 0.15056, dsc 0.84944\n",
      "Batch train [1] loss 0.17168, dsc 0.82832\n",
      "Batch train [1] loss 0.19309, dsc 0.80691\n",
      "Batch train [1] loss 0.12489, dsc 0.87511\n",
      "Batch train [1] loss 0.15031, dsc 0.84969\n",
      "Batch train [1] loss 0.16396, dsc 0.83604\n",
      "Batch train [1] loss 0.11488, dsc 0.88512\n",
      "Batch train [1] loss 0.18177, dsc 0.81823\n",
      "Batch train [1] loss 0.18097, dsc 0.81903\n",
      "Batch train [1] loss 0.17741, dsc 0.82259\n",
      "Batch train [1] loss 0.11297, dsc 0.88703\n",
      "Batch train [1] loss 0.13572, dsc 0.86428\n",
      "Batch train [1] loss 0.17448, dsc 0.82552\n",
      "Batch train [1] loss 0.17698, dsc 0.82302\n",
      "Batch train [1] loss 0.12052, dsc 0.87948\n",
      "Batch train [1] loss 0.14700, dsc 0.85300\n",
      "Batch train [1] loss 0.12855, dsc 0.87145\n",
      "Batch train [1] loss 0.14139, dsc 0.85861\n",
      "Batch train [1] loss 0.14237, dsc 0.85763\n",
      "Batch train [1] loss 0.13972, dsc 0.86028\n",
      "Batch train [1] loss 0.15421, dsc 0.84579\n",
      "Batch train [1] loss 0.14924, dsc 0.85076\n",
      "Batch train [1] loss 0.19534, dsc 0.80466\n",
      "Batch train [1] loss 0.20553, dsc 0.79447\n",
      "Batch train [1] loss 0.12650, dsc 0.87350\n",
      "Batch train [1] loss 0.15178, dsc 0.84822\n",
      "Batch train [1] loss 0.14005, dsc 0.85995\n",
      "Batch train [1] loss 0.12955, dsc 0.87045\n",
      "Batch train [1] loss 0.17798, dsc 0.82202\n",
      "Batch train [1] loss 0.17398, dsc 0.82602\n",
      "Batch train [1] loss 0.14425, dsc 0.85575\n",
      "Epoch [49] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 48, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  48, step 0\n",
      "Batch eval [1] loss 0.16687, dsc 0.83313\n",
      "Batch eval [1] loss 0.16526, dsc 0.83474\n",
      "Batch eval [1] loss 0.24474, dsc 0.75526\n",
      "Batch eval [1] loss 0.16067, dsc 0.83933\n",
      "Batch eval [1] loss 0.27990, dsc 0.72010\n",
      "Epoch [49] valid done\n",
      "Epoch [49] T 5982.90s, deltaT 122.34s, loss: train 0.15119, valid 0.20349, dsc: train 0.84881, valid 0.79651\n",
      "DEBUG: Writing to tensorboard before epoch True, 49, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  49, step 0\n",
      "Batch train [1] loss 0.15364, dsc 0.84636\n",
      "Batch train [1] loss 0.14120, dsc 0.85880\n",
      "Batch train [1] loss 0.11557, dsc 0.88443\n",
      "Batch train [1] loss 0.14705, dsc 0.85295\n",
      "Batch train [1] loss 0.12439, dsc 0.87561\n",
      "Batch train [1] loss 0.16694, dsc 0.83306\n",
      "Batch train [1] loss 0.12225, dsc 0.87775\n",
      "Batch train [1] loss 0.13249, dsc 0.86751\n",
      "Batch train [1] loss 0.10119, dsc 0.89881\n",
      "Batch train [1] loss 0.14154, dsc 0.85846\n",
      "Batch train [1] loss 0.14327, dsc 0.85673\n",
      "Batch train [1] loss 0.11732, dsc 0.88268\n",
      "Batch train [1] loss 0.12398, dsc 0.87602\n",
      "Batch train [1] loss 0.12651, dsc 0.87349\n",
      "Batch train [1] loss 0.16915, dsc 0.83085\n",
      "Batch train [1] loss 0.15648, dsc 0.84352\n",
      "Batch train [1] loss 0.12120, dsc 0.87880\n",
      "Batch train [1] loss 0.13506, dsc 0.86494\n",
      "Batch train [1] loss 0.13920, dsc 0.86080\n",
      "Batch train [1] loss 0.14815, dsc 0.85185\n",
      "Batch train [1] loss 0.15447, dsc 0.84553\n",
      "Batch train [1] loss 0.16716, dsc 0.83284\n",
      "Batch train [1] loss 0.13005, dsc 0.86995\n",
      "Batch train [1] loss 0.16703, dsc 0.83297\n",
      "Batch train [1] loss 0.12851, dsc 0.87149\n",
      "Batch train [1] loss 0.15209, dsc 0.84791\n",
      "Batch train [1] loss 0.15258, dsc 0.84742\n",
      "Batch train [1] loss 0.19747, dsc 0.80253\n",
      "Batch train [1] loss 0.16201, dsc 0.83799\n",
      "Batch train [1] loss 0.15667, dsc 0.84333\n",
      "Batch train [1] loss 0.19515, dsc 0.80485\n",
      "Batch train [1] loss 0.18486, dsc 0.81514\n",
      "Batch train [1] loss 0.12403, dsc 0.87597\n",
      "Batch train [1] loss 0.14638, dsc 0.85362\n",
      "Batch train [1] loss 0.16284, dsc 0.83716\n",
      "Batch train [1] loss 0.19061, dsc 0.80939\n",
      "Batch train [1] loss 0.14438, dsc 0.85562\n",
      "Batch train [1] loss 0.11758, dsc 0.88242\n",
      "Batch train [1] loss 0.17238, dsc 0.82762\n",
      "Batch train [1] loss 0.13492, dsc 0.86508\n",
      "Epoch [50] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 49, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  49, step 0\n",
      "Batch eval [1] loss 0.15332, dsc 0.84668\n",
      "Batch eval [1] loss 0.14918, dsc 0.85082\n",
      "Batch eval [1] loss 0.20798, dsc 0.79202\n",
      "Batch eval [1] loss 0.14683, dsc 0.85317\n",
      "Batch eval [1] loss 0.25595, dsc 0.74405\n",
      "Epoch [50] valid done\n",
      "Epoch [50] T 6104.88s, deltaT 121.98s, loss: train 0.14669, valid 0.18265, dsc: train 0.85331, valid 0.81735\n",
      "DEBUG: Writing to tensorboard before epoch True, 50, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  50, step 0\n",
      "Batch train [1] loss 0.16721, dsc 0.83279\n",
      "Batch train [1] loss 0.18162, dsc 0.81838\n",
      "Batch train [1] loss 0.11918, dsc 0.88082\n",
      "Batch train [1] loss 0.13502, dsc 0.86498\n",
      "Batch train [1] loss 0.15598, dsc 0.84402\n",
      "Batch train [1] loss 0.12049, dsc 0.87951\n",
      "Batch train [1] loss 0.14552, dsc 0.85448\n",
      "Batch train [1] loss 0.13796, dsc 0.86204\n",
      "Batch train [1] loss 0.13532, dsc 0.86468\n",
      "Batch train [1] loss 0.18098, dsc 0.81902\n",
      "Batch train [1] loss 0.15911, dsc 0.84089\n",
      "Batch train [1] loss 0.11906, dsc 0.88094\n",
      "Batch train [1] loss 0.12001, dsc 0.87999\n",
      "Batch train [1] loss 0.12971, dsc 0.87029\n",
      "Batch train [1] loss 0.10820, dsc 0.89180\n",
      "Batch train [1] loss 0.17539, dsc 0.82461\n",
      "Batch train [1] loss 0.14718, dsc 0.85282\n",
      "Batch train [1] loss 0.10057, dsc 0.89943\n",
      "Batch train [1] loss 0.19420, dsc 0.80580\n",
      "Batch train [1] loss 0.16372, dsc 0.83628\n",
      "Batch train [1] loss 0.12670, dsc 0.87330\n",
      "Batch train [1] loss 0.14046, dsc 0.85954\n",
      "Batch train [1] loss 0.19945, dsc 0.80055\n",
      "Batch train [1] loss 0.15410, dsc 0.84590\n",
      "Batch train [1] loss 0.14959, dsc 0.85041\n",
      "Batch train [1] loss 0.12849, dsc 0.87151\n",
      "Batch train [1] loss 0.16874, dsc 0.83126\n",
      "Batch train [1] loss 0.11960, dsc 0.88040\n",
      "Batch train [1] loss 0.12041, dsc 0.87959\n",
      "Batch train [1] loss 0.14303, dsc 0.85697\n",
      "Batch train [1] loss 0.12092, dsc 0.87908\n",
      "Batch train [1] loss 0.17289, dsc 0.82711\n",
      "Batch train [1] loss 0.14194, dsc 0.85806\n",
      "Batch train [1] loss 0.15916, dsc 0.84084\n",
      "Batch train [1] loss 0.12749, dsc 0.87251\n",
      "Batch train [1] loss 0.11913, dsc 0.88087\n",
      "Batch train [1] loss 0.17892, dsc 0.82108\n",
      "Batch train [1] loss 0.13887, dsc 0.86113\n",
      "Batch train [1] loss 0.17850, dsc 0.82150\n",
      "Batch train [1] loss 0.15318, dsc 0.84682\n",
      "Epoch [51] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 50, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  50, step 0\n",
      "Batch eval [1] loss 0.18162, dsc 0.81838\n",
      "Batch eval [1] loss 0.15463, dsc 0.84537\n",
      "Batch eval [1] loss 0.25238, dsc 0.74762\n",
      "Batch eval [1] loss 0.15701, dsc 0.84299\n",
      "Batch eval [1] loss 0.27803, dsc 0.72197\n",
      "Epoch [51] valid done\n",
      "Epoch [51] T 6226.49s, deltaT 121.60s, loss: train 0.14595, valid 0.20473, dsc: train 0.85405, valid 0.79527\n",
      "DEBUG: Writing to tensorboard before epoch True, 51, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  51, step 0\n",
      "Batch train [1] loss 0.11841, dsc 0.88159\n",
      "Batch train [1] loss 0.18825, dsc 0.81175\n",
      "Batch train [1] loss 0.14177, dsc 0.85823\n",
      "Batch train [1] loss 0.11755, dsc 0.88245\n",
      "Batch train [1] loss 0.14264, dsc 0.85736\n",
      "Batch train [1] loss 0.14781, dsc 0.85219\n",
      "Batch train [1] loss 0.17491, dsc 0.82509\n",
      "Batch train [1] loss 0.15222, dsc 0.84778\n",
      "Batch train [1] loss 0.16227, dsc 0.83773\n",
      "Batch train [1] loss 0.11653, dsc 0.88347\n",
      "Batch train [1] loss 0.13414, dsc 0.86586\n",
      "Batch train [1] loss 0.15381, dsc 0.84619\n",
      "Batch train [1] loss 0.12663, dsc 0.87337\n",
      "Batch train [1] loss 0.12982, dsc 0.87018\n",
      "Batch train [1] loss 0.17391, dsc 0.82609\n",
      "Batch train [1] loss 0.13804, dsc 0.86196\n",
      "Batch train [1] loss 0.15225, dsc 0.84775\n",
      "Batch train [1] loss 0.12005, dsc 0.87995\n",
      "Batch train [1] loss 0.10887, dsc 0.89113\n",
      "Batch train [1] loss 0.11661, dsc 0.88339\n",
      "Batch train [1] loss 0.14041, dsc 0.85959\n",
      "Batch train [1] loss 0.17112, dsc 0.82888\n",
      "Batch train [1] loss 0.16844, dsc 0.83156\n",
      "Batch train [1] loss 0.16166, dsc 0.83834\n",
      "Batch train [1] loss 0.13413, dsc 0.86587\n",
      "Batch train [1] loss 0.12993, dsc 0.87007\n",
      "Batch train [1] loss 0.13427, dsc 0.86573\n",
      "Batch train [1] loss 0.10816, dsc 0.89184\n",
      "Batch train [1] loss 0.17518, dsc 0.82482\n",
      "Batch train [1] loss 0.12605, dsc 0.87395\n",
      "Batch train [1] loss 0.17127, dsc 0.82873\n",
      "Batch train [1] loss 0.13416, dsc 0.86584\n",
      "Batch train [1] loss 0.11619, dsc 0.88381\n",
      "Batch train [1] loss 0.14321, dsc 0.85679\n",
      "Batch train [1] loss 0.14288, dsc 0.85712\n",
      "Batch train [1] loss 0.15695, dsc 0.84305\n",
      "Batch train [1] loss 0.09062, dsc 0.90938\n",
      "Batch train [1] loss 0.18641, dsc 0.81359\n",
      "Batch train [1] loss 0.18224, dsc 0.81776\n",
      "Batch train [1] loss 0.18333, dsc 0.81667\n",
      "Epoch [52] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 51, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  51, step 0\n",
      "Batch eval [1] loss 0.15190, dsc 0.84810\n",
      "Batch eval [1] loss 0.15707, dsc 0.84293\n",
      "Batch eval [1] loss 0.27356, dsc 0.72644\n",
      "Batch eval [1] loss 0.18259, dsc 0.81741\n",
      "Batch eval [1] loss 0.30142, dsc 0.69858\n",
      "Epoch [52] valid done\n",
      "Epoch [52] T 6348.15s, deltaT 121.66s, loss: train 0.14433, valid 0.21331, dsc: train 0.85567, valid 0.78669\n",
      "DEBUG: Writing to tensorboard before epoch True, 52, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  52, step 0\n",
      "Batch train [1] loss 0.14912, dsc 0.85088\n",
      "Batch train [1] loss 0.12545, dsc 0.87455\n",
      "Batch train [1] loss 0.13744, dsc 0.86256\n",
      "Batch train [1] loss 0.13269, dsc 0.86731\n",
      "Batch train [1] loss 0.16349, dsc 0.83651\n",
      "Batch train [1] loss 0.13024, dsc 0.86976\n",
      "Batch train [1] loss 0.12362, dsc 0.87638\n",
      "Batch train [1] loss 0.12608, dsc 0.87392\n",
      "Batch train [1] loss 0.15831, dsc 0.84169\n",
      "Batch train [1] loss 0.15731, dsc 0.84269\n",
      "Batch train [1] loss 0.11496, dsc 0.88504\n",
      "Batch train [1] loss 0.11498, dsc 0.88502\n",
      "Batch train [1] loss 0.11660, dsc 0.88340\n",
      "Batch train [1] loss 0.14700, dsc 0.85300\n",
      "Batch train [1] loss 0.13190, dsc 0.86810\n",
      "Batch train [1] loss 0.17532, dsc 0.82468\n",
      "Batch train [1] loss 0.15930, dsc 0.84070\n",
      "Batch train [1] loss 0.09942, dsc 0.90058\n",
      "Batch train [1] loss 0.14866, dsc 0.85134\n",
      "Batch train [1] loss 0.17196, dsc 0.82804\n",
      "Batch train [1] loss 0.13070, dsc 0.86930\n",
      "Batch train [1] loss 0.16041, dsc 0.83959\n",
      "Batch train [1] loss 0.14052, dsc 0.85948\n",
      "Batch train [1] loss 0.21158, dsc 0.78842\n",
      "Batch train [1] loss 0.12414, dsc 0.87586\n",
      "Batch train [1] loss 0.16524, dsc 0.83476\n",
      "Batch train [1] loss 0.10529, dsc 0.89471\n",
      "Batch train [1] loss 0.14450, dsc 0.85550\n",
      "Batch train [1] loss 0.10306, dsc 0.89694\n",
      "Batch train [1] loss 0.17530, dsc 0.82470\n",
      "Batch train [1] loss 0.12797, dsc 0.87203\n",
      "Batch train [1] loss 0.20683, dsc 0.79317\n",
      "Batch train [1] loss 0.14245, dsc 0.85755\n",
      "Batch train [1] loss 0.12869, dsc 0.87131\n",
      "Batch train [1] loss 0.12612, dsc 0.87388\n",
      "Batch train [1] loss 0.18196, dsc 0.81804\n",
      "Batch train [1] loss 0.12350, dsc 0.87650\n",
      "Batch train [1] loss 0.14368, dsc 0.85632\n",
      "Batch train [1] loss 0.15099, dsc 0.84901\n",
      "Batch train [1] loss 0.16224, dsc 0.83776\n",
      "Epoch [53] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 52, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  52, step 0\n",
      "Batch eval [1] loss 0.18584, dsc 0.81416\n",
      "Batch eval [1] loss 0.12771, dsc 0.87229\n",
      "Batch eval [1] loss 0.22556, dsc 0.77444\n",
      "Batch eval [1] loss 0.13756, dsc 0.86244\n",
      "Batch eval [1] loss 0.26516, dsc 0.73484\n",
      "Epoch [53] valid done\n",
      "Epoch [53] T 6469.83s, deltaT 121.67s, loss: train 0.14348, valid 0.18837, dsc: train 0.85652, valid 0.81163\n",
      "DEBUG: Writing to tensorboard before epoch True, 53, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  53, step 0\n",
      "Batch train [1] loss 0.17428, dsc 0.82572\n",
      "Batch train [1] loss 0.19655, dsc 0.80345\n",
      "Batch train [1] loss 0.12553, dsc 0.87447\n",
      "Batch train [1] loss 0.14362, dsc 0.85638\n",
      "Batch train [1] loss 0.15542, dsc 0.84458\n",
      "Batch train [1] loss 0.11064, dsc 0.88936\n",
      "Batch train [1] loss 0.14413, dsc 0.85587\n",
      "Batch train [1] loss 0.16463, dsc 0.83537\n",
      "Batch train [1] loss 0.12895, dsc 0.87105\n",
      "Batch train [1] loss 0.14834, dsc 0.85166\n",
      "Batch train [1] loss 0.15006, dsc 0.84994\n",
      "Batch train [1] loss 0.15072, dsc 0.84928\n",
      "Batch train [1] loss 0.11754, dsc 0.88246\n",
      "Batch train [1] loss 0.16430, dsc 0.83570\n",
      "Batch train [1] loss 0.14071, dsc 0.85929\n",
      "Batch train [1] loss 0.10668, dsc 0.89332\n",
      "Batch train [1] loss 0.15111, dsc 0.84889\n",
      "Batch train [1] loss 0.12399, dsc 0.87601\n",
      "Batch train [1] loss 0.16397, dsc 0.83603\n",
      "Batch train [1] loss 0.11962, dsc 0.88038\n",
      "Batch train [1] loss 0.20618, dsc 0.79382\n",
      "Batch train [1] loss 0.15710, dsc 0.84290\n",
      "Batch train [1] loss 0.14665, dsc 0.85335\n",
      "Batch train [1] loss 0.15876, dsc 0.84124\n",
      "Batch train [1] loss 0.12344, dsc 0.87656\n",
      "Batch train [1] loss 0.15930, dsc 0.84070\n",
      "Batch train [1] loss 0.11771, dsc 0.88229\n",
      "Batch train [1] loss 0.13649, dsc 0.86351\n",
      "Batch train [1] loss 0.10181, dsc 0.89819\n",
      "Batch train [1] loss 0.14242, dsc 0.85758\n",
      "Batch train [1] loss 0.12277, dsc 0.87723\n",
      "Batch train [1] loss 0.13094, dsc 0.86906\n",
      "Batch train [1] loss 0.18339, dsc 0.81661\n",
      "Batch train [1] loss 0.11155, dsc 0.88845\n",
      "Batch train [1] loss 0.13150, dsc 0.86850\n",
      "Batch train [1] loss 0.16878, dsc 0.83122\n",
      "Batch train [1] loss 0.12787, dsc 0.87213\n",
      "Batch train [1] loss 0.12454, dsc 0.87546\n",
      "Batch train [1] loss 0.13087, dsc 0.86913\n",
      "Batch train [1] loss 0.11423, dsc 0.88577\n",
      "Epoch [54] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 53, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  53, step 0\n",
      "Batch eval [1] loss 0.22613, dsc 0.77387\n",
      "Batch eval [1] loss 0.13252, dsc 0.86748\n",
      "Batch eval [1] loss 0.22589, dsc 0.77411\n",
      "Batch eval [1] loss 0.12323, dsc 0.87677\n",
      "Batch eval [1] loss 0.25135, dsc 0.74865\n",
      "Epoch [54] valid done\n",
      "Epoch [54] T 6591.48s, deltaT 121.64s, loss: train 0.14193, valid 0.19182, dsc: train 0.85807, valid 0.80818\n",
      "DEBUG: Writing to tensorboard before epoch True, 54, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  54, step 0\n",
      "Batch train [1] loss 0.15627, dsc 0.84373\n",
      "Batch train [1] loss 0.12990, dsc 0.87010\n",
      "Batch train [1] loss 0.14231, dsc 0.85769\n",
      "Batch train [1] loss 0.14199, dsc 0.85801\n",
      "Batch train [1] loss 0.11599, dsc 0.88401\n",
      "Batch train [1] loss 0.17865, dsc 0.82135\n",
      "Batch train [1] loss 0.13158, dsc 0.86842\n",
      "Batch train [1] loss 0.10955, dsc 0.89045\n",
      "Batch train [1] loss 0.16476, dsc 0.83524\n",
      "Batch train [1] loss 0.16631, dsc 0.83369\n",
      "Batch train [1] loss 0.10818, dsc 0.89182\n",
      "Batch train [1] loss 0.17210, dsc 0.82790\n",
      "Batch train [1] loss 0.12631, dsc 0.87369\n",
      "Batch train [1] loss 0.15436, dsc 0.84564\n",
      "Batch train [1] loss 0.11222, dsc 0.88778\n",
      "Batch train [1] loss 0.13728, dsc 0.86272\n",
      "Batch train [1] loss 0.12702, dsc 0.87298\n",
      "Batch train [1] loss 0.11070, dsc 0.88930\n",
      "Batch train [1] loss 0.14697, dsc 0.85303\n",
      "Batch train [1] loss 0.12849, dsc 0.87151\n",
      "Batch train [1] loss 0.11722, dsc 0.88278\n",
      "Batch train [1] loss 0.15609, dsc 0.84391\n",
      "Batch train [1] loss 0.14379, dsc 0.85621\n",
      "Batch train [1] loss 0.16616, dsc 0.83384\n",
      "Batch train [1] loss 0.18367, dsc 0.81633\n",
      "Batch train [1] loss 0.14058, dsc 0.85942\n",
      "Batch train [1] loss 0.14346, dsc 0.85654\n",
      "Batch train [1] loss 0.17424, dsc 0.82576\n",
      "Batch train [1] loss 0.15313, dsc 0.84687\n",
      "Batch train [1] loss 0.14110, dsc 0.85890\n",
      "Batch train [1] loss 0.12486, dsc 0.87514\n",
      "Batch train [1] loss 0.12205, dsc 0.87795\n",
      "Batch train [1] loss 0.18320, dsc 0.81680\n",
      "Batch train [1] loss 0.13787, dsc 0.86213\n",
      "Batch train [1] loss 0.11977, dsc 0.88023\n",
      "Batch train [1] loss 0.18888, dsc 0.81112\n",
      "Batch train [1] loss 0.14698, dsc 0.85302\n",
      "Batch train [1] loss 0.11694, dsc 0.88306\n",
      "Batch train [1] loss 0.11441, dsc 0.88559\n",
      "Batch train [1] loss 0.12331, dsc 0.87669\n",
      "Epoch [55] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 54, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  54, step 0\n",
      "Batch eval [1] loss 0.20548, dsc 0.79452\n",
      "Batch eval [1] loss 0.13042, dsc 0.86958\n",
      "Batch eval [1] loss 0.23235, dsc 0.76765\n",
      "Batch eval [1] loss 0.13310, dsc 0.86690\n",
      "Batch eval [1] loss 0.24113, dsc 0.75887\n",
      "Epoch [55] valid done\n",
      "Epoch [55] T 6713.18s, deltaT 121.70s, loss: train 0.14147, valid 0.18850, dsc: train 0.85853, valid 0.81150\n",
      "DEBUG: Writing to tensorboard before epoch True, 55, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  55, step 0\n",
      "Batch train [1] loss 0.13503, dsc 0.86497\n",
      "Batch train [1] loss 0.13590, dsc 0.86410\n",
      "Batch train [1] loss 0.10407, dsc 0.89593\n",
      "Batch train [1] loss 0.12093, dsc 0.87907\n",
      "Batch train [1] loss 0.12430, dsc 0.87570\n",
      "Batch train [1] loss 0.13827, dsc 0.86173\n",
      "Batch train [1] loss 0.14541, dsc 0.85459\n",
      "Batch train [1] loss 0.13552, dsc 0.86448\n",
      "Batch train [1] loss 0.13851, dsc 0.86149\n",
      "Batch train [1] loss 0.19483, dsc 0.80517\n",
      "Batch train [1] loss 0.12574, dsc 0.87426\n",
      "Batch train [1] loss 0.12159, dsc 0.87841\n",
      "Batch train [1] loss 0.12436, dsc 0.87564\n",
      "Batch train [1] loss 0.13261, dsc 0.86739\n",
      "Batch train [1] loss 0.14720, dsc 0.85280\n",
      "Batch train [1] loss 0.15504, dsc 0.84496\n",
      "Batch train [1] loss 0.18292, dsc 0.81708\n",
      "Batch train [1] loss 0.13706, dsc 0.86294\n",
      "Batch train [1] loss 0.16118, dsc 0.83882\n",
      "Batch train [1] loss 0.10527, dsc 0.89473\n",
      "Batch train [1] loss 0.14039, dsc 0.85961\n",
      "Batch train [1] loss 0.14454, dsc 0.85546\n",
      "Batch train [1] loss 0.12142, dsc 0.87858\n",
      "Batch train [1] loss 0.12949, dsc 0.87051\n",
      "Batch train [1] loss 0.13270, dsc 0.86730\n",
      "Batch train [1] loss 0.09471, dsc 0.90529\n",
      "Batch train [1] loss 0.14908, dsc 0.85092\n",
      "Batch train [1] loss 0.16778, dsc 0.83222\n",
      "Batch train [1] loss 0.13789, dsc 0.86211\n",
      "Batch train [1] loss 0.13751, dsc 0.86249\n",
      "Batch train [1] loss 0.16595, dsc 0.83405\n",
      "Batch train [1] loss 0.16380, dsc 0.83620\n",
      "Batch train [1] loss 0.17504, dsc 0.82496\n",
      "Batch train [1] loss 0.11868, dsc 0.88132\n",
      "Batch train [1] loss 0.17734, dsc 0.82266\n",
      "Batch train [1] loss 0.11018, dsc 0.88982\n",
      "Batch train [1] loss 0.11887, dsc 0.88113\n",
      "Batch train [1] loss 0.14420, dsc 0.85580\n",
      "Batch train [1] loss 0.13088, dsc 0.86912\n",
      "Batch train [1] loss 0.12339, dsc 0.87661\n",
      "Epoch [56] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 55, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  55, step 0\n",
      "Batch eval [1] loss 0.18610, dsc 0.81390\n",
      "Batch eval [1] loss 0.13947, dsc 0.86053\n",
      "Batch eval [1] loss 0.24654, dsc 0.75346\n",
      "Batch eval [1] loss 0.14313, dsc 0.85687\n",
      "Batch eval [1] loss 0.29604, dsc 0.70396\n",
      "Epoch [56] valid done\n",
      "Epoch [56] T 6836.73s, deltaT 123.54s, loss: train 0.13874, valid 0.20226, dsc: train 0.86126, valid 0.79774\n",
      "DEBUG: Writing to tensorboard before epoch True, 56, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  56, step 0\n",
      "Batch train [1] loss 0.11440, dsc 0.88560\n",
      "Batch train [1] loss 0.12259, dsc 0.87741\n",
      "Batch train [1] loss 0.15465, dsc 0.84535\n",
      "Batch train [1] loss 0.12151, dsc 0.87849\n",
      "Batch train [1] loss 0.10917, dsc 0.89083\n",
      "Batch train [1] loss 0.12414, dsc 0.87586\n",
      "Batch train [1] loss 0.14990, dsc 0.85010\n",
      "Batch train [1] loss 0.13762, dsc 0.86238\n",
      "Batch train [1] loss 0.11424, dsc 0.88576\n",
      "Batch train [1] loss 0.16218, dsc 0.83782\n",
      "Batch train [1] loss 0.13429, dsc 0.86571\n",
      "Batch train [1] loss 0.13450, dsc 0.86550\n",
      "Batch train [1] loss 0.16794, dsc 0.83206\n",
      "Batch train [1] loss 0.16580, dsc 0.83420\n",
      "Batch train [1] loss 0.11610, dsc 0.88390\n",
      "Batch train [1] loss 0.19110, dsc 0.80890\n",
      "Batch train [1] loss 0.13288, dsc 0.86712\n",
      "Batch train [1] loss 0.14676, dsc 0.85324\n",
      "Batch train [1] loss 0.13356, dsc 0.86644\n",
      "Batch train [1] loss 0.11937, dsc 0.88063\n",
      "Batch train [1] loss 0.15931, dsc 0.84069\n",
      "Batch train [1] loss 0.16095, dsc 0.83905\n",
      "Batch train [1] loss 0.10505, dsc 0.89495\n",
      "Batch train [1] loss 0.13287, dsc 0.86713\n",
      "Batch train [1] loss 0.15207, dsc 0.84793\n",
      "Batch train [1] loss 0.12357, dsc 0.87643\n",
      "Batch train [1] loss 0.15663, dsc 0.84337\n",
      "Batch train [1] loss 0.13103, dsc 0.86897\n",
      "Batch train [1] loss 0.09672, dsc 0.90328\n",
      "Batch train [1] loss 0.17510, dsc 0.82490\n",
      "Batch train [1] loss 0.12557, dsc 0.87443\n",
      "Batch train [1] loss 0.10870, dsc 0.89130\n",
      "Batch train [1] loss 0.11725, dsc 0.88275\n",
      "Batch train [1] loss 0.10678, dsc 0.89322\n",
      "Batch train [1] loss 0.12300, dsc 0.87700\n",
      "Batch train [1] loss 0.11625, dsc 0.88375\n",
      "Batch train [1] loss 0.13405, dsc 0.86595\n",
      "Batch train [1] loss 0.16557, dsc 0.83443\n",
      "Batch train [1] loss 0.13510, dsc 0.86490\n",
      "Batch train [1] loss 0.14477, dsc 0.85523\n",
      "Epoch [57] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 56, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  56, step 0\n",
      "Batch eval [1] loss 0.20949, dsc 0.79051\n",
      "Batch eval [1] loss 0.14566, dsc 0.85434\n",
      "Batch eval [1] loss 0.22580, dsc 0.77420\n",
      "Batch eval [1] loss 0.15248, dsc 0.84752\n",
      "Batch eval [1] loss 0.27877, dsc 0.72123\n",
      "Epoch [57] valid done\n",
      "Epoch [57] T 6958.28s, deltaT 121.54s, loss: train 0.13558, valid 0.20244, dsc: train 0.86442, valid 0.79756\n",
      "DEBUG: Writing to tensorboard before epoch True, 57, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  57, step 0\n",
      "Batch train [1] loss 0.15945, dsc 0.84055\n",
      "Batch train [1] loss 0.11843, dsc 0.88157\n",
      "Batch train [1] loss 0.13373, dsc 0.86627\n",
      "Batch train [1] loss 0.15615, dsc 0.84385\n",
      "Batch train [1] loss 0.12419, dsc 0.87581\n",
      "Batch train [1] loss 0.14235, dsc 0.85765\n",
      "Batch train [1] loss 0.16207, dsc 0.83793\n",
      "Batch train [1] loss 0.14213, dsc 0.85787\n",
      "Batch train [1] loss 0.13148, dsc 0.86852\n",
      "Batch train [1] loss 0.12279, dsc 0.87721\n",
      "Batch train [1] loss 0.21823, dsc 0.78177\n",
      "Batch train [1] loss 0.10746, dsc 0.89254\n",
      "Batch train [1] loss 0.11360, dsc 0.88640\n",
      "Batch train [1] loss 0.13862, dsc 0.86138\n",
      "Batch train [1] loss 0.12774, dsc 0.87226\n",
      "Batch train [1] loss 0.12833, dsc 0.87167\n",
      "Batch train [1] loss 0.14483, dsc 0.85517\n",
      "Batch train [1] loss 0.16543, dsc 0.83457\n",
      "Batch train [1] loss 0.15477, dsc 0.84523\n",
      "Batch train [1] loss 0.14119, dsc 0.85881\n",
      "Batch train [1] loss 0.12866, dsc 0.87134\n",
      "Batch train [1] loss 0.13576, dsc 0.86424\n",
      "Batch train [1] loss 0.13477, dsc 0.86523\n",
      "Batch train [1] loss 0.14487, dsc 0.85513\n",
      "Batch train [1] loss 0.12395, dsc 0.87605\n",
      "Batch train [1] loss 0.11531, dsc 0.88469\n",
      "Batch train [1] loss 0.11888, dsc 0.88112\n",
      "Batch train [1] loss 0.14065, dsc 0.85935\n",
      "Batch train [1] loss 0.12063, dsc 0.87937\n",
      "Batch train [1] loss 0.12426, dsc 0.87574\n",
      "Batch train [1] loss 0.10892, dsc 0.89108\n",
      "Batch train [1] loss 0.11592, dsc 0.88408\n",
      "Batch train [1] loss 0.11467, dsc 0.88533\n",
      "Batch train [1] loss 0.14602, dsc 0.85398\n",
      "Batch train [1] loss 0.15626, dsc 0.84374\n",
      "Batch train [1] loss 0.17627, dsc 0.82373\n",
      "Batch train [1] loss 0.12757, dsc 0.87243\n",
      "Batch train [1] loss 0.10018, dsc 0.89982\n",
      "Batch train [1] loss 0.15919, dsc 0.84081\n",
      "Batch train [1] loss 0.09123, dsc 0.90877\n",
      "Epoch [58] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 57, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  57, step 0\n",
      "Batch eval [1] loss 0.15610, dsc 0.84390\n",
      "Batch eval [1] loss 0.15414, dsc 0.84586\n",
      "Batch eval [1] loss 0.24526, dsc 0.75474\n",
      "Batch eval [1] loss 0.15179, dsc 0.84821\n",
      "Batch eval [1] loss 0.27908, dsc 0.72092\n",
      "Epoch [58] valid done\n",
      "Epoch [58] T 7080.09s, deltaT 121.81s, loss: train 0.13542, valid 0.19727, dsc: train 0.86458, valid 0.80273\n",
      "DEBUG: Writing to tensorboard before epoch True, 58, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  58, step 0\n",
      "Batch train [1] loss 0.11552, dsc 0.88448\n",
      "Batch train [1] loss 0.15535, dsc 0.84465\n",
      "Batch train [1] loss 0.13364, dsc 0.86636\n",
      "Batch train [1] loss 0.16384, dsc 0.83616\n",
      "Batch train [1] loss 0.12080, dsc 0.87920\n",
      "Batch train [1] loss 0.12254, dsc 0.87746\n",
      "Batch train [1] loss 0.11546, dsc 0.88454\n",
      "Batch train [1] loss 0.16633, dsc 0.83367\n",
      "Batch train [1] loss 0.14677, dsc 0.85323\n",
      "Batch train [1] loss 0.19773, dsc 0.80227\n",
      "Batch train [1] loss 0.14129, dsc 0.85871\n",
      "Batch train [1] loss 0.13683, dsc 0.86317\n",
      "Batch train [1] loss 0.10520, dsc 0.89480\n",
      "Batch train [1] loss 0.14990, dsc 0.85010\n",
      "Batch train [1] loss 0.18053, dsc 0.81947\n",
      "Batch train [1] loss 0.11711, dsc 0.88289\n",
      "Batch train [1] loss 0.12309, dsc 0.87691\n",
      "Batch train [1] loss 0.14013, dsc 0.85987\n",
      "Batch train [1] loss 0.14528, dsc 0.85472\n",
      "Batch train [1] loss 0.13573, dsc 0.86427\n",
      "Batch train [1] loss 0.10884, dsc 0.89116\n",
      "Batch train [1] loss 0.16501, dsc 0.83499\n",
      "Batch train [1] loss 0.13522, dsc 0.86478\n",
      "Batch train [1] loss 0.11705, dsc 0.88295\n",
      "Batch train [1] loss 0.11410, dsc 0.88590\n",
      "Batch train [1] loss 0.15615, dsc 0.84385\n",
      "Batch train [1] loss 0.12392, dsc 0.87608\n",
      "Batch train [1] loss 0.13465, dsc 0.86535\n",
      "Batch train [1] loss 0.09016, dsc 0.90984\n",
      "Batch train [1] loss 0.11919, dsc 0.88081\n",
      "Batch train [1] loss 0.14416, dsc 0.85584\n",
      "Batch train [1] loss 0.12847, dsc 0.87153\n",
      "Batch train [1] loss 0.14639, dsc 0.85361\n",
      "Batch train [1] loss 0.11350, dsc 0.88650\n",
      "Batch train [1] loss 0.14339, dsc 0.85661\n",
      "Batch train [1] loss 0.13910, dsc 0.86090\n",
      "Batch train [1] loss 0.10719, dsc 0.89281\n",
      "Batch train [1] loss 0.12497, dsc 0.87503\n",
      "Batch train [1] loss 0.14078, dsc 0.85922\n",
      "Batch train [1] loss 0.14803, dsc 0.85197\n",
      "Epoch [59] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 58, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  58, step 0\n",
      "Batch eval [1] loss 0.17552, dsc 0.82448\n",
      "Batch eval [1] loss 0.13265, dsc 0.86735\n",
      "Batch eval [1] loss 0.27440, dsc 0.72560\n",
      "Batch eval [1] loss 0.14300, dsc 0.85700\n",
      "Batch eval [1] loss 0.24693, dsc 0.75307\n",
      "Epoch [59] valid done\n",
      "Epoch [59] T 7201.72s, deltaT 121.62s, loss: train 0.13533, valid 0.19450, dsc: train 0.86467, valid 0.80550\n",
      "DEBUG: Writing to tensorboard before epoch True, 59, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  59, step 0\n",
      "Batch train [1] loss 0.13935, dsc 0.86065\n",
      "Batch train [1] loss 0.12674, dsc 0.87326\n",
      "Batch train [1] loss 0.09639, dsc 0.90361\n",
      "Batch train [1] loss 0.15744, dsc 0.84256\n",
      "Batch train [1] loss 0.11774, dsc 0.88226\n",
      "Batch train [1] loss 0.17489, dsc 0.82511\n",
      "Batch train [1] loss 0.11281, dsc 0.88719\n",
      "Batch train [1] loss 0.17204, dsc 0.82796\n",
      "Batch train [1] loss 0.14252, dsc 0.85748\n",
      "Batch train [1] loss 0.16041, dsc 0.83959\n",
      "Batch train [1] loss 0.11788, dsc 0.88212\n",
      "Batch train [1] loss 0.13240, dsc 0.86760\n",
      "Batch train [1] loss 0.14306, dsc 0.85694\n",
      "Batch train [1] loss 0.11603, dsc 0.88397\n",
      "Batch train [1] loss 0.11354, dsc 0.88646\n",
      "Batch train [1] loss 0.11569, dsc 0.88431\n",
      "Batch train [1] loss 0.10720, dsc 0.89280\n",
      "Batch train [1] loss 0.13529, dsc 0.86471\n",
      "Batch train [1] loss 0.12152, dsc 0.87848\n",
      "Batch train [1] loss 0.11364, dsc 0.88636\n",
      "Batch train [1] loss 0.18917, dsc 0.81083\n",
      "Batch train [1] loss 0.12701, dsc 0.87299\n",
      "Batch train [1] loss 0.11009, dsc 0.88991\n",
      "Batch train [1] loss 0.15080, dsc 0.84920\n",
      "Batch train [1] loss 0.14258, dsc 0.85742\n",
      "Batch train [1] loss 0.12803, dsc 0.87197\n",
      "Batch train [1] loss 0.15411, dsc 0.84589\n",
      "Batch train [1] loss 0.15168, dsc 0.84832\n",
      "Batch train [1] loss 0.17102, dsc 0.82898\n",
      "Batch train [1] loss 0.13320, dsc 0.86680\n",
      "Batch train [1] loss 0.11749, dsc 0.88251\n",
      "Batch train [1] loss 0.14438, dsc 0.85562\n",
      "Batch train [1] loss 0.12758, dsc 0.87242\n",
      "Batch train [1] loss 0.15908, dsc 0.84092\n",
      "Batch train [1] loss 0.16404, dsc 0.83596\n",
      "Batch train [1] loss 0.13066, dsc 0.86934\n",
      "Batch train [1] loss 0.12356, dsc 0.87644\n",
      "Batch train [1] loss 0.13308, dsc 0.86692\n",
      "Batch train [1] loss 0.16436, dsc 0.83564\n",
      "Batch train [1] loss 0.14117, dsc 0.85883\n",
      "Epoch [60] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 59, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  59, step 0\n",
      "Batch eval [1] loss 0.13269, dsc 0.86731\n",
      "Batch eval [1] loss 0.15398, dsc 0.84602\n",
      "Batch eval [1] loss 0.20856, dsc 0.79144\n",
      "Batch eval [1] loss 0.13494, dsc 0.86506\n",
      "Batch eval [1] loss 0.26114, dsc 0.73886\n",
      "Epoch [60] valid done\n",
      "Epoch [60] T 7323.34s, deltaT 121.61s, loss: train 0.13699, valid 0.17826, dsc: train 0.86301, valid 0.82174\n",
      "DEBUG: Writing to tensorboard before epoch True, 60, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  60, step 0\n",
      "Batch train [1] loss 0.13113, dsc 0.86887\n",
      "Batch train [1] loss 0.16178, dsc 0.83822\n",
      "Batch train [1] loss 0.16069, dsc 0.83931\n",
      "Batch train [1] loss 0.14861, dsc 0.85139\n",
      "Batch train [1] loss 0.12920, dsc 0.87080\n",
      "Batch train [1] loss 0.13683, dsc 0.86317\n",
      "Batch train [1] loss 0.14858, dsc 0.85142\n",
      "Batch train [1] loss 0.13317, dsc 0.86683\n",
      "Batch train [1] loss 0.13788, dsc 0.86212\n",
      "Batch train [1] loss 0.11656, dsc 0.88344\n",
      "Batch train [1] loss 0.12095, dsc 0.87905\n",
      "Batch train [1] loss 0.12000, dsc 0.88000\n",
      "Batch train [1] loss 0.13472, dsc 0.86528\n",
      "Batch train [1] loss 0.20312, dsc 0.79688\n",
      "Batch train [1] loss 0.13800, dsc 0.86200\n",
      "Batch train [1] loss 0.09784, dsc 0.90216\n",
      "Batch train [1] loss 0.13008, dsc 0.86992\n",
      "Batch train [1] loss 0.19056, dsc 0.80944\n",
      "Batch train [1] loss 0.11975, dsc 0.88025\n",
      "Batch train [1] loss 0.15197, dsc 0.84803\n",
      "Batch train [1] loss 0.11442, dsc 0.88558\n",
      "Batch train [1] loss 0.13239, dsc 0.86761\n",
      "Batch train [1] loss 0.12089, dsc 0.87911\n",
      "Batch train [1] loss 0.15845, dsc 0.84155\n",
      "Batch train [1] loss 0.17102, dsc 0.82898\n",
      "Batch train [1] loss 0.16760, dsc 0.83240\n",
      "Batch train [1] loss 0.14156, dsc 0.85844\n",
      "Batch train [1] loss 0.13182, dsc 0.86818\n",
      "Batch train [1] loss 0.11960, dsc 0.88040\n",
      "Batch train [1] loss 0.10154, dsc 0.89846\n",
      "Batch train [1] loss 0.16216, dsc 0.83784\n",
      "Batch train [1] loss 0.14509, dsc 0.85491\n",
      "Batch train [1] loss 0.16519, dsc 0.83481\n",
      "Batch train [1] loss 0.11305, dsc 0.88695\n",
      "Batch train [1] loss 0.17098, dsc 0.82902\n",
      "Batch train [1] loss 0.11441, dsc 0.88559\n",
      "Batch train [1] loss 0.15061, dsc 0.84939\n",
      "Batch train [1] loss 0.12824, dsc 0.87176\n",
      "Batch train [1] loss 0.11078, dsc 0.88922\n",
      "Batch train [1] loss 0.15903, dsc 0.84097\n",
      "Epoch [61] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 60, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  60, step 0\n",
      "Batch eval [1] loss 0.18940, dsc 0.81060\n",
      "Batch eval [1] loss 0.12718, dsc 0.87282\n",
      "Batch eval [1] loss 0.24384, dsc 0.75616\n",
      "Batch eval [1] loss 0.13723, dsc 0.86277\n",
      "Batch eval [1] loss 0.23028, dsc 0.76972\n",
      "Epoch [61] valid done\n",
      "Epoch [61] T 7445.45s, deltaT 122.10s, loss: train 0.13976, valid 0.18559, dsc: train 0.86024, valid 0.81441\n",
      "DEBUG: Writing to tensorboard before epoch True, 61, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  61, step 0\n",
      "Batch train [1] loss 0.12058, dsc 0.87942\n",
      "Batch train [1] loss 0.12737, dsc 0.87263\n",
      "Batch train [1] loss 0.14961, dsc 0.85039\n",
      "Batch train [1] loss 0.13813, dsc 0.86187\n",
      "Batch train [1] loss 0.14465, dsc 0.85535\n",
      "Batch train [1] loss 0.16564, dsc 0.83436\n",
      "Batch train [1] loss 0.11539, dsc 0.88461\n",
      "Batch train [1] loss 0.13135, dsc 0.86865\n",
      "Batch train [1] loss 0.13148, dsc 0.86852\n",
      "Batch train [1] loss 0.16090, dsc 0.83910\n",
      "Batch train [1] loss 0.18903, dsc 0.81097\n",
      "Batch train [1] loss 0.10701, dsc 0.89299\n",
      "Batch train [1] loss 0.16415, dsc 0.83585\n",
      "Batch train [1] loss 0.11157, dsc 0.88843\n",
      "Batch train [1] loss 0.13442, dsc 0.86558\n",
      "Batch train [1] loss 0.13274, dsc 0.86726\n",
      "Batch train [1] loss 0.11288, dsc 0.88712\n",
      "Batch train [1] loss 0.09368, dsc 0.90632\n",
      "Batch train [1] loss 0.15925, dsc 0.84075\n",
      "Batch train [1] loss 0.13136, dsc 0.86864\n",
      "Batch train [1] loss 0.11656, dsc 0.88344\n",
      "Batch train [1] loss 0.14005, dsc 0.85995\n",
      "Batch train [1] loss 0.15169, dsc 0.84831\n",
      "Batch train [1] loss 0.10192, dsc 0.89808\n",
      "Batch train [1] loss 0.11660, dsc 0.88340\n",
      "Batch train [1] loss 0.14556, dsc 0.85444\n",
      "Batch train [1] loss 0.14068, dsc 0.85932\n",
      "Batch train [1] loss 0.09867, dsc 0.90133\n",
      "Batch train [1] loss 0.12925, dsc 0.87075\n",
      "Batch train [1] loss 0.13185, dsc 0.86815\n",
      "Batch train [1] loss 0.12252, dsc 0.87748\n",
      "Batch train [1] loss 0.16206, dsc 0.83794\n",
      "Batch train [1] loss 0.10109, dsc 0.89891\n",
      "Batch train [1] loss 0.13597, dsc 0.86403\n",
      "Batch train [1] loss 0.13628, dsc 0.86372\n",
      "Batch train [1] loss 0.11207, dsc 0.88793\n",
      "Batch train [1] loss 0.11517, dsc 0.88483\n",
      "Batch train [1] loss 0.12599, dsc 0.87401\n",
      "Batch train [1] loss 0.13882, dsc 0.86118\n",
      "Batch train [1] loss 0.11121, dsc 0.88879\n",
      "Epoch [62] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 61, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  61, step 0\n",
      "Batch eval [1] loss 0.14711, dsc 0.85289\n",
      "Batch eval [1] loss 0.13775, dsc 0.86225\n",
      "Batch eval [1] loss 0.21429, dsc 0.78571\n",
      "Batch eval [1] loss 0.13313, dsc 0.86687\n",
      "Batch eval [1] loss 0.24959, dsc 0.75041\n",
      "Epoch [62] valid done\n",
      "Epoch [62] T 7567.06s, deltaT 121.61s, loss: train 0.13138, valid 0.17638, dsc: train 0.86862, valid 0.82362\n",
      "DEBUG: Writing to tensorboard before epoch True, 62, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  62, step 0\n",
      "Batch train [1] loss 0.16367, dsc 0.83633\n",
      "Batch train [1] loss 0.17446, dsc 0.82554\n",
      "Batch train [1] loss 0.11408, dsc 0.88592\n",
      "Batch train [1] loss 0.12252, dsc 0.87748\n",
      "Batch train [1] loss 0.10920, dsc 0.89080\n",
      "Batch train [1] loss 0.11972, dsc 0.88028\n",
      "Batch train [1] loss 0.11917, dsc 0.88083\n",
      "Batch train [1] loss 0.13003, dsc 0.86997\n",
      "Batch train [1] loss 0.15434, dsc 0.84566\n",
      "Batch train [1] loss 0.14606, dsc 0.85394\n",
      "Batch train [1] loss 0.16241, dsc 0.83759\n",
      "Batch train [1] loss 0.13438, dsc 0.86562\n",
      "Batch train [1] loss 0.12586, dsc 0.87414\n",
      "Batch train [1] loss 0.12998, dsc 0.87002\n",
      "Batch train [1] loss 0.11343, dsc 0.88657\n",
      "Batch train [1] loss 0.10137, dsc 0.89863\n",
      "Batch train [1] loss 0.15785, dsc 0.84215\n",
      "Batch train [1] loss 0.12392, dsc 0.87608\n",
      "Batch train [1] loss 0.11579, dsc 0.88421\n",
      "Batch train [1] loss 0.15490, dsc 0.84510\n",
      "Batch train [1] loss 0.11138, dsc 0.88862\n",
      "Batch train [1] loss 0.11198, dsc 0.88802\n",
      "Batch train [1] loss 0.12408, dsc 0.87592\n",
      "Batch train [1] loss 0.11977, dsc 0.88023\n",
      "Batch train [1] loss 0.14214, dsc 0.85786\n",
      "Batch train [1] loss 0.12919, dsc 0.87081\n",
      "Batch train [1] loss 0.11359, dsc 0.88641\n",
      "Batch train [1] loss 0.15112, dsc 0.84888\n",
      "Batch train [1] loss 0.12005, dsc 0.87995\n",
      "Batch train [1] loss 0.14122, dsc 0.85878\n",
      "Batch train [1] loss 0.13131, dsc 0.86869\n",
      "Batch train [1] loss 0.13605, dsc 0.86395\n",
      "Batch train [1] loss 0.11570, dsc 0.88430\n",
      "Batch train [1] loss 0.09235, dsc 0.90765\n",
      "Batch train [1] loss 0.14179, dsc 0.85821\n",
      "Batch train [1] loss 0.13512, dsc 0.86488\n",
      "Batch train [1] loss 0.13263, dsc 0.86737\n",
      "Batch train [1] loss 0.12563, dsc 0.87437\n",
      "Batch train [1] loss 0.13695, dsc 0.86305\n",
      "Batch train [1] loss 0.12228, dsc 0.87772\n",
      "Epoch [63] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 62, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  62, step 0\n",
      "Batch eval [1] loss 0.17140, dsc 0.82860\n",
      "Batch eval [1] loss 0.12526, dsc 0.87474\n",
      "Batch eval [1] loss 0.21967, dsc 0.78033\n",
      "Batch eval [1] loss 0.13101, dsc 0.86899\n",
      "Batch eval [1] loss 0.23739, dsc 0.76261\n",
      "Epoch [63] valid done\n",
      "Epoch [63] T 7688.95s, deltaT 121.88s, loss: train 0.13019, valid 0.17694, dsc: train 0.86981, valid 0.82306\n",
      "DEBUG: Writing to tensorboard before epoch True, 63, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  63, step 0\n",
      "Batch train [1] loss 0.13294, dsc 0.86706\n",
      "Batch train [1] loss 0.10686, dsc 0.89314\n",
      "Batch train [1] loss 0.10735, dsc 0.89265\n",
      "Batch train [1] loss 0.14554, dsc 0.85446\n",
      "Batch train [1] loss 0.13385, dsc 0.86615\n",
      "Batch train [1] loss 0.10205, dsc 0.89795\n",
      "Batch train [1] loss 0.09955, dsc 0.90045\n",
      "Batch train [1] loss 0.11186, dsc 0.88814\n",
      "Batch train [1] loss 0.13920, dsc 0.86080\n",
      "Batch train [1] loss 0.10346, dsc 0.89654\n",
      "Batch train [1] loss 0.10764, dsc 0.89236\n",
      "Batch train [1] loss 0.13216, dsc 0.86784\n",
      "Batch train [1] loss 0.13683, dsc 0.86317\n",
      "Batch train [1] loss 0.13527, dsc 0.86473\n",
      "Batch train [1] loss 0.12952, dsc 0.87048\n",
      "Batch train [1] loss 0.13246, dsc 0.86754\n",
      "Batch train [1] loss 0.14077, dsc 0.85923\n",
      "Batch train [1] loss 0.13906, dsc 0.86094\n",
      "Batch train [1] loss 0.13627, dsc 0.86373\n",
      "Batch train [1] loss 0.11993, dsc 0.88007\n",
      "Batch train [1] loss 0.17898, dsc 0.82102\n",
      "Batch train [1] loss 0.11104, dsc 0.88896\n",
      "Batch train [1] loss 0.14290, dsc 0.85710\n",
      "Batch train [1] loss 0.10206, dsc 0.89794\n",
      "Batch train [1] loss 0.12913, dsc 0.87087\n",
      "Batch train [1] loss 0.16242, dsc 0.83758\n",
      "Batch train [1] loss 0.10532, dsc 0.89468\n",
      "Batch train [1] loss 0.11622, dsc 0.88378\n",
      "Batch train [1] loss 0.12274, dsc 0.87726\n",
      "Batch train [1] loss 0.13612, dsc 0.86388\n",
      "Batch train [1] loss 0.13774, dsc 0.86226\n",
      "Batch train [1] loss 0.14343, dsc 0.85657\n",
      "Batch train [1] loss 0.10647, dsc 0.89353\n",
      "Batch train [1] loss 0.13958, dsc 0.86042\n",
      "Batch train [1] loss 0.16157, dsc 0.83843\n",
      "Batch train [1] loss 0.10963, dsc 0.89037\n",
      "Batch train [1] loss 0.08770, dsc 0.91230\n",
      "Batch train [1] loss 0.14504, dsc 0.85496\n",
      "Batch train [1] loss 0.10810, dsc 0.89190\n",
      "Batch train [1] loss 0.14171, dsc 0.85829\n",
      "Epoch [64] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 63, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  63, step 0\n",
      "Batch eval [1] loss 0.12119, dsc 0.87881\n",
      "Batch eval [1] loss 0.14988, dsc 0.85012\n",
      "Batch eval [1] loss 0.25489, dsc 0.74511\n",
      "Batch eval [1] loss 0.14309, dsc 0.85691\n",
      "Batch eval [1] loss 0.27195, dsc 0.72805\n",
      "Epoch [64] valid done\n",
      "Epoch [64] T 7810.56s, deltaT 121.61s, loss: train 0.12701, valid 0.18820, dsc: train 0.87299, valid 0.81180\n",
      "DEBUG: Writing to tensorboard before epoch True, 64, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  64, step 0\n",
      "Batch train [1] loss 0.15263, dsc 0.84737\n",
      "Batch train [1] loss 0.13743, dsc 0.86257\n",
      "Batch train [1] loss 0.10608, dsc 0.89392\n",
      "Batch train [1] loss 0.13881, dsc 0.86119\n",
      "Batch train [1] loss 0.10314, dsc 0.89686\n",
      "Batch train [1] loss 0.10200, dsc 0.89800\n",
      "Batch train [1] loss 0.13755, dsc 0.86245\n",
      "Batch train [1] loss 0.12047, dsc 0.87953\n",
      "Batch train [1] loss 0.19796, dsc 0.80204\n",
      "Batch train [1] loss 0.12673, dsc 0.87327\n",
      "Batch train [1] loss 0.13586, dsc 0.86414\n",
      "Batch train [1] loss 0.15546, dsc 0.84454\n",
      "Batch train [1] loss 0.12252, dsc 0.87748\n",
      "Batch train [1] loss 0.10358, dsc 0.89642\n",
      "Batch train [1] loss 0.11586, dsc 0.88414\n",
      "Batch train [1] loss 0.13982, dsc 0.86018\n",
      "Batch train [1] loss 0.17999, dsc 0.82001\n",
      "Batch train [1] loss 0.15287, dsc 0.84713\n",
      "Batch train [1] loss 0.11441, dsc 0.88559\n",
      "Batch train [1] loss 0.11450, dsc 0.88550\n",
      "Batch train [1] loss 0.10800, dsc 0.89200\n",
      "Batch train [1] loss 0.14803, dsc 0.85197\n",
      "Batch train [1] loss 0.12948, dsc 0.87052\n",
      "Batch train [1] loss 0.13105, dsc 0.86895\n",
      "Batch train [1] loss 0.19669, dsc 0.80331\n",
      "Batch train [1] loss 0.13017, dsc 0.86983\n",
      "Batch train [1] loss 0.14831, dsc 0.85169\n",
      "Batch train [1] loss 0.13275, dsc 0.86725\n",
      "Batch train [1] loss 0.11314, dsc 0.88686\n",
      "Batch train [1] loss 0.12732, dsc 0.87268\n",
      "Batch train [1] loss 0.12342, dsc 0.87658\n",
      "Batch train [1] loss 0.11533, dsc 0.88467\n",
      "Batch train [1] loss 0.09456, dsc 0.90544\n",
      "Batch train [1] loss 0.11493, dsc 0.88507\n",
      "Batch train [1] loss 0.10473, dsc 0.89527\n",
      "Batch train [1] loss 0.12486, dsc 0.87514\n",
      "Batch train [1] loss 0.10236, dsc 0.89764\n",
      "Batch train [1] loss 0.13273, dsc 0.86727\n",
      "Batch train [1] loss 0.10322, dsc 0.89678\n",
      "Batch train [1] loss 0.12298, dsc 0.87702\n",
      "Epoch [65] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 64, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  64, step 0\n",
      "Batch eval [1] loss 0.13208, dsc 0.86792\n",
      "Batch eval [1] loss 0.12805, dsc 0.87195\n",
      "Batch eval [1] loss 0.25418, dsc 0.74582\n",
      "Batch eval [1] loss 0.13406, dsc 0.86594\n",
      "Batch eval [1] loss 0.23945, dsc 0.76055\n",
      "Epoch [65] valid done\n",
      "Epoch [65] T 7932.10s, deltaT 121.53s, loss: train 0.12904, valid 0.17756, dsc: train 0.87096, valid 0.82244\n",
      "DEBUG: Writing to tensorboard before epoch True, 65, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  65, step 0\n",
      "Batch train [1] loss 0.12788, dsc 0.87212\n",
      "Batch train [1] loss 0.09736, dsc 0.90264\n",
      "Batch train [1] loss 0.13125, dsc 0.86875\n",
      "Batch train [1] loss 0.12441, dsc 0.87559\n",
      "Batch train [1] loss 0.11344, dsc 0.88656\n",
      "Batch train [1] loss 0.11537, dsc 0.88463\n",
      "Batch train [1] loss 0.13261, dsc 0.86739\n",
      "Batch train [1] loss 0.09960, dsc 0.90040\n",
      "Batch train [1] loss 0.13533, dsc 0.86467\n",
      "Batch train [1] loss 0.15341, dsc 0.84659\n",
      "Batch train [1] loss 0.10787, dsc 0.89213\n",
      "Batch train [1] loss 0.12056, dsc 0.87944\n",
      "Batch train [1] loss 0.10108, dsc 0.89892\n",
      "Batch train [1] loss 0.15473, dsc 0.84527\n",
      "Batch train [1] loss 0.11820, dsc 0.88180\n",
      "Batch train [1] loss 0.12422, dsc 0.87578\n",
      "Batch train [1] loss 0.14820, dsc 0.85180\n",
      "Batch train [1] loss 0.13592, dsc 0.86408\n",
      "Batch train [1] loss 0.12222, dsc 0.87778\n",
      "Batch train [1] loss 0.12101, dsc 0.87899\n",
      "Batch train [1] loss 0.10643, dsc 0.89357\n",
      "Batch train [1] loss 0.11243, dsc 0.88757\n",
      "Batch train [1] loss 0.12719, dsc 0.87281\n",
      "Batch train [1] loss 0.10213, dsc 0.89787\n",
      "Batch train [1] loss 0.10208, dsc 0.89792\n",
      "Batch train [1] loss 0.12899, dsc 0.87101\n",
      "Batch train [1] loss 0.13193, dsc 0.86807\n",
      "Batch train [1] loss 0.15060, dsc 0.84940\n",
      "Batch train [1] loss 0.12225, dsc 0.87775\n",
      "Batch train [1] loss 0.11128, dsc 0.88872\n",
      "Batch train [1] loss 0.15716, dsc 0.84284\n",
      "Batch train [1] loss 0.16039, dsc 0.83961\n",
      "Batch train [1] loss 0.14535, dsc 0.85465\n",
      "Batch train [1] loss 0.18076, dsc 0.81924\n",
      "Batch train [1] loss 0.13996, dsc 0.86004\n",
      "Batch train [1] loss 0.14257, dsc 0.85743\n",
      "Batch train [1] loss 0.12140, dsc 0.87860\n",
      "Batch train [1] loss 0.10042, dsc 0.89958\n",
      "Batch train [1] loss 0.12950, dsc 0.87050\n",
      "Batch train [1] loss 0.12753, dsc 0.87247\n",
      "Epoch [66] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 65, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  65, step 0\n",
      "Batch eval [1] loss 0.18413, dsc 0.81587\n",
      "Batch eval [1] loss 0.11690, dsc 0.88310\n",
      "Batch eval [1] loss 0.30036, dsc 0.69964\n",
      "Batch eval [1] loss 0.14006, dsc 0.85994\n",
      "Batch eval [1] loss 0.22984, dsc 0.77016\n",
      "Epoch [66] valid done\n",
      "Epoch [66] T 8053.77s, deltaT 121.66s, loss: train 0.12713, valid 0.19426, dsc: train 0.87287, valid 0.80574\n",
      "DEBUG: Writing to tensorboard before epoch True, 66, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  66, step 0\n",
      "Batch train [1] loss 0.13444, dsc 0.86556\n",
      "Batch train [1] loss 0.09868, dsc 0.90132\n",
      "Batch train [1] loss 0.15023, dsc 0.84977\n",
      "Batch train [1] loss 0.10619, dsc 0.89381\n",
      "Batch train [1] loss 0.13292, dsc 0.86708\n",
      "Batch train [1] loss 0.10629, dsc 0.89371\n",
      "Batch train [1] loss 0.14352, dsc 0.85648\n",
      "Batch train [1] loss 0.14297, dsc 0.85703\n",
      "Batch train [1] loss 0.08773, dsc 0.91227\n",
      "Batch train [1] loss 0.12375, dsc 0.87625\n",
      "Batch train [1] loss 0.13326, dsc 0.86674\n",
      "Batch train [1] loss 0.11088, dsc 0.88912\n",
      "Batch train [1] loss 0.14171, dsc 0.85829\n",
      "Batch train [1] loss 0.13240, dsc 0.86760\n",
      "Batch train [1] loss 0.14247, dsc 0.85753\n",
      "Batch train [1] loss 0.16761, dsc 0.83239\n",
      "Batch train [1] loss 0.13814, dsc 0.86186\n",
      "Batch train [1] loss 0.16359, dsc 0.83641\n",
      "Batch train [1] loss 0.12945, dsc 0.87055\n",
      "Batch train [1] loss 0.14237, dsc 0.85763\n",
      "Batch train [1] loss 0.10399, dsc 0.89601\n",
      "Batch train [1] loss 0.12541, dsc 0.87459\n",
      "Batch train [1] loss 0.11799, dsc 0.88201\n",
      "Batch train [1] loss 0.12698, dsc 0.87302\n",
      "Batch train [1] loss 0.12146, dsc 0.87854\n",
      "Batch train [1] loss 0.13184, dsc 0.86816\n",
      "Batch train [1] loss 0.10435, dsc 0.89565\n",
      "Batch train [1] loss 0.12126, dsc 0.87874\n",
      "Batch train [1] loss 0.13455, dsc 0.86545\n",
      "Batch train [1] loss 0.15748, dsc 0.84252\n",
      "Batch train [1] loss 0.14819, dsc 0.85181\n",
      "Batch train [1] loss 0.11263, dsc 0.88737\n",
      "Batch train [1] loss 0.15934, dsc 0.84066\n",
      "Batch train [1] loss 0.15217, dsc 0.84783\n",
      "Batch train [1] loss 0.11397, dsc 0.88603\n",
      "Batch train [1] loss 0.15165, dsc 0.84835\n",
      "Batch train [1] loss 0.14486, dsc 0.85514\n",
      "Batch train [1] loss 0.14093, dsc 0.85907\n",
      "Batch train [1] loss 0.13655, dsc 0.86345\n",
      "Batch train [1] loss 0.11345, dsc 0.88655\n",
      "Epoch [67] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 66, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  66, step 0\n",
      "Batch eval [1] loss 0.14037, dsc 0.85963\n",
      "Batch eval [1] loss 0.11832, dsc 0.88168\n",
      "Batch eval [1] loss 0.24782, dsc 0.75218\n",
      "Batch eval [1] loss 0.13662, dsc 0.86338\n",
      "Batch eval [1] loss 0.25882, dsc 0.74118\n",
      "Epoch [67] valid done\n",
      "Epoch [67] T 8175.50s, deltaT 121.72s, loss: train 0.13119, valid 0.18039, dsc: train 0.86881, valid 0.81961\n",
      "DEBUG: Writing to tensorboard before epoch True, 67, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  67, step 0\n",
      "Batch train [1] loss 0.09943, dsc 0.90057\n",
      "Batch train [1] loss 0.11372, dsc 0.88628\n",
      "Batch train [1] loss 0.12027, dsc 0.87973\n",
      "Batch train [1] loss 0.12340, dsc 0.87660\n",
      "Batch train [1] loss 0.13345, dsc 0.86655\n",
      "Batch train [1] loss 0.10353, dsc 0.89647\n",
      "Batch train [1] loss 0.14790, dsc 0.85210\n",
      "Batch train [1] loss 0.13193, dsc 0.86807\n",
      "Batch train [1] loss 0.10169, dsc 0.89831\n",
      "Batch train [1] loss 0.15120, dsc 0.84880\n",
      "Batch train [1] loss 0.14002, dsc 0.85998\n",
      "Batch train [1] loss 0.14347, dsc 0.85653\n",
      "Batch train [1] loss 0.11349, dsc 0.88651\n",
      "Batch train [1] loss 0.13118, dsc 0.86882\n",
      "Batch train [1] loss 0.13752, dsc 0.86248\n",
      "Batch train [1] loss 0.14887, dsc 0.85113\n",
      "Batch train [1] loss 0.15821, dsc 0.84179\n",
      "Batch train [1] loss 0.15065, dsc 0.84935\n",
      "Batch train [1] loss 0.13256, dsc 0.86744\n",
      "Batch train [1] loss 0.12108, dsc 0.87892\n",
      "Batch train [1] loss 0.13126, dsc 0.86874\n",
      "Batch train [1] loss 0.11820, dsc 0.88180\n",
      "Batch train [1] loss 0.15160, dsc 0.84840\n",
      "Batch train [1] loss 0.11945, dsc 0.88055\n",
      "Batch train [1] loss 0.11817, dsc 0.88183\n",
      "Batch train [1] loss 0.12952, dsc 0.87048\n",
      "Batch train [1] loss 0.14461, dsc 0.85539\n",
      "Batch train [1] loss 0.12979, dsc 0.87021\n",
      "Batch train [1] loss 0.11229, dsc 0.88771\n",
      "Batch train [1] loss 0.13610, dsc 0.86390\n",
      "Batch train [1] loss 0.09703, dsc 0.90297\n",
      "Batch train [1] loss 0.10903, dsc 0.89097\n",
      "Batch train [1] loss 0.10729, dsc 0.89271\n",
      "Batch train [1] loss 0.10716, dsc 0.89284\n",
      "Batch train [1] loss 0.11941, dsc 0.88059\n",
      "Batch train [1] loss 0.10557, dsc 0.89443\n",
      "Batch train [1] loss 0.09977, dsc 0.90023\n",
      "Batch train [1] loss 0.15326, dsc 0.84674\n",
      "Batch train [1] loss 0.10674, dsc 0.89326\n",
      "Batch train [1] loss 0.12488, dsc 0.87512\n",
      "Epoch [68] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 67, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  67, step 0\n",
      "Batch eval [1] loss 0.15056, dsc 0.84944\n",
      "Batch eval [1] loss 0.11890, dsc 0.88110\n",
      "Batch eval [1] loss 0.25983, dsc 0.74017\n",
      "Batch eval [1] loss 0.14223, dsc 0.85777\n",
      "Batch eval [1] loss 0.26709, dsc 0.73291\n",
      "Epoch [68] valid done\n",
      "Epoch [68] T 8297.13s, deltaT 121.63s, loss: train 0.12562, valid 0.18772, dsc: train 0.87438, valid 0.81228\n",
      "DEBUG: Writing to tensorboard before epoch True, 68, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  68, step 0\n",
      "Batch train [1] loss 0.13618, dsc 0.86382\n",
      "Batch train [1] loss 0.12397, dsc 0.87603\n",
      "Batch train [1] loss 0.10824, dsc 0.89176\n",
      "Batch train [1] loss 0.11050, dsc 0.88950\n",
      "Batch train [1] loss 0.15331, dsc 0.84669\n",
      "Batch train [1] loss 0.10817, dsc 0.89183\n",
      "Batch train [1] loss 0.11771, dsc 0.88229\n",
      "Batch train [1] loss 0.10251, dsc 0.89749\n",
      "Batch train [1] loss 0.10192, dsc 0.89808\n",
      "Batch train [1] loss 0.12568, dsc 0.87432\n",
      "Batch train [1] loss 0.12821, dsc 0.87179\n",
      "Batch train [1] loss 0.11972, dsc 0.88028\n",
      "Batch train [1] loss 0.14064, dsc 0.85936\n",
      "Batch train [1] loss 0.13608, dsc 0.86392\n",
      "Batch train [1] loss 0.14061, dsc 0.85939\n",
      "Batch train [1] loss 0.08937, dsc 0.91063\n",
      "Batch train [1] loss 0.10797, dsc 0.89203\n",
      "Batch train [1] loss 0.12020, dsc 0.87980\n",
      "Batch train [1] loss 0.11029, dsc 0.88971\n",
      "Batch train [1] loss 0.15282, dsc 0.84718\n",
      "Batch train [1] loss 0.11499, dsc 0.88501\n",
      "Batch train [1] loss 0.13098, dsc 0.86902\n",
      "Batch train [1] loss 0.10868, dsc 0.89132\n",
      "Batch train [1] loss 0.09218, dsc 0.90782\n",
      "Batch train [1] loss 0.13665, dsc 0.86335\n",
      "Batch train [1] loss 0.12750, dsc 0.87250\n",
      "Batch train [1] loss 0.10926, dsc 0.89074\n",
      "Batch train [1] loss 0.11418, dsc 0.88582\n",
      "Batch train [1] loss 0.10737, dsc 0.89263\n",
      "Batch train [1] loss 0.14223, dsc 0.85777\n",
      "Batch train [1] loss 0.16030, dsc 0.83970\n",
      "Batch train [1] loss 0.11367, dsc 0.88633\n",
      "Batch train [1] loss 0.15277, dsc 0.84723\n",
      "Batch train [1] loss 0.14744, dsc 0.85256\n",
      "Batch train [1] loss 0.13068, dsc 0.86932\n",
      "Batch train [1] loss 0.13089, dsc 0.86911\n",
      "Batch train [1] loss 0.13465, dsc 0.86535\n",
      "Batch train [1] loss 0.13014, dsc 0.86986\n",
      "Batch train [1] loss 0.13257, dsc 0.86743\n",
      "Batch train [1] loss 0.11208, dsc 0.88792\n",
      "Epoch [69] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 68, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  68, step 0\n",
      "Batch eval [1] loss 0.11819, dsc 0.88181\n",
      "Batch eval [1] loss 0.13543, dsc 0.86457\n",
      "Batch eval [1] loss 0.23595, dsc 0.76405\n",
      "Batch eval [1] loss 0.13381, dsc 0.86619\n",
      "Batch eval [1] loss 0.25273, dsc 0.74727\n",
      "Epoch [69] valid done\n",
      "Epoch [69] T 8418.85s, deltaT 121.71s, loss: train 0.12408, valid 0.17522, dsc: train 0.87592, valid 0.82478\n",
      "DEBUG: Writing to tensorboard before epoch True, 69, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  69, step 0\n",
      "Batch train [1] loss 0.10060, dsc 0.89940\n",
      "Batch train [1] loss 0.10566, dsc 0.89434\n",
      "Batch train [1] loss 0.11273, dsc 0.88727\n",
      "Batch train [1] loss 0.14530, dsc 0.85470\n",
      "Batch train [1] loss 0.15000, dsc 0.85000\n",
      "Batch train [1] loss 0.17135, dsc 0.82865\n",
      "Batch train [1] loss 0.18054, dsc 0.81946\n",
      "Batch train [1] loss 0.09918, dsc 0.90082\n",
      "Batch train [1] loss 0.13203, dsc 0.86797\n",
      "Batch train [1] loss 0.11118, dsc 0.88882\n",
      "Batch train [1] loss 0.11321, dsc 0.88679\n",
      "Batch train [1] loss 0.17286, dsc 0.82714\n",
      "Batch train [1] loss 0.13256, dsc 0.86744\n",
      "Batch train [1] loss 0.15878, dsc 0.84122\n",
      "Batch train [1] loss 0.14213, dsc 0.85787\n",
      "Batch train [1] loss 0.12693, dsc 0.87307\n",
      "Batch train [1] loss 0.08867, dsc 0.91133\n",
      "Batch train [1] loss 0.13359, dsc 0.86641\n",
      "Batch train [1] loss 0.10662, dsc 0.89338\n",
      "Batch train [1] loss 0.11876, dsc 0.88124\n",
      "Batch train [1] loss 0.09943, dsc 0.90057\n",
      "Batch train [1] loss 0.14157, dsc 0.85843\n",
      "Batch train [1] loss 0.13850, dsc 0.86150\n",
      "Batch train [1] loss 0.09829, dsc 0.90171\n",
      "Batch train [1] loss 0.11371, dsc 0.88629\n",
      "Batch train [1] loss 0.11926, dsc 0.88074\n",
      "Batch train [1] loss 0.11123, dsc 0.88877\n",
      "Batch train [1] loss 0.10686, dsc 0.89314\n",
      "Batch train [1] loss 0.15713, dsc 0.84287\n",
      "Batch train [1] loss 0.09736, dsc 0.90264\n",
      "Batch train [1] loss 0.12909, dsc 0.87091\n",
      "Batch train [1] loss 0.14020, dsc 0.85980\n",
      "Batch train [1] loss 0.11603, dsc 0.88397\n",
      "Batch train [1] loss 0.10646, dsc 0.89354\n",
      "Batch train [1] loss 0.11402, dsc 0.88598\n",
      "Batch train [1] loss 0.12345, dsc 0.87655\n",
      "Batch train [1] loss 0.12218, dsc 0.87782\n",
      "Batch train [1] loss 0.11686, dsc 0.88314\n",
      "Batch train [1] loss 0.11898, dsc 0.88102\n",
      "Batch train [1] loss 0.14330, dsc 0.85670\n",
      "Epoch [70] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 69, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  69, step 0\n",
      "Batch eval [1] loss 0.16295, dsc 0.83705\n",
      "Batch eval [1] loss 0.12385, dsc 0.87615\n",
      "Batch eval [1] loss 0.23044, dsc 0.76956\n",
      "Batch eval [1] loss 0.12889, dsc 0.87111\n",
      "Batch eval [1] loss 0.24166, dsc 0.75834\n",
      "Epoch [70] valid done\n",
      "Epoch [70] T 8541.99s, deltaT 123.13s, loss: train 0.12541, valid 0.17756, dsc: train 0.87459, valid 0.82244\n",
      "DEBUG: Writing to tensorboard before epoch True, 70, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  70, step 0\n",
      "Batch train [1] loss 0.08399, dsc 0.91601\n",
      "Batch train [1] loss 0.11160, dsc 0.88840\n",
      "Batch train [1] loss 0.09806, dsc 0.90194\n",
      "Batch train [1] loss 0.12349, dsc 0.87651\n",
      "Batch train [1] loss 0.12830, dsc 0.87170\n",
      "Batch train [1] loss 0.13748, dsc 0.86252\n",
      "Batch train [1] loss 0.13176, dsc 0.86824\n",
      "Batch train [1] loss 0.15613, dsc 0.84387\n",
      "Batch train [1] loss 0.11423, dsc 0.88577\n",
      "Batch train [1] loss 0.14613, dsc 0.85387\n",
      "Batch train [1] loss 0.16787, dsc 0.83213\n",
      "Batch train [1] loss 0.11726, dsc 0.88274\n",
      "Batch train [1] loss 0.10363, dsc 0.89637\n",
      "Batch train [1] loss 0.10107, dsc 0.89893\n",
      "Batch train [1] loss 0.15740, dsc 0.84260\n",
      "Batch train [1] loss 0.13543, dsc 0.86457\n",
      "Batch train [1] loss 0.10094, dsc 0.89906\n",
      "Batch train [1] loss 0.10634, dsc 0.89366\n",
      "Batch train [1] loss 0.14705, dsc 0.85295\n",
      "Batch train [1] loss 0.11424, dsc 0.88576\n",
      "Batch train [1] loss 0.09714, dsc 0.90286\n",
      "Batch train [1] loss 0.12683, dsc 0.87317\n",
      "Batch train [1] loss 0.12032, dsc 0.87968\n",
      "Batch train [1] loss 0.14192, dsc 0.85808\n",
      "Batch train [1] loss 0.14701, dsc 0.85299\n",
      "Batch train [1] loss 0.13587, dsc 0.86413\n",
      "Batch train [1] loss 0.10421, dsc 0.89579\n",
      "Batch train [1] loss 0.12100, dsc 0.87900\n",
      "Batch train [1] loss 0.10511, dsc 0.89489\n",
      "Batch train [1] loss 0.10939, dsc 0.89061\n",
      "Batch train [1] loss 0.14676, dsc 0.85324\n",
      "Batch train [1] loss 0.12411, dsc 0.87589\n",
      "Batch train [1] loss 0.11239, dsc 0.88761\n",
      "Batch train [1] loss 0.16884, dsc 0.83116\n",
      "Batch train [1] loss 0.09851, dsc 0.90149\n",
      "Batch train [1] loss 0.10875, dsc 0.89125\n",
      "Batch train [1] loss 0.10597, dsc 0.89403\n",
      "Batch train [1] loss 0.10124, dsc 0.89876\n",
      "Batch train [1] loss 0.12211, dsc 0.87789\n",
      "Batch train [1] loss 0.12001, dsc 0.87999\n",
      "Epoch [71] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 70, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  70, step 0\n",
      "Batch eval [1] loss 0.20375, dsc 0.79625\n",
      "Batch eval [1] loss 0.13741, dsc 0.86259\n",
      "Batch eval [1] loss 0.25919, dsc 0.74081\n",
      "Batch eval [1] loss 0.14969, dsc 0.85031\n",
      "Batch eval [1] loss 0.27283, dsc 0.72717\n",
      "Epoch [71] valid done\n",
      "Epoch [71] T 8665.92s, deltaT 123.93s, loss: train 0.12250, valid 0.20457, dsc: train 0.87750, valid 0.79543\n",
      "DEBUG: Writing to tensorboard before epoch True, 71, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  71, step 0\n",
      "Batch train [1] loss 0.10665, dsc 0.89335\n",
      "Batch train [1] loss 0.12496, dsc 0.87504\n",
      "Batch train [1] loss 0.14192, dsc 0.85808\n",
      "Batch train [1] loss 0.11174, dsc 0.88826\n",
      "Batch train [1] loss 0.10691, dsc 0.89309\n",
      "Batch train [1] loss 0.09586, dsc 0.90414\n",
      "Batch train [1] loss 0.14326, dsc 0.85674\n",
      "Batch train [1] loss 0.10043, dsc 0.89957\n",
      "Batch train [1] loss 0.10367, dsc 0.89633\n",
      "Batch train [1] loss 0.09915, dsc 0.90085\n",
      "Batch train [1] loss 0.10545, dsc 0.89455\n",
      "Batch train [1] loss 0.11042, dsc 0.88958\n",
      "Batch train [1] loss 0.13417, dsc 0.86583\n",
      "Batch train [1] loss 0.09815, dsc 0.90185\n",
      "Batch train [1] loss 0.11398, dsc 0.88602\n",
      "Batch train [1] loss 0.13605, dsc 0.86395\n",
      "Batch train [1] loss 0.16343, dsc 0.83657\n",
      "Batch train [1] loss 0.13905, dsc 0.86095\n",
      "Batch train [1] loss 0.10539, dsc 0.89461\n",
      "Batch train [1] loss 0.13476, dsc 0.86524\n",
      "Batch train [1] loss 0.10399, dsc 0.89601\n",
      "Batch train [1] loss 0.10932, dsc 0.89068\n",
      "Batch train [1] loss 0.11521, dsc 0.88479\n",
      "Batch train [1] loss 0.16380, dsc 0.83620\n",
      "Batch train [1] loss 0.11598, dsc 0.88402\n",
      "Batch train [1] loss 0.12984, dsc 0.87016\n",
      "Batch train [1] loss 0.10050, dsc 0.89950\n",
      "Batch train [1] loss 0.13070, dsc 0.86930\n",
      "Batch train [1] loss 0.10019, dsc 0.89981\n",
      "Batch train [1] loss 0.14071, dsc 0.85929\n",
      "Batch train [1] loss 0.08909, dsc 0.91091\n",
      "Batch train [1] loss 0.13454, dsc 0.86546\n",
      "Batch train [1] loss 0.15862, dsc 0.84138\n",
      "Batch train [1] loss 0.13835, dsc 0.86165\n",
      "Batch train [1] loss 0.13629, dsc 0.86371\n",
      "Batch train [1] loss 0.13240, dsc 0.86760\n",
      "Batch train [1] loss 0.12643, dsc 0.87357\n",
      "Batch train [1] loss 0.11290, dsc 0.88710\n",
      "Batch train [1] loss 0.11462, dsc 0.88538\n",
      "Batch train [1] loss 0.11824, dsc 0.88176\n",
      "Epoch [72] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 71, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  71, step 0\n",
      "Batch eval [1] loss 0.17553, dsc 0.82447\n",
      "Batch eval [1] loss 0.12251, dsc 0.87749\n",
      "Batch eval [1] loss 0.24426, dsc 0.75574\n",
      "Batch eval [1] loss 0.13946, dsc 0.86054\n",
      "Batch eval [1] loss 0.26080, dsc 0.73920\n",
      "Epoch [72] valid done\n",
      "Epoch [72] T 8789.73s, deltaT 123.80s, loss: train 0.12118, valid 0.18851, dsc: train 0.87882, valid 0.81149\n",
      "DEBUG: Writing to tensorboard before epoch True, 72, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  72, step 0\n",
      "Batch train [1] loss 0.13291, dsc 0.86709\n",
      "Batch train [1] loss 0.13460, dsc 0.86540\n",
      "Batch train [1] loss 0.10528, dsc 0.89472\n",
      "Batch train [1] loss 0.12853, dsc 0.87147\n",
      "Batch train [1] loss 0.13414, dsc 0.86586\n",
      "Batch train [1] loss 0.08680, dsc 0.91320\n",
      "Batch train [1] loss 0.11333, dsc 0.88667\n",
      "Batch train [1] loss 0.11915, dsc 0.88085\n",
      "Batch train [1] loss 0.15414, dsc 0.84586\n",
      "Batch train [1] loss 0.13203, dsc 0.86797\n",
      "Batch train [1] loss 0.12559, dsc 0.87441\n",
      "Batch train [1] loss 0.15221, dsc 0.84779\n",
      "Batch train [1] loss 0.11841, dsc 0.88159\n",
      "Batch train [1] loss 0.11015, dsc 0.88985\n",
      "Batch train [1] loss 0.11394, dsc 0.88606\n",
      "Batch train [1] loss 0.12246, dsc 0.87754\n",
      "Batch train [1] loss 0.12916, dsc 0.87084\n",
      "Batch train [1] loss 0.14655, dsc 0.85345\n",
      "Batch train [1] loss 0.09794, dsc 0.90206\n",
      "Batch train [1] loss 0.13597, dsc 0.86403\n",
      "Batch train [1] loss 0.09495, dsc 0.90505\n",
      "Batch train [1] loss 0.16439, dsc 0.83561\n",
      "Batch train [1] loss 0.12251, dsc 0.87749\n",
      "Batch train [1] loss 0.10325, dsc 0.89675\n",
      "Batch train [1] loss 0.12546, dsc 0.87454\n",
      "Batch train [1] loss 0.12094, dsc 0.87906\n",
      "Batch train [1] loss 0.09081, dsc 0.90919\n",
      "Batch train [1] loss 0.10623, dsc 0.89377\n",
      "Batch train [1] loss 0.13872, dsc 0.86128\n",
      "Batch train [1] loss 0.11264, dsc 0.88736\n",
      "Batch train [1] loss 0.12392, dsc 0.87608\n",
      "Batch train [1] loss 0.16073, dsc 0.83927\n",
      "Batch train [1] loss 0.10586, dsc 0.89414\n",
      "Batch train [1] loss 0.12572, dsc 0.87428\n",
      "Batch train [1] loss 0.11476, dsc 0.88524\n",
      "Batch train [1] loss 0.11931, dsc 0.88069\n",
      "Batch train [1] loss 0.09349, dsc 0.90651\n",
      "Batch train [1] loss 0.10405, dsc 0.89595\n",
      "Batch train [1] loss 0.11047, dsc 0.88953\n",
      "Batch train [1] loss 0.10227, dsc 0.89773\n",
      "Epoch [73] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 72, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  72, step 0\n",
      "Batch eval [1] loss 0.17869, dsc 0.82131\n",
      "Batch eval [1] loss 0.11543, dsc 0.88457\n",
      "Batch eval [1] loss 0.25097, dsc 0.74903\n",
      "Batch eval [1] loss 0.12909, dsc 0.87091\n",
      "Batch eval [1] loss 0.24765, dsc 0.75235\n",
      "Epoch [73] valid done\n",
      "Epoch [73] T 8913.65s, deltaT 123.92s, loss: train 0.12084, valid 0.18437, dsc: train 0.87916, valid 0.81563\n",
      "DEBUG: Writing to tensorboard before epoch True, 73, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  73, step 0\n",
      "Batch train [1] loss 0.09282, dsc 0.90718\n",
      "Batch train [1] loss 0.11609, dsc 0.88391\n",
      "Batch train [1] loss 0.13256, dsc 0.86744\n",
      "Batch train [1] loss 0.09412, dsc 0.90588\n",
      "Batch train [1] loss 0.13696, dsc 0.86304\n",
      "Batch train [1] loss 0.10887, dsc 0.89113\n",
      "Batch train [1] loss 0.16894, dsc 0.83106\n",
      "Batch train [1] loss 0.16051, dsc 0.83949\n",
      "Batch train [1] loss 0.10670, dsc 0.89330\n",
      "Batch train [1] loss 0.13189, dsc 0.86811\n",
      "Batch train [1] loss 0.09831, dsc 0.90169\n",
      "Batch train [1] loss 0.10817, dsc 0.89183\n",
      "Batch train [1] loss 0.12031, dsc 0.87969\n",
      "Batch train [1] loss 0.12888, dsc 0.87112\n",
      "Batch train [1] loss 0.12391, dsc 0.87609\n",
      "Batch train [1] loss 0.09730, dsc 0.90270\n",
      "Batch train [1] loss 0.10004, dsc 0.89996\n",
      "Batch train [1] loss 0.12525, dsc 0.87475\n",
      "Batch train [1] loss 0.13725, dsc 0.86275\n",
      "Batch train [1] loss 0.11110, dsc 0.88890\n",
      "Batch train [1] loss 0.13504, dsc 0.86496\n",
      "Batch train [1] loss 0.10772, dsc 0.89228\n",
      "Batch train [1] loss 0.11935, dsc 0.88065\n",
      "Batch train [1] loss 0.13293, dsc 0.86707\n",
      "Batch train [1] loss 0.12286, dsc 0.87714\n",
      "Batch train [1] loss 0.11954, dsc 0.88046\n",
      "Batch train [1] loss 0.09007, dsc 0.90993\n",
      "Batch train [1] loss 0.10684, dsc 0.89316\n",
      "Batch train [1] loss 0.13155, dsc 0.86845\n",
      "Batch train [1] loss 0.12419, dsc 0.87581\n",
      "Batch train [1] loss 0.13572, dsc 0.86428\n",
      "Batch train [1] loss 0.13856, dsc 0.86144\n",
      "Batch train [1] loss 0.14084, dsc 0.85916\n",
      "Batch train [1] loss 0.13158, dsc 0.86842\n",
      "Batch train [1] loss 0.13560, dsc 0.86440\n",
      "Batch train [1] loss 0.10914, dsc 0.89086\n",
      "Batch train [1] loss 0.11611, dsc 0.88389\n",
      "Batch train [1] loss 0.12855, dsc 0.87145\n",
      "Batch train [1] loss 0.10405, dsc 0.89595\n",
      "Batch train [1] loss 0.12620, dsc 0.87380\n",
      "Epoch [74] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 73, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  73, step 0\n",
      "Batch eval [1] loss 0.18162, dsc 0.81838\n",
      "Batch eval [1] loss 0.11533, dsc 0.88467\n",
      "Batch eval [1] loss 0.25336, dsc 0.74664\n",
      "Batch eval [1] loss 0.14295, dsc 0.85705\n",
      "Batch eval [1] loss 0.24031, dsc 0.75969\n",
      "Epoch [74] valid done\n",
      "Epoch [74] T 9037.00s, deltaT 123.34s, loss: train 0.12141, valid 0.18671, dsc: train 0.87859, valid 0.81329\n",
      "DEBUG: Writing to tensorboard before epoch True, 74, step 0\n",
      "DEBUG: Writing to tensorboard after epoch True,  74, step 0\n",
      "Batch train [1] loss 0.12234, dsc 0.87766\n",
      "Batch train [1] loss 0.10331, dsc 0.89669\n",
      "Batch train [1] loss 0.13229, dsc 0.86771\n",
      "Batch train [1] loss 0.09709, dsc 0.90291\n",
      "Batch train [1] loss 0.11038, dsc 0.88962\n",
      "Batch train [1] loss 0.11139, dsc 0.88861\n",
      "Batch train [1] loss 0.09695, dsc 0.90305\n",
      "Batch train [1] loss 0.12717, dsc 0.87283\n",
      "Batch train [1] loss 0.10348, dsc 0.89652\n",
      "Batch train [1] loss 0.13301, dsc 0.86699\n",
      "Batch train [1] loss 0.12507, dsc 0.87493\n",
      "Batch train [1] loss 0.11852, dsc 0.88148\n",
      "Batch train [1] loss 0.10689, dsc 0.89311\n",
      "Batch train [1] loss 0.09571, dsc 0.90429\n",
      "Batch train [1] loss 0.12881, dsc 0.87119\n",
      "Batch train [1] loss 0.11280, dsc 0.88720\n",
      "Batch train [1] loss 0.12959, dsc 0.87041\n",
      "Batch train [1] loss 0.08708, dsc 0.91292\n",
      "Batch train [1] loss 0.10951, dsc 0.89049\n",
      "Batch train [1] loss 0.10563, dsc 0.89437\n",
      "Batch train [1] loss 0.10125, dsc 0.89875\n",
      "Batch train [1] loss 0.16325, dsc 0.83675\n",
      "Batch train [1] loss 0.14620, dsc 0.85380\n",
      "Batch train [1] loss 0.15286, dsc 0.84714\n",
      "Batch train [1] loss 0.11810, dsc 0.88190\n",
      "Batch train [1] loss 0.14065, dsc 0.85935\n",
      "Batch train [1] loss 0.10159, dsc 0.89841\n",
      "Batch train [1] loss 0.10137, dsc 0.89863\n",
      "Batch train [1] loss 0.14175, dsc 0.85825\n",
      "Batch train [1] loss 0.11562, dsc 0.88438\n",
      "Batch train [1] loss 0.14092, dsc 0.85908\n",
      "Batch train [1] loss 0.13879, dsc 0.86121\n",
      "Batch train [1] loss 0.09463, dsc 0.90537\n",
      "Batch train [1] loss 0.13256, dsc 0.86744\n",
      "Batch train [1] loss 0.13061, dsc 0.86939\n",
      "Batch train [1] loss 0.14822, dsc 0.85178\n",
      "Batch train [1] loss 0.14939, dsc 0.85061\n",
      "Batch train [1] loss 0.11084, dsc 0.88916\n",
      "Batch train [1] loss 0.10443, dsc 0.89557\n",
      "Batch train [1] loss 0.13149, dsc 0.86851\n",
      "Epoch [75] train done\n",
      "DEBUG: Writing to tensorboard before epoch False, 74, step 0\n",
      "DEBUG: Writing to tensorboard after epoch False,  74, step 0\n",
      "Batch eval [1] loss 0.24717, dsc 0.75283\n",
      "Batch eval [1] loss 0.13869, dsc 0.86131\n",
      "Batch eval [1] loss 0.24278, dsc 0.75722\n",
      "Batch eval [1] loss 0.15081, dsc 0.84919\n",
      "Batch eval [1] loss 0.24482, dsc 0.75518\n",
      "Epoch [75] valid done\n",
      "Epoch [75] T 9159.74s, deltaT 122.73s, loss: train 0.12054, valid 0.20486, dsc: train 0.87946, valid 0.79514\n",
      "Elapsed time 2:32:39\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_MODELS = False\n",
    "if TRAIN_MODELS:\n",
    "    for OAR_KEY, OAR_VALUE in labels_list:\n",
    "        cut_full_res_dataset.set_output_label(OAR_VALUE)\n",
    "        log_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_name = f'{log_date}_3d_unet_lowres_model3v2_{OAR_KEY}'\n",
    "\n",
    "        print(f'Training model with dataset label \\'{OAR_KEY}\\', value \\'{OAR_VALUE}\\'')\n",
    "        print(f'folder \\'{model_name}\\'')\n",
    "        cut_model_info = prepare_model(epochs=75,\n",
    "                                       learning_rate=3e-4,\n",
    "                                       in_channels=8,\n",
    "                                       input_data_channels=1,\n",
    "                                       output_label_channels=1,\n",
    "                                       dropout_rate=0.2,\n",
    "                                       train_batch_size=1,\n",
    "                                       model_name=model_name,\n",
    "                                       train_dataset=cut_train_dataset, \n",
    "                                       valid_dataset=cut_valid_dataset, \n",
    "                                       test_dataset=cut_test_dataset,\n",
    "                                       model_class=UNetV3v2)\n",
    "        show_model_info(cut_model_info)\n",
    "        print('\\n\\n')\n",
    "        train_loop(cut_model_info, iterate_model_fn=iterate_model_v3v2)\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # clearing memory\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT_NERVE_L, 6\n",
      "OPT_NERVE_R, 7\n",
      "OPT_CHIASMA, 8\n",
      "PITUITARY, 11\n",
      "PAROTID_GLAND_L, 12\n",
      "PAROTID_GLAND_R, 13\n"
     ]
    }
   ],
   "source": [
    "filter_labels = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels['SPINAL_CORD']\n",
    "\n",
    "tmp_list = list(filter_labels.items())\n",
    "labels_list = [tmp_list[5], tmp_list[6], tmp_list[7], tmp_list[10], tmp_list[11], tmp_list[12]]\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    print(f\"{OAR_KEY}, {OAR_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_models(oar_key):\n",
    "    possible_models = [folder_name for folder_name in os.listdir('./models') if oar_key in folder_name]    \n",
    "    \n",
    "    return possible_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading models to CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT_NERVE_L Model: No avaiable model\n",
      "OPT_NERVE_R Model: No avaiable model\n",
      "OPT_CHIASMA Model: No avaiable model\n",
      "PITUITARY Model: No avaiable model\n",
      "PAROTID_GLAND_L Model: No avaiable model\n",
      "PAROTID_GLAND_R Model: Loading model 20210323-133350_3d_unet_lowres_model3v2_PAROTID_GLAND_R\n"
     ]
    }
   ],
   "source": [
    "models = dict()\n",
    "for OAR_KEY, OAR_VALUE in labels_list:\n",
    "    epoch = 75\n",
    "    possible_models = get_possible_models(f\"model3v2_{OAR_KEY}\")\n",
    "    if len(possible_models) <= 0:\n",
    "        print(f'{OAR_KEY} Model: No avaiable model')\n",
    "        continue\n",
    "\n",
    "    model_name = possible_models[0]\n",
    "    print(f'{OAR_KEY} Model: Loading model {model_name}')\n",
    "\n",
    "    # loading model checkpoint\n",
    "    cut_model_info = load_checkpoint_model_info(model_name, epoch, cut_train_dataset, cut_valid_dataset, cut_test_dataset, model_class=UNetV3v2)\n",
    "\n",
    "    # moving model to cpu/cuda with eval mode\n",
    "    cut_model_info['device'] = 'cpu'\n",
    "    cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "    cut_model_info['model'].eval()\n",
    "    cut_model_info['model'].disable_tensorboard_writing = True\n",
    "    \n",
    "    models[OAR_KEY] = cut_model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Eval vs Train Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing iteration function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch eval [1] loss 0.14641, dsc 0.85359\n",
      "Batch eval [1] loss 0.15079, dsc 0.84921\n",
      "Batch eval [1] loss 0.12301, dsc 0.87699\n",
      "Batch eval [1] loss 0.70439, dsc 0.29561\n",
      "Batch eval [1] loss 0.11283, dsc 0.88717\n",
      "Batch eval [1] loss 0.17049, dsc 0.82951\n",
      "Batch eval [1] loss 0.98432, dsc 0.01568\n",
      "Batch eval [1] loss 0.13727, dsc 0.86273\n",
      "Batch eval [1] loss 0.16639, dsc 0.83361\n",
      "Batch eval [1] loss 0.12086, dsc 0.87914\n",
      "Batch eval [1] loss 0.10898, dsc 0.89102\n",
      "Batch eval [1] loss 0.11375, dsc 0.88625\n",
      "Batch eval [1] loss 0.12126, dsc 0.87874\n",
      "Batch eval [1] loss 0.11761, dsc 0.88239\n",
      "Batch eval [1] loss 0.33616, dsc 0.66384\n",
      "Batch eval [1] loss 0.12310, dsc 0.87690\n",
      "Batch eval [1] loss 0.16178, dsc 0.83822\n",
      "Batch eval [1] loss 0.11586, dsc 0.88414\n",
      "Batch eval [1] loss 0.17341, dsc 0.82659\n",
      "Batch eval [1] loss 0.15074, dsc 0.84926\n",
      "Batch eval [1] loss 0.14803, dsc 0.85197\n",
      "Batch eval [1] loss 0.15248, dsc 0.84752\n",
      "Batch eval [1] loss 0.11864, dsc 0.88136\n",
      "Batch eval [1] loss 0.14578, dsc 0.85422\n",
      "Batch eval [1] loss 0.12000, dsc 0.88000\n",
      "Batch eval [1] loss 0.10170, dsc 0.89830\n",
      "Batch eval [1] loss 0.11976, dsc 0.88024\n",
      "Batch eval [1] loss 0.10437, dsc 0.89563\n",
      "Batch eval [1] loss 0.12885, dsc 0.87115\n",
      "Batch eval [1] loss 0.15616, dsc 0.84384\n",
      "Batch eval [1] loss 0.13223, dsc 0.86777\n",
      "Batch eval [1] loss 0.24500, dsc 0.75500\n",
      "Batch eval [1] loss 0.10970, dsc 0.89030\n",
      "Batch eval [1] loss 0.12043, dsc 0.87957\n",
      "Batch eval [1] loss 0.13799, dsc 0.86201\n",
      "Batch eval [1] loss 0.22109, dsc 0.77891\n",
      "Batch eval [1] loss 0.99998, dsc 0.00002\n",
      "Batch eval [1] loss 0.16731, dsc 0.83269\n",
      "Batch eval [1] loss 0.12300, dsc 0.87700\n",
      "Batch eval [1] loss 0.13621, dsc 0.86379\n",
      "0.20070238709449767 tensor(0.7993, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cut_full_res_dataset.set_output_label(OARS_LABELS.PAROTID_GLAND_R)\n",
    "cut_model_info = models['PAROTID_GLAND_R']\n",
    "cut_model_info['device'] = get_device()\n",
    "cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "cut_model_info['model'].eval()\n",
    "cut_model_info['model'].disable_tensorboard_writing = True\n",
    "    \n",
    "model, model_name, optimizer, criterion = itemgetter('model', 'model_name', 'optimizer', 'criterion')(cut_model_info)\n",
    "epochs, device, tensorboard_writer = itemgetter('epochs', 'device', 'tensorboard_writer')(cut_model_info)\n",
    "train_dataloader, valid_dataloader, test_dataloader = itemgetter('train_dataloader',\n",
    "                                                                 'valid_dataloader',\n",
    "                                                                 'test_dataloader')(cut_model_info)\n",
    "\n",
    "valid_loss, valid_dsc = iterate_model_v3v2(train_dataloader, model, optimizer, criterion, device, is_eval=True)\n",
    "print(valid_loss, valid_dsc)\n",
    "\n",
    "cut_model_info['device'] = 'cpu'\n",
    "cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT_NERVE_L Model: No avaiable model\n",
      "OPT_NERVE_R Model: No avaiable model\n",
      "OPT_CHIASMA Model: No avaiable model\n",
      "PITUITARY Model: No avaiable model\n",
      "PAROTID_GLAND_L Model: No avaiable model\n",
      "PAROTID_GLAND_R Model: DSC train 0.8044 valid 0.7993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train_dsc_mean    80.44\n",
       "train_dsc_std     21.01\n",
       "valid_dsc_mean    79.93\n",
       "valid_dsc_std      5.54\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oar_key</th>\n",
       "      <th>train_dsc_mean</th>\n",
       "      <th>train_dsc_std</th>\n",
       "      <th>valid_dsc_mean</th>\n",
       "      <th>valid_dsc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAROTID_GLAND_R</td>\n",
       "      <td>80.44</td>\n",
       "      <td>21.01</td>\n",
       "      <td>79.93</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           oar_key  train_dsc_mean  train_dsc_std  valid_dsc_mean  \\\n",
       "0  PAROTID_GLAND_R           80.44          21.01           79.93   \n",
       "\n",
       "   valid_dsc_std  \n",
       "0           5.54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oar_key</th>\n",
       "      <th>train_dsc_mean</th>\n",
       "      <th>train_dsc_std</th>\n",
       "      <th>valid_dsc_mean</th>\n",
       "      <th>valid_dsc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAROTID_GLAND_R</td>\n",
       "      <td>80.44</td>\n",
       "      <td>21.01</td>\n",
       "      <td>79.93</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           oar_key  train_dsc_mean  train_dsc_std  valid_dsc_mean  \\\n",
       "0  PAROTID_GLAND_R           80.44          21.01           79.93   \n",
       "\n",
       "   valid_dsc_std  \n",
       "0           5.54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oar_key</th>\n",
       "      <th>train_dsc_mean</th>\n",
       "      <th>train_dsc_std</th>\n",
       "      <th>train_dsc_median</th>\n",
       "      <th>train_dsc_min</th>\n",
       "      <th>train_dsc_max</th>\n",
       "      <th>valid_dsc_mean</th>\n",
       "      <th>valid_dsc_std</th>\n",
       "      <th>valid_dsc_median</th>\n",
       "      <th>valid_dsc_min</th>\n",
       "      <th>valid_dsc_max</th>\n",
       "      <th>train_valid_mean_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAROTID_GLAND_R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           oar_key  train_dsc_mean  train_dsc_std  train_dsc_median  \\\n",
       "0  PAROTID_GLAND_R             0.8           0.21              0.87   \n",
       "\n",
       "   train_dsc_min  train_dsc_max  valid_dsc_mean  valid_dsc_std  \\\n",
       "0            0.0            0.9             0.8           0.06   \n",
       "\n",
       "   valid_dsc_median  valid_dsc_min  valid_dsc_max  train_valid_mean_delta  \n",
       "0              0.76           0.76           0.87                    0.01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oar_key</th>\n",
       "      <th>train_dsc_mean</th>\n",
       "      <th>train_dsc_std</th>\n",
       "      <th>train_dsc_median</th>\n",
       "      <th>train_dsc_min</th>\n",
       "      <th>train_dsc_max</th>\n",
       "      <th>valid_dsc_mean</th>\n",
       "      <th>valid_dsc_std</th>\n",
       "      <th>valid_dsc_median</th>\n",
       "      <th>valid_dsc_min</th>\n",
       "      <th>valid_dsc_max</th>\n",
       "      <th>train_valid_mean_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAROTID_GLAND_R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           oar_key  train_dsc_mean  train_dsc_std  train_dsc_median  \\\n",
       "0  PAROTID_GLAND_R             0.8           0.21              0.87   \n",
       "\n",
       "   train_dsc_min  train_dsc_max  valid_dsc_mean  valid_dsc_std  \\\n",
       "0            0.0            0.9             0.8           0.06   \n",
       "\n",
       "   valid_dsc_median  valid_dsc_min  valid_dsc_max  train_valid_mean_delta  \n",
       "0              0.76           0.76           0.87                    0.01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SHOW_DSC_INFO = True\n",
    "if SHOW_DSC_INFO:\n",
    "    info_per_organs_df = {}\n",
    "    models_info = list()\n",
    "    for OAR_KEY, OAR_VALUE in labels_list:\n",
    "        if OAR_KEY not in models:\n",
    "            print(f'{OAR_KEY} Model: No avaiable model')\n",
    "            continue\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[OAR_KEY]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "        cut_model_info['model'].disable_tensorboard_writing = True\n",
    "\n",
    "        # preparing dataset for comparison\n",
    "        cut_full_res_dataset.set_output_label(OARS_LABELS.PAROTID_GLAND_R)\n",
    "\n",
    "        # calculating dsc predictions        \n",
    "        info_df, preds, rescaled_preds = get_threshold_info_df(\n",
    "                                    model=cut_model_info['model'], \n",
    "                                    dataset=cut_full_res_dataset, \n",
    "                                    device=cut_model_info['device'], \n",
    "                                    train_indices=cut_train_dataset.indices, \n",
    "                                    valid_indices=cut_valid_dataset.indices, \n",
    "                                    test_indices=cut_test_dataset.indices,\n",
    "                                    step=0.5,\n",
    "                                    transform_input_fn=transform_input_with_registration)\n",
    "        info_per_organs_df[OAR_KEY] = info_df\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "\n",
    "        # parsing data\n",
    "        best_threshold_col = 'thres_rescaled_dsc_0.50'\n",
    "        train_tmp_df = info_df[info_df['is_train']][best_threshold_col]\n",
    "        valid_tmp_df = info_df[info_df['is_valid']][best_threshold_col]\n",
    "        train_dsc = train_tmp_df.mean()\n",
    "        valid_dsc = valid_tmp_df.mean()\n",
    "        print(f'{OAR_KEY} Model: DSC train {round(train_dsc, 4)} valid {round(valid_dsc, 4)}')\n",
    "\n",
    "        models_info.append({\n",
    "            'oar_key': OAR_KEY,\n",
    "            'model_name': model_name,\n",
    "            # Train\n",
    "            'train_dsc_mean': train_dsc,\n",
    "            'train_dsc_std': train_tmp_df.std(),\n",
    "            'train_dsc_median': train_tmp_df.median(),\n",
    "            'train_dsc_min': train_tmp_df.min(),\n",
    "            'train_dsc_max': train_tmp_df.max(),\n",
    "            # Valid\n",
    "            'valid_dsc_mean': valid_dsc,\n",
    "            'valid_dsc_std': valid_tmp_df.std(),\n",
    "            'valid_dsc_median': valid_tmp_df.median(),\n",
    "            'valid_dsc_min': valid_tmp_df.min(),\n",
    "            'valid_dsc_max': valid_tmp_df.max(),\n",
    "            # Both\n",
    "            'train_valid_mean_delta': train_dsc - valid_dsc\n",
    "        })\n",
    "\n",
    "    models_info_df = pd.DataFrame(models_info)\n",
    "    \n",
    "    tmp_df = models_info_df[['oar_key', 'train_dsc_mean', 'train_dsc_std', 'valid_dsc_mean', 'valid_dsc_std']].copy()\n",
    "    tmp_df['train_dsc_mean'] = (tmp_df['train_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_mean'] = (tmp_df['valid_dsc_mean'] * 100).round(2)\n",
    "    tmp_df['train_dsc_std'] = (tmp_df['train_dsc_std'] * 100).round(2)\n",
    "    tmp_df['valid_dsc_std'] = (tmp_df['valid_dsc_std'] * 100).round(2)\n",
    "    \n",
    "    display(tmp_df.mean().round(2))\n",
    "    display(tmp_df.round(2))\n",
    "    display(tmp_df.sort_values(by=['train_dsc_std']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_dsc_mean']).drop(columns=['model_name']).round(2))\n",
    "    display(models_info_df.sort_values(by=['train_valid_mean_delta']).drop(columns=['model_name']).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OARS_LABELS.PAROTID_GLAND_R\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dsc</th>\n",
       "      <th>rescaled_dsc</th>\n",
       "      <th>is_train</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>is_test</th>\n",
       "      <th>thres_rescaled_dsc_0.00</th>\n",
       "      <th>thres_rescaled_dsc_0.50</th>\n",
       "      <th>thres_rescaled_dsc_1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>8.637816e-11</td>\n",
       "      <td>8.667014e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.015680</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>1.227566e-02</td>\n",
       "      <td>7.817386e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.295612</td>\n",
       "      <td>0.295641</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>2.982952e-01</td>\n",
       "      <td>1.006847e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.663836</td>\n",
       "      <td>0.663839</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>6.660281e-01</td>\n",
       "      <td>8.499788e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.754997</td>\n",
       "      <td>0.755002</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>7.612163e-01</td>\n",
       "      <td>2.019386e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.778914</td>\n",
       "      <td>0.778917</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>7.829325e-01</td>\n",
       "      <td>1.249844e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.826591</td>\n",
       "      <td>0.826591</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>8.305613e-01</td>\n",
       "      <td>9.402031e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.829509</td>\n",
       "      <td>0.829509</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>8.381529e-01</td>\n",
       "      <td>2.138123e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.832689</td>\n",
       "      <td>0.832690</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>8.388868e-01</td>\n",
       "      <td>1.733403e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.833613</td>\n",
       "      <td>0.833613</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>8.406501e-01</td>\n",
       "      <td>2.060581e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.838218</td>\n",
       "      <td>0.838221</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>8.460981e-01</td>\n",
       "      <td>1.858736e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.843839</td>\n",
       "      <td>0.843841</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>8.487908e-01</td>\n",
       "      <td>1.348254e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.847517</td>\n",
       "      <td>0.847517</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>8.560233e-01</td>\n",
       "      <td>2.662407e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.851975</td>\n",
       "      <td>0.851975</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>8.562636e-01</td>\n",
       "      <td>1.149029e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.849256</td>\n",
       "      <td>0.849256</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>8.563077e-01</td>\n",
       "      <td>1.738828e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.849205</td>\n",
       "      <td>0.849205</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>8.568877e-01</td>\n",
       "      <td>2.386065e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.853592</td>\n",
       "      <td>0.853593</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>8.576898e-01</td>\n",
       "      <td>1.212562e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.854219</td>\n",
       "      <td>0.854219</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>8.628495e-01</td>\n",
       "      <td>2.448580e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.862010</td>\n",
       "      <td>0.862010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>8.663287e-01</td>\n",
       "      <td>1.085894e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.863789</td>\n",
       "      <td>0.863789</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>8.678955e-01</td>\n",
       "      <td>1.191043e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.862734</td>\n",
       "      <td>0.862734</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>8.693547e-01</td>\n",
       "      <td>1.834862e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.867774</td>\n",
       "      <td>0.867774</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>8.736932e-01</td>\n",
       "      <td>1.570598e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.871147</td>\n",
       "      <td>0.871148</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>8.790175e-01</td>\n",
       "      <td>2.268603e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.876900</td>\n",
       "      <td>0.876901</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>8.792498e-01</td>\n",
       "      <td>7.825951e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.876996</td>\n",
       "      <td>0.876997</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>8.794980e-01</td>\n",
       "      <td>8.824567e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.876993</td>\n",
       "      <td>0.876993</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>8.811373e-01</td>\n",
       "      <td>1.296176e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.879998</td>\n",
       "      <td>0.879999</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>8.834884e-01</td>\n",
       "      <td>1.036269e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.879144</td>\n",
       "      <td>0.879144</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>8.842515e-01</td>\n",
       "      <td>1.191327e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.881365</td>\n",
       "      <td>0.881365</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007884</td>\n",
       "      <td>8.845853e-01</td>\n",
       "      <td>1.088021e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.880244</td>\n",
       "      <td>0.880244</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>8.852788e-01</td>\n",
       "      <td>1.177579e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.879575</td>\n",
       "      <td>0.879575</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>8.855177e-01</td>\n",
       "      <td>1.482800e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.878742</td>\n",
       "      <td>0.878742</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>8.883309e-01</td>\n",
       "      <td>2.585315e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.884141</td>\n",
       "      <td>0.884142</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>8.891813e-01</td>\n",
       "      <td>1.442169e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.886248</td>\n",
       "      <td>0.886248</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>8.894951e-01</td>\n",
       "      <td>9.219989e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.882390</td>\n",
       "      <td>0.882390</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>8.907092e-01</td>\n",
       "      <td>2.054654e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.887175</td>\n",
       "      <td>0.887175</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>8.942409e-01</td>\n",
       "      <td>2.016942e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.890295</td>\n",
       "      <td>0.890295</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>8.949963e-01</td>\n",
       "      <td>1.161036e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891022</td>\n",
       "      <td>0.891022</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>8.968114e-01</td>\n",
       "      <td>1.535862e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.895634</td>\n",
       "      <td>0.895634</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>9.002411e-01</td>\n",
       "      <td>1.281066e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.898302</td>\n",
       "      <td>0.898302</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>9.027617e-01</td>\n",
       "      <td>1.271133e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dsc  rescaled_dsc  is_train  is_valid  is_test  \\\n",
       "index                                                        \n",
       "28     0.000023      0.003454      True     False    False   \n",
       "21     0.015680      0.015981      True     False    False   \n",
       "2      0.295612      0.295641      True     False    False   \n",
       "35     0.663836      0.663839      True     False    False   \n",
       "49     0.754997      0.755002      True     False    False   \n",
       "24     0.778914      0.778917      True     False    False   \n",
       "10     0.826591      0.826591      True     False    False   \n",
       "7      0.829509      0.829509      True     False    False   \n",
       "3      0.832689      0.832690      True     False    False   \n",
       "31     0.833613      0.833613      True     False    False   \n",
       "9      0.838218      0.838221      True     False    False   \n",
       "46     0.843839      0.843841      True     False    False   \n",
       "48     0.847517      0.847517      True     False    False   \n",
       "34     0.851975      0.851975      True     False    False   \n",
       "47     0.849256      0.849256      True     False    False   \n",
       "30     0.849205      0.849205      True     False    False   \n",
       "36     0.853592      0.853593      True     False    False   \n",
       "45     0.854219      0.854219      True     False    False   \n",
       "12     0.862010      0.862010      True     False    False   \n",
       "1      0.863789      0.863789      True     False    False   \n",
       "33     0.862734      0.862734      True     False    False   \n",
       "15     0.867774      0.867774      True     False    False   \n",
       "37     0.871147      0.871148      True     False    False   \n",
       "44     0.876900      0.876901      True     False    False   \n",
       "17     0.876996      0.876997      True     False    False   \n",
       "32     0.876993      0.876993      True     False    False   \n",
       "18     0.879998      0.879999      True     False    False   \n",
       "20     0.879144      0.879144      True     False    False   \n",
       "8      0.881365      0.881365      True     False    False   \n",
       "14     0.880244      0.880244      True     False    False   \n",
       "40     0.879575      0.879575      True     False    False   \n",
       "22     0.878742      0.878742      True     False    False   \n",
       "42     0.884141      0.884142      True     False    False   \n",
       "4      0.886248      0.886248      True     False    False   \n",
       "23     0.882390      0.882390      True     False    False   \n",
       "43     0.887175      0.887175      True     False    False   \n",
       "11     0.890295      0.890295      True     False    False   \n",
       "0      0.891022      0.891022      True     False    False   \n",
       "41     0.895634      0.895634      True     False    False   \n",
       "5      0.898302      0.898302      True     False    False   \n",
       "\n",
       "       thres_rescaled_dsc_0.00  thres_rescaled_dsc_0.50  \\\n",
       "index                                                     \n",
       "28                    0.009887             8.637816e-11   \n",
       "21                    0.010955             1.227566e-02   \n",
       "2                     0.008517             2.982952e-01   \n",
       "35                    0.010081             6.660281e-01   \n",
       "49                    0.004255             7.612163e-01   \n",
       "24                    0.006867             7.829325e-01   \n",
       "10                    0.009118             8.305613e-01   \n",
       "7                     0.004020             8.381529e-01   \n",
       "3                     0.004956             8.388868e-01   \n",
       "31                    0.004171             8.406501e-01   \n",
       "9                     0.004622             8.460981e-01   \n",
       "46                    0.006367             8.487908e-01   \n",
       "48                    0.003229             8.560233e-01   \n",
       "34                    0.007467             8.562636e-01   \n",
       "47                    0.004940             8.563077e-01   \n",
       "30                    0.003603             8.568877e-01   \n",
       "36                    0.007077             8.576898e-01   \n",
       "45                    0.003511             8.628495e-01   \n",
       "12                    0.007899             8.663287e-01   \n",
       "1                     0.007204             8.678955e-01   \n",
       "33                    0.004682             8.693547e-01   \n",
       "15                    0.005468             8.736932e-01   \n",
       "37                    0.003789             8.790175e-01   \n",
       "44                    0.010944             8.792498e-01   \n",
       "17                    0.009711             8.794980e-01   \n",
       "32                    0.006622             8.811373e-01   \n",
       "18                    0.008276             8.834884e-01   \n",
       "20                    0.007203             8.842515e-01   \n",
       "8                     0.007884             8.845853e-01   \n",
       "14                    0.007286             8.852788e-01   \n",
       "40                    0.005791             8.855177e-01   \n",
       "22                    0.003325             8.883309e-01   \n",
       "42                    0.005954             8.891813e-01   \n",
       "4                     0.009297             8.894951e-01   \n",
       "23                    0.004183             8.907092e-01   \n",
       "43                    0.004261             8.942409e-01   \n",
       "11                    0.007390             8.949963e-01   \n",
       "0                     0.005591             8.968114e-01   \n",
       "41                    0.006700             9.002411e-01   \n",
       "5                     0.006752             9.027617e-01   \n",
       "\n",
       "       thres_rescaled_dsc_1.00  \n",
       "index                           \n",
       "28                8.667014e-11  \n",
       "21                7.817386e-11  \n",
       "2                 1.006847e-10  \n",
       "35                8.499788e-11  \n",
       "49                2.019386e-10  \n",
       "24                1.249844e-10  \n",
       "10                9.402031e-11  \n",
       "7                 2.138123e-10  \n",
       "3                 1.733403e-10  \n",
       "31                2.060581e-10  \n",
       "9                 1.858736e-10  \n",
       "46                1.348254e-10  \n",
       "48                2.662407e-10  \n",
       "34                1.149029e-10  \n",
       "47                1.738828e-10  \n",
       "30                2.386065e-10  \n",
       "36                1.212562e-10  \n",
       "45                2.448580e-10  \n",
       "12                1.085894e-10  \n",
       "1                 1.191043e-10  \n",
       "33                1.834862e-10  \n",
       "15                1.570598e-10  \n",
       "37                2.268603e-10  \n",
       "44                7.825951e-11  \n",
       "17                8.824567e-11  \n",
       "32                1.296176e-10  \n",
       "18                1.036269e-10  \n",
       "20                1.191327e-10  \n",
       "8                 1.088021e-10  \n",
       "14                1.177579e-10  \n",
       "40                1.482800e-10  \n",
       "22                2.585315e-10  \n",
       "42                1.442169e-10  \n",
       "4                 9.219989e-11  \n",
       "23                2.054654e-10  \n",
       "43                2.016942e-10  \n",
       "11                1.161036e-10  \n",
       "0                 1.535862e-10  \n",
       "41                1.281066e-10  \n",
       "5                 1.271133e-10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OARS_LABELS.PAROTID_GLAND_L\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'PAROTID_GLAND_L'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-3c3e38070812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OARS_LABELS.PAROTID_GLAND_L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_per_organs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOARS_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOARS_LABELS_R_DICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOARS_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAROTID_GLAND_L\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'thres_rescaled_dsc_0.50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PAROTID_GLAND_L'"
     ]
    }
   ],
   "source": [
    "if SHOW_DSC_INFO:\n",
    "    tmp_column = 'is_train' \n",
    "    \n",
    "    print('OARS_LABELS.PAROTID_GLAND_R')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PAROTID_GLAND_R]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.PAROTID_GLAND_L')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PAROTID_GLAND_L]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.OPT_NERVE_L')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.OPT_NERVE_L]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))\n",
    "    \n",
    "    print('OARS_LABELS.PITUITARY')\n",
    "    tmp_df = info_per_organs_df[OARS_LABELS.OARS_LABELS_R_DICT[OARS_LABELS.PITUITARY]]\n",
    "    display(tmp_df[tmp_df[tmp_column]].sort_values(by='thres_rescaled_dsc_0.50'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions merging and checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071.0, min -1024.0\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e13108a2f5b42a1b0a0051a8b8f1fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=10, max=20))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f49408e3684085b1933de4a07661c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_labels_dict = OARS_LABELS.OARS_LABELS_DICT\n",
    "if 'SPINAL_CORD' in filter_labels:\n",
    "    del filter_labels_dict['SPINAL_CORD']\n",
    "\n",
    "cut_full_res_dataset.set_output_label(filter_labels_dict)\n",
    "preview_dataset(cut_full_res_dataset, preview_index=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/21: BRAIN_STEM Model: No avaiable model\n",
      "2/21: EYE_L Model: No avaiable model\n",
      "3/21: EYE_R Model: No avaiable model\n",
      "4/21: LENS_L Model: No avaiable model\n",
      "5/21: LENS_R Model: No avaiable model\n",
      "6/21: OPT_NERVE_L Model: No avaiable model\n",
      "7/21: OPT_NERVE_R Model: No avaiable model\n",
      "8/21: OPT_CHIASMA Model: No avaiable model\n",
      "9/21: TEMPORAL_LOBES_L Model: No avaiable model\n",
      "10/21: TEMPORAL_LOBES_R Model: No avaiable model\n",
      "11/21: PITUITARY Model: No avaiable model\n",
      "12/21: PAROTID_GLAND_L Model: No avaiable model\n",
      "13/21: PAROTID_GLAND_R Model: got model 2021-03-23 17:07:51.579602\n",
      "14/21: INNER_EAR_L Model: No avaiable model\n",
      "15/21: INNER_EAR_R Model: No avaiable model\n",
      "16/21: MID_EAR_L Model: No avaiable model\n",
      "17/21: MID_EAR_R Model: No avaiable model\n",
      "18/21: T_M_JOINT_L Model: No avaiable model\n",
      "19/21: T_M_JOINT_R Model: No avaiable model\n",
      "20/21: MANDIBLE_L Model: No avaiable model\n",
      "21/21: MANDIBLE_R Model: No avaiable model\n"
     ]
    }
   ],
   "source": [
    "PARSE_CUT_DATASET = True\n",
    "if PARSE_CUT_DATASET:\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    prediction_threshold = 0.5\n",
    "    output_label_items = list(cut_full_res_dataset.output_label.items())[:]\n",
    "    cut_dataset_predictions = defaultdict(lambda: defaultdict(lambda: np.zeros(cut_full_res_dataset[0][0][0].shape)))\n",
    "    \n",
    "    # for each label\n",
    "    for label_index, val in enumerate(output_label_items[:]):\n",
    "        OAR_KEY, OAR_VALUE = val\n",
    "        # loading model\n",
    "        if OAR_KEY not in models:\n",
    "            print(f'{label_index+1}/{len(output_label_items)}: {OAR_KEY} Model: No avaiable model')\n",
    "            continue\n",
    "        print(f'{label_index+1}/{len(output_label_items)}: {OAR_KEY} Model: got model {datetime.datetime.now()}')\n",
    "\n",
    "        # getting model to gpu\n",
    "        cut_model_info = models[OAR_KEY]\n",
    "        cut_model_info['device'] = get_device()\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])\n",
    "        cut_model_info['model'].eval()\n",
    "        cut_model_info['model'].disable_tensorboard_writing = True\n",
    "\n",
    "        # for label in whole dataset\n",
    "        for index in range(len(cut_full_res_dataset)):\n",
    "            prediction, rescaled_pred = get_rescaled_pred(cut_model_info['model'], cut_full_res_dataset, \n",
    "                                                          cut_model_info['device'], index, use_only_one_dimension=False)\n",
    "    \n",
    "            cut_dataset_predictions[index][OAR_VALUE] = prediction[0]\n",
    "            # extended_cut_full_res_dataset.data_list[index][label_index + 1] = prediction\n",
    "            # extended_cut_full_res_dataset.data_list[index][label_index + 1] = ((rescaled_pred > prediction_threshold) * 1).astype(np.int8)\n",
    "\n",
    "        # moving model back to cpu\n",
    "        cut_model_info['device'] = 'cpu'\n",
    "        cut_model_info['model'] = cut_model_info['model'].to(cut_model_info['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 3071.0, min -1024.0\n",
      "label max 1, min 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5630af00d50a4765bc0c8ceb88695291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=35, max=71), IntSlider(value=10, max=20))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bf8bf3c7104b36894619dd6db7d71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if PARSE_CUT_DATASET:\n",
    "    def custom_preview_dataset(dataset, predictions, preview_index=0, show_hist=False, use_transform=False):\n",
    "        data, label = dataset.get_raw_item_with_label_filter(preview_index)  # equivalent dataset[preview_index]\n",
    "        if use_transform:\n",
    "            transform = get_dataset_transform()\n",
    "            data, label = transform_input(data, label, transform)\n",
    "\n",
    "        prediction = predictions[preview_index]\n",
    "        max_channels = label.shape[0]\n",
    "        max_slices = label.shape[1]\n",
    "\n",
    "        print(f'data max {data.max()}, min {data.min()}')\n",
    "        print(f'label max {label.max()}, min {label.min()}')\n",
    "\n",
    "        def f(slice_index, label_channel):\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(data[0, slice_index], cmap=\"gray\")\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(prediction[label_channel+1][slice_index])\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(label[label_channel, slice_index])\n",
    "            plt.show()\n",
    "\n",
    "            if show_hist:\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.hist(data.flatten(), 128)\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.hist(label.flatten(), 128)\n",
    "                plt.show()\n",
    "\n",
    "        sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "        labelChannelSlider = widgets.IntSlider(min=0, max=max_channels - 1, step=1, value=(max_channels - 1) / 2)\n",
    "        ui = widgets.VBox([widgets.HBox([sliceSlider, labelChannelSlider])])\n",
    "        out = widgets.interactive_output(f, {'slice_index': sliceSlider, 'label_channel': labelChannelSlider})\n",
    "        # noinspection PyTypeChecker\n",
    "        display(ui, out)\n",
    "    \n",
    "    index = cut_valid_dataset.indices[3]\n",
    "    index = 35\n",
    "    custom_preview_dataset(cut_full_res_dataset, cut_dataset_predictions, preview_index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: refactor\n",
    "\n",
    "MERGE_PREDICTIONS = False\n",
    "if MERGE_PREDICTIONS:\n",
    "    merged_predictions = [None] * len(extended_cut_full_res_dataset)\n",
    "    for index in range(len(extended_cut_full_res_dataset)):\n",
    "        # print(f\"{index+1}/{len(extended_cut_full_res_dataset)}: Merging predictions to single label\")\n",
    "        data, label = extended_cut_full_res_dataset.get_raw_item_with_label_filter(index)\n",
    "\n",
    "        new_data = np.zeros(data[0].shape, dtype=np.int16)\n",
    "        for i in range(1, 22):\n",
    "            new_data += data[i]\n",
    "\n",
    "        merged_predictions[index] = new_data\n",
    "    print('Merging done')\n",
    "\n",
    "    # checking how many masks are overlapping\n",
    "    for i, tmp_merged in enumerate(merged_predictions):\n",
    "        display(f'scan id {i}: {np.where(tmp_merged == 1)[0].shape[0]}, {np.where(tmp_merged == 2)[0].shape[0]}, {np.where(tmp_merged == 3)[0].shape[0]}, {np.where(tmp_merged == 4)[0].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: refactor\n",
    "\n",
    "from src.losses import calc_dscm\n",
    "\n",
    "def custom_preview_dataset2(dataset, preview_index=0, use_transform=False):\n",
    "    data, label = dataset.get_raw_item_with_label_filter(preview_index)\n",
    "    if use_transform:\n",
    "        transform = get_dataset_transform()\n",
    "        data, label = transform_input(data, label, transform)\n",
    "        \n",
    "    cut_data, cut_label = cut_full_res_dataset.get_raw_item_with_label_filter(preview_index)\n",
    "    max_channels = label.shape[0]\n",
    "    max_slices = label.shape[1]\n",
    "    \n",
    "    print(f'data max {data.max()}, min {data.min()}')\n",
    "    print(f'label max {label.max()}, min {label.min()}')\n",
    "    print(f'{data.shape}, {cut_data.shape}, {label.shape}, {cut_label.shape}')\n",
    "    print(f'{data.dtype}, {cut_data.dtype}, {label.dtype}, {cut_label.dtype}')\n",
    "    tmp_merged = merged_predictions[preview_index]\n",
    "    print(f'{np.where(tmp_merged == 1)[0].shape},{np.where(tmp_merged == 2)[0].shape},{np.where(tmp_merged == 3)[0].shape},{np.where(tmp_merged == 4)[0].shape}')\n",
    "\n",
    "    def f(slice_index, label_channel):\n",
    "        print(f'{OARS_LABELS.OARS_LABELS_R_DICT[label_channel+1]}')\n",
    "        tmp_tensor_label = torch.tensor(label[label_channel])\n",
    "        tmp_tensor_prediciton = torch.tensor(data[label_channel+1])\n",
    "        tmp_dsc = calc_dsc(tmp_tensor_label, tmp_tensor_prediciton)\n",
    "        print(f'dsc {tmp_dsc}')\n",
    "\n",
    "        plt.figure(figsize=(30, 20))\n",
    "\n",
    "        plt.subplot(2, 3, 1).title.set_text('data')\n",
    "        plt.imshow(cut_data[0, slice_index], cmap=\"gray\")\n",
    "        plt.subplot(2, 3, 2).title.set_text('label')\n",
    "        plt.imshow(label[label_channel, slice_index])\n",
    "        plt.subplot(2, 3, 3).title.set_text('prediciton')\n",
    "        plt.imshow(data[label_channel+1, slice_index])\n",
    "        # print(data.shape, np.sum(data[label_channel+1]), np.unique(data[1])[-1])\n",
    "        print(f'slices with values > 0', (np.where(data[label_channel+1] > 0))[0])\n",
    "        \n",
    "        plt.subplot(2, 3, 4).title.set_text('merged prediction labels')\n",
    "        plt.imshow(tmp_merged[slice_index], vmin=0, vmax=np.unique(tmp_merged)[-1])\n",
    "        plt.subplot(2, 3, 5).title.set_text('merged labels ')\n",
    "        plt.imshow(np.sum(label, axis=0)[slice_index])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    sliceSlider = widgets.IntSlider(min=0, max=max_slices - 1, step=1, value=(max_slices - 1) / 2)\n",
    "    labelChannelSlider = widgets.IntSlider(min=0, max=max_channels - 1, step=1, value=(max_channels - 1) / 2)\n",
    "    ui = widgets.VBox([widgets.HBox([sliceSlider, labelChannelSlider])])\n",
    "    out = widgets.interactive_output(f, {'slice_index': sliceSlider, 'label_channel': labelChannelSlider})\n",
    "    # noinspection PyTypeChecker\n",
    "    display(ui, out)\n",
    "\n",
    "custom_preview_dataset2(extended_cut_full_res_dataset, preview_index=35, use_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
